I0425 19:35:21.510983      23 e2e.go:116] Starting e2e run "efc57b0c-51af-4be6-a02d-33534060be11" on Ginkgo node 1
Apr 25 19:35:21.535: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1682451321 - will randomize all specs

Will run 360 of 7066 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Apr 25 19:35:21.700: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 19:35:21.702: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 25 19:35:21.761: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 25 19:35:21.842: INFO: 36 / 36 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 25 19:35:21.842: INFO: expected 21 pod replicas in namespace 'kube-system', 21 are Running and Ready.
Apr 25 19:35:21.842: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 25 19:35:21.861: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Apr 25 19:35:21.861: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Apr 25 19:35:21.861: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibmcloud-block-storage-driver' (0 seconds elapsed)
Apr 25 19:35:21.861: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'konnectivity-agent' (0 seconds elapsed)
Apr 25 19:35:21.861: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Apr 25 19:35:21.861: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Apr 25 19:35:21.861: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Apr 25 19:35:21.861: INFO: e2e test version: v1.25.9
Apr 25 19:35:21.891: INFO: kube-apiserver version: v1.25.9+IKS
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Apr 25 19:35:21.891: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 19:35:21.907: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.208 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Apr 25 19:35:21.700: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 19:35:21.702: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Apr 25 19:35:21.761: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Apr 25 19:35:21.842: INFO: 36 / 36 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Apr 25 19:35:21.842: INFO: expected 21 pod replicas in namespace 'kube-system', 21 are Running and Ready.
    Apr 25 19:35:21.842: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Apr 25 19:35:21.861: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
    Apr 25 19:35:21.861: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
    Apr 25 19:35:21.861: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibmcloud-block-storage-driver' (0 seconds elapsed)
    Apr 25 19:35:21.861: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'konnectivity-agent' (0 seconds elapsed)
    Apr 25 19:35:21.861: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
    Apr 25 19:35:21.861: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
    Apr 25 19:35:21.861: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
    Apr 25 19:35:21.861: INFO: e2e test version: v1.25.9
    Apr 25 19:35:21.891: INFO: kube-apiserver version: v1.25.9+IKS
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Apr 25 19:35:21.891: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 19:35:21.907: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:35:21.959
Apr 25 19:35:21.959: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename runtimeclass 04/25/23 19:35:21.96
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:22.025
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:22.066
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Apr 25 19:35:22.124: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-3512 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 25 19:35:22.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-3512" for this suite. 04/25/23 19:35:22.175
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":1,"skipped":88,"failed":0}
------------------------------
• [0.234 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:35:21.959
    Apr 25 19:35:21.959: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename runtimeclass 04/25/23 19:35:21.96
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:22.025
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:22.066
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Apr 25 19:35:22.124: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-3512 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 25 19:35:22.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-3512" for this suite. 04/25/23 19:35:22.175
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:35:22.2
Apr 25 19:35:22.201: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 19:35:22.204
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:22.269
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:22.277
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/25/23 19:35:22.288
Apr 25 19:35:22.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8652 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr 25 19:35:22.624: INFO: stderr: ""
Apr 25 19:35:22.624: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 04/25/23 19:35:22.624
STEP: verifying the pod e2e-test-httpd-pod was created 04/25/23 19:35:32.676
Apr 25 19:35:32.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8652 get pod e2e-test-httpd-pod -o json'
Apr 25 19:35:32.839: INFO: stderr: ""
Apr 25 19:35:32.839: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"4bca0c8d64167da64440047fb717a3218df7a7687bd15ce858caa1ba1d47cc13\",\n            \"cni.projectcalico.org/podIP\": \"172.30.226.114/32\",\n            \"cni.projectcalico.org/podIPs\": \"172.30.226.114/32\"\n        },\n        \"creationTimestamp\": \"2023-04-25T19:35:22Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8652\",\n        \"resourceVersion\": \"17318\",\n        \"uid\": \"c5065c28-86c7-43ba-9fbb-d2152b05f7d3\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-gpj6n\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.10.21.161\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-gpj6n\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-25T19:35:22Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-25T19:35:30Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-25T19:35:30Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-25T19:35:22Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://ba5985b840f3548e887192ea050f4ea0b93b5c3e268967c632b9097bd8450e37\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-04-25T19:35:29Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.10.21.161\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.226.114\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.30.226.114\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-04-25T19:35:22Z\"\n    }\n}\n"
STEP: replace the image in the pod 04/25/23 19:35:32.839
Apr 25 19:35:32.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8652 replace -f -'
Apr 25 19:35:33.115: INFO: stderr: ""
Apr 25 19:35:33.115: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 04/25/23 19:35:33.115
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Apr 25 19:35:33.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8652 delete pods e2e-test-httpd-pod'
Apr 25 19:35:39.420: INFO: stderr: ""
Apr 25 19:35:39.420: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 19:35:39.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8652" for this suite. 04/25/23 19:35:39.45
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":2,"skipped":92,"failed":0}
------------------------------
• [SLOW TEST] [17.269 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:35:22.2
    Apr 25 19:35:22.201: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 19:35:22.204
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:22.269
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:22.277
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/25/23 19:35:22.288
    Apr 25 19:35:22.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8652 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Apr 25 19:35:22.624: INFO: stderr: ""
    Apr 25 19:35:22.624: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 04/25/23 19:35:22.624
    STEP: verifying the pod e2e-test-httpd-pod was created 04/25/23 19:35:32.676
    Apr 25 19:35:32.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8652 get pod e2e-test-httpd-pod -o json'
    Apr 25 19:35:32.839: INFO: stderr: ""
    Apr 25 19:35:32.839: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"4bca0c8d64167da64440047fb717a3218df7a7687bd15ce858caa1ba1d47cc13\",\n            \"cni.projectcalico.org/podIP\": \"172.30.226.114/32\",\n            \"cni.projectcalico.org/podIPs\": \"172.30.226.114/32\"\n        },\n        \"creationTimestamp\": \"2023-04-25T19:35:22Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8652\",\n        \"resourceVersion\": \"17318\",\n        \"uid\": \"c5065c28-86c7-43ba-9fbb-d2152b05f7d3\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-gpj6n\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.10.21.161\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-gpj6n\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-25T19:35:22Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-25T19:35:30Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-25T19:35:30Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-25T19:35:22Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://ba5985b840f3548e887192ea050f4ea0b93b5c3e268967c632b9097bd8450e37\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-04-25T19:35:29Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.10.21.161\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.226.114\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.30.226.114\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-04-25T19:35:22Z\"\n    }\n}\n"
    STEP: replace the image in the pod 04/25/23 19:35:32.839
    Apr 25 19:35:32.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8652 replace -f -'
    Apr 25 19:35:33.115: INFO: stderr: ""
    Apr 25 19:35:33.115: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 04/25/23 19:35:33.115
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Apr 25 19:35:33.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8652 delete pods e2e-test-httpd-pod'
    Apr 25 19:35:39.420: INFO: stderr: ""
    Apr 25 19:35:39.420: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 19:35:39.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8652" for this suite. 04/25/23 19:35:39.45
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:35:39.473
Apr 25 19:35:39.473: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename custom-resource-definition 04/25/23 19:35:39.474
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:39.521
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:39.533
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Apr 25 19:35:39.548: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 19:35:42.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-719" for this suite. 04/25/23 19:35:42.842
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":3,"skipped":112,"failed":0}
------------------------------
• [3.387 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:35:39.473
    Apr 25 19:35:39.473: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename custom-resource-definition 04/25/23 19:35:39.474
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:39.521
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:39.533
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Apr 25 19:35:39.548: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 19:35:42.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-719" for this suite. 04/25/23 19:35:42.842
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:35:42.869
Apr 25 19:35:42.869: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename server-version 04/25/23 19:35:42.87
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:42.915
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:42.923
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 04/25/23 19:35:42.932
STEP: Confirm major version 04/25/23 19:35:42.937
Apr 25 19:35:42.938: INFO: Major version: 1
STEP: Confirm minor version 04/25/23 19:35:42.938
Apr 25 19:35:42.938: INFO: cleanMinorVersion: 25
Apr 25 19:35:42.938: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Apr 25 19:35:42.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-264" for this suite. 04/25/23 19:35:42.954
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":4,"skipped":144,"failed":0}
------------------------------
• [0.133 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:35:42.869
    Apr 25 19:35:42.869: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename server-version 04/25/23 19:35:42.87
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:42.915
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:42.923
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 04/25/23 19:35:42.932
    STEP: Confirm major version 04/25/23 19:35:42.937
    Apr 25 19:35:42.938: INFO: Major version: 1
    STEP: Confirm minor version 04/25/23 19:35:42.938
    Apr 25 19:35:42.938: INFO: cleanMinorVersion: 25
    Apr 25 19:35:42.938: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Apr 25 19:35:42.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-264" for this suite. 04/25/23 19:35:42.954
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:35:43.004
Apr 25 19:35:43.005: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename secrets 04/25/23 19:35:43.008
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:43.045
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:43.058
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-0a0d426e-18a3-4ae7-8e81-e90c3165ea6d 04/25/23 19:35:43.096
STEP: Creating a pod to test consume secrets 04/25/23 19:35:43.111
Apr 25 19:35:43.130: INFO: Waiting up to 5m0s for pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62" in namespace "secrets-9575" to be "Succeeded or Failed"
Apr 25 19:35:43.163: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62": Phase="Pending", Reason="", readiness=false. Elapsed: 33.253987ms
Apr 25 19:35:45.175: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044442968s
Apr 25 19:35:47.176: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62": Phase="Pending", Reason="", readiness=false. Elapsed: 4.046290711s
Apr 25 19:35:49.176: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62": Phase="Pending", Reason="", readiness=false. Elapsed: 6.046395158s
Apr 25 19:35:51.180: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62": Phase="Running", Reason="", readiness=true. Elapsed: 8.049653026s
Apr 25 19:35:53.176: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62": Phase="Running", Reason="", readiness=false. Elapsed: 10.04615144s
Apr 25 19:35:55.187: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.056818895s
STEP: Saw pod success 04/25/23 19:35:55.187
Apr 25 19:35:55.188: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62" satisfied condition "Succeeded or Failed"
Apr 25 19:35:55.197: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62 container secret-volume-test: <nil>
STEP: delete the pod 04/25/23 19:35:55.277
Apr 25 19:35:55.304: INFO: Waiting for pod pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62 to disappear
Apr 25 19:35:55.312: INFO: Pod pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 25 19:35:55.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9575" for this suite. 04/25/23 19:35:55.327
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":5,"skipped":144,"failed":0}
------------------------------
• [SLOW TEST] [12.338 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:35:43.004
    Apr 25 19:35:43.005: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename secrets 04/25/23 19:35:43.008
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:43.045
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:43.058
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-0a0d426e-18a3-4ae7-8e81-e90c3165ea6d 04/25/23 19:35:43.096
    STEP: Creating a pod to test consume secrets 04/25/23 19:35:43.111
    Apr 25 19:35:43.130: INFO: Waiting up to 5m0s for pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62" in namespace "secrets-9575" to be "Succeeded or Failed"
    Apr 25 19:35:43.163: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62": Phase="Pending", Reason="", readiness=false. Elapsed: 33.253987ms
    Apr 25 19:35:45.175: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044442968s
    Apr 25 19:35:47.176: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62": Phase="Pending", Reason="", readiness=false. Elapsed: 4.046290711s
    Apr 25 19:35:49.176: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62": Phase="Pending", Reason="", readiness=false. Elapsed: 6.046395158s
    Apr 25 19:35:51.180: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62": Phase="Running", Reason="", readiness=true. Elapsed: 8.049653026s
    Apr 25 19:35:53.176: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62": Phase="Running", Reason="", readiness=false. Elapsed: 10.04615144s
    Apr 25 19:35:55.187: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.056818895s
    STEP: Saw pod success 04/25/23 19:35:55.187
    Apr 25 19:35:55.188: INFO: Pod "pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62" satisfied condition "Succeeded or Failed"
    Apr 25 19:35:55.197: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62 container secret-volume-test: <nil>
    STEP: delete the pod 04/25/23 19:35:55.277
    Apr 25 19:35:55.304: INFO: Waiting for pod pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62 to disappear
    Apr 25 19:35:55.312: INFO: Pod pod-secrets-6d010cfe-9e47-4bc4-ad56-78179f050a62 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 25 19:35:55.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9575" for this suite. 04/25/23 19:35:55.327
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:35:55.345
Apr 25 19:35:55.345: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename namespaces 04/25/23 19:35:55.346
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:55.391
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:55.4
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 04/25/23 19:35:55.407
Apr 25 19:35:55.418: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 04/25/23 19:35:55.418
Apr 25 19:35:55.430: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 04/25/23 19:35:55.43
Apr 25 19:35:55.451: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 25 19:35:55.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3522" for this suite. 04/25/23 19:35:55.469
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":6,"skipped":147,"failed":0}
------------------------------
• [0.146 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:35:55.345
    Apr 25 19:35:55.345: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename namespaces 04/25/23 19:35:55.346
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:55.391
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:55.4
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 04/25/23 19:35:55.407
    Apr 25 19:35:55.418: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 04/25/23 19:35:55.418
    Apr 25 19:35:55.430: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 04/25/23 19:35:55.43
    Apr 25 19:35:55.451: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 19:35:55.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-3522" for this suite. 04/25/23 19:35:55.469
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:35:55.494
Apr 25 19:35:55.495: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 19:35:55.497
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:55.539
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:55.548
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-0fb67108-67cf-4eb4-b125-fb37916b5d94 04/25/23 19:35:55.557
STEP: Creating a pod to test consume configMaps 04/25/23 19:35:55.571
Apr 25 19:35:55.609: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7" in namespace "projected-288" to be "Succeeded or Failed"
Apr 25 19:35:55.623: INFO: Pod "pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7": Phase="Pending", Reason="", readiness=false. Elapsed: 13.70211ms
Apr 25 19:35:57.634: INFO: Pod "pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025304447s
Apr 25 19:35:59.639: INFO: Pod "pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029689615s
STEP: Saw pod success 04/25/23 19:35:59.639
Apr 25 19:35:59.639: INFO: Pod "pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7" satisfied condition "Succeeded or Failed"
Apr 25 19:35:59.648: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7 container agnhost-container: <nil>
STEP: delete the pod 04/25/23 19:35:59.677
Apr 25 19:35:59.708: INFO: Waiting for pod pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7 to disappear
Apr 25 19:35:59.719: INFO: Pod pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 25 19:35:59.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-288" for this suite. 04/25/23 19:35:59.738
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":7,"skipped":152,"failed":0}
------------------------------
• [4.260 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:35:55.494
    Apr 25 19:35:55.495: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 19:35:55.497
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:55.539
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:55.548
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-0fb67108-67cf-4eb4-b125-fb37916b5d94 04/25/23 19:35:55.557
    STEP: Creating a pod to test consume configMaps 04/25/23 19:35:55.571
    Apr 25 19:35:55.609: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7" in namespace "projected-288" to be "Succeeded or Failed"
    Apr 25 19:35:55.623: INFO: Pod "pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7": Phase="Pending", Reason="", readiness=false. Elapsed: 13.70211ms
    Apr 25 19:35:57.634: INFO: Pod "pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025304447s
    Apr 25 19:35:59.639: INFO: Pod "pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029689615s
    STEP: Saw pod success 04/25/23 19:35:59.639
    Apr 25 19:35:59.639: INFO: Pod "pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7" satisfied condition "Succeeded or Failed"
    Apr 25 19:35:59.648: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7 container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 19:35:59.677
    Apr 25 19:35:59.708: INFO: Waiting for pod pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7 to disappear
    Apr 25 19:35:59.719: INFO: Pod pod-projected-configmaps-a7c08d8e-7886-4eb9-a815-3ddc7b4943f7 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 25 19:35:59.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-288" for this suite. 04/25/23 19:35:59.738
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:35:59.771
Apr 25 19:35:59.771: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename taint-multiple-pods 04/25/23 19:35:59.773
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:59.835
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:59.848
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Apr 25 19:35:59.857: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 25 19:36:59.939: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Apr 25 19:36:59.951: INFO: Starting informer...
STEP: Starting pods... 04/25/23 19:36:59.952
Apr 25 19:37:00.217: INFO: Pod1 is running on 10.10.21.190. Tainting Node
Apr 25 19:37:00.439: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-9477" to be "running"
Apr 25 19:37:00.451: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.472176ms
Apr 25 19:37:02.462: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022648057s
Apr 25 19:37:04.461: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021510214s
Apr 25 19:37:06.463: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 6.023470684s
Apr 25 19:37:06.463: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Apr 25 19:37:06.463: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-9477" to be "running"
Apr 25 19:37:06.473: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 10.136918ms
Apr 25 19:37:06.474: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Apr 25 19:37:06.474: INFO: Pod2 is running on 10.10.21.190. Tainting Node
STEP: Trying to apply a taint on the Node 04/25/23 19:37:06.474
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/25/23 19:37:06.512
STEP: Waiting for Pod1 and Pod2 to be deleted 04/25/23 19:37:06.525
Apr 25 19:37:13.175: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Apr 25 19:37:33.285: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/25/23 19:37:33.313
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Apr 25 19:37:33.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-9477" for this suite. 04/25/23 19:37:33.366
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":8,"skipped":210,"failed":0}
------------------------------
• [SLOW TEST] [93.613 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:35:59.771
    Apr 25 19:35:59.771: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename taint-multiple-pods 04/25/23 19:35:59.773
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:35:59.835
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:35:59.848
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Apr 25 19:35:59.857: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 25 19:36:59.939: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Apr 25 19:36:59.951: INFO: Starting informer...
    STEP: Starting pods... 04/25/23 19:36:59.952
    Apr 25 19:37:00.217: INFO: Pod1 is running on 10.10.21.190. Tainting Node
    Apr 25 19:37:00.439: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-9477" to be "running"
    Apr 25 19:37:00.451: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.472176ms
    Apr 25 19:37:02.462: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022648057s
    Apr 25 19:37:04.461: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021510214s
    Apr 25 19:37:06.463: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 6.023470684s
    Apr 25 19:37:06.463: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Apr 25 19:37:06.463: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-9477" to be "running"
    Apr 25 19:37:06.473: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 10.136918ms
    Apr 25 19:37:06.474: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Apr 25 19:37:06.474: INFO: Pod2 is running on 10.10.21.190. Tainting Node
    STEP: Trying to apply a taint on the Node 04/25/23 19:37:06.474
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/25/23 19:37:06.512
    STEP: Waiting for Pod1 and Pod2 to be deleted 04/25/23 19:37:06.525
    Apr 25 19:37:13.175: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Apr 25 19:37:33.285: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/25/23 19:37:33.313
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 19:37:33.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-9477" for this suite. 04/25/23 19:37:33.366
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:37:33.384
Apr 25 19:37:33.385: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename replicaset 04/25/23 19:37:33.386
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:37:33.427
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:37:33.435
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 04/25/23 19:37:33.444
STEP: Verify that the required pods have come up 04/25/23 19:37:33.462
Apr 25 19:37:33.470: INFO: Pod name sample-pod: Found 0 pods out of 3
Apr 25 19:37:38.486: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 04/25/23 19:37:38.486
Apr 25 19:37:38.486: INFO: Waiting up to 5m0s for pod "test-rs-jstrd" in namespace "replicaset-1624" to be "running"
Apr 25 19:37:38.486: INFO: Waiting up to 5m0s for pod "test-rs-d2w6v" in namespace "replicaset-1624" to be "running"
Apr 25 19:37:38.497: INFO: Pod "test-rs-jstrd": Phase="Pending", Reason="", readiness=false. Elapsed: 11.021999ms
Apr 25 19:37:38.498: INFO: Pod "test-rs-d2w6v": Phase="Pending", Reason="", readiness=false. Elapsed: 11.905071ms
Apr 25 19:37:40.508: INFO: Pod "test-rs-jstrd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02230416s
Apr 25 19:37:40.512: INFO: Pod "test-rs-d2w6v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025521004s
Apr 25 19:37:42.511: INFO: Pod "test-rs-jstrd": Phase="Running", Reason="", readiness=true. Elapsed: 4.024721313s
Apr 25 19:37:42.511: INFO: Pod "test-rs-jstrd" satisfied condition "running"
Apr 25 19:37:42.511: INFO: Pod "test-rs-d2w6v": Phase="Running", Reason="", readiness=true. Elapsed: 4.024640439s
Apr 25 19:37:42.512: INFO: Pod "test-rs-d2w6v" satisfied condition "running"
Apr 25 19:37:42.523: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 04/25/23 19:37:42.523
STEP: DeleteCollection of the ReplicaSets 04/25/23 19:37:42.539
STEP: After DeleteCollection verify that ReplicaSets have been deleted 04/25/23 19:37:42.576
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 25 19:37:42.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1624" for this suite. 04/25/23 19:37:42.611
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":9,"skipped":216,"failed":0}
------------------------------
• [SLOW TEST] [9.242 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:37:33.384
    Apr 25 19:37:33.385: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename replicaset 04/25/23 19:37:33.386
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:37:33.427
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:37:33.435
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 04/25/23 19:37:33.444
    STEP: Verify that the required pods have come up 04/25/23 19:37:33.462
    Apr 25 19:37:33.470: INFO: Pod name sample-pod: Found 0 pods out of 3
    Apr 25 19:37:38.486: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 04/25/23 19:37:38.486
    Apr 25 19:37:38.486: INFO: Waiting up to 5m0s for pod "test-rs-jstrd" in namespace "replicaset-1624" to be "running"
    Apr 25 19:37:38.486: INFO: Waiting up to 5m0s for pod "test-rs-d2w6v" in namespace "replicaset-1624" to be "running"
    Apr 25 19:37:38.497: INFO: Pod "test-rs-jstrd": Phase="Pending", Reason="", readiness=false. Elapsed: 11.021999ms
    Apr 25 19:37:38.498: INFO: Pod "test-rs-d2w6v": Phase="Pending", Reason="", readiness=false. Elapsed: 11.905071ms
    Apr 25 19:37:40.508: INFO: Pod "test-rs-jstrd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02230416s
    Apr 25 19:37:40.512: INFO: Pod "test-rs-d2w6v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025521004s
    Apr 25 19:37:42.511: INFO: Pod "test-rs-jstrd": Phase="Running", Reason="", readiness=true. Elapsed: 4.024721313s
    Apr 25 19:37:42.511: INFO: Pod "test-rs-jstrd" satisfied condition "running"
    Apr 25 19:37:42.511: INFO: Pod "test-rs-d2w6v": Phase="Running", Reason="", readiness=true. Elapsed: 4.024640439s
    Apr 25 19:37:42.512: INFO: Pod "test-rs-d2w6v" satisfied condition "running"
    Apr 25 19:37:42.523: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 04/25/23 19:37:42.523
    STEP: DeleteCollection of the ReplicaSets 04/25/23 19:37:42.539
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 04/25/23 19:37:42.576
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 25 19:37:42.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-1624" for this suite. 04/25/23 19:37:42.611
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:37:42.628
Apr 25 19:37:42.631: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename dns 04/25/23 19:37:42.634
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:37:42.738
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:37:42.747
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 04/25/23 19:37:42.753
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local;sleep 1; done
 04/25/23 19:37:42.801
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local;sleep 1; done
 04/25/23 19:37:42.801
STEP: creating a pod to probe DNS 04/25/23 19:37:42.802
STEP: submitting the pod to kubernetes 04/25/23 19:37:42.802
Apr 25 19:37:42.825: INFO: Waiting up to 15m0s for pod "dns-test-bde61130-41d5-4439-a710-fffccf0fed96" in namespace "dns-1548" to be "running"
Apr 25 19:37:42.925: INFO: Pod "dns-test-bde61130-41d5-4439-a710-fffccf0fed96": Phase="Pending", Reason="", readiness=false. Elapsed: 99.961045ms
Apr 25 19:37:44.936: INFO: Pod "dns-test-bde61130-41d5-4439-a710-fffccf0fed96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.110669749s
Apr 25 19:37:46.936: INFO: Pod "dns-test-bde61130-41d5-4439-a710-fffccf0fed96": Phase="Pending", Reason="", readiness=false. Elapsed: 4.111114313s
Apr 25 19:37:48.936: INFO: Pod "dns-test-bde61130-41d5-4439-a710-fffccf0fed96": Phase="Pending", Reason="", readiness=false. Elapsed: 6.1101871s
Apr 25 19:37:50.938: INFO: Pod "dns-test-bde61130-41d5-4439-a710-fffccf0fed96": Phase="Running", Reason="", readiness=true. Elapsed: 8.112921993s
Apr 25 19:37:50.938: INFO: Pod "dns-test-bde61130-41d5-4439-a710-fffccf0fed96" satisfied condition "running"
STEP: retrieving the pod 04/25/23 19:37:50.938
STEP: looking for the results for each expected name from probers 04/25/23 19:37:50.949
Apr 25 19:37:50.998: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:51.017: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:51.034: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:51.051: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:51.067: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:51.083: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:51.099: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:51.115: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:51.115: INFO: Lookups using dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local]

Apr 25 19:37:56.136: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:56.152: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:56.168: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:56.184: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:56.201: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:56.246: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:56.263: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:56.281: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:37:56.282: INFO: Lookups using dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local]

Apr 25 19:38:01.132: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:01.148: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:01.163: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:01.179: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:01.218: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:01.234: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:01.250: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:01.266: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:01.266: INFO: Lookups using dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local]

Apr 25 19:38:06.134: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:06.152: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:06.168: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:06.185: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:06.201: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:06.222: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:06.240: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:06.279: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:06.279: INFO: Lookups using dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local]

Apr 25 19:38:11.133: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:11.149: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:11.168: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:11.186: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:11.202: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:11.235: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:11.250: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:11.270: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
Apr 25 19:38:11.270: INFO: Lookups using dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local]

Apr 25 19:38:16.250: INFO: DNS probes using dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96 succeeded

STEP: deleting the pod 04/25/23 19:38:16.25
STEP: deleting the test headless service 04/25/23 19:38:16.285
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 25 19:38:16.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1548" for this suite. 04/25/23 19:38:16.347
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":10,"skipped":216,"failed":0}
------------------------------
• [SLOW TEST] [33.736 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:37:42.628
    Apr 25 19:37:42.631: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename dns 04/25/23 19:37:42.634
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:37:42.738
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:37:42.747
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 04/25/23 19:37:42.753
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local;sleep 1; done
     04/25/23 19:37:42.801
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1548.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local;sleep 1; done
     04/25/23 19:37:42.801
    STEP: creating a pod to probe DNS 04/25/23 19:37:42.802
    STEP: submitting the pod to kubernetes 04/25/23 19:37:42.802
    Apr 25 19:37:42.825: INFO: Waiting up to 15m0s for pod "dns-test-bde61130-41d5-4439-a710-fffccf0fed96" in namespace "dns-1548" to be "running"
    Apr 25 19:37:42.925: INFO: Pod "dns-test-bde61130-41d5-4439-a710-fffccf0fed96": Phase="Pending", Reason="", readiness=false. Elapsed: 99.961045ms
    Apr 25 19:37:44.936: INFO: Pod "dns-test-bde61130-41d5-4439-a710-fffccf0fed96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.110669749s
    Apr 25 19:37:46.936: INFO: Pod "dns-test-bde61130-41d5-4439-a710-fffccf0fed96": Phase="Pending", Reason="", readiness=false. Elapsed: 4.111114313s
    Apr 25 19:37:48.936: INFO: Pod "dns-test-bde61130-41d5-4439-a710-fffccf0fed96": Phase="Pending", Reason="", readiness=false. Elapsed: 6.1101871s
    Apr 25 19:37:50.938: INFO: Pod "dns-test-bde61130-41d5-4439-a710-fffccf0fed96": Phase="Running", Reason="", readiness=true. Elapsed: 8.112921993s
    Apr 25 19:37:50.938: INFO: Pod "dns-test-bde61130-41d5-4439-a710-fffccf0fed96" satisfied condition "running"
    STEP: retrieving the pod 04/25/23 19:37:50.938
    STEP: looking for the results for each expected name from probers 04/25/23 19:37:50.949
    Apr 25 19:37:50.998: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:51.017: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:51.034: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:51.051: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:51.067: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:51.083: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:51.099: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:51.115: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:51.115: INFO: Lookups using dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local]

    Apr 25 19:37:56.136: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:56.152: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:56.168: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:56.184: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:56.201: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:56.246: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:56.263: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:56.281: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:37:56.282: INFO: Lookups using dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local]

    Apr 25 19:38:01.132: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:01.148: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:01.163: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:01.179: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:01.218: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:01.234: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:01.250: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:01.266: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:01.266: INFO: Lookups using dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local]

    Apr 25 19:38:06.134: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:06.152: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:06.168: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:06.185: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:06.201: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:06.222: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:06.240: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:06.279: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:06.279: INFO: Lookups using dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local]

    Apr 25 19:38:11.133: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:11.149: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:11.168: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:11.186: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:11.202: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:11.235: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:11.250: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:11.270: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local from pod dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96: the server could not find the requested resource (get pods dns-test-bde61130-41d5-4439-a710-fffccf0fed96)
    Apr 25 19:38:11.270: INFO: Lookups using dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1548.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1548.svc.cluster.local jessie_udp@dns-test-service-2.dns-1548.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1548.svc.cluster.local]

    Apr 25 19:38:16.250: INFO: DNS probes using dns-1548/dns-test-bde61130-41d5-4439-a710-fffccf0fed96 succeeded

    STEP: deleting the pod 04/25/23 19:38:16.25
    STEP: deleting the test headless service 04/25/23 19:38:16.285
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 25 19:38:16.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1548" for this suite. 04/25/23 19:38:16.347
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:38:16.372
Apr 25 19:38:16.372: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename job 04/25/23 19:38:16.375
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:38:16.424
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:38:16.436
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 04/25/23 19:38:16.444
STEP: Ensure pods equal to paralellism count is attached to the job 04/25/23 19:38:16.458
STEP: patching /status 04/25/23 19:38:22.47
STEP: updating /status 04/25/23 19:38:22.488
STEP: get /status 04/25/23 19:38:22.55
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 25 19:38:22.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1883" for this suite. 04/25/23 19:38:22.587
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":11,"skipped":237,"failed":0}
------------------------------
• [SLOW TEST] [6.237 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:38:16.372
    Apr 25 19:38:16.372: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename job 04/25/23 19:38:16.375
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:38:16.424
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:38:16.436
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 04/25/23 19:38:16.444
    STEP: Ensure pods equal to paralellism count is attached to the job 04/25/23 19:38:16.458
    STEP: patching /status 04/25/23 19:38:22.47
    STEP: updating /status 04/25/23 19:38:22.488
    STEP: get /status 04/25/23 19:38:22.55
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 25 19:38:22.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-1883" for this suite. 04/25/23 19:38:22.587
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:38:22.611
Apr 25 19:38:22.611: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename cronjob 04/25/23 19:38:22.614
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:38:22.658
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:38:22.668
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 04/25/23 19:38:22.678
STEP: creating 04/25/23 19:38:22.679
STEP: getting 04/25/23 19:38:22.702
STEP: listing 04/25/23 19:38:22.719
STEP: watching 04/25/23 19:38:22.731
Apr 25 19:38:22.731: INFO: starting watch
STEP: cluster-wide listing 04/25/23 19:38:22.736
STEP: cluster-wide watching 04/25/23 19:38:22.747
Apr 25 19:38:22.747: INFO: starting watch
STEP: patching 04/25/23 19:38:22.75
STEP: updating 04/25/23 19:38:22.765
Apr 25 19:38:22.791: INFO: waiting for watch events with expected annotations
Apr 25 19:38:22.791: INFO: saw patched and updated annotations
STEP: patching /status 04/25/23 19:38:22.791
STEP: updating /status 04/25/23 19:38:22.811
STEP: get /status 04/25/23 19:38:22.834
STEP: deleting 04/25/23 19:38:22.845
STEP: deleting a collection 04/25/23 19:38:22.885
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 25 19:38:22.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2933" for this suite. 04/25/23 19:38:22.936
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":12,"skipped":240,"failed":0}
------------------------------
• [0.349 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:38:22.611
    Apr 25 19:38:22.611: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename cronjob 04/25/23 19:38:22.614
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:38:22.658
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:38:22.668
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 04/25/23 19:38:22.678
    STEP: creating 04/25/23 19:38:22.679
    STEP: getting 04/25/23 19:38:22.702
    STEP: listing 04/25/23 19:38:22.719
    STEP: watching 04/25/23 19:38:22.731
    Apr 25 19:38:22.731: INFO: starting watch
    STEP: cluster-wide listing 04/25/23 19:38:22.736
    STEP: cluster-wide watching 04/25/23 19:38:22.747
    Apr 25 19:38:22.747: INFO: starting watch
    STEP: patching 04/25/23 19:38:22.75
    STEP: updating 04/25/23 19:38:22.765
    Apr 25 19:38:22.791: INFO: waiting for watch events with expected annotations
    Apr 25 19:38:22.791: INFO: saw patched and updated annotations
    STEP: patching /status 04/25/23 19:38:22.791
    STEP: updating /status 04/25/23 19:38:22.811
    STEP: get /status 04/25/23 19:38:22.834
    STEP: deleting 04/25/23 19:38:22.845
    STEP: deleting a collection 04/25/23 19:38:22.885
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 25 19:38:22.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2933" for this suite. 04/25/23 19:38:22.936
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:38:22.962
Apr 25 19:38:22.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename watch 04/25/23 19:38:22.965
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:38:23.003
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:38:23.011
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 04/25/23 19:38:23.019
STEP: modifying the configmap once 04/25/23 19:38:23.033
STEP: modifying the configmap a second time 04/25/23 19:38:23.059
STEP: deleting the configmap 04/25/23 19:38:23.088
STEP: creating a watch on configmaps from the resource version returned by the first update 04/25/23 19:38:23.106
STEP: Expecting to observe notifications for all changes to the configmap after the first update 04/25/23 19:38:23.109
Apr 25 19:38:23.110: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4572  22dc89e9-1993-4709-bf74-02a0fa65c34b 18150 0 2023-04-25 19:38:23 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-25 19:38:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 25 19:38:23.111: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4572  22dc89e9-1993-4709-bf74-02a0fa65c34b 18151 0 2023-04-25 19:38:23 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-25 19:38:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 25 19:38:23.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4572" for this suite. 04/25/23 19:38:23.127
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":13,"skipped":241,"failed":0}
------------------------------
• [0.182 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:38:22.962
    Apr 25 19:38:22.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename watch 04/25/23 19:38:22.965
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:38:23.003
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:38:23.011
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 04/25/23 19:38:23.019
    STEP: modifying the configmap once 04/25/23 19:38:23.033
    STEP: modifying the configmap a second time 04/25/23 19:38:23.059
    STEP: deleting the configmap 04/25/23 19:38:23.088
    STEP: creating a watch on configmaps from the resource version returned by the first update 04/25/23 19:38:23.106
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 04/25/23 19:38:23.109
    Apr 25 19:38:23.110: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4572  22dc89e9-1993-4709-bf74-02a0fa65c34b 18150 0 2023-04-25 19:38:23 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-25 19:38:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 25 19:38:23.111: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4572  22dc89e9-1993-4709-bf74-02a0fa65c34b 18151 0 2023-04-25 19:38:23 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-25 19:38:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 25 19:38:23.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-4572" for this suite. 04/25/23 19:38:23.127
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:38:23.15
Apr 25 19:38:23.151: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename crd-watch 04/25/23 19:38:23.153
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:38:23.272
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:38:23.282
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Apr 25 19:38:23.291: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Creating first CR  04/25/23 19:38:25.89
Apr 25 19:38:25.903: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-25T19:38:25Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-25T19:38:25Z]] name:name1 resourceVersion:18167 uid:615d89f9-6b5e-4210-b586-025800a558d2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 04/25/23 19:38:35.906
Apr 25 19:38:35.925: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-25T19:38:35Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-25T19:38:35Z]] name:name2 resourceVersion:18206 uid:39521423-1ca1-48cd-962a-a36fb9d54da2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 04/25/23 19:38:45.93
Apr 25 19:38:45.945: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-25T19:38:25Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-25T19:38:45Z]] name:name1 resourceVersion:18219 uid:615d89f9-6b5e-4210-b586-025800a558d2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 04/25/23 19:38:55.946
Apr 25 19:38:55.962: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-25T19:38:35Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-25T19:38:55Z]] name:name2 resourceVersion:18229 uid:39521423-1ca1-48cd-962a-a36fb9d54da2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 04/25/23 19:39:05.965
Apr 25 19:39:06.006: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-25T19:38:25Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-25T19:38:45Z]] name:name1 resourceVersion:18256 uid:615d89f9-6b5e-4210-b586-025800a558d2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 04/25/23 19:39:16.01
Apr 25 19:39:16.032: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-25T19:38:35Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-25T19:38:55Z]] name:name2 resourceVersion:18269 uid:39521423-1ca1-48cd-962a-a36fb9d54da2] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 19:39:26.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-881" for this suite. 04/25/23 19:39:26.582
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":14,"skipped":252,"failed":0}
------------------------------
• [SLOW TEST] [63.482 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:38:23.15
    Apr 25 19:38:23.151: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename crd-watch 04/25/23 19:38:23.153
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:38:23.272
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:38:23.282
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Apr 25 19:38:23.291: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Creating first CR  04/25/23 19:38:25.89
    Apr 25 19:38:25.903: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-25T19:38:25Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-25T19:38:25Z]] name:name1 resourceVersion:18167 uid:615d89f9-6b5e-4210-b586-025800a558d2] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 04/25/23 19:38:35.906
    Apr 25 19:38:35.925: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-25T19:38:35Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-25T19:38:35Z]] name:name2 resourceVersion:18206 uid:39521423-1ca1-48cd-962a-a36fb9d54da2] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 04/25/23 19:38:45.93
    Apr 25 19:38:45.945: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-25T19:38:25Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-25T19:38:45Z]] name:name1 resourceVersion:18219 uid:615d89f9-6b5e-4210-b586-025800a558d2] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 04/25/23 19:38:55.946
    Apr 25 19:38:55.962: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-25T19:38:35Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-25T19:38:55Z]] name:name2 resourceVersion:18229 uid:39521423-1ca1-48cd-962a-a36fb9d54da2] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 04/25/23 19:39:05.965
    Apr 25 19:39:06.006: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-25T19:38:25Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-25T19:38:45Z]] name:name1 resourceVersion:18256 uid:615d89f9-6b5e-4210-b586-025800a558d2] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 04/25/23 19:39:16.01
    Apr 25 19:39:16.032: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-25T19:38:35Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-25T19:38:55Z]] name:name2 resourceVersion:18269 uid:39521423-1ca1-48cd-962a-a36fb9d54da2] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 19:39:26.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-881" for this suite. 04/25/23 19:39:26.582
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3185
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:39:26.638
Apr 25 19:39:26.639: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 19:39:26.641
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:39:26.689
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:39:26.697
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3185
STEP: fetching services 04/25/23 19:39:26.706
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 19:39:26.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4558" for this suite. 04/25/23 19:39:26.736
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":15,"skipped":274,"failed":0}
------------------------------
• [0.114 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:39:26.638
    Apr 25 19:39:26.639: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 19:39:26.641
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:39:26.689
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:39:26.697
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3185
    STEP: fetching services 04/25/23 19:39:26.706
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 19:39:26.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4558" for this suite. 04/25/23 19:39:26.736
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:39:26.76
Apr 25 19:39:26.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-probe 04/25/23 19:39:26.763
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:39:26.847
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:39:26.857
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-48967415-dab1-44f3-b716-c6d7a984a8f6 in namespace container-probe-3016 04/25/23 19:39:26.867
Apr 25 19:39:26.892: INFO: Waiting up to 5m0s for pod "liveness-48967415-dab1-44f3-b716-c6d7a984a8f6" in namespace "container-probe-3016" to be "not pending"
Apr 25 19:39:26.914: INFO: Pod "liveness-48967415-dab1-44f3-b716-c6d7a984a8f6": Phase="Pending", Reason="", readiness=false. Elapsed: 21.458731ms
Apr 25 19:39:28.928: INFO: Pod "liveness-48967415-dab1-44f3-b716-c6d7a984a8f6": Phase="Running", Reason="", readiness=true. Elapsed: 2.035492638s
Apr 25 19:39:28.928: INFO: Pod "liveness-48967415-dab1-44f3-b716-c6d7a984a8f6" satisfied condition "not pending"
Apr 25 19:39:28.928: INFO: Started pod liveness-48967415-dab1-44f3-b716-c6d7a984a8f6 in namespace container-probe-3016
STEP: checking the pod's current state and verifying that restartCount is present 04/25/23 19:39:28.928
Apr 25 19:39:28.938: INFO: Initial restart count of pod liveness-48967415-dab1-44f3-b716-c6d7a984a8f6 is 0
STEP: deleting the pod 04/25/23 19:43:30.593
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 25 19:43:30.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3016" for this suite. 04/25/23 19:43:30.768
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":16,"skipped":309,"failed":0}
------------------------------
• [SLOW TEST] [244.079 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:39:26.76
    Apr 25 19:39:26.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-probe 04/25/23 19:39:26.763
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:39:26.847
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:39:26.857
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-48967415-dab1-44f3-b716-c6d7a984a8f6 in namespace container-probe-3016 04/25/23 19:39:26.867
    Apr 25 19:39:26.892: INFO: Waiting up to 5m0s for pod "liveness-48967415-dab1-44f3-b716-c6d7a984a8f6" in namespace "container-probe-3016" to be "not pending"
    Apr 25 19:39:26.914: INFO: Pod "liveness-48967415-dab1-44f3-b716-c6d7a984a8f6": Phase="Pending", Reason="", readiness=false. Elapsed: 21.458731ms
    Apr 25 19:39:28.928: INFO: Pod "liveness-48967415-dab1-44f3-b716-c6d7a984a8f6": Phase="Running", Reason="", readiness=true. Elapsed: 2.035492638s
    Apr 25 19:39:28.928: INFO: Pod "liveness-48967415-dab1-44f3-b716-c6d7a984a8f6" satisfied condition "not pending"
    Apr 25 19:39:28.928: INFO: Started pod liveness-48967415-dab1-44f3-b716-c6d7a984a8f6 in namespace container-probe-3016
    STEP: checking the pod's current state and verifying that restartCount is present 04/25/23 19:39:28.928
    Apr 25 19:39:28.938: INFO: Initial restart count of pod liveness-48967415-dab1-44f3-b716-c6d7a984a8f6 is 0
    STEP: deleting the pod 04/25/23 19:43:30.593
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 25 19:43:30.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3016" for this suite. 04/25/23 19:43:30.768
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:43:30.842
Apr 25 19:43:30.843: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename runtimeclass 04/25/23 19:43:30.847
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:43:30.926
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:43:30.933
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Apr 25 19:43:31.008: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-7190 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 25 19:43:31.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7190" for this suite. 04/25/23 19:43:31.054
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":17,"skipped":311,"failed":0}
------------------------------
• [0.231 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:43:30.842
    Apr 25 19:43:30.843: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename runtimeclass 04/25/23 19:43:30.847
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:43:30.926
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:43:30.933
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Apr 25 19:43:31.008: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-7190 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 25 19:43:31.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-7190" for this suite. 04/25/23 19:43:31.054
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:43:31.074
Apr 25 19:43:31.075: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir 04/25/23 19:43:31.079
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:43:31.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:43:31.128
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 04/25/23 19:43:31.137
Apr 25 19:43:31.167: INFO: Waiting up to 5m0s for pod "pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0" in namespace "emptydir-1374" to be "Succeeded or Failed"
Apr 25 19:43:31.179: INFO: Pod "pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.172604ms
Apr 25 19:43:33.190: INFO: Pod "pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023060803s
Apr 25 19:43:35.192: INFO: Pod "pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024746168s
STEP: Saw pod success 04/25/23 19:43:35.192
Apr 25 19:43:35.192: INFO: Pod "pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0" satisfied condition "Succeeded or Failed"
Apr 25 19:43:35.201: INFO: Trying to get logs from node 10.10.21.190 pod pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0 container test-container: <nil>
STEP: delete the pod 04/25/23 19:43:35.28
Apr 25 19:43:35.331: INFO: Waiting for pod pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0 to disappear
Apr 25 19:43:35.377: INFO: Pod pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 25 19:43:35.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1374" for this suite. 04/25/23 19:43:35.416
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":18,"skipped":315,"failed":0}
------------------------------
• [4.416 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:43:31.074
    Apr 25 19:43:31.075: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir 04/25/23 19:43:31.079
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:43:31.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:43:31.128
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 04/25/23 19:43:31.137
    Apr 25 19:43:31.167: INFO: Waiting up to 5m0s for pod "pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0" in namespace "emptydir-1374" to be "Succeeded or Failed"
    Apr 25 19:43:31.179: INFO: Pod "pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.172604ms
    Apr 25 19:43:33.190: INFO: Pod "pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023060803s
    Apr 25 19:43:35.192: INFO: Pod "pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024746168s
    STEP: Saw pod success 04/25/23 19:43:35.192
    Apr 25 19:43:35.192: INFO: Pod "pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0" satisfied condition "Succeeded or Failed"
    Apr 25 19:43:35.201: INFO: Trying to get logs from node 10.10.21.190 pod pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0 container test-container: <nil>
    STEP: delete the pod 04/25/23 19:43:35.28
    Apr 25 19:43:35.331: INFO: Waiting for pod pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0 to disappear
    Apr 25 19:43:35.377: INFO: Pod pod-d3fd84c4-b0bd-4373-8e70-3135c43299e0 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 25 19:43:35.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1374" for this suite. 04/25/23 19:43:35.416
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:43:35.498
Apr 25 19:43:35.499: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename disruption 04/25/23 19:43:35.502
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:43:35.61
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:43:35.654
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 04/25/23 19:43:35.662
STEP: Waiting for the pdb to be processed 04/25/23 19:43:35.678
STEP: First trying to evict a pod which shouldn't be evictable 04/25/23 19:43:37.722
STEP: Waiting for all pods to be running 04/25/23 19:43:37.722
Apr 25 19:43:37.732: INFO: pods: 0 < 3
Apr 25 19:43:39.746: INFO: running pods: 0 < 3
Apr 25 19:43:41.744: INFO: running pods: 1 < 3
STEP: locating a running pod 04/25/23 19:43:43.771
STEP: Updating the pdb to allow a pod to be evicted 04/25/23 19:43:43.824
STEP: Waiting for the pdb to be processed 04/25/23 19:43:43.847
STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/25/23 19:43:45.882
STEP: Waiting for all pods to be running 04/25/23 19:43:45.882
STEP: Waiting for the pdb to observed all healthy pods 04/25/23 19:43:45.914
STEP: Patching the pdb to disallow a pod to be evicted 04/25/23 19:43:46.019
STEP: Waiting for the pdb to be processed 04/25/23 19:43:46.052
STEP: Waiting for all pods to be running 04/25/23 19:43:46.076
Apr 25 19:43:46.139: INFO: running pods: 2 < 3
Apr 25 19:43:48.151: INFO: running pods: 2 < 3
STEP: locating a running pod 04/25/23 19:43:50.153
STEP: Deleting the pdb to allow a pod to be evicted 04/25/23 19:43:50.179
STEP: Waiting for the pdb to be deleted 04/25/23 19:43:50.196
STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/25/23 19:43:50.206
STEP: Waiting for all pods to be running 04/25/23 19:43:50.206
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 25 19:43:50.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9552" for this suite. 04/25/23 19:43:50.315
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":19,"skipped":324,"failed":0}
------------------------------
• [SLOW TEST] [14.845 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:43:35.498
    Apr 25 19:43:35.499: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename disruption 04/25/23 19:43:35.502
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:43:35.61
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:43:35.654
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 04/25/23 19:43:35.662
    STEP: Waiting for the pdb to be processed 04/25/23 19:43:35.678
    STEP: First trying to evict a pod which shouldn't be evictable 04/25/23 19:43:37.722
    STEP: Waiting for all pods to be running 04/25/23 19:43:37.722
    Apr 25 19:43:37.732: INFO: pods: 0 < 3
    Apr 25 19:43:39.746: INFO: running pods: 0 < 3
    Apr 25 19:43:41.744: INFO: running pods: 1 < 3
    STEP: locating a running pod 04/25/23 19:43:43.771
    STEP: Updating the pdb to allow a pod to be evicted 04/25/23 19:43:43.824
    STEP: Waiting for the pdb to be processed 04/25/23 19:43:43.847
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/25/23 19:43:45.882
    STEP: Waiting for all pods to be running 04/25/23 19:43:45.882
    STEP: Waiting for the pdb to observed all healthy pods 04/25/23 19:43:45.914
    STEP: Patching the pdb to disallow a pod to be evicted 04/25/23 19:43:46.019
    STEP: Waiting for the pdb to be processed 04/25/23 19:43:46.052
    STEP: Waiting for all pods to be running 04/25/23 19:43:46.076
    Apr 25 19:43:46.139: INFO: running pods: 2 < 3
    Apr 25 19:43:48.151: INFO: running pods: 2 < 3
    STEP: locating a running pod 04/25/23 19:43:50.153
    STEP: Deleting the pdb to allow a pod to be evicted 04/25/23 19:43:50.179
    STEP: Waiting for the pdb to be deleted 04/25/23 19:43:50.196
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/25/23 19:43:50.206
    STEP: Waiting for all pods to be running 04/25/23 19:43:50.206
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 25 19:43:50.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-9552" for this suite. 04/25/23 19:43:50.315
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:43:50.344
Apr 25 19:43:50.345: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir 04/25/23 19:43:50.347
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:43:50.42
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:43:50.429
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 04/25/23 19:43:50.467
Apr 25 19:43:50.485: INFO: Waiting up to 5m0s for pod "pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb" in namespace "emptydir-1632" to be "Succeeded or Failed"
Apr 25 19:43:50.497: INFO: Pod "pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb": Phase="Pending", Reason="", readiness=false. Elapsed: 12.16088ms
Apr 25 19:43:52.536: INFO: Pod "pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051216411s
Apr 25 19:43:54.511: INFO: Pod "pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026760315s
STEP: Saw pod success 04/25/23 19:43:54.512
Apr 25 19:43:54.512: INFO: Pod "pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb" satisfied condition "Succeeded or Failed"
Apr 25 19:43:54.552: INFO: Trying to get logs from node 10.10.21.190 pod pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb container test-container: <nil>
STEP: delete the pod 04/25/23 19:43:54.588
Apr 25 19:43:54.701: INFO: Waiting for pod pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb to disappear
Apr 25 19:43:54.710: INFO: Pod pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 25 19:43:54.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1632" for this suite. 04/25/23 19:43:54.732
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":20,"skipped":330,"failed":0}
------------------------------
• [4.418 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:43:50.344
    Apr 25 19:43:50.345: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir 04/25/23 19:43:50.347
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:43:50.42
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:43:50.429
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 04/25/23 19:43:50.467
    Apr 25 19:43:50.485: INFO: Waiting up to 5m0s for pod "pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb" in namespace "emptydir-1632" to be "Succeeded or Failed"
    Apr 25 19:43:50.497: INFO: Pod "pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb": Phase="Pending", Reason="", readiness=false. Elapsed: 12.16088ms
    Apr 25 19:43:52.536: INFO: Pod "pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051216411s
    Apr 25 19:43:54.511: INFO: Pod "pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026760315s
    STEP: Saw pod success 04/25/23 19:43:54.512
    Apr 25 19:43:54.512: INFO: Pod "pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb" satisfied condition "Succeeded or Failed"
    Apr 25 19:43:54.552: INFO: Trying to get logs from node 10.10.21.190 pod pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb container test-container: <nil>
    STEP: delete the pod 04/25/23 19:43:54.588
    Apr 25 19:43:54.701: INFO: Waiting for pod pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb to disappear
    Apr 25 19:43:54.710: INFO: Pod pod-bc8aa5a9-12c0-4566-9cbe-f7f679cac5bb no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 25 19:43:54.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1632" for this suite. 04/25/23 19:43:54.732
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:43:54.77
Apr 25 19:43:54.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename configmap 04/25/23 19:43:54.773
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:43:54.856
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:43:54.865
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-63ffac1b-54ed-4374-b0c8-701b72621f7f 04/25/23 19:43:54.874
STEP: Creating a pod to test consume configMaps 04/25/23 19:43:54.893
Apr 25 19:43:54.938: INFO: Waiting up to 5m0s for pod "pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d" in namespace "configmap-5337" to be "Succeeded or Failed"
Apr 25 19:43:55.002: INFO: Pod "pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d": Phase="Pending", Reason="", readiness=false. Elapsed: 64.596496ms
Apr 25 19:43:57.013: INFO: Pod "pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075208317s
Apr 25 19:43:59.015: INFO: Pod "pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.077480968s
Apr 25 19:44:01.041: INFO: Pod "pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.102938772s
STEP: Saw pod success 04/25/23 19:44:01.041
Apr 25 19:44:01.042: INFO: Pod "pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d" satisfied condition "Succeeded or Failed"
Apr 25 19:44:01.083: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d container configmap-volume-test: <nil>
STEP: delete the pod 04/25/23 19:44:01.136
Apr 25 19:44:01.175: INFO: Waiting for pod pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d to disappear
Apr 25 19:44:01.210: INFO: Pod pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 25 19:44:01.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5337" for this suite. 04/25/23 19:44:01.228
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":21,"skipped":346,"failed":0}
------------------------------
• [SLOW TEST] [6.486 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:43:54.77
    Apr 25 19:43:54.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename configmap 04/25/23 19:43:54.773
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:43:54.856
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:43:54.865
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-63ffac1b-54ed-4374-b0c8-701b72621f7f 04/25/23 19:43:54.874
    STEP: Creating a pod to test consume configMaps 04/25/23 19:43:54.893
    Apr 25 19:43:54.938: INFO: Waiting up to 5m0s for pod "pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d" in namespace "configmap-5337" to be "Succeeded or Failed"
    Apr 25 19:43:55.002: INFO: Pod "pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d": Phase="Pending", Reason="", readiness=false. Elapsed: 64.596496ms
    Apr 25 19:43:57.013: INFO: Pod "pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075208317s
    Apr 25 19:43:59.015: INFO: Pod "pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.077480968s
    Apr 25 19:44:01.041: INFO: Pod "pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.102938772s
    STEP: Saw pod success 04/25/23 19:44:01.041
    Apr 25 19:44:01.042: INFO: Pod "pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d" satisfied condition "Succeeded or Failed"
    Apr 25 19:44:01.083: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d container configmap-volume-test: <nil>
    STEP: delete the pod 04/25/23 19:44:01.136
    Apr 25 19:44:01.175: INFO: Waiting for pod pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d to disappear
    Apr 25 19:44:01.210: INFO: Pod pod-configmaps-462daa39-bda8-4d7d-96bf-6e61d8ef4a3d no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 25 19:44:01.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5337" for this suite. 04/25/23 19:44:01.228
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:44:01.266
Apr 25 19:44:01.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename crd-webhook 04/25/23 19:44:01.268
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:01.353
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:01.377
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 04/25/23 19:44:01.386
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/25/23 19:44:01.943
STEP: Deploying the custom resource conversion webhook pod 04/25/23 19:44:01.966
STEP: Wait for the deployment to be ready 04/25/23 19:44:02.027
Apr 25 19:44:02.075: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
Apr 25 19:44:04.111: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 19, 44, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 19, 44, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 19, 44, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 19, 44, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/25/23 19:44:06.125
STEP: Verifying the service has paired with the endpoint 04/25/23 19:44:06.158
Apr 25 19:44:07.159: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Apr 25 19:44:07.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Creating a v1 custom resource 04/25/23 19:44:09.994
STEP: v2 custom resource should be converted 04/25/23 19:44:10.007
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 19:44:10.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6354" for this suite. 04/25/23 19:44:10.684
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":22,"skipped":374,"failed":0}
------------------------------
• [SLOW TEST] [9.594 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:44:01.266
    Apr 25 19:44:01.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename crd-webhook 04/25/23 19:44:01.268
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:01.353
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:01.377
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 04/25/23 19:44:01.386
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/25/23 19:44:01.943
    STEP: Deploying the custom resource conversion webhook pod 04/25/23 19:44:01.966
    STEP: Wait for the deployment to be ready 04/25/23 19:44:02.027
    Apr 25 19:44:02.075: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
    Apr 25 19:44:04.111: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 19, 44, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 19, 44, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 19, 44, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 19, 44, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/25/23 19:44:06.125
    STEP: Verifying the service has paired with the endpoint 04/25/23 19:44:06.158
    Apr 25 19:44:07.159: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Apr 25 19:44:07.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Creating a v1 custom resource 04/25/23 19:44:09.994
    STEP: v2 custom resource should be converted 04/25/23 19:44:10.007
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 19:44:10.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-6354" for this suite. 04/25/23 19:44:10.684
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:44:10.866
Apr 25 19:44:10.866: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename runtimeclass 04/25/23 19:44:10.868
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:10.911
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:10.92
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 04/25/23 19:44:10.931
STEP: getting /apis/node.k8s.io 04/25/23 19:44:10.937
STEP: getting /apis/node.k8s.io/v1 04/25/23 19:44:10.942
STEP: creating 04/25/23 19:44:10.947
STEP: watching 04/25/23 19:44:10.994
Apr 25 19:44:10.994: INFO: starting watch
STEP: getting 04/25/23 19:44:11.045
STEP: listing 04/25/23 19:44:11.076
STEP: patching 04/25/23 19:44:11.092
STEP: updating 04/25/23 19:44:11.13
Apr 25 19:44:11.145: INFO: waiting for watch events with expected annotations
STEP: deleting 04/25/23 19:44:11.145
STEP: deleting a collection 04/25/23 19:44:11.215
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 25 19:44:11.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-8101" for this suite. 04/25/23 19:44:11.331
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":23,"skipped":402,"failed":0}
------------------------------
• [0.529 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:44:10.866
    Apr 25 19:44:10.866: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename runtimeclass 04/25/23 19:44:10.868
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:10.911
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:10.92
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 04/25/23 19:44:10.931
    STEP: getting /apis/node.k8s.io 04/25/23 19:44:10.937
    STEP: getting /apis/node.k8s.io/v1 04/25/23 19:44:10.942
    STEP: creating 04/25/23 19:44:10.947
    STEP: watching 04/25/23 19:44:10.994
    Apr 25 19:44:10.994: INFO: starting watch
    STEP: getting 04/25/23 19:44:11.045
    STEP: listing 04/25/23 19:44:11.076
    STEP: patching 04/25/23 19:44:11.092
    STEP: updating 04/25/23 19:44:11.13
    Apr 25 19:44:11.145: INFO: waiting for watch events with expected annotations
    STEP: deleting 04/25/23 19:44:11.145
    STEP: deleting a collection 04/25/23 19:44:11.215
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 25 19:44:11.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-8101" for this suite. 04/25/23 19:44:11.331
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:44:11.4
Apr 25 19:44:11.400: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 19:44:11.401
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:11.479
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:11.487
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 04/25/23 19:44:11.494
Apr 25 19:44:11.529: INFO: Waiting up to 5m0s for pod "labelsupdateb19be943-6b03-4b99-a808-c08f9868f7f0" in namespace "downward-api-3043" to be "running and ready"
Apr 25 19:44:11.569: INFO: Pod "labelsupdateb19be943-6b03-4b99-a808-c08f9868f7f0": Phase="Pending", Reason="", readiness=false. Elapsed: 38.938991ms
Apr 25 19:44:11.569: INFO: The phase of Pod labelsupdateb19be943-6b03-4b99-a808-c08f9868f7f0 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 19:44:13.585: INFO: Pod "labelsupdateb19be943-6b03-4b99-a808-c08f9868f7f0": Phase="Running", Reason="", readiness=true. Elapsed: 2.055430835s
Apr 25 19:44:13.585: INFO: The phase of Pod labelsupdateb19be943-6b03-4b99-a808-c08f9868f7f0 is Running (Ready = true)
Apr 25 19:44:13.585: INFO: Pod "labelsupdateb19be943-6b03-4b99-a808-c08f9868f7f0" satisfied condition "running and ready"
Apr 25 19:44:14.243: INFO: Successfully updated pod "labelsupdateb19be943-6b03-4b99-a808-c08f9868f7f0"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 25 19:44:16.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3043" for this suite. 04/25/23 19:44:16.367
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":24,"skipped":427,"failed":0}
------------------------------
• [4.986 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:44:11.4
    Apr 25 19:44:11.400: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 19:44:11.401
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:11.479
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:11.487
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 04/25/23 19:44:11.494
    Apr 25 19:44:11.529: INFO: Waiting up to 5m0s for pod "labelsupdateb19be943-6b03-4b99-a808-c08f9868f7f0" in namespace "downward-api-3043" to be "running and ready"
    Apr 25 19:44:11.569: INFO: Pod "labelsupdateb19be943-6b03-4b99-a808-c08f9868f7f0": Phase="Pending", Reason="", readiness=false. Elapsed: 38.938991ms
    Apr 25 19:44:11.569: INFO: The phase of Pod labelsupdateb19be943-6b03-4b99-a808-c08f9868f7f0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 19:44:13.585: INFO: Pod "labelsupdateb19be943-6b03-4b99-a808-c08f9868f7f0": Phase="Running", Reason="", readiness=true. Elapsed: 2.055430835s
    Apr 25 19:44:13.585: INFO: The phase of Pod labelsupdateb19be943-6b03-4b99-a808-c08f9868f7f0 is Running (Ready = true)
    Apr 25 19:44:13.585: INFO: Pod "labelsupdateb19be943-6b03-4b99-a808-c08f9868f7f0" satisfied condition "running and ready"
    Apr 25 19:44:14.243: INFO: Successfully updated pod "labelsupdateb19be943-6b03-4b99-a808-c08f9868f7f0"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 25 19:44:16.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3043" for this suite. 04/25/23 19:44:16.367
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:44:16.411
Apr 25 19:44:16.411: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 19:44:16.413
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:16.456
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:16.465
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 04/25/23 19:44:16.472
Apr 25 19:44:16.491: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167" in namespace "projected-9439" to be "Succeeded or Failed"
Apr 25 19:44:16.526: INFO: Pod "downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167": Phase="Pending", Reason="", readiness=false. Elapsed: 35.777592ms
Apr 25 19:44:18.547: INFO: Pod "downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056017367s
Apr 25 19:44:20.561: INFO: Pod "downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.070520083s
STEP: Saw pod success 04/25/23 19:44:20.562
Apr 25 19:44:20.562: INFO: Pod "downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167" satisfied condition "Succeeded or Failed"
Apr 25 19:44:20.592: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167 container client-container: <nil>
STEP: delete the pod 04/25/23 19:44:20.62
Apr 25 19:44:20.662: INFO: Waiting for pod downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167 to disappear
Apr 25 19:44:20.672: INFO: Pod downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 25 19:44:20.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9439" for this suite. 04/25/23 19:44:20.688
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":25,"skipped":472,"failed":0}
------------------------------
• [4.295 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:44:16.411
    Apr 25 19:44:16.411: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 19:44:16.413
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:16.456
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:16.465
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 04/25/23 19:44:16.472
    Apr 25 19:44:16.491: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167" in namespace "projected-9439" to be "Succeeded or Failed"
    Apr 25 19:44:16.526: INFO: Pod "downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167": Phase="Pending", Reason="", readiness=false. Elapsed: 35.777592ms
    Apr 25 19:44:18.547: INFO: Pod "downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056017367s
    Apr 25 19:44:20.561: INFO: Pod "downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.070520083s
    STEP: Saw pod success 04/25/23 19:44:20.562
    Apr 25 19:44:20.562: INFO: Pod "downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167" satisfied condition "Succeeded or Failed"
    Apr 25 19:44:20.592: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167 container client-container: <nil>
    STEP: delete the pod 04/25/23 19:44:20.62
    Apr 25 19:44:20.662: INFO: Waiting for pod downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167 to disappear
    Apr 25 19:44:20.672: INFO: Pod downwardapi-volume-eea99da3-26aa-48bb-87b0-a2de9ee05167 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 25 19:44:20.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9439" for this suite. 04/25/23 19:44:20.688
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:44:20.71
Apr 25 19:44:20.711: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename secrets 04/25/23 19:44:20.714
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:20.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:20.763
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 04/25/23 19:44:20.771
STEP: listing secrets in all namespaces to ensure that there are more than zero 04/25/23 19:44:20.785
STEP: patching the secret 04/25/23 19:44:20.803
STEP: deleting the secret using a LabelSelector 04/25/23 19:44:20.83
STEP: listing secrets in all namespaces, searching for label name and value in patch 04/25/23 19:44:20.857
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 25 19:44:20.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3072" for this suite. 04/25/23 19:44:20.885
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":26,"skipped":474,"failed":0}
------------------------------
• [0.191 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:44:20.71
    Apr 25 19:44:20.711: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename secrets 04/25/23 19:44:20.714
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:20.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:20.763
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 04/25/23 19:44:20.771
    STEP: listing secrets in all namespaces to ensure that there are more than zero 04/25/23 19:44:20.785
    STEP: patching the secret 04/25/23 19:44:20.803
    STEP: deleting the secret using a LabelSelector 04/25/23 19:44:20.83
    STEP: listing secrets in all namespaces, searching for label name and value in patch 04/25/23 19:44:20.857
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 25 19:44:20.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3072" for this suite. 04/25/23 19:44:20.885
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:44:20.908
Apr 25 19:44:20.909: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename var-expansion 04/25/23 19:44:20.911
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:20.969
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:20.98
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Apr 25 19:44:21.005: INFO: Waiting up to 2m0s for pod "var-expansion-7637840f-41ad-401a-944b-d64169bf32e8" in namespace "var-expansion-6139" to be "container 0 failed with reason CreateContainerConfigError"
Apr 25 19:44:21.017: INFO: Pod "var-expansion-7637840f-41ad-401a-944b-d64169bf32e8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.470491ms
Apr 25 19:44:23.063: INFO: Pod "var-expansion-7637840f-41ad-401a-944b-d64169bf32e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057324007s
Apr 25 19:44:23.063: INFO: Pod "var-expansion-7637840f-41ad-401a-944b-d64169bf32e8" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Apr 25 19:44:23.063: INFO: Deleting pod "var-expansion-7637840f-41ad-401a-944b-d64169bf32e8" in namespace "var-expansion-6139"
Apr 25 19:44:23.113: INFO: Wait up to 5m0s for pod "var-expansion-7637840f-41ad-401a-944b-d64169bf32e8" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 25 19:44:27.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6139" for this suite. 04/25/23 19:44:27.153
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":27,"skipped":492,"failed":0}
------------------------------
• [SLOW TEST] [6.263 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:44:20.908
    Apr 25 19:44:20.909: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename var-expansion 04/25/23 19:44:20.911
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:20.969
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:20.98
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Apr 25 19:44:21.005: INFO: Waiting up to 2m0s for pod "var-expansion-7637840f-41ad-401a-944b-d64169bf32e8" in namespace "var-expansion-6139" to be "container 0 failed with reason CreateContainerConfigError"
    Apr 25 19:44:21.017: INFO: Pod "var-expansion-7637840f-41ad-401a-944b-d64169bf32e8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.470491ms
    Apr 25 19:44:23.063: INFO: Pod "var-expansion-7637840f-41ad-401a-944b-d64169bf32e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057324007s
    Apr 25 19:44:23.063: INFO: Pod "var-expansion-7637840f-41ad-401a-944b-d64169bf32e8" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Apr 25 19:44:23.063: INFO: Deleting pod "var-expansion-7637840f-41ad-401a-944b-d64169bf32e8" in namespace "var-expansion-6139"
    Apr 25 19:44:23.113: INFO: Wait up to 5m0s for pod "var-expansion-7637840f-41ad-401a-944b-d64169bf32e8" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 25 19:44:27.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-6139" for this suite. 04/25/23 19:44:27.153
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:44:27.181
Apr 25 19:44:27.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename disruption 04/25/23 19:44:27.183
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:27.232
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:27.241
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 04/25/23 19:44:27.26
STEP: Waiting for all pods to be running 04/25/23 19:44:29.332
Apr 25 19:44:29.350: INFO: running pods: 0 < 3
Apr 25 19:44:31.364: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 25 19:44:33.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8367" for this suite. 04/25/23 19:44:33.387
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":28,"skipped":523,"failed":0}
------------------------------
• [SLOW TEST] [6.223 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:44:27.181
    Apr 25 19:44:27.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename disruption 04/25/23 19:44:27.183
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:27.232
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:27.241
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 04/25/23 19:44:27.26
    STEP: Waiting for all pods to be running 04/25/23 19:44:29.332
    Apr 25 19:44:29.350: INFO: running pods: 0 < 3
    Apr 25 19:44:31.364: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 25 19:44:33.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-8367" for this suite. 04/25/23 19:44:33.387
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:44:33.414
Apr 25 19:44:33.414: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename lease-test 04/25/23 19:44:33.416
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:33.46
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:33.476
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Apr 25 19:44:33.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-3415" for this suite. 04/25/23 19:44:33.719
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":29,"skipped":554,"failed":0}
------------------------------
• [0.322 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:44:33.414
    Apr 25 19:44:33.414: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename lease-test 04/25/23 19:44:33.416
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:33.46
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:33.476
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Apr 25 19:44:33.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-3415" for this suite. 04/25/23 19:44:33.719
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:44:33.738
Apr 25 19:44:33.739: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename endpointslice 04/25/23 19:44:33.743
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:33.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:33.795
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 04/25/23 19:44:44.04
STEP: referencing matching pods with named port 04/25/23 19:44:49.12
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 04/25/23 19:44:54.147
STEP: recreating EndpointSlices after they've been deleted 04/25/23 19:44:59.183
Apr 25 19:44:59.248: INFO: EndpointSlice for Service endpointslice-9774/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 25 19:45:09.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9774" for this suite. 04/25/23 19:45:09.292
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":30,"skipped":556,"failed":0}
------------------------------
• [SLOW TEST] [35.573 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:44:33.738
    Apr 25 19:44:33.739: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename endpointslice 04/25/23 19:44:33.743
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:44:33.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:44:33.795
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 04/25/23 19:44:44.04
    STEP: referencing matching pods with named port 04/25/23 19:44:49.12
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 04/25/23 19:44:54.147
    STEP: recreating EndpointSlices after they've been deleted 04/25/23 19:44:59.183
    Apr 25 19:44:59.248: INFO: EndpointSlice for Service endpointslice-9774/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 25 19:45:09.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-9774" for this suite. 04/25/23 19:45:09.292
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:45:09.326
Apr 25 19:45:09.326: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename containers 04/25/23 19:45:09.328
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:45:09.373
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:45:09.381
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Apr 25 19:45:09.408: INFO: Waiting up to 5m0s for pod "client-containers-99ab4085-42d6-4c0f-851b-73454a6f09af" in namespace "containers-6964" to be "running"
Apr 25 19:45:09.422: INFO: Pod "client-containers-99ab4085-42d6-4c0f-851b-73454a6f09af": Phase="Pending", Reason="", readiness=false. Elapsed: 14.038349ms
Apr 25 19:45:11.438: INFO: Pod "client-containers-99ab4085-42d6-4c0f-851b-73454a6f09af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029774449s
Apr 25 19:45:13.433: INFO: Pod "client-containers-99ab4085-42d6-4c0f-851b-73454a6f09af": Phase="Running", Reason="", readiness=true. Elapsed: 4.024678764s
Apr 25 19:45:13.433: INFO: Pod "client-containers-99ab4085-42d6-4c0f-851b-73454a6f09af" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 25 19:45:13.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6964" for this suite. 04/25/23 19:45:13.532
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":31,"skipped":562,"failed":0}
------------------------------
• [4.224 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:45:09.326
    Apr 25 19:45:09.326: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename containers 04/25/23 19:45:09.328
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:45:09.373
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:45:09.381
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Apr 25 19:45:09.408: INFO: Waiting up to 5m0s for pod "client-containers-99ab4085-42d6-4c0f-851b-73454a6f09af" in namespace "containers-6964" to be "running"
    Apr 25 19:45:09.422: INFO: Pod "client-containers-99ab4085-42d6-4c0f-851b-73454a6f09af": Phase="Pending", Reason="", readiness=false. Elapsed: 14.038349ms
    Apr 25 19:45:11.438: INFO: Pod "client-containers-99ab4085-42d6-4c0f-851b-73454a6f09af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029774449s
    Apr 25 19:45:13.433: INFO: Pod "client-containers-99ab4085-42d6-4c0f-851b-73454a6f09af": Phase="Running", Reason="", readiness=true. Elapsed: 4.024678764s
    Apr 25 19:45:13.433: INFO: Pod "client-containers-99ab4085-42d6-4c0f-851b-73454a6f09af" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 25 19:45:13.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-6964" for this suite. 04/25/23 19:45:13.532
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:45:13.56
Apr 25 19:45:13.561: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 19:45:13.563
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:45:13.623
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:45:13.631
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 04/25/23 19:45:13.64
Apr 25 19:45:13.641: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 19:45:16.753: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 19:45:30.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-78" for this suite. 04/25/23 19:45:30.268
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":32,"skipped":568,"failed":0}
------------------------------
• [SLOW TEST] [16.755 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:45:13.56
    Apr 25 19:45:13.561: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 19:45:13.563
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:45:13.623
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:45:13.631
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 04/25/23 19:45:13.64
    Apr 25 19:45:13.641: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 19:45:16.753: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 19:45:30.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-78" for this suite. 04/25/23 19:45:30.268
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:45:30.32
Apr 25 19:45:30.320: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename svcaccounts 04/25/23 19:45:30.323
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:45:30.371
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:45:30.383
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Apr 25 19:45:30.440: INFO: Waiting up to 5m0s for pod "pod-service-account-1a7b14e7-1673-481d-b143-fbb97a9c8e6b" in namespace "svcaccounts-2257" to be "running"
Apr 25 19:45:30.452: INFO: Pod "pod-service-account-1a7b14e7-1673-481d-b143-fbb97a9c8e6b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.094766ms
Apr 25 19:45:32.466: INFO: Pod "pod-service-account-1a7b14e7-1673-481d-b143-fbb97a9c8e6b": Phase="Running", Reason="", readiness=true. Elapsed: 2.025412249s
Apr 25 19:45:32.466: INFO: Pod "pod-service-account-1a7b14e7-1673-481d-b143-fbb97a9c8e6b" satisfied condition "running"
STEP: reading a file in the container 04/25/23 19:45:32.466
Apr 25 19:45:32.467: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2257 pod-service-account-1a7b14e7-1673-481d-b143-fbb97a9c8e6b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 04/25/23 19:45:32.866
Apr 25 19:45:32.867: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2257 pod-service-account-1a7b14e7-1673-481d-b143-fbb97a9c8e6b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 04/25/23 19:45:33.244
Apr 25 19:45:33.245: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2257 pod-service-account-1a7b14e7-1673-481d-b143-fbb97a9c8e6b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Apr 25 19:45:33.625: INFO: Got root ca configmap in namespace "svcaccounts-2257"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 25 19:45:33.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2257" for this suite. 04/25/23 19:45:33.65
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":33,"skipped":572,"failed":0}
------------------------------
• [3.363 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:45:30.32
    Apr 25 19:45:30.320: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename svcaccounts 04/25/23 19:45:30.323
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:45:30.371
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:45:30.383
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Apr 25 19:45:30.440: INFO: Waiting up to 5m0s for pod "pod-service-account-1a7b14e7-1673-481d-b143-fbb97a9c8e6b" in namespace "svcaccounts-2257" to be "running"
    Apr 25 19:45:30.452: INFO: Pod "pod-service-account-1a7b14e7-1673-481d-b143-fbb97a9c8e6b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.094766ms
    Apr 25 19:45:32.466: INFO: Pod "pod-service-account-1a7b14e7-1673-481d-b143-fbb97a9c8e6b": Phase="Running", Reason="", readiness=true. Elapsed: 2.025412249s
    Apr 25 19:45:32.466: INFO: Pod "pod-service-account-1a7b14e7-1673-481d-b143-fbb97a9c8e6b" satisfied condition "running"
    STEP: reading a file in the container 04/25/23 19:45:32.466
    Apr 25 19:45:32.467: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2257 pod-service-account-1a7b14e7-1673-481d-b143-fbb97a9c8e6b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 04/25/23 19:45:32.866
    Apr 25 19:45:32.867: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2257 pod-service-account-1a7b14e7-1673-481d-b143-fbb97a9c8e6b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 04/25/23 19:45:33.244
    Apr 25 19:45:33.245: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2257 pod-service-account-1a7b14e7-1673-481d-b143-fbb97a9c8e6b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Apr 25 19:45:33.625: INFO: Got root ca configmap in namespace "svcaccounts-2257"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 25 19:45:33.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2257" for this suite. 04/25/23 19:45:33.65
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:45:33.687
Apr 25 19:45:33.688: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename svcaccounts 04/25/23 19:45:33.691
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:45:33.739
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:45:33.751
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 04/25/23 19:45:33.763
STEP: watching for the ServiceAccount to be added 04/25/23 19:45:33.787
STEP: patching the ServiceAccount 04/25/23 19:45:33.792
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 04/25/23 19:45:33.806
STEP: deleting the ServiceAccount 04/25/23 19:45:33.818
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 25 19:45:33.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1225" for this suite. 04/25/23 19:45:33.87
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":34,"skipped":592,"failed":0}
------------------------------
• [0.203 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:45:33.687
    Apr 25 19:45:33.688: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename svcaccounts 04/25/23 19:45:33.691
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:45:33.739
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:45:33.751
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 04/25/23 19:45:33.763
    STEP: watching for the ServiceAccount to be added 04/25/23 19:45:33.787
    STEP: patching the ServiceAccount 04/25/23 19:45:33.792
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 04/25/23 19:45:33.806
    STEP: deleting the ServiceAccount 04/25/23 19:45:33.818
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 25 19:45:33.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-1225" for this suite. 04/25/23 19:45:33.87
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:45:33.894
Apr 25 19:45:33.895: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 19:45:33.898
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:45:33.941
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:45:33.951
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 19:45:33.998
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 19:45:34.244
STEP: Deploying the webhook pod 04/25/23 19:45:34.267
STEP: Wait for the deployment to be ready 04/25/23 19:45:34.303
Apr 25 19:45:34.328: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/25/23 19:45:36.37
STEP: Verifying the service has paired with the endpoint 04/25/23 19:45:36.406
Apr 25 19:45:37.406: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Apr 25 19:45:37.431: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4025-crds.webhook.example.com via the AdmissionRegistration API 04/25/23 19:45:37.965
STEP: Creating a custom resource while v1 is storage version 04/25/23 19:45:38.047
STEP: Patching Custom Resource Definition to set v2 as storage 04/25/23 19:45:40.196
STEP: Patching the custom resource while v2 is storage version 04/25/23 19:45:40.234
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 19:45:40.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3999" for this suite. 04/25/23 19:45:40.98
STEP: Destroying namespace "webhook-3999-markers" for this suite. 04/25/23 19:45:41.001
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":35,"skipped":595,"failed":0}
------------------------------
• [SLOW TEST] [7.248 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:45:33.894
    Apr 25 19:45:33.895: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 19:45:33.898
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:45:33.941
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:45:33.951
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 19:45:33.998
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 19:45:34.244
    STEP: Deploying the webhook pod 04/25/23 19:45:34.267
    STEP: Wait for the deployment to be ready 04/25/23 19:45:34.303
    Apr 25 19:45:34.328: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/25/23 19:45:36.37
    STEP: Verifying the service has paired with the endpoint 04/25/23 19:45:36.406
    Apr 25 19:45:37.406: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Apr 25 19:45:37.431: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4025-crds.webhook.example.com via the AdmissionRegistration API 04/25/23 19:45:37.965
    STEP: Creating a custom resource while v1 is storage version 04/25/23 19:45:38.047
    STEP: Patching Custom Resource Definition to set v2 as storage 04/25/23 19:45:40.196
    STEP: Patching the custom resource while v2 is storage version 04/25/23 19:45:40.234
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 19:45:40.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3999" for this suite. 04/25/23 19:45:40.98
    STEP: Destroying namespace "webhook-3999-markers" for this suite. 04/25/23 19:45:41.001
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:45:41.149
Apr 25 19:45:41.149: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubelet-test 04/25/23 19:45:41.151
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:45:41.202
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:45:41.214
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 25 19:45:41.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6482" for this suite. 04/25/23 19:45:41.323
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":36,"skipped":599,"failed":0}
------------------------------
• [0.196 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:45:41.149
    Apr 25 19:45:41.149: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubelet-test 04/25/23 19:45:41.151
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:45:41.202
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:45:41.214
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 25 19:45:41.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-6482" for this suite. 04/25/23 19:45:41.323
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:45:41.352
Apr 25 19:45:41.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename subpath 04/25/23 19:45:41.355
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:45:41.397
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:45:41.41
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/25/23 19:45:41.423
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-7r6m 04/25/23 19:45:41.451
STEP: Creating a pod to test atomic-volume-subpath 04/25/23 19:45:41.451
Apr 25 19:45:41.473: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-7r6m" in namespace "subpath-3092" to be "Succeeded or Failed"
Apr 25 19:45:41.487: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Pending", Reason="", readiness=false. Elapsed: 14.462531ms
Apr 25 19:45:43.502: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 2.029558275s
Apr 25 19:45:45.526: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 4.053215512s
Apr 25 19:45:47.501: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 6.028180726s
Apr 25 19:45:49.503: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 8.029780056s
Apr 25 19:45:51.501: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 10.028135522s
Apr 25 19:45:53.502: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 12.029255241s
Apr 25 19:45:55.503: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 14.030294605s
Apr 25 19:45:57.500: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 16.027560384s
Apr 25 19:45:59.522: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 18.04895031s
Apr 25 19:46:01.502: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 20.029372496s
Apr 25 19:46:03.515: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=false. Elapsed: 22.041851393s
Apr 25 19:46:05.501: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.028320125s
STEP: Saw pod success 04/25/23 19:46:05.502
Apr 25 19:46:05.503: INFO: Pod "pod-subpath-test-projected-7r6m" satisfied condition "Succeeded or Failed"
Apr 25 19:46:05.516: INFO: Trying to get logs from node 10.10.21.190 pod pod-subpath-test-projected-7r6m container test-container-subpath-projected-7r6m: <nil>
STEP: delete the pod 04/25/23 19:46:05.595
Apr 25 19:46:05.664: INFO: Waiting for pod pod-subpath-test-projected-7r6m to disappear
Apr 25 19:46:05.675: INFO: Pod pod-subpath-test-projected-7r6m no longer exists
STEP: Deleting pod pod-subpath-test-projected-7r6m 04/25/23 19:46:05.675
Apr 25 19:46:05.675: INFO: Deleting pod "pod-subpath-test-projected-7r6m" in namespace "subpath-3092"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 25 19:46:05.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3092" for this suite. 04/25/23 19:46:05.705
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":37,"skipped":629,"failed":0}
------------------------------
• [SLOW TEST] [24.373 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:45:41.352
    Apr 25 19:45:41.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename subpath 04/25/23 19:45:41.355
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:45:41.397
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:45:41.41
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/25/23 19:45:41.423
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-7r6m 04/25/23 19:45:41.451
    STEP: Creating a pod to test atomic-volume-subpath 04/25/23 19:45:41.451
    Apr 25 19:45:41.473: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-7r6m" in namespace "subpath-3092" to be "Succeeded or Failed"
    Apr 25 19:45:41.487: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Pending", Reason="", readiness=false. Elapsed: 14.462531ms
    Apr 25 19:45:43.502: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 2.029558275s
    Apr 25 19:45:45.526: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 4.053215512s
    Apr 25 19:45:47.501: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 6.028180726s
    Apr 25 19:45:49.503: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 8.029780056s
    Apr 25 19:45:51.501: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 10.028135522s
    Apr 25 19:45:53.502: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 12.029255241s
    Apr 25 19:45:55.503: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 14.030294605s
    Apr 25 19:45:57.500: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 16.027560384s
    Apr 25 19:45:59.522: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 18.04895031s
    Apr 25 19:46:01.502: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=true. Elapsed: 20.029372496s
    Apr 25 19:46:03.515: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Running", Reason="", readiness=false. Elapsed: 22.041851393s
    Apr 25 19:46:05.501: INFO: Pod "pod-subpath-test-projected-7r6m": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.028320125s
    STEP: Saw pod success 04/25/23 19:46:05.502
    Apr 25 19:46:05.503: INFO: Pod "pod-subpath-test-projected-7r6m" satisfied condition "Succeeded or Failed"
    Apr 25 19:46:05.516: INFO: Trying to get logs from node 10.10.21.190 pod pod-subpath-test-projected-7r6m container test-container-subpath-projected-7r6m: <nil>
    STEP: delete the pod 04/25/23 19:46:05.595
    Apr 25 19:46:05.664: INFO: Waiting for pod pod-subpath-test-projected-7r6m to disappear
    Apr 25 19:46:05.675: INFO: Pod pod-subpath-test-projected-7r6m no longer exists
    STEP: Deleting pod pod-subpath-test-projected-7r6m 04/25/23 19:46:05.675
    Apr 25 19:46:05.675: INFO: Deleting pod "pod-subpath-test-projected-7r6m" in namespace "subpath-3092"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 25 19:46:05.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-3092" for this suite. 04/25/23 19:46:05.705
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:46:05.741
Apr 25 19:46:05.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename configmap 04/25/23 19:46:05.742
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:05.81
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:05.821
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-491/configmap-test-9ba5a968-e6ee-4f21-9f37-2914bd387650 04/25/23 19:46:05.835
STEP: Creating a pod to test consume configMaps 04/25/23 19:46:05.85
Apr 25 19:46:05.890: INFO: Waiting up to 5m0s for pod "pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b" in namespace "configmap-491" to be "Succeeded or Failed"
Apr 25 19:46:05.930: INFO: Pod "pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b": Phase="Pending", Reason="", readiness=false. Elapsed: 39.922986ms
Apr 25 19:46:07.943: INFO: Pod "pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053108796s
Apr 25 19:46:09.945: INFO: Pod "pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05482562s
Apr 25 19:46:11.943: INFO: Pod "pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.053417479s
STEP: Saw pod success 04/25/23 19:46:11.943
Apr 25 19:46:11.943: INFO: Pod "pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b" satisfied condition "Succeeded or Failed"
Apr 25 19:46:11.957: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b container env-test: <nil>
STEP: delete the pod 04/25/23 19:46:11.99
Apr 25 19:46:12.066: INFO: Waiting for pod pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b to disappear
Apr 25 19:46:12.080: INFO: Pod pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 25 19:46:12.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-491" for this suite. 04/25/23 19:46:12.097
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":38,"skipped":649,"failed":0}
------------------------------
• [SLOW TEST] [6.374 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:46:05.741
    Apr 25 19:46:05.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename configmap 04/25/23 19:46:05.742
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:05.81
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:05.821
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-491/configmap-test-9ba5a968-e6ee-4f21-9f37-2914bd387650 04/25/23 19:46:05.835
    STEP: Creating a pod to test consume configMaps 04/25/23 19:46:05.85
    Apr 25 19:46:05.890: INFO: Waiting up to 5m0s for pod "pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b" in namespace "configmap-491" to be "Succeeded or Failed"
    Apr 25 19:46:05.930: INFO: Pod "pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b": Phase="Pending", Reason="", readiness=false. Elapsed: 39.922986ms
    Apr 25 19:46:07.943: INFO: Pod "pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053108796s
    Apr 25 19:46:09.945: INFO: Pod "pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05482562s
    Apr 25 19:46:11.943: INFO: Pod "pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.053417479s
    STEP: Saw pod success 04/25/23 19:46:11.943
    Apr 25 19:46:11.943: INFO: Pod "pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b" satisfied condition "Succeeded or Failed"
    Apr 25 19:46:11.957: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b container env-test: <nil>
    STEP: delete the pod 04/25/23 19:46:11.99
    Apr 25 19:46:12.066: INFO: Waiting for pod pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b to disappear
    Apr 25 19:46:12.080: INFO: Pod pod-configmaps-264e7d48-cde3-446b-b8bc-d74fdb69197b no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 25 19:46:12.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-491" for this suite. 04/25/23 19:46:12.097
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:46:12.12
Apr 25 19:46:12.121: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir 04/25/23 19:46:12.124
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:12.169
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:12.181
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 04/25/23 19:46:12.192
Apr 25 19:46:12.217: INFO: Waiting up to 5m0s for pod "pod-9885b897-a691-4a1f-9701-063ff37ceed1" in namespace "emptydir-8921" to be "Succeeded or Failed"
Apr 25 19:46:12.235: INFO: Pod "pod-9885b897-a691-4a1f-9701-063ff37ceed1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.803331ms
Apr 25 19:46:14.250: INFO: Pod "pod-9885b897-a691-4a1f-9701-063ff37ceed1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033061572s
Apr 25 19:46:16.251: INFO: Pod "pod-9885b897-a691-4a1f-9701-063ff37ceed1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033507526s
STEP: Saw pod success 04/25/23 19:46:16.251
Apr 25 19:46:16.251: INFO: Pod "pod-9885b897-a691-4a1f-9701-063ff37ceed1" satisfied condition "Succeeded or Failed"
Apr 25 19:46:16.264: INFO: Trying to get logs from node 10.10.21.190 pod pod-9885b897-a691-4a1f-9701-063ff37ceed1 container test-container: <nil>
STEP: delete the pod 04/25/23 19:46:16.301
Apr 25 19:46:16.342: INFO: Waiting for pod pod-9885b897-a691-4a1f-9701-063ff37ceed1 to disappear
Apr 25 19:46:16.355: INFO: Pod pod-9885b897-a691-4a1f-9701-063ff37ceed1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 25 19:46:16.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8921" for this suite. 04/25/23 19:46:16.374
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":39,"skipped":664,"failed":0}
------------------------------
• [4.274 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:46:12.12
    Apr 25 19:46:12.121: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir 04/25/23 19:46:12.124
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:12.169
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:12.181
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 04/25/23 19:46:12.192
    Apr 25 19:46:12.217: INFO: Waiting up to 5m0s for pod "pod-9885b897-a691-4a1f-9701-063ff37ceed1" in namespace "emptydir-8921" to be "Succeeded or Failed"
    Apr 25 19:46:12.235: INFO: Pod "pod-9885b897-a691-4a1f-9701-063ff37ceed1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.803331ms
    Apr 25 19:46:14.250: INFO: Pod "pod-9885b897-a691-4a1f-9701-063ff37ceed1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033061572s
    Apr 25 19:46:16.251: INFO: Pod "pod-9885b897-a691-4a1f-9701-063ff37ceed1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033507526s
    STEP: Saw pod success 04/25/23 19:46:16.251
    Apr 25 19:46:16.251: INFO: Pod "pod-9885b897-a691-4a1f-9701-063ff37ceed1" satisfied condition "Succeeded or Failed"
    Apr 25 19:46:16.264: INFO: Trying to get logs from node 10.10.21.190 pod pod-9885b897-a691-4a1f-9701-063ff37ceed1 container test-container: <nil>
    STEP: delete the pod 04/25/23 19:46:16.301
    Apr 25 19:46:16.342: INFO: Waiting for pod pod-9885b897-a691-4a1f-9701-063ff37ceed1 to disappear
    Apr 25 19:46:16.355: INFO: Pod pod-9885b897-a691-4a1f-9701-063ff37ceed1 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 25 19:46:16.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8921" for this suite. 04/25/23 19:46:16.374
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:46:16.404
Apr 25 19:46:16.404: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 19:46:16.405
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:16.454
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:16.465
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/25/23 19:46:16.478
Apr 25 19:46:16.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-6785 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Apr 25 19:46:16.627: INFO: stderr: ""
Apr 25 19:46:16.627: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 04/25/23 19:46:16.627
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Apr 25 19:46:16.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-6785 delete pods e2e-test-httpd-pod'
Apr 25 19:46:19.115: INFO: stderr: ""
Apr 25 19:46:19.115: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 19:46:19.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6785" for this suite. 04/25/23 19:46:19.137
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":40,"skipped":698,"failed":0}
------------------------------
• [2.755 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:46:16.404
    Apr 25 19:46:16.404: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 19:46:16.405
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:16.454
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:16.465
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/25/23 19:46:16.478
    Apr 25 19:46:16.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-6785 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Apr 25 19:46:16.627: INFO: stderr: ""
    Apr 25 19:46:16.627: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 04/25/23 19:46:16.627
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Apr 25 19:46:16.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-6785 delete pods e2e-test-httpd-pod'
    Apr 25 19:46:19.115: INFO: stderr: ""
    Apr 25 19:46:19.115: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 19:46:19.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6785" for this suite. 04/25/23 19:46:19.137
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:46:19.178
Apr 25 19:46:19.179: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename ingress 04/25/23 19:46:19.18
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:19.24
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:19.251
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 04/25/23 19:46:19.263
STEP: getting /apis/networking.k8s.io 04/25/23 19:46:19.273
STEP: getting /apis/networking.k8s.iov1 04/25/23 19:46:19.279
STEP: creating 04/25/23 19:46:19.285
STEP: getting 04/25/23 19:46:19.367
STEP: listing 04/25/23 19:46:19.408
STEP: watching 04/25/23 19:46:19.422
Apr 25 19:46:19.422: INFO: starting watch
STEP: cluster-wide listing 04/25/23 19:46:19.427
STEP: cluster-wide watching 04/25/23 19:46:19.439
Apr 25 19:46:19.439: INFO: starting watch
STEP: patching 04/25/23 19:46:19.444
STEP: updating 04/25/23 19:46:19.475
Apr 25 19:46:19.504: INFO: waiting for watch events with expected annotations
Apr 25 19:46:19.504: INFO: saw patched and updated annotations
STEP: patching /status 04/25/23 19:46:19.504
STEP: updating /status 04/25/23 19:46:19.518
STEP: get /status 04/25/23 19:46:19.54
STEP: deleting 04/25/23 19:46:19.551
STEP: deleting a collection 04/25/23 19:46:19.64
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Apr 25 19:46:19.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-8739" for this suite. 04/25/23 19:46:19.711
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":41,"skipped":776,"failed":0}
------------------------------
• [0.555 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:46:19.178
    Apr 25 19:46:19.179: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename ingress 04/25/23 19:46:19.18
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:19.24
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:19.251
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 04/25/23 19:46:19.263
    STEP: getting /apis/networking.k8s.io 04/25/23 19:46:19.273
    STEP: getting /apis/networking.k8s.iov1 04/25/23 19:46:19.279
    STEP: creating 04/25/23 19:46:19.285
    STEP: getting 04/25/23 19:46:19.367
    STEP: listing 04/25/23 19:46:19.408
    STEP: watching 04/25/23 19:46:19.422
    Apr 25 19:46:19.422: INFO: starting watch
    STEP: cluster-wide listing 04/25/23 19:46:19.427
    STEP: cluster-wide watching 04/25/23 19:46:19.439
    Apr 25 19:46:19.439: INFO: starting watch
    STEP: patching 04/25/23 19:46:19.444
    STEP: updating 04/25/23 19:46:19.475
    Apr 25 19:46:19.504: INFO: waiting for watch events with expected annotations
    Apr 25 19:46:19.504: INFO: saw patched and updated annotations
    STEP: patching /status 04/25/23 19:46:19.504
    STEP: updating /status 04/25/23 19:46:19.518
    STEP: get /status 04/25/23 19:46:19.54
    STEP: deleting 04/25/23 19:46:19.551
    STEP: deleting a collection 04/25/23 19:46:19.64
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Apr 25 19:46:19.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-8739" for this suite. 04/25/23 19:46:19.711
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:46:19.733
Apr 25 19:46:19.733: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename daemonsets 04/25/23 19:46:19.736
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:19.784
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:19.799
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 04/25/23 19:46:19.884
STEP: Check that daemon pods launch on every node of the cluster. 04/25/23 19:46:19.898
Apr 25 19:46:19.930: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 19:46:19.930: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 19:46:20.981: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 19:46:20.981: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 19:46:21.984: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 25 19:46:21.984: INFO: Node 10.10.21.161 is running 0 daemon pod, expected 1
Apr 25 19:46:22.976: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 25 19:46:22.976: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 04/25/23 19:46:22.987
Apr 25 19:46:23.049: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 25 19:46:23.049: INFO: Node 10.10.21.190 is running 0 daemon pod, expected 1
Apr 25 19:46:24.082: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 25 19:46:24.082: INFO: Node 10.10.21.190 is running 0 daemon pod, expected 1
Apr 25 19:46:25.081: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 25 19:46:25.081: INFO: Node 10.10.21.190 is running 0 daemon pod, expected 1
Apr 25 19:46:26.085: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 25 19:46:26.085: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 04/25/23 19:46:26.085
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/25/23 19:46:26.117
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2220, will wait for the garbage collector to delete the pods 04/25/23 19:46:26.119
Apr 25 19:46:26.200: INFO: Deleting DaemonSet.extensions daemon-set took: 17.5999ms
Apr 25 19:46:26.501: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.592571ms
Apr 25 19:46:28.314: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 19:46:28.314: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 25 19:46:28.333: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19861"},"items":null}

Apr 25 19:46:28.345: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19861"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 25 19:46:28.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2220" for this suite. 04/25/23 19:46:28.443
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":42,"skipped":779,"failed":0}
------------------------------
• [SLOW TEST] [8.728 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:46:19.733
    Apr 25 19:46:19.733: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename daemonsets 04/25/23 19:46:19.736
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:19.784
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:19.799
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 04/25/23 19:46:19.884
    STEP: Check that daemon pods launch on every node of the cluster. 04/25/23 19:46:19.898
    Apr 25 19:46:19.930: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 19:46:19.930: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 19:46:20.981: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 19:46:20.981: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 19:46:21.984: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 25 19:46:21.984: INFO: Node 10.10.21.161 is running 0 daemon pod, expected 1
    Apr 25 19:46:22.976: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 25 19:46:22.976: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 04/25/23 19:46:22.987
    Apr 25 19:46:23.049: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 25 19:46:23.049: INFO: Node 10.10.21.190 is running 0 daemon pod, expected 1
    Apr 25 19:46:24.082: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 25 19:46:24.082: INFO: Node 10.10.21.190 is running 0 daemon pod, expected 1
    Apr 25 19:46:25.081: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 25 19:46:25.081: INFO: Node 10.10.21.190 is running 0 daemon pod, expected 1
    Apr 25 19:46:26.085: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 25 19:46:26.085: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 04/25/23 19:46:26.085
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/25/23 19:46:26.117
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2220, will wait for the garbage collector to delete the pods 04/25/23 19:46:26.119
    Apr 25 19:46:26.200: INFO: Deleting DaemonSet.extensions daemon-set took: 17.5999ms
    Apr 25 19:46:26.501: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.592571ms
    Apr 25 19:46:28.314: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 19:46:28.314: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 25 19:46:28.333: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19861"},"items":null}

    Apr 25 19:46:28.345: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19861"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 19:46:28.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-2220" for this suite. 04/25/23 19:46:28.443
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:46:28.465
Apr 25 19:46:28.467: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename gc 04/25/23 19:46:28.47
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:28.513
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:28.524
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Apr 25 19:46:28.610: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"53aac0e2-dc3f-44c4-8c61-e0d3e9ee67a2", Controller:(*bool)(0xc003b1ffe6), BlockOwnerDeletion:(*bool)(0xc003b1ffe7)}}
Apr 25 19:46:28.643: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"f9b7e7b3-a21d-4ab3-855d-d6d42b53a657", Controller:(*bool)(0xc003c9c456), BlockOwnerDeletion:(*bool)(0xc003c9c457)}}
Apr 25 19:46:28.697: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"39cc05e8-61d3-4c97-a1e8-c1b5c69ef66a", Controller:(*bool)(0xc0034c1a0e), BlockOwnerDeletion:(*bool)(0xc0034c1a0f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 25 19:46:33.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-312" for this suite. 04/25/23 19:46:33.75
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":43,"skipped":782,"failed":0}
------------------------------
• [SLOW TEST] [5.312 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:46:28.465
    Apr 25 19:46:28.467: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename gc 04/25/23 19:46:28.47
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:28.513
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:28.524
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Apr 25 19:46:28.610: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"53aac0e2-dc3f-44c4-8c61-e0d3e9ee67a2", Controller:(*bool)(0xc003b1ffe6), BlockOwnerDeletion:(*bool)(0xc003b1ffe7)}}
    Apr 25 19:46:28.643: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"f9b7e7b3-a21d-4ab3-855d-d6d42b53a657", Controller:(*bool)(0xc003c9c456), BlockOwnerDeletion:(*bool)(0xc003c9c457)}}
    Apr 25 19:46:28.697: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"39cc05e8-61d3-4c97-a1e8-c1b5c69ef66a", Controller:(*bool)(0xc0034c1a0e), BlockOwnerDeletion:(*bool)(0xc0034c1a0f)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 25 19:46:33.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-312" for this suite. 04/25/23 19:46:33.75
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:46:33.788
Apr 25 19:46:33.789: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 19:46:33.792
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:33.842
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:33.851
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 19:46:33.894
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 19:46:34.21
STEP: Deploying the webhook pod 04/25/23 19:46:34.242
STEP: Wait for the deployment to be ready 04/25/23 19:46:34.273
Apr 25 19:46:34.310: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/25/23 19:46:36.346
STEP: Verifying the service has paired with the endpoint 04/25/23 19:46:36.376
Apr 25 19:46:37.379: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 04/25/23 19:46:37.392
STEP: create a configmap that should be updated by the webhook 04/25/23 19:46:37.47
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 19:46:37.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3834" for this suite. 04/25/23 19:46:37.59
STEP: Destroying namespace "webhook-3834-markers" for this suite. 04/25/23 19:46:37.609
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":44,"skipped":785,"failed":0}
------------------------------
• [4.019 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:46:33.788
    Apr 25 19:46:33.789: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 19:46:33.792
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:33.842
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:33.851
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 19:46:33.894
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 19:46:34.21
    STEP: Deploying the webhook pod 04/25/23 19:46:34.242
    STEP: Wait for the deployment to be ready 04/25/23 19:46:34.273
    Apr 25 19:46:34.310: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/25/23 19:46:36.346
    STEP: Verifying the service has paired with the endpoint 04/25/23 19:46:36.376
    Apr 25 19:46:37.379: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 04/25/23 19:46:37.392
    STEP: create a configmap that should be updated by the webhook 04/25/23 19:46:37.47
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 19:46:37.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3834" for this suite. 04/25/23 19:46:37.59
    STEP: Destroying namespace "webhook-3834-markers" for this suite. 04/25/23 19:46:37.609
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:46:37.819
Apr 25 19:46:37.819: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 19:46:37.821
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:37.874
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:37.884
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 04/25/23 19:46:37.894
Apr 25 19:46:37.922: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239" in namespace "downward-api-2992" to be "Succeeded or Failed"
Apr 25 19:46:37.933: INFO: Pod "downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239": Phase="Pending", Reason="", readiness=false. Elapsed: 11.222709ms
Apr 25 19:46:39.945: INFO: Pod "downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023249184s
Apr 25 19:46:41.945: INFO: Pod "downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022741951s
STEP: Saw pod success 04/25/23 19:46:41.945
Apr 25 19:46:41.945: INFO: Pod "downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239" satisfied condition "Succeeded or Failed"
Apr 25 19:46:41.961: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239 container client-container: <nil>
STEP: delete the pod 04/25/23 19:46:41.992
Apr 25 19:46:42.020: INFO: Waiting for pod downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239 to disappear
Apr 25 19:46:42.031: INFO: Pod downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 25 19:46:42.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2992" for this suite. 04/25/23 19:46:42.051
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":45,"skipped":795,"failed":0}
------------------------------
• [4.250 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:46:37.819
    Apr 25 19:46:37.819: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 19:46:37.821
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:37.874
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:37.884
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 04/25/23 19:46:37.894
    Apr 25 19:46:37.922: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239" in namespace "downward-api-2992" to be "Succeeded or Failed"
    Apr 25 19:46:37.933: INFO: Pod "downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239": Phase="Pending", Reason="", readiness=false. Elapsed: 11.222709ms
    Apr 25 19:46:39.945: INFO: Pod "downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023249184s
    Apr 25 19:46:41.945: INFO: Pod "downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022741951s
    STEP: Saw pod success 04/25/23 19:46:41.945
    Apr 25 19:46:41.945: INFO: Pod "downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239" satisfied condition "Succeeded or Failed"
    Apr 25 19:46:41.961: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239 container client-container: <nil>
    STEP: delete the pod 04/25/23 19:46:41.992
    Apr 25 19:46:42.020: INFO: Waiting for pod downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239 to disappear
    Apr 25 19:46:42.031: INFO: Pod downwardapi-volume-9ca24e5b-c7d2-4af0-ad66-d802678ba239 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 25 19:46:42.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2992" for this suite. 04/25/23 19:46:42.051
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:46:42.081
Apr 25 19:46:42.082: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename namespaces 04/25/23 19:46:42.085
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:42.146
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:42.153
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 04/25/23 19:46:42.162
STEP: patching the Namespace 04/25/23 19:46:42.205
STEP: get the Namespace and ensuring it has the label 04/25/23 19:46:42.221
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 25 19:46:42.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6360" for this suite. 04/25/23 19:46:42.248
STEP: Destroying namespace "nspatchtest-4eb8ce13-fbce-4721-8b6f-8b8dea15d022-942" for this suite. 04/25/23 19:46:42.27
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":46,"skipped":832,"failed":0}
------------------------------
• [0.209 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:46:42.081
    Apr 25 19:46:42.082: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename namespaces 04/25/23 19:46:42.085
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:42.146
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:42.153
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 04/25/23 19:46:42.162
    STEP: patching the Namespace 04/25/23 19:46:42.205
    STEP: get the Namespace and ensuring it has the label 04/25/23 19:46:42.221
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 19:46:42.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-6360" for this suite. 04/25/23 19:46:42.248
    STEP: Destroying namespace "nspatchtest-4eb8ce13-fbce-4721-8b6f-8b8dea15d022-942" for this suite. 04/25/23 19:46:42.27
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:46:42.301
Apr 25 19:46:42.301: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename security-context-test 04/25/23 19:46:42.303
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:42.346
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:42.355
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Apr 25 19:46:42.410: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-20a43e45-ab41-45d0-82b2-0d5ffa6d4328" in namespace "security-context-test-8210" to be "Succeeded or Failed"
Apr 25 19:46:42.421: INFO: Pod "alpine-nnp-false-20a43e45-ab41-45d0-82b2-0d5ffa6d4328": Phase="Pending", Reason="", readiness=false. Elapsed: 10.482542ms
Apr 25 19:46:44.433: INFO: Pod "alpine-nnp-false-20a43e45-ab41-45d0-82b2-0d5ffa6d4328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022213209s
Apr 25 19:46:46.436: INFO: Pod "alpine-nnp-false-20a43e45-ab41-45d0-82b2-0d5ffa6d4328": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025181783s
Apr 25 19:46:48.432: INFO: Pod "alpine-nnp-false-20a43e45-ab41-45d0-82b2-0d5ffa6d4328": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021120521s
Apr 25 19:46:50.434: INFO: Pod "alpine-nnp-false-20a43e45-ab41-45d0-82b2-0d5ffa6d4328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.022990194s
Apr 25 19:46:50.434: INFO: Pod "alpine-nnp-false-20a43e45-ab41-45d0-82b2-0d5ffa6d4328" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 25 19:46:50.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8210" for this suite. 04/25/23 19:46:50.483
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":47,"skipped":841,"failed":0}
------------------------------
• [SLOW TEST] [8.200 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:46:42.301
    Apr 25 19:46:42.301: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename security-context-test 04/25/23 19:46:42.303
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:42.346
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:42.355
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Apr 25 19:46:42.410: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-20a43e45-ab41-45d0-82b2-0d5ffa6d4328" in namespace "security-context-test-8210" to be "Succeeded or Failed"
    Apr 25 19:46:42.421: INFO: Pod "alpine-nnp-false-20a43e45-ab41-45d0-82b2-0d5ffa6d4328": Phase="Pending", Reason="", readiness=false. Elapsed: 10.482542ms
    Apr 25 19:46:44.433: INFO: Pod "alpine-nnp-false-20a43e45-ab41-45d0-82b2-0d5ffa6d4328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022213209s
    Apr 25 19:46:46.436: INFO: Pod "alpine-nnp-false-20a43e45-ab41-45d0-82b2-0d5ffa6d4328": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025181783s
    Apr 25 19:46:48.432: INFO: Pod "alpine-nnp-false-20a43e45-ab41-45d0-82b2-0d5ffa6d4328": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021120521s
    Apr 25 19:46:50.434: INFO: Pod "alpine-nnp-false-20a43e45-ab41-45d0-82b2-0d5ffa6d4328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.022990194s
    Apr 25 19:46:50.434: INFO: Pod "alpine-nnp-false-20a43e45-ab41-45d0-82b2-0d5ffa6d4328" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 25 19:46:50.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-8210" for this suite. 04/25/23 19:46:50.483
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:46:50.521
Apr 25 19:46:50.522: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename secrets 04/25/23 19:46:50.524
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:50.579
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:50.588
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-56dcf356-7c40-44be-97cb-5da32ff0702a 04/25/23 19:46:50.598
STEP: Creating a pod to test consume secrets 04/25/23 19:46:50.614
Apr 25 19:46:50.636: INFO: Waiting up to 5m0s for pod "pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d" in namespace "secrets-4717" to be "Succeeded or Failed"
Apr 25 19:46:50.652: INFO: Pod "pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d": Phase="Pending", Reason="", readiness=false. Elapsed: 15.731586ms
Apr 25 19:46:52.666: INFO: Pod "pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03013787s
Apr 25 19:46:54.666: INFO: Pod "pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029622896s
STEP: Saw pod success 04/25/23 19:46:54.666
Apr 25 19:46:54.667: INFO: Pod "pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d" satisfied condition "Succeeded or Failed"
Apr 25 19:46:54.678: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d container secret-volume-test: <nil>
STEP: delete the pod 04/25/23 19:46:54.73
Apr 25 19:46:54.803: INFO: Waiting for pod pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d to disappear
Apr 25 19:46:54.815: INFO: Pod pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 25 19:46:54.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4717" for this suite. 04/25/23 19:46:54.832
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":48,"skipped":885,"failed":0}
------------------------------
• [4.329 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:46:50.521
    Apr 25 19:46:50.522: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename secrets 04/25/23 19:46:50.524
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:50.579
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:50.588
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-56dcf356-7c40-44be-97cb-5da32ff0702a 04/25/23 19:46:50.598
    STEP: Creating a pod to test consume secrets 04/25/23 19:46:50.614
    Apr 25 19:46:50.636: INFO: Waiting up to 5m0s for pod "pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d" in namespace "secrets-4717" to be "Succeeded or Failed"
    Apr 25 19:46:50.652: INFO: Pod "pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d": Phase="Pending", Reason="", readiness=false. Elapsed: 15.731586ms
    Apr 25 19:46:52.666: INFO: Pod "pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03013787s
    Apr 25 19:46:54.666: INFO: Pod "pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029622896s
    STEP: Saw pod success 04/25/23 19:46:54.666
    Apr 25 19:46:54.667: INFO: Pod "pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d" satisfied condition "Succeeded or Failed"
    Apr 25 19:46:54.678: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d container secret-volume-test: <nil>
    STEP: delete the pod 04/25/23 19:46:54.73
    Apr 25 19:46:54.803: INFO: Waiting for pod pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d to disappear
    Apr 25 19:46:54.815: INFO: Pod pod-secrets-958f9965-5af6-49d4-93dc-f20070f8ee4d no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 25 19:46:54.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4717" for this suite. 04/25/23 19:46:54.832
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:46:54.861
Apr 25 19:46:54.861: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename crd-webhook 04/25/23 19:46:54.863
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:54.914
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:54.923
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 04/25/23 19:46:54.934
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/25/23 19:46:55.356
STEP: Deploying the custom resource conversion webhook pod 04/25/23 19:46:55.369
STEP: Wait for the deployment to be ready 04/25/23 19:46:55.403
Apr 25 19:46:55.439: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/25/23 19:46:57.489
STEP: Verifying the service has paired with the endpoint 04/25/23 19:46:57.532
Apr 25 19:46:58.533: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Apr 25 19:46:58.553: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Creating a v1 custom resource 04/25/23 19:47:01.313
STEP: Create a v2 custom resource 04/25/23 19:47:01.353
STEP: List CRs in v1 04/25/23 19:47:01.495
STEP: List CRs in v2 04/25/23 19:47:01.519
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 19:47:02.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-366" for this suite. 04/25/23 19:47:02.105
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":49,"skipped":916,"failed":0}
------------------------------
• [SLOW TEST] [7.446 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:46:54.861
    Apr 25 19:46:54.861: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename crd-webhook 04/25/23 19:46:54.863
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:46:54.914
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:46:54.923
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 04/25/23 19:46:54.934
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/25/23 19:46:55.356
    STEP: Deploying the custom resource conversion webhook pod 04/25/23 19:46:55.369
    STEP: Wait for the deployment to be ready 04/25/23 19:46:55.403
    Apr 25 19:46:55.439: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/25/23 19:46:57.489
    STEP: Verifying the service has paired with the endpoint 04/25/23 19:46:57.532
    Apr 25 19:46:58.533: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Apr 25 19:46:58.553: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Creating a v1 custom resource 04/25/23 19:47:01.313
    STEP: Create a v2 custom resource 04/25/23 19:47:01.353
    STEP: List CRs in v1 04/25/23 19:47:01.495
    STEP: List CRs in v2 04/25/23 19:47:01.519
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 19:47:02.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-366" for this suite. 04/25/23 19:47:02.105
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:47:02.316
Apr 25 19:47:02.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename secrets 04/25/23 19:47:02.317
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:47:02.382
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:47:02.392
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-8905e301-68f1-41cd-a3d2-83ca9844b624 04/25/23 19:47:02.437
STEP: Creating secret with name s-test-opt-upd-1fb79f9b-e3cb-4425-98c2-f1244800f33c 04/25/23 19:47:02.476
STEP: Creating the pod 04/25/23 19:47:02.491
Apr 25 19:47:02.785: INFO: Waiting up to 5m0s for pod "pod-secrets-56f9b0e0-8373-48cd-bdab-5f58f47ad360" in namespace "secrets-1767" to be "running and ready"
Apr 25 19:47:02.815: INFO: Pod "pod-secrets-56f9b0e0-8373-48cd-bdab-5f58f47ad360": Phase="Pending", Reason="", readiness=false. Elapsed: 30.277475ms
Apr 25 19:47:02.815: INFO: The phase of Pod pod-secrets-56f9b0e0-8373-48cd-bdab-5f58f47ad360 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 19:47:04.829: INFO: Pod "pod-secrets-56f9b0e0-8373-48cd-bdab-5f58f47ad360": Phase="Running", Reason="", readiness=true. Elapsed: 2.043613196s
Apr 25 19:47:04.829: INFO: The phase of Pod pod-secrets-56f9b0e0-8373-48cd-bdab-5f58f47ad360 is Running (Ready = true)
Apr 25 19:47:04.829: INFO: Pod "pod-secrets-56f9b0e0-8373-48cd-bdab-5f58f47ad360" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-8905e301-68f1-41cd-a3d2-83ca9844b624 04/25/23 19:47:04.931
STEP: Updating secret s-test-opt-upd-1fb79f9b-e3cb-4425-98c2-f1244800f33c 04/25/23 19:47:04.952
STEP: Creating secret with name s-test-opt-create-4bd59c79-9679-40a9-a71c-be91d8a17d71 04/25/23 19:47:04.966
STEP: waiting to observe update in volume 04/25/23 19:47:04.981
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 25 19:47:07.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1767" for this suite. 04/25/23 19:47:07.131
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":50,"skipped":924,"failed":0}
------------------------------
• [4.857 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:47:02.316
    Apr 25 19:47:02.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename secrets 04/25/23 19:47:02.317
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:47:02.382
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:47:02.392
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-8905e301-68f1-41cd-a3d2-83ca9844b624 04/25/23 19:47:02.437
    STEP: Creating secret with name s-test-opt-upd-1fb79f9b-e3cb-4425-98c2-f1244800f33c 04/25/23 19:47:02.476
    STEP: Creating the pod 04/25/23 19:47:02.491
    Apr 25 19:47:02.785: INFO: Waiting up to 5m0s for pod "pod-secrets-56f9b0e0-8373-48cd-bdab-5f58f47ad360" in namespace "secrets-1767" to be "running and ready"
    Apr 25 19:47:02.815: INFO: Pod "pod-secrets-56f9b0e0-8373-48cd-bdab-5f58f47ad360": Phase="Pending", Reason="", readiness=false. Elapsed: 30.277475ms
    Apr 25 19:47:02.815: INFO: The phase of Pod pod-secrets-56f9b0e0-8373-48cd-bdab-5f58f47ad360 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 19:47:04.829: INFO: Pod "pod-secrets-56f9b0e0-8373-48cd-bdab-5f58f47ad360": Phase="Running", Reason="", readiness=true. Elapsed: 2.043613196s
    Apr 25 19:47:04.829: INFO: The phase of Pod pod-secrets-56f9b0e0-8373-48cd-bdab-5f58f47ad360 is Running (Ready = true)
    Apr 25 19:47:04.829: INFO: Pod "pod-secrets-56f9b0e0-8373-48cd-bdab-5f58f47ad360" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-8905e301-68f1-41cd-a3d2-83ca9844b624 04/25/23 19:47:04.931
    STEP: Updating secret s-test-opt-upd-1fb79f9b-e3cb-4425-98c2-f1244800f33c 04/25/23 19:47:04.952
    STEP: Creating secret with name s-test-opt-create-4bd59c79-9679-40a9-a71c-be91d8a17d71 04/25/23 19:47:04.966
    STEP: waiting to observe update in volume 04/25/23 19:47:04.981
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 25 19:47:07.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1767" for this suite. 04/25/23 19:47:07.131
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2216
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:47:07.176
Apr 25 19:47:07.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 19:47:07.178
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:47:07.231
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:47:07.242
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2216
STEP: creating service in namespace services-3136 04/25/23 19:47:07.252
STEP: creating service affinity-nodeport-transition in namespace services-3136 04/25/23 19:47:07.252
STEP: creating replication controller affinity-nodeport-transition in namespace services-3136 04/25/23 19:47:07.318
I0425 19:47:07.354885      23 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-3136, replica count: 3
I0425 19:47:10.405954      23 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0425 19:47:13.406270      23 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0425 19:47:16.407534      23 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 25 19:47:16.447: INFO: Creating new exec pod
Apr 25 19:47:16.472: INFO: Waiting up to 5m0s for pod "execpod-affinitym8x8w" in namespace "services-3136" to be "running"
Apr 25 19:47:16.482: INFO: Pod "execpod-affinitym8x8w": Phase="Pending", Reason="", readiness=false. Elapsed: 10.542759ms
Apr 25 19:47:18.496: INFO: Pod "execpod-affinitym8x8w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024025868s
Apr 25 19:47:20.496: INFO: Pod "execpod-affinitym8x8w": Phase="Running", Reason="", readiness=true. Elapsed: 4.02404104s
Apr 25 19:47:20.496: INFO: Pod "execpod-affinitym8x8w" satisfied condition "running"
Apr 25 19:47:21.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-3136 exec execpod-affinitym8x8w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Apr 25 19:47:21.876: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Apr 25 19:47:21.876: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 19:47:21.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-3136 exec execpod-affinitym8x8w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.209.76 80'
Apr 25 19:47:22.253: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.209.76 80\nConnection to 172.21.209.76 80 port [tcp/http] succeeded!\n"
Apr 25 19:47:22.254: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 19:47:22.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-3136 exec execpod-affinitym8x8w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.136 30556'
Apr 25 19:47:22.623: INFO: stderr: "+ nc -v -t -w 2 10.10.21.136 30556\n+ echo hostName\nConnection to 10.10.21.136 30556 port [tcp/*] succeeded!\n"
Apr 25 19:47:22.623: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 19:47:22.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-3136 exec execpod-affinitym8x8w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.161 30556'
Apr 25 19:47:23.006: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.161 30556\nConnection to 10.10.21.161 30556 port [tcp/*] succeeded!\n"
Apr 25 19:47:23.006: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 19:47:23.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-3136 exec execpod-affinitym8x8w -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.21.136:30556/ ; done'
Apr 25 19:47:23.562: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n"
Apr 25 19:47:23.563: INFO: stdout: "\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-2jx25"
Apr 25 19:47:23.563: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:23.563: INFO: Received response from host: affinity-nodeport-transition-sjzx2
Apr 25 19:47:23.563: INFO: Received response from host: affinity-nodeport-transition-sjzx2
Apr 25 19:47:23.563: INFO: Received response from host: affinity-nodeport-transition-sjzx2
Apr 25 19:47:23.563: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:23.563: INFO: Received response from host: affinity-nodeport-transition-sjzx2
Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-sjzx2
Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-sjzx2
Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-2jx25
Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-2jx25
Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-2jx25
Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-sjzx2
Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-2jx25
Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-2jx25
Apr 25 19:47:23.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-3136 exec execpod-affinitym8x8w -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.21.136:30556/ ; done'
Apr 25 19:47:24.145: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n"
Apr 25 19:47:24.146: INFO: stdout: "\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-2jx25"
Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-2jx25
Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-sjzx2
Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-2jx25
Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-sjzx2
Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-2jx25
Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-sjzx2
Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-sjzx2
Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-2jx25
Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-sjzx2
Apr 25 19:47:24.147: INFO: Received response from host: affinity-nodeport-transition-2jx25
Apr 25 19:47:24.147: INFO: Received response from host: affinity-nodeport-transition-2jx25
Apr 25 19:47:24.147: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:24.147: INFO: Received response from host: affinity-nodeport-transition-2jx25
Apr 25 19:47:54.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-3136 exec execpod-affinitym8x8w -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.21.136:30556/ ; done'
Apr 25 19:47:54.700: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n"
Apr 25 19:47:54.700: INFO: stdout: "\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9"
Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.701: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.701: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.701: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.701: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.701: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.701: INFO: Received response from host: affinity-nodeport-transition-zvvg9
Apr 25 19:47:54.701: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-3136, will wait for the garbage collector to delete the pods 04/25/23 19:47:54.732
Apr 25 19:47:54.816: INFO: Deleting ReplicationController affinity-nodeport-transition took: 16.708129ms
Apr 25 19:47:55.018: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 201.677687ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 19:47:57.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3136" for this suite. 04/25/23 19:47:57.932
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":51,"skipped":935,"failed":0}
------------------------------
• [SLOW TEST] [50.778 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:47:07.176
    Apr 25 19:47:07.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 19:47:07.178
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:47:07.231
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:47:07.242
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2216
    STEP: creating service in namespace services-3136 04/25/23 19:47:07.252
    STEP: creating service affinity-nodeport-transition in namespace services-3136 04/25/23 19:47:07.252
    STEP: creating replication controller affinity-nodeport-transition in namespace services-3136 04/25/23 19:47:07.318
    I0425 19:47:07.354885      23 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-3136, replica count: 3
    I0425 19:47:10.405954      23 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0425 19:47:13.406270      23 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0425 19:47:16.407534      23 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 25 19:47:16.447: INFO: Creating new exec pod
    Apr 25 19:47:16.472: INFO: Waiting up to 5m0s for pod "execpod-affinitym8x8w" in namespace "services-3136" to be "running"
    Apr 25 19:47:16.482: INFO: Pod "execpod-affinitym8x8w": Phase="Pending", Reason="", readiness=false. Elapsed: 10.542759ms
    Apr 25 19:47:18.496: INFO: Pod "execpod-affinitym8x8w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024025868s
    Apr 25 19:47:20.496: INFO: Pod "execpod-affinitym8x8w": Phase="Running", Reason="", readiness=true. Elapsed: 4.02404104s
    Apr 25 19:47:20.496: INFO: Pod "execpod-affinitym8x8w" satisfied condition "running"
    Apr 25 19:47:21.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-3136 exec execpod-affinitym8x8w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Apr 25 19:47:21.876: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Apr 25 19:47:21.876: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 19:47:21.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-3136 exec execpod-affinitym8x8w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.209.76 80'
    Apr 25 19:47:22.253: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.209.76 80\nConnection to 172.21.209.76 80 port [tcp/http] succeeded!\n"
    Apr 25 19:47:22.254: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 19:47:22.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-3136 exec execpod-affinitym8x8w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.136 30556'
    Apr 25 19:47:22.623: INFO: stderr: "+ nc -v -t -w 2 10.10.21.136 30556\n+ echo hostName\nConnection to 10.10.21.136 30556 port [tcp/*] succeeded!\n"
    Apr 25 19:47:22.623: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 19:47:22.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-3136 exec execpod-affinitym8x8w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.161 30556'
    Apr 25 19:47:23.006: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.161 30556\nConnection to 10.10.21.161 30556 port [tcp/*] succeeded!\n"
    Apr 25 19:47:23.006: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 19:47:23.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-3136 exec execpod-affinitym8x8w -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.21.136:30556/ ; done'
    Apr 25 19:47:23.562: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n"
    Apr 25 19:47:23.563: INFO: stdout: "\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-2jx25"
    Apr 25 19:47:23.563: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:23.563: INFO: Received response from host: affinity-nodeport-transition-sjzx2
    Apr 25 19:47:23.563: INFO: Received response from host: affinity-nodeport-transition-sjzx2
    Apr 25 19:47:23.563: INFO: Received response from host: affinity-nodeport-transition-sjzx2
    Apr 25 19:47:23.563: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:23.563: INFO: Received response from host: affinity-nodeport-transition-sjzx2
    Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-sjzx2
    Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-sjzx2
    Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-2jx25
    Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-2jx25
    Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-2jx25
    Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-sjzx2
    Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-2jx25
    Apr 25 19:47:23.564: INFO: Received response from host: affinity-nodeport-transition-2jx25
    Apr 25 19:47:23.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-3136 exec execpod-affinitym8x8w -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.21.136:30556/ ; done'
    Apr 25 19:47:24.145: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n"
    Apr 25 19:47:24.146: INFO: stdout: "\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-sjzx2\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-2jx25\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-2jx25"
    Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-2jx25
    Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-sjzx2
    Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-2jx25
    Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-sjzx2
    Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-2jx25
    Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-sjzx2
    Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-sjzx2
    Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-2jx25
    Apr 25 19:47:24.146: INFO: Received response from host: affinity-nodeport-transition-sjzx2
    Apr 25 19:47:24.147: INFO: Received response from host: affinity-nodeport-transition-2jx25
    Apr 25 19:47:24.147: INFO: Received response from host: affinity-nodeport-transition-2jx25
    Apr 25 19:47:24.147: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:24.147: INFO: Received response from host: affinity-nodeport-transition-2jx25
    Apr 25 19:47:54.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-3136 exec execpod-affinitym8x8w -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.21.136:30556/ ; done'
    Apr 25 19:47:54.700: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:30556/\n"
    Apr 25 19:47:54.700: INFO: stdout: "\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9\naffinity-nodeport-transition-zvvg9"
    Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.700: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.701: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.701: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.701: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.701: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.701: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.701: INFO: Received response from host: affinity-nodeport-transition-zvvg9
    Apr 25 19:47:54.701: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-3136, will wait for the garbage collector to delete the pods 04/25/23 19:47:54.732
    Apr 25 19:47:54.816: INFO: Deleting ReplicationController affinity-nodeport-transition took: 16.708129ms
    Apr 25 19:47:55.018: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 201.677687ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 19:47:57.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3136" for this suite. 04/25/23 19:47:57.932
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:47:57.973
Apr 25 19:47:57.973: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename configmap 04/25/23 19:47:57.974
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:47:58.025
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:47:58.035
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-86f6b6fa-d842-46d0-ba49-5fe9617ad5e5 04/25/23 19:47:58.044
STEP: Creating a pod to test consume configMaps 04/25/23 19:47:58.057
Apr 25 19:47:58.078: INFO: Waiting up to 5m0s for pod "pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299" in namespace "configmap-743" to be "Succeeded or Failed"
Apr 25 19:47:58.088: INFO: Pod "pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299": Phase="Pending", Reason="", readiness=false. Elapsed: 10.263096ms
Apr 25 19:48:00.101: INFO: Pod "pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022574676s
Apr 25 19:48:02.102: INFO: Pod "pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023950306s
STEP: Saw pod success 04/25/23 19:48:02.102
Apr 25 19:48:02.102: INFO: Pod "pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299" satisfied condition "Succeeded or Failed"
Apr 25 19:48:02.112: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299 container agnhost-container: <nil>
STEP: delete the pod 04/25/23 19:48:02.158
Apr 25 19:48:02.198: INFO: Waiting for pod pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299 to disappear
Apr 25 19:48:02.209: INFO: Pod pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 25 19:48:02.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-743" for this suite. 04/25/23 19:48:02.242
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":52,"skipped":994,"failed":0}
------------------------------
• [4.286 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:47:57.973
    Apr 25 19:47:57.973: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename configmap 04/25/23 19:47:57.974
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:47:58.025
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:47:58.035
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-86f6b6fa-d842-46d0-ba49-5fe9617ad5e5 04/25/23 19:47:58.044
    STEP: Creating a pod to test consume configMaps 04/25/23 19:47:58.057
    Apr 25 19:47:58.078: INFO: Waiting up to 5m0s for pod "pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299" in namespace "configmap-743" to be "Succeeded or Failed"
    Apr 25 19:47:58.088: INFO: Pod "pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299": Phase="Pending", Reason="", readiness=false. Elapsed: 10.263096ms
    Apr 25 19:48:00.101: INFO: Pod "pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022574676s
    Apr 25 19:48:02.102: INFO: Pod "pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023950306s
    STEP: Saw pod success 04/25/23 19:48:02.102
    Apr 25 19:48:02.102: INFO: Pod "pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299" satisfied condition "Succeeded or Failed"
    Apr 25 19:48:02.112: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299 container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 19:48:02.158
    Apr 25 19:48:02.198: INFO: Waiting for pod pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299 to disappear
    Apr 25 19:48:02.209: INFO: Pod pod-configmaps-223da82a-4ebb-4106-b8ad-d8e036218299 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 25 19:48:02.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-743" for this suite. 04/25/23 19:48:02.242
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:48:02.263
Apr 25 19:48:02.264: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubelet-test 04/25/23 19:48:02.268
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:48:02.311
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:48:02.328
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 04/25/23 19:48:02.362
Apr 25 19:48:02.362: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases4dd74fbb-9b47-4c26-9ffe-f71688f49d58" in namespace "kubelet-test-6904" to be "completed"
Apr 25 19:48:02.373: INFO: Pod "agnhost-host-aliases4dd74fbb-9b47-4c26-9ffe-f71688f49d58": Phase="Pending", Reason="", readiness=false. Elapsed: 10.586647ms
Apr 25 19:48:04.402: INFO: Pod "agnhost-host-aliases4dd74fbb-9b47-4c26-9ffe-f71688f49d58": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039019379s
Apr 25 19:48:06.385: INFO: Pod "agnhost-host-aliases4dd74fbb-9b47-4c26-9ffe-f71688f49d58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02213351s
Apr 25 19:48:06.385: INFO: Pod "agnhost-host-aliases4dd74fbb-9b47-4c26-9ffe-f71688f49d58" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 25 19:48:06.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6904" for this suite. 04/25/23 19:48:06.434
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":53,"skipped":1005,"failed":0}
------------------------------
• [4.189 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:48:02.263
    Apr 25 19:48:02.264: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubelet-test 04/25/23 19:48:02.268
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:48:02.311
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:48:02.328
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 04/25/23 19:48:02.362
    Apr 25 19:48:02.362: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases4dd74fbb-9b47-4c26-9ffe-f71688f49d58" in namespace "kubelet-test-6904" to be "completed"
    Apr 25 19:48:02.373: INFO: Pod "agnhost-host-aliases4dd74fbb-9b47-4c26-9ffe-f71688f49d58": Phase="Pending", Reason="", readiness=false. Elapsed: 10.586647ms
    Apr 25 19:48:04.402: INFO: Pod "agnhost-host-aliases4dd74fbb-9b47-4c26-9ffe-f71688f49d58": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039019379s
    Apr 25 19:48:06.385: INFO: Pod "agnhost-host-aliases4dd74fbb-9b47-4c26-9ffe-f71688f49d58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02213351s
    Apr 25 19:48:06.385: INFO: Pod "agnhost-host-aliases4dd74fbb-9b47-4c26-9ffe-f71688f49d58" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 25 19:48:06.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-6904" for this suite. 04/25/23 19:48:06.434
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:48:06.458
Apr 25 19:48:06.459: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename gc 04/25/23 19:48:06.462
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:48:06.506
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:48:06.519
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 04/25/23 19:48:06.542
STEP: delete the rc 04/25/23 19:48:11.576
STEP: wait for the rc to be deleted 04/25/23 19:48:11.597
Apr 25 19:48:12.643: INFO: 14 pods remaining
Apr 25 19:48:12.643: INFO: 7 pods has nil DeletionTimestamp
Apr 25 19:48:12.643: INFO: 
STEP: Gathering metrics 04/25/23 19:48:13.619
W0425 19:48:13.676099      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 25 19:48:13.676: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 25 19:48:13.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3988" for this suite. 04/25/23 19:48:13.708
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":54,"skipped":1018,"failed":0}
------------------------------
• [SLOW TEST] [7.268 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:48:06.458
    Apr 25 19:48:06.459: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename gc 04/25/23 19:48:06.462
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:48:06.506
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:48:06.519
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 04/25/23 19:48:06.542
    STEP: delete the rc 04/25/23 19:48:11.576
    STEP: wait for the rc to be deleted 04/25/23 19:48:11.597
    Apr 25 19:48:12.643: INFO: 14 pods remaining
    Apr 25 19:48:12.643: INFO: 7 pods has nil DeletionTimestamp
    Apr 25 19:48:12.643: INFO: 
    STEP: Gathering metrics 04/25/23 19:48:13.619
    W0425 19:48:13.676099      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 25 19:48:13.676: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 25 19:48:13.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-3988" for this suite. 04/25/23 19:48:13.708
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:48:13.731
Apr 25 19:48:13.731: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-probe 04/25/23 19:48:13.733
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:48:13.82
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:48:13.83
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8 in namespace container-probe-7461 04/25/23 19:48:13.838
Apr 25 19:48:13.857: INFO: Waiting up to 5m0s for pod "liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8" in namespace "container-probe-7461" to be "not pending"
Apr 25 19:48:13.877: INFO: Pod "liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8": Phase="Pending", Reason="", readiness=false. Elapsed: 20.516483ms
Apr 25 19:48:15.890: INFO: Pod "liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032976178s
Apr 25 19:48:17.886: INFO: Pod "liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029706683s
Apr 25 19:48:19.897: INFO: Pod "liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.040096412s
Apr 25 19:48:21.890: INFO: Pod "liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8": Phase="Running", Reason="", readiness=true. Elapsed: 8.033268353s
Apr 25 19:48:21.890: INFO: Pod "liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8" satisfied condition "not pending"
Apr 25 19:48:21.890: INFO: Started pod liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8 in namespace container-probe-7461
STEP: checking the pod's current state and verifying that restartCount is present 04/25/23 19:48:21.891
Apr 25 19:48:21.904: INFO: Initial restart count of pod liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8 is 0
Apr 25 19:48:36.016: INFO: Restart count of pod container-probe-7461/liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8 is now 1 (14.112567091s elapsed)
STEP: deleting the pod 04/25/23 19:48:36.016
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 25 19:48:36.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7461" for this suite. 04/25/23 19:48:36.074
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":55,"skipped":1028,"failed":0}
------------------------------
• [SLOW TEST] [22.383 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:48:13.731
    Apr 25 19:48:13.731: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-probe 04/25/23 19:48:13.733
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:48:13.82
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:48:13.83
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8 in namespace container-probe-7461 04/25/23 19:48:13.838
    Apr 25 19:48:13.857: INFO: Waiting up to 5m0s for pod "liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8" in namespace "container-probe-7461" to be "not pending"
    Apr 25 19:48:13.877: INFO: Pod "liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8": Phase="Pending", Reason="", readiness=false. Elapsed: 20.516483ms
    Apr 25 19:48:15.890: INFO: Pod "liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032976178s
    Apr 25 19:48:17.886: INFO: Pod "liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029706683s
    Apr 25 19:48:19.897: INFO: Pod "liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.040096412s
    Apr 25 19:48:21.890: INFO: Pod "liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8": Phase="Running", Reason="", readiness=true. Elapsed: 8.033268353s
    Apr 25 19:48:21.890: INFO: Pod "liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8" satisfied condition "not pending"
    Apr 25 19:48:21.890: INFO: Started pod liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8 in namespace container-probe-7461
    STEP: checking the pod's current state and verifying that restartCount is present 04/25/23 19:48:21.891
    Apr 25 19:48:21.904: INFO: Initial restart count of pod liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8 is 0
    Apr 25 19:48:36.016: INFO: Restart count of pod container-probe-7461/liveness-a3f804ba-7bff-44ff-8791-d21a5645f8f8 is now 1 (14.112567091s elapsed)
    STEP: deleting the pod 04/25/23 19:48:36.016
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 25 19:48:36.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7461" for this suite. 04/25/23 19:48:36.074
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:48:36.131
Apr 25 19:48:36.132: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir 04/25/23 19:48:36.133
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:48:36.178
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:48:36.187
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 04/25/23 19:48:36.198
Apr 25 19:48:36.220: INFO: Waiting up to 5m0s for pod "pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c" in namespace "emptydir-1559" to be "Succeeded or Failed"
Apr 25 19:48:36.230: INFO: Pod "pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.15176ms
Apr 25 19:48:38.244: INFO: Pod "pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02378258s
Apr 25 19:48:40.244: INFO: Pod "pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024051641s
STEP: Saw pod success 04/25/23 19:48:40.244
Apr 25 19:48:40.245: INFO: Pod "pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c" satisfied condition "Succeeded or Failed"
Apr 25 19:48:40.257: INFO: Trying to get logs from node 10.10.21.190 pod pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c container test-container: <nil>
STEP: delete the pod 04/25/23 19:48:40.301
Apr 25 19:48:40.347: INFO: Waiting for pod pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c to disappear
Apr 25 19:48:40.356: INFO: Pod pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 25 19:48:40.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1559" for this suite. 04/25/23 19:48:40.376
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":56,"skipped":1066,"failed":0}
------------------------------
• [4.262 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:48:36.131
    Apr 25 19:48:36.132: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir 04/25/23 19:48:36.133
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:48:36.178
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:48:36.187
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 04/25/23 19:48:36.198
    Apr 25 19:48:36.220: INFO: Waiting up to 5m0s for pod "pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c" in namespace "emptydir-1559" to be "Succeeded or Failed"
    Apr 25 19:48:36.230: INFO: Pod "pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.15176ms
    Apr 25 19:48:38.244: INFO: Pod "pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02378258s
    Apr 25 19:48:40.244: INFO: Pod "pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024051641s
    STEP: Saw pod success 04/25/23 19:48:40.244
    Apr 25 19:48:40.245: INFO: Pod "pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c" satisfied condition "Succeeded or Failed"
    Apr 25 19:48:40.257: INFO: Trying to get logs from node 10.10.21.190 pod pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c container test-container: <nil>
    STEP: delete the pod 04/25/23 19:48:40.301
    Apr 25 19:48:40.347: INFO: Waiting for pod pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c to disappear
    Apr 25 19:48:40.356: INFO: Pod pod-26a44c13-1d8c-451a-9e0b-45f1f9acae7c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 25 19:48:40.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1559" for this suite. 04/25/23 19:48:40.376
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:48:40.395
Apr 25 19:48:40.395: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 19:48:40.398
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:48:40.464
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:48:40.473
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 04/25/23 19:48:40.482
Apr 25 19:48:40.503: INFO: Waiting up to 5m0s for pod "downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba" in namespace "downward-api-7025" to be "Succeeded or Failed"
Apr 25 19:48:40.512: INFO: Pod "downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba": Phase="Pending", Reason="", readiness=false. Elapsed: 9.798032ms
Apr 25 19:48:42.526: INFO: Pod "downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023205703s
Apr 25 19:48:44.525: INFO: Pod "downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021962978s
STEP: Saw pod success 04/25/23 19:48:44.525
Apr 25 19:48:44.525: INFO: Pod "downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba" satisfied condition "Succeeded or Failed"
Apr 25 19:48:44.545: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba container client-container: <nil>
STEP: delete the pod 04/25/23 19:48:44.573
Apr 25 19:48:44.612: INFO: Waiting for pod downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba to disappear
Apr 25 19:48:44.622: INFO: Pod downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 25 19:48:44.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7025" for this suite. 04/25/23 19:48:44.67
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":57,"skipped":1069,"failed":0}
------------------------------
• [4.293 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:48:40.395
    Apr 25 19:48:40.395: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 19:48:40.398
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:48:40.464
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:48:40.473
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 04/25/23 19:48:40.482
    Apr 25 19:48:40.503: INFO: Waiting up to 5m0s for pod "downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba" in namespace "downward-api-7025" to be "Succeeded or Failed"
    Apr 25 19:48:40.512: INFO: Pod "downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba": Phase="Pending", Reason="", readiness=false. Elapsed: 9.798032ms
    Apr 25 19:48:42.526: INFO: Pod "downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023205703s
    Apr 25 19:48:44.525: INFO: Pod "downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021962978s
    STEP: Saw pod success 04/25/23 19:48:44.525
    Apr 25 19:48:44.525: INFO: Pod "downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba" satisfied condition "Succeeded or Failed"
    Apr 25 19:48:44.545: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba container client-container: <nil>
    STEP: delete the pod 04/25/23 19:48:44.573
    Apr 25 19:48:44.612: INFO: Waiting for pod downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba to disappear
    Apr 25 19:48:44.622: INFO: Pod downwardapi-volume-db276f10-241c-4be0-ace8-ae3c673f38ba no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 25 19:48:44.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7025" for this suite. 04/25/23 19:48:44.67
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:48:44.692
Apr 25 19:48:44.693: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename svcaccounts 04/25/23 19:48:44.695
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:48:44.739
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:48:44.748
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Apr 25 19:48:44.795: INFO: created pod
Apr 25 19:48:44.795: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-4210" to be "Succeeded or Failed"
Apr 25 19:48:44.806: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 11.101329ms
Apr 25 19:48:46.818: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022824668s
Apr 25 19:48:48.818: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022337385s
STEP: Saw pod success 04/25/23 19:48:48.818
Apr 25 19:48:48.818: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Apr 25 19:49:18.819: INFO: polling logs
Apr 25 19:49:18.892: INFO: Pod logs: 
I0425 19:48:45.898282       1 log.go:195] OK: Got token
I0425 19:48:45.898328       1 log.go:195] validating with in-cluster discovery
I0425 19:48:45.898757       1 log.go:195] OK: got issuer https://kubernetes.default.svc
I0425 19:48:45.898825       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-4210:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682452724, NotBefore:1682452124, IssuedAt:1682452124, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4210", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"4671298f-7bcd-4d1f-ac02-50c606130a78"}}}
I0425 19:48:45.919695       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
I0425 19:48:45.939761       1 log.go:195] OK: Validated signature on JWT
I0425 19:48:45.939929       1 log.go:195] OK: Got valid claims from token!
I0425 19:48:45.939981       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-4210:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682452724, NotBefore:1682452124, IssuedAt:1682452124, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4210", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"4671298f-7bcd-4d1f-ac02-50c606130a78"}}}

Apr 25 19:49:18.892: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 25 19:49:18.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4210" for this suite. 04/25/23 19:49:18.95
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":58,"skipped":1082,"failed":0}
------------------------------
• [SLOW TEST] [34.284 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:48:44.692
    Apr 25 19:48:44.693: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename svcaccounts 04/25/23 19:48:44.695
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:48:44.739
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:48:44.748
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Apr 25 19:48:44.795: INFO: created pod
    Apr 25 19:48:44.795: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-4210" to be "Succeeded or Failed"
    Apr 25 19:48:44.806: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 11.101329ms
    Apr 25 19:48:46.818: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022824668s
    Apr 25 19:48:48.818: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022337385s
    STEP: Saw pod success 04/25/23 19:48:48.818
    Apr 25 19:48:48.818: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Apr 25 19:49:18.819: INFO: polling logs
    Apr 25 19:49:18.892: INFO: Pod logs: 
    I0425 19:48:45.898282       1 log.go:195] OK: Got token
    I0425 19:48:45.898328       1 log.go:195] validating with in-cluster discovery
    I0425 19:48:45.898757       1 log.go:195] OK: got issuer https://kubernetes.default.svc
    I0425 19:48:45.898825       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-4210:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682452724, NotBefore:1682452124, IssuedAt:1682452124, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4210", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"4671298f-7bcd-4d1f-ac02-50c606130a78"}}}
    I0425 19:48:45.919695       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
    I0425 19:48:45.939761       1 log.go:195] OK: Validated signature on JWT
    I0425 19:48:45.939929       1 log.go:195] OK: Got valid claims from token!
    I0425 19:48:45.939981       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-4210:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682452724, NotBefore:1682452124, IssuedAt:1682452124, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4210", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"4671298f-7bcd-4d1f-ac02-50c606130a78"}}}

    Apr 25 19:49:18.892: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 25 19:49:18.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4210" for this suite. 04/25/23 19:49:18.95
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:49:18.986
Apr 25 19:49:18.987: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 19:49:18.988
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:49:19.035
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:49:19.045
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-2135 04/25/23 19:49:19.054
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2135 to expose endpoints map[] 04/25/23 19:49:19.089
Apr 25 19:49:19.120: INFO: successfully validated that service endpoint-test2 in namespace services-2135 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-2135 04/25/23 19:49:19.12
Apr 25 19:49:19.139: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-2135" to be "running and ready"
Apr 25 19:49:19.149: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.177794ms
Apr 25 19:49:19.149: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 19:49:21.160: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.02172455s
Apr 25 19:49:21.161: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 25 19:49:21.161: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2135 to expose endpoints map[pod1:[80]] 04/25/23 19:49:21.171
Apr 25 19:49:21.203: INFO: successfully validated that service endpoint-test2 in namespace services-2135 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 04/25/23 19:49:21.204
Apr 25 19:49:21.204: INFO: Creating new exec pod
Apr 25 19:49:21.246: INFO: Waiting up to 5m0s for pod "execpodhkj9c" in namespace "services-2135" to be "running"
Apr 25 19:49:21.256: INFO: Pod "execpodhkj9c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.152101ms
Apr 25 19:49:23.267: INFO: Pod "execpodhkj9c": Phase="Running", Reason="", readiness=true. Elapsed: 2.020988497s
Apr 25 19:49:23.267: INFO: Pod "execpodhkj9c" satisfied condition "running"
Apr 25 19:49:24.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2135 exec execpodhkj9c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 25 19:49:24.666: INFO: stderr: "+ + echonc hostName -v\n -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 25 19:49:24.666: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 19:49:24.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2135 exec execpodhkj9c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.65.200 80'
Apr 25 19:49:25.083: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.65.200 80\nConnection to 172.21.65.200 80 port [tcp/http] succeeded!\n"
Apr 25 19:49:25.084: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-2135 04/25/23 19:49:25.084
Apr 25 19:49:25.097: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-2135" to be "running and ready"
Apr 25 19:49:25.112: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.12325ms
Apr 25 19:49:25.112: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 19:49:27.122: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.02525437s
Apr 25 19:49:27.122: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 25 19:49:27.122: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2135 to expose endpoints map[pod1:[80] pod2:[80]] 04/25/23 19:49:27.133
Apr 25 19:49:27.206: INFO: successfully validated that service endpoint-test2 in namespace services-2135 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 04/25/23 19:49:27.206
Apr 25 19:49:28.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2135 exec execpodhkj9c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 25 19:49:28.566: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 25 19:49:28.566: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 19:49:28.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2135 exec execpodhkj9c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.65.200 80'
Apr 25 19:49:28.941: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.65.200 80\nConnection to 172.21.65.200 80 port [tcp/http] succeeded!\n"
Apr 25 19:49:28.941: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-2135 04/25/23 19:49:28.941
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2135 to expose endpoints map[pod2:[80]] 04/25/23 19:49:29.052
Apr 25 19:49:29.092: INFO: successfully validated that service endpoint-test2 in namespace services-2135 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 04/25/23 19:49:29.092
Apr 25 19:49:30.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2135 exec execpodhkj9c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 25 19:49:30.468: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 25 19:49:30.468: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 19:49:30.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2135 exec execpodhkj9c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.65.200 80'
Apr 25 19:49:30.872: INFO: stderr: "+ nc -v -t -w 2 172.21.65.200 80\n+ echo hostName\nConnection to 172.21.65.200 80 port [tcp/http] succeeded!\n"
Apr 25 19:49:30.873: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-2135 04/25/23 19:49:30.873
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2135 to expose endpoints map[] 04/25/23 19:49:30.911
Apr 25 19:49:30.984: INFO: successfully validated that service endpoint-test2 in namespace services-2135 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 19:49:31.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2135" for this suite. 04/25/23 19:49:31.139
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":59,"skipped":1101,"failed":0}
------------------------------
• [SLOW TEST] [12.170 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:49:18.986
    Apr 25 19:49:18.987: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 19:49:18.988
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:49:19.035
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:49:19.045
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-2135 04/25/23 19:49:19.054
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2135 to expose endpoints map[] 04/25/23 19:49:19.089
    Apr 25 19:49:19.120: INFO: successfully validated that service endpoint-test2 in namespace services-2135 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-2135 04/25/23 19:49:19.12
    Apr 25 19:49:19.139: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-2135" to be "running and ready"
    Apr 25 19:49:19.149: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.177794ms
    Apr 25 19:49:19.149: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 19:49:21.160: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.02172455s
    Apr 25 19:49:21.161: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 25 19:49:21.161: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2135 to expose endpoints map[pod1:[80]] 04/25/23 19:49:21.171
    Apr 25 19:49:21.203: INFO: successfully validated that service endpoint-test2 in namespace services-2135 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 04/25/23 19:49:21.204
    Apr 25 19:49:21.204: INFO: Creating new exec pod
    Apr 25 19:49:21.246: INFO: Waiting up to 5m0s for pod "execpodhkj9c" in namespace "services-2135" to be "running"
    Apr 25 19:49:21.256: INFO: Pod "execpodhkj9c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.152101ms
    Apr 25 19:49:23.267: INFO: Pod "execpodhkj9c": Phase="Running", Reason="", readiness=true. Elapsed: 2.020988497s
    Apr 25 19:49:23.267: INFO: Pod "execpodhkj9c" satisfied condition "running"
    Apr 25 19:49:24.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2135 exec execpodhkj9c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Apr 25 19:49:24.666: INFO: stderr: "+ + echonc hostName -v\n -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 25 19:49:24.666: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 19:49:24.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2135 exec execpodhkj9c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.65.200 80'
    Apr 25 19:49:25.083: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.65.200 80\nConnection to 172.21.65.200 80 port [tcp/http] succeeded!\n"
    Apr 25 19:49:25.084: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-2135 04/25/23 19:49:25.084
    Apr 25 19:49:25.097: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-2135" to be "running and ready"
    Apr 25 19:49:25.112: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.12325ms
    Apr 25 19:49:25.112: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 19:49:27.122: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.02525437s
    Apr 25 19:49:27.122: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 25 19:49:27.122: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2135 to expose endpoints map[pod1:[80] pod2:[80]] 04/25/23 19:49:27.133
    Apr 25 19:49:27.206: INFO: successfully validated that service endpoint-test2 in namespace services-2135 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 04/25/23 19:49:27.206
    Apr 25 19:49:28.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2135 exec execpodhkj9c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Apr 25 19:49:28.566: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 25 19:49:28.566: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 19:49:28.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2135 exec execpodhkj9c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.65.200 80'
    Apr 25 19:49:28.941: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.65.200 80\nConnection to 172.21.65.200 80 port [tcp/http] succeeded!\n"
    Apr 25 19:49:28.941: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-2135 04/25/23 19:49:28.941
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2135 to expose endpoints map[pod2:[80]] 04/25/23 19:49:29.052
    Apr 25 19:49:29.092: INFO: successfully validated that service endpoint-test2 in namespace services-2135 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 04/25/23 19:49:29.092
    Apr 25 19:49:30.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2135 exec execpodhkj9c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Apr 25 19:49:30.468: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 25 19:49:30.468: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 19:49:30.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2135 exec execpodhkj9c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.65.200 80'
    Apr 25 19:49:30.872: INFO: stderr: "+ nc -v -t -w 2 172.21.65.200 80\n+ echo hostName\nConnection to 172.21.65.200 80 port [tcp/http] succeeded!\n"
    Apr 25 19:49:30.873: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-2135 04/25/23 19:49:30.873
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2135 to expose endpoints map[] 04/25/23 19:49:30.911
    Apr 25 19:49:30.984: INFO: successfully validated that service endpoint-test2 in namespace services-2135 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 19:49:31.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2135" for this suite. 04/25/23 19:49:31.139
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:49:31.165
Apr 25 19:49:31.165: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename deployment 04/25/23 19:49:31.167
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:49:31.22
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:49:31.229
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Apr 25 19:49:31.238: INFO: Creating deployment "test-recreate-deployment"
Apr 25 19:49:31.252: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 25 19:49:31.305: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr 25 19:49:33.330: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 25 19:49:33.341: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 25 19:49:33.376: INFO: Updating deployment test-recreate-deployment
Apr 25 19:49:33.376: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 25 19:49:33.612: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-6249  3849a224-cd93-400f-b370-df2a57f000fd 22418 2 2023-04-25 19:49:31 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004080498 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-25 19:49:33 +0000 UTC,LastTransitionTime:2023-04-25 19:49:33 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-04-25 19:49:33 +0000 UTC,LastTransitionTime:2023-04-25 19:49:31 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Apr 25 19:49:33.625: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-6249  c8a6c6b1-4920-4ad5-9a7a-b9e017a8d771 22416 1 2023-04-25 19:49:33 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 3849a224-cd93-400f-b370-df2a57f000fd 0xc004bb6570 0xc004bb6571}] [] [{kube-controller-manager Update apps/v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3849a224-cd93-400f-b370-df2a57f000fd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004bb6608 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 25 19:49:33.625: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 25 19:49:33.626: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-6249  40c9929a-e779-4966-969f-38cab8057f04 22406 2 2023-04-25 19:49:31 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 3849a224-cd93-400f-b370-df2a57f000fd 0xc004bb6457 0xc004bb6458}] [] [{kube-controller-manager Update apps/v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3849a224-cd93-400f-b370-df2a57f000fd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004bb6508 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 25 19:49:33.666: INFO: Pod "test-recreate-deployment-9d58999df-xw28g" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-xw28g test-recreate-deployment-9d58999df- deployment-6249  2c47e477-3825-4198-bedb-36cb1519affa 22417 0 2023-04-25 19:49:33 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df c8a6c6b1-4920-4ad5-9a7a-b9e017a8d771 0xc004bb6aa0 0xc004bb6aa1}] [] [{kube-controller-manager Update v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c8a6c6b1-4920-4ad5-9a7a-b9e017a8d771\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dx9lz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dx9lz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 19:49:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 19:49:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 19:49:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 19:49:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:,StartTime:2023-04-25 19:49:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 25 19:49:33.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6249" for this suite. 04/25/23 19:49:33.686
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":60,"skipped":1123,"failed":0}
------------------------------
• [2.554 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:49:31.165
    Apr 25 19:49:31.165: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename deployment 04/25/23 19:49:31.167
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:49:31.22
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:49:31.229
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Apr 25 19:49:31.238: INFO: Creating deployment "test-recreate-deployment"
    Apr 25 19:49:31.252: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Apr 25 19:49:31.305: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Apr 25 19:49:33.330: INFO: Waiting deployment "test-recreate-deployment" to complete
    Apr 25 19:49:33.341: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Apr 25 19:49:33.376: INFO: Updating deployment test-recreate-deployment
    Apr 25 19:49:33.376: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 25 19:49:33.612: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-6249  3849a224-cd93-400f-b370-df2a57f000fd 22418 2 2023-04-25 19:49:31 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004080498 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-25 19:49:33 +0000 UTC,LastTransitionTime:2023-04-25 19:49:33 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-04-25 19:49:33 +0000 UTC,LastTransitionTime:2023-04-25 19:49:31 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Apr 25 19:49:33.625: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-6249  c8a6c6b1-4920-4ad5-9a7a-b9e017a8d771 22416 1 2023-04-25 19:49:33 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 3849a224-cd93-400f-b370-df2a57f000fd 0xc004bb6570 0xc004bb6571}] [] [{kube-controller-manager Update apps/v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3849a224-cd93-400f-b370-df2a57f000fd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004bb6608 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 25 19:49:33.625: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Apr 25 19:49:33.626: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-6249  40c9929a-e779-4966-969f-38cab8057f04 22406 2 2023-04-25 19:49:31 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 3849a224-cd93-400f-b370-df2a57f000fd 0xc004bb6457 0xc004bb6458}] [] [{kube-controller-manager Update apps/v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3849a224-cd93-400f-b370-df2a57f000fd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004bb6508 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 25 19:49:33.666: INFO: Pod "test-recreate-deployment-9d58999df-xw28g" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-xw28g test-recreate-deployment-9d58999df- deployment-6249  2c47e477-3825-4198-bedb-36cb1519affa 22417 0 2023-04-25 19:49:33 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df c8a6c6b1-4920-4ad5-9a7a-b9e017a8d771 0xc004bb6aa0 0xc004bb6aa1}] [] [{kube-controller-manager Update v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c8a6c6b1-4920-4ad5-9a7a-b9e017a8d771\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 19:49:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dx9lz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dx9lz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 19:49:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 19:49:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 19:49:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 19:49:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:,StartTime:2023-04-25 19:49:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 25 19:49:33.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-6249" for this suite. 04/25/23 19:49:33.686
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:49:33.722
Apr 25 19:49:33.722: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename sched-preemption 04/25/23 19:49:33.724
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:49:33.784
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:49:33.791
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 25 19:49:33.867: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 25 19:50:34.002: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 04/25/23 19:50:34.014
Apr 25 19:50:34.122: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr 25 19:50:34.138: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr 25 19:50:34.219: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr 25 19:50:34.265: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Apr 25 19:50:34.361: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Apr 25 19:50:34.442: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 04/25/23 19:50:34.442
Apr 25 19:50:34.442: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8812" to be "running"
Apr 25 19:50:34.460: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 17.508111ms
Apr 25 19:50:36.493: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050359416s
Apr 25 19:50:38.471: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029015104s
Apr 25 19:50:40.472: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.029066066s
Apr 25 19:50:42.471: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.028678303s
Apr 25 19:50:44.473: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.03069676s
Apr 25 19:50:44.473: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Apr 25 19:50:44.474: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8812" to be "running"
Apr 25 19:50:44.491: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 17.074016ms
Apr 25 19:50:44.491: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 25 19:50:44.491: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8812" to be "running"
Apr 25 19:50:44.509: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 18.051923ms
Apr 25 19:50:44.509: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 25 19:50:44.509: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8812" to be "running"
Apr 25 19:50:44.520: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.786938ms
Apr 25 19:50:44.521: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 25 19:50:44.521: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8812" to be "running"
Apr 25 19:50:44.532: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.477772ms
Apr 25 19:50:46.544: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.023235111s
Apr 25 19:50:46.545: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 25 19:50:46.545: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8812" to be "running"
Apr 25 19:50:46.567: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 21.51273ms
Apr 25 19:50:46.567: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 04/25/23 19:50:46.567
Apr 25 19:50:46.580: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-8812" to be "running"
Apr 25 19:50:46.591: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.729713ms
Apr 25 19:50:48.603: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022586109s
Apr 25 19:50:50.603: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02308138s
Apr 25 19:50:52.605: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.024832695s
Apr 25 19:50:52.605: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 25 19:50:52.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8812" for this suite. 04/25/23 19:50:52.696
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":61,"skipped":1151,"failed":0}
------------------------------
• [SLOW TEST] [79.106 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:49:33.722
    Apr 25 19:49:33.722: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename sched-preemption 04/25/23 19:49:33.724
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:49:33.784
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:49:33.791
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 25 19:49:33.867: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 25 19:50:34.002: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 04/25/23 19:50:34.014
    Apr 25 19:50:34.122: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Apr 25 19:50:34.138: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Apr 25 19:50:34.219: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Apr 25 19:50:34.265: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Apr 25 19:50:34.361: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Apr 25 19:50:34.442: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 04/25/23 19:50:34.442
    Apr 25 19:50:34.442: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8812" to be "running"
    Apr 25 19:50:34.460: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 17.508111ms
    Apr 25 19:50:36.493: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050359416s
    Apr 25 19:50:38.471: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029015104s
    Apr 25 19:50:40.472: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.029066066s
    Apr 25 19:50:42.471: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.028678303s
    Apr 25 19:50:44.473: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.03069676s
    Apr 25 19:50:44.473: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Apr 25 19:50:44.474: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8812" to be "running"
    Apr 25 19:50:44.491: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 17.074016ms
    Apr 25 19:50:44.491: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 25 19:50:44.491: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8812" to be "running"
    Apr 25 19:50:44.509: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 18.051923ms
    Apr 25 19:50:44.509: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 25 19:50:44.509: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8812" to be "running"
    Apr 25 19:50:44.520: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.786938ms
    Apr 25 19:50:44.521: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 25 19:50:44.521: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8812" to be "running"
    Apr 25 19:50:44.532: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.477772ms
    Apr 25 19:50:46.544: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.023235111s
    Apr 25 19:50:46.545: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 25 19:50:46.545: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8812" to be "running"
    Apr 25 19:50:46.567: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 21.51273ms
    Apr 25 19:50:46.567: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 04/25/23 19:50:46.567
    Apr 25 19:50:46.580: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-8812" to be "running"
    Apr 25 19:50:46.591: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.729713ms
    Apr 25 19:50:48.603: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022586109s
    Apr 25 19:50:50.603: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02308138s
    Apr 25 19:50:52.605: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.024832695s
    Apr 25 19:50:52.605: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 19:50:52.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8812" for this suite. 04/25/23 19:50:52.696
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:50:52.835
Apr 25 19:50:52.836: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename secrets 04/25/23 19:50:52.839
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:50:52.884
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:50:52.894
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 25 19:50:53.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5186" for this suite. 04/25/23 19:50:53.037
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":62,"skipped":1151,"failed":0}
------------------------------
• [0.237 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:50:52.835
    Apr 25 19:50:52.836: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename secrets 04/25/23 19:50:52.839
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:50:52.884
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:50:52.894
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 25 19:50:53.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5186" for this suite. 04/25/23 19:50:53.037
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:50:53.08
Apr 25 19:50:53.081: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename secrets 04/25/23 19:50:53.082
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:50:53.165
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:50:53.175
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-5666cc53-08c3-429f-b4d0-1389c66d0b18 04/25/23 19:50:53.184
STEP: Creating a pod to test consume secrets 04/25/23 19:50:53.197
Apr 25 19:50:53.215: INFO: Waiting up to 5m0s for pod "pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816" in namespace "secrets-3636" to be "Succeeded or Failed"
Apr 25 19:50:53.226: INFO: Pod "pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816": Phase="Pending", Reason="", readiness=false. Elapsed: 10.502724ms
Apr 25 19:50:55.238: INFO: Pod "pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0230084s
Apr 25 19:50:57.242: INFO: Pod "pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026639076s
STEP: Saw pod success 04/25/23 19:50:57.242
Apr 25 19:50:57.243: INFO: Pod "pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816" satisfied condition "Succeeded or Failed"
Apr 25 19:50:57.253: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816 container secret-volume-test: <nil>
STEP: delete the pod 04/25/23 19:50:57.332
Apr 25 19:50:57.367: INFO: Waiting for pod pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816 to disappear
Apr 25 19:50:57.378: INFO: Pod pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 25 19:50:57.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3636" for this suite. 04/25/23 19:50:57.396
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":63,"skipped":1187,"failed":0}
------------------------------
• [4.331 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:50:53.08
    Apr 25 19:50:53.081: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename secrets 04/25/23 19:50:53.082
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:50:53.165
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:50:53.175
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-5666cc53-08c3-429f-b4d0-1389c66d0b18 04/25/23 19:50:53.184
    STEP: Creating a pod to test consume secrets 04/25/23 19:50:53.197
    Apr 25 19:50:53.215: INFO: Waiting up to 5m0s for pod "pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816" in namespace "secrets-3636" to be "Succeeded or Failed"
    Apr 25 19:50:53.226: INFO: Pod "pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816": Phase="Pending", Reason="", readiness=false. Elapsed: 10.502724ms
    Apr 25 19:50:55.238: INFO: Pod "pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0230084s
    Apr 25 19:50:57.242: INFO: Pod "pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026639076s
    STEP: Saw pod success 04/25/23 19:50:57.242
    Apr 25 19:50:57.243: INFO: Pod "pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816" satisfied condition "Succeeded or Failed"
    Apr 25 19:50:57.253: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816 container secret-volume-test: <nil>
    STEP: delete the pod 04/25/23 19:50:57.332
    Apr 25 19:50:57.367: INFO: Waiting for pod pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816 to disappear
    Apr 25 19:50:57.378: INFO: Pod pod-secrets-977077f3-70da-4719-9229-0ae0f2aca816 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 25 19:50:57.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3636" for this suite. 04/25/23 19:50:57.396
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:50:57.423
Apr 25 19:50:57.423: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename secrets 04/25/23 19:50:57.425
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:50:57.469
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:50:57.478
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-3a9a5652-85ed-4a38-917f-1deccf093814 04/25/23 19:50:57.487
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 25 19:50:57.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9616" for this suite. 04/25/23 19:50:57.513
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":64,"skipped":1202,"failed":0}
------------------------------
• [0.106 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:50:57.423
    Apr 25 19:50:57.423: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename secrets 04/25/23 19:50:57.425
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:50:57.469
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:50:57.478
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-3a9a5652-85ed-4a38-917f-1deccf093814 04/25/23 19:50:57.487
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 25 19:50:57.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9616" for this suite. 04/25/23 19:50:57.513
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:50:57.535
Apr 25 19:50:57.535: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename endpointslicemirroring 04/25/23 19:50:57.536
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:50:57.576
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:50:57.585
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 04/25/23 19:50:57.622
Apr 25 19:50:57.651: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 04/25/23 19:50:59.686
STEP: mirroring deletion of a custom Endpoint 04/25/23 19:50:59.737
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Apr 25 19:50:59.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-6617" for this suite. 04/25/23 19:50:59.849
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":65,"skipped":1222,"failed":0}
------------------------------
• [2.391 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:50:57.535
    Apr 25 19:50:57.535: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename endpointslicemirroring 04/25/23 19:50:57.536
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:50:57.576
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:50:57.585
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 04/25/23 19:50:57.622
    Apr 25 19:50:57.651: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 04/25/23 19:50:59.686
    STEP: mirroring deletion of a custom Endpoint 04/25/23 19:50:59.737
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Apr 25 19:50:59.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-6617" for this suite. 04/25/23 19:50:59.849
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:50:59.933
Apr 25 19:50:59.934: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename cronjob 04/25/23 19:50:59.938
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:51:00.034
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:51:00.043
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 04/25/23 19:51:00.053
STEP: Ensuring more than one job is running at a time 04/25/23 19:51:00.072
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 04/25/23 19:53:02.086
STEP: Removing cronjob 04/25/23 19:53:02.128
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 25 19:53:02.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9012" for this suite. 04/25/23 19:53:02.201
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":66,"skipped":1244,"failed":0}
------------------------------
• [SLOW TEST] [122.293 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:50:59.933
    Apr 25 19:50:59.934: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename cronjob 04/25/23 19:50:59.938
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:51:00.034
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:51:00.043
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 04/25/23 19:51:00.053
    STEP: Ensuring more than one job is running at a time 04/25/23 19:51:00.072
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 04/25/23 19:53:02.086
    STEP: Removing cronjob 04/25/23 19:53:02.128
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 25 19:53:02.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9012" for this suite. 04/25/23 19:53:02.201
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:53:02.231
Apr 25 19:53:02.232: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 19:53:02.235
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:53:02.297
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:53:02.308
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 04/25/23 19:53:02.317
Apr 25 19:53:02.338: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994" in namespace "downward-api-1310" to be "Succeeded or Failed"
Apr 25 19:53:02.353: INFO: Pod "downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994": Phase="Pending", Reason="", readiness=false. Elapsed: 14.303565ms
Apr 25 19:53:04.363: INFO: Pod "downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024923416s
Apr 25 19:53:06.364: INFO: Pod "downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025056677s
Apr 25 19:53:08.365: INFO: Pod "downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026324176s
STEP: Saw pod success 04/25/23 19:53:08.365
Apr 25 19:53:08.365: INFO: Pod "downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994" satisfied condition "Succeeded or Failed"
Apr 25 19:53:08.377: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994 container client-container: <nil>
STEP: delete the pod 04/25/23 19:53:08.455
Apr 25 19:53:08.483: INFO: Waiting for pod downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994 to disappear
Apr 25 19:53:08.494: INFO: Pod downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 25 19:53:08.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1310" for this suite. 04/25/23 19:53:08.548
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":67,"skipped":1249,"failed":0}
------------------------------
• [SLOW TEST] [6.363 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:53:02.231
    Apr 25 19:53:02.232: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 19:53:02.235
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:53:02.297
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:53:02.308
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 04/25/23 19:53:02.317
    Apr 25 19:53:02.338: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994" in namespace "downward-api-1310" to be "Succeeded or Failed"
    Apr 25 19:53:02.353: INFO: Pod "downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994": Phase="Pending", Reason="", readiness=false. Elapsed: 14.303565ms
    Apr 25 19:53:04.363: INFO: Pod "downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024923416s
    Apr 25 19:53:06.364: INFO: Pod "downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025056677s
    Apr 25 19:53:08.365: INFO: Pod "downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026324176s
    STEP: Saw pod success 04/25/23 19:53:08.365
    Apr 25 19:53:08.365: INFO: Pod "downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994" satisfied condition "Succeeded or Failed"
    Apr 25 19:53:08.377: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994 container client-container: <nil>
    STEP: delete the pod 04/25/23 19:53:08.455
    Apr 25 19:53:08.483: INFO: Waiting for pod downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994 to disappear
    Apr 25 19:53:08.494: INFO: Pod downwardapi-volume-cacbea1f-80bc-4721-b417-bb0ea87a4994 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 25 19:53:08.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1310" for this suite. 04/25/23 19:53:08.548
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:53:08.604
Apr 25 19:53:08.604: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubelet-test 04/25/23 19:53:08.605
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:53:08.653
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:53:08.664
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Apr 25 19:53:08.697: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70" in namespace "kubelet-test-2828" to be "running and ready"
Apr 25 19:53:08.711: INFO: Pod "busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70": Phase="Pending", Reason="", readiness=false. Elapsed: 13.854417ms
Apr 25 19:53:08.711: INFO: The phase of Pod busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 19:53:10.724: INFO: Pod "busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026786075s
Apr 25 19:53:10.724: INFO: The phase of Pod busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 19:53:12.748: INFO: Pod "busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70": Phase="Running", Reason="", readiness=true. Elapsed: 4.051149728s
Apr 25 19:53:12.749: INFO: The phase of Pod busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70 is Running (Ready = true)
Apr 25 19:53:12.749: INFO: Pod "busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 25 19:53:12.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2828" for this suite. 04/25/23 19:53:12.81
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":68,"skipped":1276,"failed":0}
------------------------------
• [4.223 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:53:08.604
    Apr 25 19:53:08.604: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubelet-test 04/25/23 19:53:08.605
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:53:08.653
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:53:08.664
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Apr 25 19:53:08.697: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70" in namespace "kubelet-test-2828" to be "running and ready"
    Apr 25 19:53:08.711: INFO: Pod "busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70": Phase="Pending", Reason="", readiness=false. Elapsed: 13.854417ms
    Apr 25 19:53:08.711: INFO: The phase of Pod busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 19:53:10.724: INFO: Pod "busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026786075s
    Apr 25 19:53:10.724: INFO: The phase of Pod busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 19:53:12.748: INFO: Pod "busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70": Phase="Running", Reason="", readiness=true. Elapsed: 4.051149728s
    Apr 25 19:53:12.749: INFO: The phase of Pod busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70 is Running (Ready = true)
    Apr 25 19:53:12.749: INFO: Pod "busybox-readonly-fsa3dc336e-fe15-40a1-bf36-ee9b4ff95f70" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 25 19:53:12.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-2828" for this suite. 04/25/23 19:53:12.81
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:53:12.83
Apr 25 19:53:12.831: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename watch 04/25/23 19:53:12.834
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:53:12.881
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:53:12.9
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 04/25/23 19:53:12.91
STEP: starting a background goroutine to produce watch events 04/25/23 19:53:12.922
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 04/25/23 19:53:12.922
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 25 19:53:15.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8388" for this suite. 04/25/23 19:53:15.701
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":69,"skipped":1282,"failed":0}
------------------------------
• [2.926 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:53:12.83
    Apr 25 19:53:12.831: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename watch 04/25/23 19:53:12.834
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:53:12.881
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:53:12.9
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 04/25/23 19:53:12.91
    STEP: starting a background goroutine to produce watch events 04/25/23 19:53:12.922
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 04/25/23 19:53:12.922
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 25 19:53:15.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-8388" for this suite. 04/25/23 19:53:15.701
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:53:15.761
Apr 25 19:53:15.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename pod-network-test 04/25/23 19:53:15.762
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:53:15.809
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:53:15.82
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-5726 04/25/23 19:53:15.829
STEP: creating a selector 04/25/23 19:53:15.83
STEP: Creating the service pods in kubernetes 04/25/23 19:53:15.831
Apr 25 19:53:15.831: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 25 19:53:15.901: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5726" to be "running and ready"
Apr 25 19:53:15.913: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.640587ms
Apr 25 19:53:15.913: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 19:53:17.924: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022773609s
Apr 25 19:53:17.924: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 19:53:19.923: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.022079811s
Apr 25 19:53:19.923: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 19:53:21.924: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.023162766s
Apr 25 19:53:21.925: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 19:53:23.927: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.026056636s
Apr 25 19:53:23.927: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 19:53:25.924: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.022725915s
Apr 25 19:53:25.924: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 19:53:27.928: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.0262509s
Apr 25 19:53:27.928: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 19:53:29.924: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.022523936s
Apr 25 19:53:29.924: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 19:53:31.924: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.022959635s
Apr 25 19:53:31.924: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 19:53:33.924: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.023088794s
Apr 25 19:53:33.925: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 19:53:35.926: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.02492696s
Apr 25 19:53:35.926: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 19:53:37.924: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.023074294s
Apr 25 19:53:37.925: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 25 19:53:37.925: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 25 19:53:37.935: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5726" to be "running and ready"
Apr 25 19:53:37.944: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 9.173195ms
Apr 25 19:53:37.944: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 25 19:53:37.944: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 25 19:53:37.955: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5726" to be "running and ready"
Apr 25 19:53:37.964: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 8.894958ms
Apr 25 19:53:37.964: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 25 19:53:37.964: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/25/23 19:53:37.974
Apr 25 19:53:37.986: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5726" to be "running"
Apr 25 19:53:38.020: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 33.741518ms
Apr 25 19:53:40.033: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.046879877s
Apr 25 19:53:40.034: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 25 19:53:40.044: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 25 19:53:40.044: INFO: Breadth first check of 172.30.191.45 on host 10.10.21.136...
Apr 25 19:53:40.067: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.142.168:9080/dial?request=hostname&protocol=http&host=172.30.191.45&port=8083&tries=1'] Namespace:pod-network-test-5726 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 19:53:40.067: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 19:53:40.070: INFO: ExecWithOptions: Clientset creation
Apr 25 19:53:40.070: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5726/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.142.168%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.191.45%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 25 19:53:40.338: INFO: Waiting for responses: map[]
Apr 25 19:53:40.338: INFO: reached 172.30.191.45 after 0/1 tries
Apr 25 19:53:40.338: INFO: Breadth first check of 172.30.226.109 on host 10.10.21.161...
Apr 25 19:53:40.348: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.142.168:9080/dial?request=hostname&protocol=http&host=172.30.226.109&port=8083&tries=1'] Namespace:pod-network-test-5726 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 19:53:40.348: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 19:53:40.351: INFO: ExecWithOptions: Clientset creation
Apr 25 19:53:40.351: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5726/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.142.168%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.226.109%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 25 19:53:40.618: INFO: Waiting for responses: map[]
Apr 25 19:53:40.619: INFO: reached 172.30.226.109 after 0/1 tries
Apr 25 19:53:40.619: INFO: Breadth first check of 172.30.142.167 on host 10.10.21.190...
Apr 25 19:53:40.630: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.142.168:9080/dial?request=hostname&protocol=http&host=172.30.142.167&port=8083&tries=1'] Namespace:pod-network-test-5726 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 19:53:40.630: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 19:53:40.632: INFO: ExecWithOptions: Clientset creation
Apr 25 19:53:40.632: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5726/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.142.168%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.142.167%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 25 19:53:40.935: INFO: Waiting for responses: map[]
Apr 25 19:53:40.936: INFO: reached 172.30.142.167 after 0/1 tries
Apr 25 19:53:40.936: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 25 19:53:40.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5726" for this suite. 04/25/23 19:53:40.954
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":70,"skipped":1307,"failed":0}
------------------------------
• [SLOW TEST] [25.211 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:53:15.761
    Apr 25 19:53:15.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename pod-network-test 04/25/23 19:53:15.762
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:53:15.809
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:53:15.82
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-5726 04/25/23 19:53:15.829
    STEP: creating a selector 04/25/23 19:53:15.83
    STEP: Creating the service pods in kubernetes 04/25/23 19:53:15.831
    Apr 25 19:53:15.831: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 25 19:53:15.901: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5726" to be "running and ready"
    Apr 25 19:53:15.913: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.640587ms
    Apr 25 19:53:15.913: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 19:53:17.924: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022773609s
    Apr 25 19:53:17.924: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 19:53:19.923: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.022079811s
    Apr 25 19:53:19.923: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 19:53:21.924: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.023162766s
    Apr 25 19:53:21.925: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 19:53:23.927: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.026056636s
    Apr 25 19:53:23.927: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 19:53:25.924: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.022725915s
    Apr 25 19:53:25.924: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 19:53:27.928: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.0262509s
    Apr 25 19:53:27.928: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 19:53:29.924: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.022523936s
    Apr 25 19:53:29.924: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 19:53:31.924: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.022959635s
    Apr 25 19:53:31.924: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 19:53:33.924: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.023088794s
    Apr 25 19:53:33.925: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 19:53:35.926: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.02492696s
    Apr 25 19:53:35.926: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 19:53:37.924: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.023074294s
    Apr 25 19:53:37.925: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 25 19:53:37.925: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 25 19:53:37.935: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5726" to be "running and ready"
    Apr 25 19:53:37.944: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 9.173195ms
    Apr 25 19:53:37.944: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 25 19:53:37.944: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 25 19:53:37.955: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5726" to be "running and ready"
    Apr 25 19:53:37.964: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 8.894958ms
    Apr 25 19:53:37.964: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 25 19:53:37.964: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/25/23 19:53:37.974
    Apr 25 19:53:37.986: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5726" to be "running"
    Apr 25 19:53:38.020: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 33.741518ms
    Apr 25 19:53:40.033: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.046879877s
    Apr 25 19:53:40.034: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 25 19:53:40.044: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 25 19:53:40.044: INFO: Breadth first check of 172.30.191.45 on host 10.10.21.136...
    Apr 25 19:53:40.067: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.142.168:9080/dial?request=hostname&protocol=http&host=172.30.191.45&port=8083&tries=1'] Namespace:pod-network-test-5726 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 19:53:40.067: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 19:53:40.070: INFO: ExecWithOptions: Clientset creation
    Apr 25 19:53:40.070: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5726/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.142.168%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.191.45%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 25 19:53:40.338: INFO: Waiting for responses: map[]
    Apr 25 19:53:40.338: INFO: reached 172.30.191.45 after 0/1 tries
    Apr 25 19:53:40.338: INFO: Breadth first check of 172.30.226.109 on host 10.10.21.161...
    Apr 25 19:53:40.348: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.142.168:9080/dial?request=hostname&protocol=http&host=172.30.226.109&port=8083&tries=1'] Namespace:pod-network-test-5726 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 19:53:40.348: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 19:53:40.351: INFO: ExecWithOptions: Clientset creation
    Apr 25 19:53:40.351: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5726/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.142.168%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.226.109%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 25 19:53:40.618: INFO: Waiting for responses: map[]
    Apr 25 19:53:40.619: INFO: reached 172.30.226.109 after 0/1 tries
    Apr 25 19:53:40.619: INFO: Breadth first check of 172.30.142.167 on host 10.10.21.190...
    Apr 25 19:53:40.630: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.142.168:9080/dial?request=hostname&protocol=http&host=172.30.142.167&port=8083&tries=1'] Namespace:pod-network-test-5726 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 19:53:40.630: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 19:53:40.632: INFO: ExecWithOptions: Clientset creation
    Apr 25 19:53:40.632: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5726/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.142.168%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.142.167%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 25 19:53:40.935: INFO: Waiting for responses: map[]
    Apr 25 19:53:40.936: INFO: reached 172.30.142.167 after 0/1 tries
    Apr 25 19:53:40.936: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 25 19:53:40.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-5726" for this suite. 04/25/23 19:53:40.954
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:53:40.981
Apr 25 19:53:40.982: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-probe 04/25/23 19:53:40.984
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:53:41.03
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:53:41.039
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-e374a8b8-c1bc-4243-aa5b-422fe555a519 in namespace container-probe-5745 04/25/23 19:53:41.048
Apr 25 19:53:41.067: INFO: Waiting up to 5m0s for pod "test-webserver-e374a8b8-c1bc-4243-aa5b-422fe555a519" in namespace "container-probe-5745" to be "not pending"
Apr 25 19:53:41.081: INFO: Pod "test-webserver-e374a8b8-c1bc-4243-aa5b-422fe555a519": Phase="Pending", Reason="", readiness=false. Elapsed: 14.44582ms
Apr 25 19:53:43.093: INFO: Pod "test-webserver-e374a8b8-c1bc-4243-aa5b-422fe555a519": Phase="Running", Reason="", readiness=true. Elapsed: 2.026595162s
Apr 25 19:53:43.093: INFO: Pod "test-webserver-e374a8b8-c1bc-4243-aa5b-422fe555a519" satisfied condition "not pending"
Apr 25 19:53:43.094: INFO: Started pod test-webserver-e374a8b8-c1bc-4243-aa5b-422fe555a519 in namespace container-probe-5745
STEP: checking the pod's current state and verifying that restartCount is present 04/25/23 19:53:43.094
Apr 25 19:53:43.104: INFO: Initial restart count of pod test-webserver-e374a8b8-c1bc-4243-aa5b-422fe555a519 is 0
STEP: deleting the pod 04/25/23 19:57:44.622
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 25 19:57:44.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5745" for this suite. 04/25/23 19:57:44.682
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":71,"skipped":1322,"failed":0}
------------------------------
• [SLOW TEST] [243.718 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:53:40.981
    Apr 25 19:53:40.982: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-probe 04/25/23 19:53:40.984
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:53:41.03
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:53:41.039
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-e374a8b8-c1bc-4243-aa5b-422fe555a519 in namespace container-probe-5745 04/25/23 19:53:41.048
    Apr 25 19:53:41.067: INFO: Waiting up to 5m0s for pod "test-webserver-e374a8b8-c1bc-4243-aa5b-422fe555a519" in namespace "container-probe-5745" to be "not pending"
    Apr 25 19:53:41.081: INFO: Pod "test-webserver-e374a8b8-c1bc-4243-aa5b-422fe555a519": Phase="Pending", Reason="", readiness=false. Elapsed: 14.44582ms
    Apr 25 19:53:43.093: INFO: Pod "test-webserver-e374a8b8-c1bc-4243-aa5b-422fe555a519": Phase="Running", Reason="", readiness=true. Elapsed: 2.026595162s
    Apr 25 19:53:43.093: INFO: Pod "test-webserver-e374a8b8-c1bc-4243-aa5b-422fe555a519" satisfied condition "not pending"
    Apr 25 19:53:43.094: INFO: Started pod test-webserver-e374a8b8-c1bc-4243-aa5b-422fe555a519 in namespace container-probe-5745
    STEP: checking the pod's current state and verifying that restartCount is present 04/25/23 19:53:43.094
    Apr 25 19:53:43.104: INFO: Initial restart count of pod test-webserver-e374a8b8-c1bc-4243-aa5b-422fe555a519 is 0
    STEP: deleting the pod 04/25/23 19:57:44.622
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 25 19:57:44.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5745" for this suite. 04/25/23 19:57:44.682
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:57:44.701
Apr 25 19:57:44.701: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 19:57:44.705
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:57:44.747
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:57:44.756
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 04/25/23 19:57:44.788
Apr 25 19:57:44.808: INFO: Waiting up to 5m0s for pod "downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719" in namespace "projected-6627" to be "Succeeded or Failed"
Apr 25 19:57:44.820: INFO: Pod "downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719": Phase="Pending", Reason="", readiness=false. Elapsed: 11.974139ms
Apr 25 19:57:46.837: INFO: Pod "downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028748373s
Apr 25 19:57:48.832: INFO: Pod "downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024005449s
STEP: Saw pod success 04/25/23 19:57:48.832
Apr 25 19:57:48.832: INFO: Pod "downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719" satisfied condition "Succeeded or Failed"
Apr 25 19:57:48.847: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719 container client-container: <nil>
STEP: delete the pod 04/25/23 19:57:48.951
Apr 25 19:57:48.976: INFO: Waiting for pod downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719 to disappear
Apr 25 19:57:48.987: INFO: Pod downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 25 19:57:48.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6627" for this suite. 04/25/23 19:57:49.004
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":72,"skipped":1326,"failed":0}
------------------------------
• [4.320 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:57:44.701
    Apr 25 19:57:44.701: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 19:57:44.705
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:57:44.747
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:57:44.756
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 04/25/23 19:57:44.788
    Apr 25 19:57:44.808: INFO: Waiting up to 5m0s for pod "downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719" in namespace "projected-6627" to be "Succeeded or Failed"
    Apr 25 19:57:44.820: INFO: Pod "downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719": Phase="Pending", Reason="", readiness=false. Elapsed: 11.974139ms
    Apr 25 19:57:46.837: INFO: Pod "downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028748373s
    Apr 25 19:57:48.832: INFO: Pod "downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024005449s
    STEP: Saw pod success 04/25/23 19:57:48.832
    Apr 25 19:57:48.832: INFO: Pod "downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719" satisfied condition "Succeeded or Failed"
    Apr 25 19:57:48.847: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719 container client-container: <nil>
    STEP: delete the pod 04/25/23 19:57:48.951
    Apr 25 19:57:48.976: INFO: Waiting for pod downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719 to disappear
    Apr 25 19:57:48.987: INFO: Pod downwardapi-volume-37a25c65-fc1f-4111-a544-3be07e063719 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 25 19:57:48.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6627" for this suite. 04/25/23 19:57:49.004
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:57:49.052
Apr 25 19:57:49.052: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir 04/25/23 19:57:49.053
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:57:49.096
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:57:49.113
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 04/25/23 19:57:49.121
Apr 25 19:57:49.139: INFO: Waiting up to 5m0s for pod "pod-dd3c89ed-8005-4982-8d98-2c2c4964e412" in namespace "emptydir-3004" to be "Succeeded or Failed"
Apr 25 19:57:49.149: INFO: Pod "pod-dd3c89ed-8005-4982-8d98-2c2c4964e412": Phase="Pending", Reason="", readiness=false. Elapsed: 9.238067ms
Apr 25 19:57:51.166: INFO: Pod "pod-dd3c89ed-8005-4982-8d98-2c2c4964e412": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026772187s
Apr 25 19:57:53.161: INFO: Pod "pod-dd3c89ed-8005-4982-8d98-2c2c4964e412": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021203379s
Apr 25 19:57:55.161: INFO: Pod "pod-dd3c89ed-8005-4982-8d98-2c2c4964e412": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021160394s
STEP: Saw pod success 04/25/23 19:57:55.161
Apr 25 19:57:55.161: INFO: Pod "pod-dd3c89ed-8005-4982-8d98-2c2c4964e412" satisfied condition "Succeeded or Failed"
Apr 25 19:57:55.171: INFO: Trying to get logs from node 10.10.21.190 pod pod-dd3c89ed-8005-4982-8d98-2c2c4964e412 container test-container: <nil>
STEP: delete the pod 04/25/23 19:57:55.214
Apr 25 19:57:55.238: INFO: Waiting for pod pod-dd3c89ed-8005-4982-8d98-2c2c4964e412 to disappear
Apr 25 19:57:55.248: INFO: Pod pod-dd3c89ed-8005-4982-8d98-2c2c4964e412 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 25 19:57:55.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3004" for this suite. 04/25/23 19:57:55.265
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":73,"skipped":1429,"failed":0}
------------------------------
• [SLOW TEST] [6.231 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:57:49.052
    Apr 25 19:57:49.052: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir 04/25/23 19:57:49.053
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:57:49.096
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:57:49.113
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 04/25/23 19:57:49.121
    Apr 25 19:57:49.139: INFO: Waiting up to 5m0s for pod "pod-dd3c89ed-8005-4982-8d98-2c2c4964e412" in namespace "emptydir-3004" to be "Succeeded or Failed"
    Apr 25 19:57:49.149: INFO: Pod "pod-dd3c89ed-8005-4982-8d98-2c2c4964e412": Phase="Pending", Reason="", readiness=false. Elapsed: 9.238067ms
    Apr 25 19:57:51.166: INFO: Pod "pod-dd3c89ed-8005-4982-8d98-2c2c4964e412": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026772187s
    Apr 25 19:57:53.161: INFO: Pod "pod-dd3c89ed-8005-4982-8d98-2c2c4964e412": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021203379s
    Apr 25 19:57:55.161: INFO: Pod "pod-dd3c89ed-8005-4982-8d98-2c2c4964e412": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021160394s
    STEP: Saw pod success 04/25/23 19:57:55.161
    Apr 25 19:57:55.161: INFO: Pod "pod-dd3c89ed-8005-4982-8d98-2c2c4964e412" satisfied condition "Succeeded or Failed"
    Apr 25 19:57:55.171: INFO: Trying to get logs from node 10.10.21.190 pod pod-dd3c89ed-8005-4982-8d98-2c2c4964e412 container test-container: <nil>
    STEP: delete the pod 04/25/23 19:57:55.214
    Apr 25 19:57:55.238: INFO: Waiting for pod pod-dd3c89ed-8005-4982-8d98-2c2c4964e412 to disappear
    Apr 25 19:57:55.248: INFO: Pod pod-dd3c89ed-8005-4982-8d98-2c2c4964e412 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 25 19:57:55.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3004" for this suite. 04/25/23 19:57:55.265
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:57:55.294
Apr 25 19:57:55.294: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 19:57:55.295
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:57:55.335
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:57:55.344
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 04/25/23 19:57:55.351
Apr 25 19:57:55.375: INFO: Waiting up to 5m0s for pod "downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9" in namespace "projected-89" to be "Succeeded or Failed"
Apr 25 19:57:55.386: INFO: Pod "downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.120156ms
Apr 25 19:57:57.398: INFO: Pod "downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023106914s
Apr 25 19:57:59.398: INFO: Pod "downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023392745s
STEP: Saw pod success 04/25/23 19:57:59.399
Apr 25 19:57:59.399: INFO: Pod "downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9" satisfied condition "Succeeded or Failed"
Apr 25 19:57:59.410: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9 container client-container: <nil>
STEP: delete the pod 04/25/23 19:57:59.477
Apr 25 19:57:59.506: INFO: Waiting for pod downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9 to disappear
Apr 25 19:57:59.515: INFO: Pod downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 25 19:57:59.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-89" for this suite. 04/25/23 19:57:59.535
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":74,"skipped":1458,"failed":0}
------------------------------
• [4.259 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:57:55.294
    Apr 25 19:57:55.294: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 19:57:55.295
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:57:55.335
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:57:55.344
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 04/25/23 19:57:55.351
    Apr 25 19:57:55.375: INFO: Waiting up to 5m0s for pod "downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9" in namespace "projected-89" to be "Succeeded or Failed"
    Apr 25 19:57:55.386: INFO: Pod "downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.120156ms
    Apr 25 19:57:57.398: INFO: Pod "downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023106914s
    Apr 25 19:57:59.398: INFO: Pod "downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023392745s
    STEP: Saw pod success 04/25/23 19:57:59.399
    Apr 25 19:57:59.399: INFO: Pod "downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9" satisfied condition "Succeeded or Failed"
    Apr 25 19:57:59.410: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9 container client-container: <nil>
    STEP: delete the pod 04/25/23 19:57:59.477
    Apr 25 19:57:59.506: INFO: Waiting for pod downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9 to disappear
    Apr 25 19:57:59.515: INFO: Pod downwardapi-volume-103f4f09-afba-4e7f-8973-4b62d75a49a9 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 25 19:57:59.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-89" for this suite. 04/25/23 19:57:59.535
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:57:59.557
Apr 25 19:57:59.558: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename pods 04/25/23 19:57:59.561
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:57:59.619
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:57:59.626
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 04/25/23 19:57:59.635
STEP: submitting the pod to kubernetes 04/25/23 19:57:59.636
STEP: verifying QOS class is set on the pod 04/25/23 19:57:59.654
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Apr 25 19:57:59.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4291" for this suite. 04/25/23 19:57:59.68
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":75,"skipped":1469,"failed":0}
------------------------------
• [0.152 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:57:59.557
    Apr 25 19:57:59.558: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename pods 04/25/23 19:57:59.561
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:57:59.619
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:57:59.626
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 04/25/23 19:57:59.635
    STEP: submitting the pod to kubernetes 04/25/23 19:57:59.636
    STEP: verifying QOS class is set on the pod 04/25/23 19:57:59.654
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Apr 25 19:57:59.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4291" for this suite. 04/25/23 19:57:59.68
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:57:59.723
Apr 25 19:57:59.723: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename gc 04/25/23 19:57:59.725
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:57:59.8
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:57:59.808
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 04/25/23 19:57:59.817
STEP: Wait for the Deployment to create new ReplicaSet 04/25/23 19:57:59.839
STEP: delete the deployment 04/25/23 19:58:00.402
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 04/25/23 19:58:00.424
STEP: Gathering metrics 04/25/23 19:58:01.043
W0425 19:58:01.072152      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 25 19:58:01.072: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 25 19:58:01.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9680" for this suite. 04/25/23 19:58:01.091
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":76,"skipped":1513,"failed":0}
------------------------------
• [1.386 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:57:59.723
    Apr 25 19:57:59.723: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename gc 04/25/23 19:57:59.725
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:57:59.8
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:57:59.808
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 04/25/23 19:57:59.817
    STEP: Wait for the Deployment to create new ReplicaSet 04/25/23 19:57:59.839
    STEP: delete the deployment 04/25/23 19:58:00.402
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 04/25/23 19:58:00.424
    STEP: Gathering metrics 04/25/23 19:58:01.043
    W0425 19:58:01.072152      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 25 19:58:01.072: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 25 19:58:01.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-9680" for this suite. 04/25/23 19:58:01.091
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:58:01.113
Apr 25 19:58:01.113: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename dns 04/25/23 19:58:01.118
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:01.163
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:01.175
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 04/25/23 19:58:01.184
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 04/25/23 19:58:01.185
STEP: creating a pod to probe DNS 04/25/23 19:58:01.185
STEP: submitting the pod to kubernetes 04/25/23 19:58:01.186
Apr 25 19:58:01.205: INFO: Waiting up to 15m0s for pod "dns-test-b71689e5-bbc1-4eeb-b0d1-148a007c4219" in namespace "dns-8431" to be "running"
Apr 25 19:58:01.215: INFO: Pod "dns-test-b71689e5-bbc1-4eeb-b0d1-148a007c4219": Phase="Pending", Reason="", readiness=false. Elapsed: 9.73102ms
Apr 25 19:58:03.227: INFO: Pod "dns-test-b71689e5-bbc1-4eeb-b0d1-148a007c4219": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021969595s
Apr 25 19:58:05.227: INFO: Pod "dns-test-b71689e5-bbc1-4eeb-b0d1-148a007c4219": Phase="Running", Reason="", readiness=true. Elapsed: 4.022029249s
Apr 25 19:58:05.227: INFO: Pod "dns-test-b71689e5-bbc1-4eeb-b0d1-148a007c4219" satisfied condition "running"
STEP: retrieving the pod 04/25/23 19:58:05.227
STEP: looking for the results for each expected name from probers 04/25/23 19:58:05.236
Apr 25 19:58:05.347: INFO: DNS probes using dns-8431/dns-test-b71689e5-bbc1-4eeb-b0d1-148a007c4219 succeeded

STEP: deleting the pod 04/25/23 19:58:05.347
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 25 19:58:05.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8431" for this suite. 04/25/23 19:58:05.45
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":77,"skipped":1519,"failed":0}
------------------------------
• [4.370 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:58:01.113
    Apr 25 19:58:01.113: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename dns 04/25/23 19:58:01.118
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:01.163
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:01.175
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     04/25/23 19:58:01.184
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     04/25/23 19:58:01.185
    STEP: creating a pod to probe DNS 04/25/23 19:58:01.185
    STEP: submitting the pod to kubernetes 04/25/23 19:58:01.186
    Apr 25 19:58:01.205: INFO: Waiting up to 15m0s for pod "dns-test-b71689e5-bbc1-4eeb-b0d1-148a007c4219" in namespace "dns-8431" to be "running"
    Apr 25 19:58:01.215: INFO: Pod "dns-test-b71689e5-bbc1-4eeb-b0d1-148a007c4219": Phase="Pending", Reason="", readiness=false. Elapsed: 9.73102ms
    Apr 25 19:58:03.227: INFO: Pod "dns-test-b71689e5-bbc1-4eeb-b0d1-148a007c4219": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021969595s
    Apr 25 19:58:05.227: INFO: Pod "dns-test-b71689e5-bbc1-4eeb-b0d1-148a007c4219": Phase="Running", Reason="", readiness=true. Elapsed: 4.022029249s
    Apr 25 19:58:05.227: INFO: Pod "dns-test-b71689e5-bbc1-4eeb-b0d1-148a007c4219" satisfied condition "running"
    STEP: retrieving the pod 04/25/23 19:58:05.227
    STEP: looking for the results for each expected name from probers 04/25/23 19:58:05.236
    Apr 25 19:58:05.347: INFO: DNS probes using dns-8431/dns-test-b71689e5-bbc1-4eeb-b0d1-148a007c4219 succeeded

    STEP: deleting the pod 04/25/23 19:58:05.347
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 25 19:58:05.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-8431" for this suite. 04/25/23 19:58:05.45
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:58:05.485
Apr 25 19:58:05.486: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-runtime 04/25/23 19:58:05.49
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:05.528
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:05.538
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 04/25/23 19:58:05.548
STEP: wait for the container to reach Failed 04/25/23 19:58:05.57
STEP: get the container status 04/25/23 19:58:09.625
STEP: the container should be terminated 04/25/23 19:58:09.636
STEP: the termination message should be set 04/25/23 19:58:09.636
Apr 25 19:58:09.637: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 04/25/23 19:58:09.637
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 25 19:58:09.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7289" for this suite. 04/25/23 19:58:09.723
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":78,"skipped":1533,"failed":0}
------------------------------
• [4.257 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:58:05.485
    Apr 25 19:58:05.486: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-runtime 04/25/23 19:58:05.49
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:05.528
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:05.538
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 04/25/23 19:58:05.548
    STEP: wait for the container to reach Failed 04/25/23 19:58:05.57
    STEP: get the container status 04/25/23 19:58:09.625
    STEP: the container should be terminated 04/25/23 19:58:09.636
    STEP: the termination message should be set 04/25/23 19:58:09.636
    Apr 25 19:58:09.637: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 04/25/23 19:58:09.637
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 25 19:58:09.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-7289" for this suite. 04/25/23 19:58:09.723
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:58:09.755
Apr 25 19:58:09.755: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename configmap 04/25/23 19:58:09.758
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:09.8
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:09.809
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-653da88c-2536-44e9-a645-a22f3e6d8246 04/25/23 19:58:09.819
STEP: Creating a pod to test consume configMaps 04/25/23 19:58:09.833
Apr 25 19:58:09.853: INFO: Waiting up to 5m0s for pod "pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401" in namespace "configmap-6874" to be "Succeeded or Failed"
Apr 25 19:58:09.867: INFO: Pod "pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401": Phase="Pending", Reason="", readiness=false. Elapsed: 13.965393ms
Apr 25 19:58:11.878: INFO: Pod "pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025265703s
Apr 25 19:58:13.879: INFO: Pod "pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026464462s
STEP: Saw pod success 04/25/23 19:58:13.88
Apr 25 19:58:13.881: INFO: Pod "pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401" satisfied condition "Succeeded or Failed"
Apr 25 19:58:13.892: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401 container agnhost-container: <nil>
STEP: delete the pod 04/25/23 19:58:13.924
Apr 25 19:58:13.949: INFO: Waiting for pod pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401 to disappear
Apr 25 19:58:13.959: INFO: Pod pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 25 19:58:13.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6874" for this suite. 04/25/23 19:58:13.977
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":79,"skipped":1540,"failed":0}
------------------------------
• [4.241 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:58:09.755
    Apr 25 19:58:09.755: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename configmap 04/25/23 19:58:09.758
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:09.8
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:09.809
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-653da88c-2536-44e9-a645-a22f3e6d8246 04/25/23 19:58:09.819
    STEP: Creating a pod to test consume configMaps 04/25/23 19:58:09.833
    Apr 25 19:58:09.853: INFO: Waiting up to 5m0s for pod "pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401" in namespace "configmap-6874" to be "Succeeded or Failed"
    Apr 25 19:58:09.867: INFO: Pod "pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401": Phase="Pending", Reason="", readiness=false. Elapsed: 13.965393ms
    Apr 25 19:58:11.878: INFO: Pod "pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025265703s
    Apr 25 19:58:13.879: INFO: Pod "pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026464462s
    STEP: Saw pod success 04/25/23 19:58:13.88
    Apr 25 19:58:13.881: INFO: Pod "pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401" satisfied condition "Succeeded or Failed"
    Apr 25 19:58:13.892: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401 container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 19:58:13.924
    Apr 25 19:58:13.949: INFO: Waiting for pod pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401 to disappear
    Apr 25 19:58:13.959: INFO: Pod pod-configmaps-57584e71-73e6-43ff-bf3d-47df20ea0401 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 25 19:58:13.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6874" for this suite. 04/25/23 19:58:13.977
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:58:14.005
Apr 25 19:58:14.006: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 19:58:14.008
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:14.051
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:14.059
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Apr 25 19:58:14.069: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/25/23 19:58:17.184
Apr 25 19:58:17.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-3806 --namespace=crd-publish-openapi-3806 create -f -'
Apr 25 19:58:18.038: INFO: stderr: ""
Apr 25 19:58:18.038: INFO: stdout: "e2e-test-crd-publish-openapi-1146-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 25 19:58:18.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-3806 --namespace=crd-publish-openapi-3806 delete e2e-test-crd-publish-openapi-1146-crds test-cr'
Apr 25 19:58:18.200: INFO: stderr: ""
Apr 25 19:58:18.200: INFO: stdout: "e2e-test-crd-publish-openapi-1146-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Apr 25 19:58:18.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-3806 --namespace=crd-publish-openapi-3806 apply -f -'
Apr 25 19:58:19.074: INFO: stderr: ""
Apr 25 19:58:19.074: INFO: stdout: "e2e-test-crd-publish-openapi-1146-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 25 19:58:19.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-3806 --namespace=crd-publish-openapi-3806 delete e2e-test-crd-publish-openapi-1146-crds test-cr'
Apr 25 19:58:19.227: INFO: stderr: ""
Apr 25 19:58:19.228: INFO: stdout: "e2e-test-crd-publish-openapi-1146-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 04/25/23 19:58:19.228
Apr 25 19:58:19.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-3806 explain e2e-test-crd-publish-openapi-1146-crds'
Apr 25 19:58:19.519: INFO: stderr: ""
Apr 25 19:58:19.519: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1146-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 19:58:22.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3806" for this suite. 04/25/23 19:58:22.328
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":80,"skipped":1548,"failed":0}
------------------------------
• [SLOW TEST] [8.369 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:58:14.005
    Apr 25 19:58:14.006: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 19:58:14.008
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:14.051
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:14.059
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Apr 25 19:58:14.069: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/25/23 19:58:17.184
    Apr 25 19:58:17.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-3806 --namespace=crd-publish-openapi-3806 create -f -'
    Apr 25 19:58:18.038: INFO: stderr: ""
    Apr 25 19:58:18.038: INFO: stdout: "e2e-test-crd-publish-openapi-1146-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Apr 25 19:58:18.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-3806 --namespace=crd-publish-openapi-3806 delete e2e-test-crd-publish-openapi-1146-crds test-cr'
    Apr 25 19:58:18.200: INFO: stderr: ""
    Apr 25 19:58:18.200: INFO: stdout: "e2e-test-crd-publish-openapi-1146-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Apr 25 19:58:18.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-3806 --namespace=crd-publish-openapi-3806 apply -f -'
    Apr 25 19:58:19.074: INFO: stderr: ""
    Apr 25 19:58:19.074: INFO: stdout: "e2e-test-crd-publish-openapi-1146-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Apr 25 19:58:19.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-3806 --namespace=crd-publish-openapi-3806 delete e2e-test-crd-publish-openapi-1146-crds test-cr'
    Apr 25 19:58:19.227: INFO: stderr: ""
    Apr 25 19:58:19.228: INFO: stdout: "e2e-test-crd-publish-openapi-1146-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 04/25/23 19:58:19.228
    Apr 25 19:58:19.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-3806 explain e2e-test-crd-publish-openapi-1146-crds'
    Apr 25 19:58:19.519: INFO: stderr: ""
    Apr 25 19:58:19.519: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1146-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 19:58:22.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-3806" for this suite. 04/25/23 19:58:22.328
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:58:22.379
Apr 25 19:58:22.380: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename var-expansion 04/25/23 19:58:22.383
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:22.436
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:22.446
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 04/25/23 19:58:22.457
Apr 25 19:58:22.476: INFO: Waiting up to 5m0s for pod "var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b" in namespace "var-expansion-8896" to be "Succeeded or Failed"
Apr 25 19:58:22.511: INFO: Pod "var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b": Phase="Pending", Reason="", readiness=false. Elapsed: 35.245426ms
Apr 25 19:58:24.523: INFO: Pod "var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047592536s
Apr 25 19:58:26.526: INFO: Pod "var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050127011s
STEP: Saw pod success 04/25/23 19:58:26.526
Apr 25 19:58:26.526: INFO: Pod "var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b" satisfied condition "Succeeded or Failed"
Apr 25 19:58:26.537: INFO: Trying to get logs from node 10.10.21.190 pod var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b container dapi-container: <nil>
STEP: delete the pod 04/25/23 19:58:26.567
Apr 25 19:58:26.605: INFO: Waiting for pod var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b to disappear
Apr 25 19:58:26.615: INFO: Pod var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 25 19:58:26.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8896" for this suite. 04/25/23 19:58:26.632
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":81,"skipped":1564,"failed":0}
------------------------------
• [4.270 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:58:22.379
    Apr 25 19:58:22.380: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename var-expansion 04/25/23 19:58:22.383
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:22.436
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:22.446
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 04/25/23 19:58:22.457
    Apr 25 19:58:22.476: INFO: Waiting up to 5m0s for pod "var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b" in namespace "var-expansion-8896" to be "Succeeded or Failed"
    Apr 25 19:58:22.511: INFO: Pod "var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b": Phase="Pending", Reason="", readiness=false. Elapsed: 35.245426ms
    Apr 25 19:58:24.523: INFO: Pod "var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047592536s
    Apr 25 19:58:26.526: INFO: Pod "var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050127011s
    STEP: Saw pod success 04/25/23 19:58:26.526
    Apr 25 19:58:26.526: INFO: Pod "var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b" satisfied condition "Succeeded or Failed"
    Apr 25 19:58:26.537: INFO: Trying to get logs from node 10.10.21.190 pod var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b container dapi-container: <nil>
    STEP: delete the pod 04/25/23 19:58:26.567
    Apr 25 19:58:26.605: INFO: Waiting for pod var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b to disappear
    Apr 25 19:58:26.615: INFO: Pod var-expansion-2fe8c171-6d27-42a4-8901-9493241d440b no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 25 19:58:26.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-8896" for this suite. 04/25/23 19:58:26.632
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:58:26.653
Apr 25 19:58:26.654: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename secrets 04/25/23 19:58:26.656
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:26.696
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:26.706
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-55b5ca84-ed2f-4b9b-ba85-640a6c5dfe24 04/25/23 19:58:26.719
STEP: Creating a pod to test consume secrets 04/25/23 19:58:26.733
Apr 25 19:58:26.752: INFO: Waiting up to 5m0s for pod "pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817" in namespace "secrets-9704" to be "Succeeded or Failed"
Apr 25 19:58:26.763: INFO: Pod "pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817": Phase="Pending", Reason="", readiness=false. Elapsed: 10.989494ms
Apr 25 19:58:28.777: INFO: Pod "pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024529407s
Apr 25 19:58:30.794: INFO: Pod "pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041433259s
STEP: Saw pod success 04/25/23 19:58:30.794
Apr 25 19:58:30.795: INFO: Pod "pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817" satisfied condition "Succeeded or Failed"
Apr 25 19:58:30.830: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817 container secret-volume-test: <nil>
STEP: delete the pod 04/25/23 19:58:30.86
Apr 25 19:58:30.891: INFO: Waiting for pod pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817 to disappear
Apr 25 19:58:30.903: INFO: Pod pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 25 19:58:30.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9704" for this suite. 04/25/23 19:58:30.922
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":82,"skipped":1567,"failed":0}
------------------------------
• [4.289 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:58:26.653
    Apr 25 19:58:26.654: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename secrets 04/25/23 19:58:26.656
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:26.696
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:26.706
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-55b5ca84-ed2f-4b9b-ba85-640a6c5dfe24 04/25/23 19:58:26.719
    STEP: Creating a pod to test consume secrets 04/25/23 19:58:26.733
    Apr 25 19:58:26.752: INFO: Waiting up to 5m0s for pod "pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817" in namespace "secrets-9704" to be "Succeeded or Failed"
    Apr 25 19:58:26.763: INFO: Pod "pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817": Phase="Pending", Reason="", readiness=false. Elapsed: 10.989494ms
    Apr 25 19:58:28.777: INFO: Pod "pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024529407s
    Apr 25 19:58:30.794: INFO: Pod "pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041433259s
    STEP: Saw pod success 04/25/23 19:58:30.794
    Apr 25 19:58:30.795: INFO: Pod "pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817" satisfied condition "Succeeded or Failed"
    Apr 25 19:58:30.830: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817 container secret-volume-test: <nil>
    STEP: delete the pod 04/25/23 19:58:30.86
    Apr 25 19:58:30.891: INFO: Waiting for pod pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817 to disappear
    Apr 25 19:58:30.903: INFO: Pod pod-secrets-e5d59a8e-4e18-4126-9ec3-53c157150817 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 25 19:58:30.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9704" for this suite. 04/25/23 19:58:30.922
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:58:30.951
Apr 25 19:58:30.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 19:58:30.955
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:31.064
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:31.074
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2212 04/25/23 19:58:31.083
STEP: changing the ExternalName service to type=NodePort 04/25/23 19:58:31.102
STEP: creating replication controller externalname-service in namespace services-2212 04/25/23 19:58:31.159
I0425 19:58:31.172073      23 runners.go:193] Created replication controller with name: externalname-service, namespace: services-2212, replica count: 2
I0425 19:58:34.224051      23 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 25 19:58:34.224: INFO: Creating new exec pod
Apr 25 19:58:34.244: INFO: Waiting up to 5m0s for pod "execpodtgmq2" in namespace "services-2212" to be "running"
Apr 25 19:58:34.255: INFO: Pod "execpodtgmq2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.401349ms
Apr 25 19:58:36.270: INFO: Pod "execpodtgmq2": Phase="Running", Reason="", readiness=true. Elapsed: 2.026266603s
Apr 25 19:58:36.270: INFO: Pod "execpodtgmq2" satisfied condition "running"
Apr 25 19:58:37.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2212 exec execpodtgmq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 25 19:58:37.691: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 25 19:58:37.691: INFO: stdout: "externalname-service-26gk2"
Apr 25 19:58:37.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2212 exec execpodtgmq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.173.90 80'
Apr 25 19:58:38.045: INFO: stderr: "+ nc -v -t -w 2 172.21.173.90 80\n+ echo hostName\nConnection to 172.21.173.90 80 port [tcp/http] succeeded!\n"
Apr 25 19:58:38.045: INFO: stdout: "externalname-service-26gk2"
Apr 25 19:58:38.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2212 exec execpodtgmq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.161 30569'
Apr 25 19:58:38.427: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.161 30569\nConnection to 10.10.21.161 30569 port [tcp/*] succeeded!\n"
Apr 25 19:58:38.427: INFO: stdout: "externalname-service-26gk2"
Apr 25 19:58:38.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2212 exec execpodtgmq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.190 30569'
Apr 25 19:58:38.774: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.190 30569\nConnection to 10.10.21.190 30569 port [tcp/*] succeeded!\n"
Apr 25 19:58:38.774: INFO: stdout: "externalname-service-26gk2"
Apr 25 19:58:38.774: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 19:58:38.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2212" for this suite. 04/25/23 19:58:38.901
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":83,"skipped":1573,"failed":0}
------------------------------
• [SLOW TEST] [7.968 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:58:30.951
    Apr 25 19:58:30.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 19:58:30.955
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:31.064
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:31.074
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-2212 04/25/23 19:58:31.083
    STEP: changing the ExternalName service to type=NodePort 04/25/23 19:58:31.102
    STEP: creating replication controller externalname-service in namespace services-2212 04/25/23 19:58:31.159
    I0425 19:58:31.172073      23 runners.go:193] Created replication controller with name: externalname-service, namespace: services-2212, replica count: 2
    I0425 19:58:34.224051      23 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 25 19:58:34.224: INFO: Creating new exec pod
    Apr 25 19:58:34.244: INFO: Waiting up to 5m0s for pod "execpodtgmq2" in namespace "services-2212" to be "running"
    Apr 25 19:58:34.255: INFO: Pod "execpodtgmq2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.401349ms
    Apr 25 19:58:36.270: INFO: Pod "execpodtgmq2": Phase="Running", Reason="", readiness=true. Elapsed: 2.026266603s
    Apr 25 19:58:36.270: INFO: Pod "execpodtgmq2" satisfied condition "running"
    Apr 25 19:58:37.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2212 exec execpodtgmq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 25 19:58:37.691: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 25 19:58:37.691: INFO: stdout: "externalname-service-26gk2"
    Apr 25 19:58:37.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2212 exec execpodtgmq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.173.90 80'
    Apr 25 19:58:38.045: INFO: stderr: "+ nc -v -t -w 2 172.21.173.90 80\n+ echo hostName\nConnection to 172.21.173.90 80 port [tcp/http] succeeded!\n"
    Apr 25 19:58:38.045: INFO: stdout: "externalname-service-26gk2"
    Apr 25 19:58:38.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2212 exec execpodtgmq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.161 30569'
    Apr 25 19:58:38.427: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.161 30569\nConnection to 10.10.21.161 30569 port [tcp/*] succeeded!\n"
    Apr 25 19:58:38.427: INFO: stdout: "externalname-service-26gk2"
    Apr 25 19:58:38.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-2212 exec execpodtgmq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.190 30569'
    Apr 25 19:58:38.774: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.190 30569\nConnection to 10.10.21.190 30569 port [tcp/*] succeeded!\n"
    Apr 25 19:58:38.774: INFO: stdout: "externalname-service-26gk2"
    Apr 25 19:58:38.774: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 19:58:38.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2212" for this suite. 04/25/23 19:58:38.901
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:58:38.924
Apr 25 19:58:38.924: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir-wrapper 04/25/23 19:58:38.925
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:38.967
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:38.974
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 04/25/23 19:58:38.983
STEP: Creating RC which spawns configmap-volume pods 04/25/23 19:58:39.714
Apr 25 19:58:39.744: INFO: Pod name wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b: Found 0 pods out of 5
Apr 25 19:58:44.774: INFO: Pod name wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/25/23 19:58:44.774
Apr 25 19:58:44.775: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-96p9n" in namespace "emptydir-wrapper-8037" to be "running"
Apr 25 19:58:44.790: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-96p9n": Phase="Running", Reason="", readiness=true. Elapsed: 14.066717ms
Apr 25 19:58:44.790: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-96p9n" satisfied condition "running"
Apr 25 19:58:44.790: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-dx66h" in namespace "emptydir-wrapper-8037" to be "running"
Apr 25 19:58:44.830: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-dx66h": Phase="Running", Reason="", readiness=true. Elapsed: 39.785542ms
Apr 25 19:58:44.830: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-dx66h" satisfied condition "running"
Apr 25 19:58:44.830: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-sdk4z" in namespace "emptydir-wrapper-8037" to be "running"
Apr 25 19:58:44.844: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-sdk4z": Phase="Running", Reason="", readiness=true. Elapsed: 13.462643ms
Apr 25 19:58:44.844: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-sdk4z" satisfied condition "running"
Apr 25 19:58:44.844: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-w8xrp" in namespace "emptydir-wrapper-8037" to be "running"
Apr 25 19:58:44.871: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-w8xrp": Phase="Running", Reason="", readiness=true. Elapsed: 27.15706ms
Apr 25 19:58:44.872: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-w8xrp" satisfied condition "running"
Apr 25 19:58:44.872: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-z6bmm" in namespace "emptydir-wrapper-8037" to be "running"
Apr 25 19:58:44.892: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-z6bmm": Phase="Running", Reason="", readiness=true. Elapsed: 18.478352ms
Apr 25 19:58:44.892: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-z6bmm" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b in namespace emptydir-wrapper-8037, will wait for the garbage collector to delete the pods 04/25/23 19:58:44.892
Apr 25 19:58:44.977: INFO: Deleting ReplicationController wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b took: 21.431554ms
Apr 25 19:58:45.178: INFO: Terminating ReplicationController wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b pods took: 201.255495ms
STEP: Creating RC which spawns configmap-volume pods 04/25/23 19:58:48.095
Apr 25 19:58:48.127: INFO: Pod name wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672: Found 0 pods out of 5
Apr 25 19:58:53.151: INFO: Pod name wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/25/23 19:58:53.151
Apr 25 19:58:53.151: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-8tpnz" in namespace "emptydir-wrapper-8037" to be "running"
Apr 25 19:58:53.163: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-8tpnz": Phase="Running", Reason="", readiness=true. Elapsed: 11.33187ms
Apr 25 19:58:53.163: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-8tpnz" satisfied condition "running"
Apr 25 19:58:53.163: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-brfks" in namespace "emptydir-wrapper-8037" to be "running"
Apr 25 19:58:53.173: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-brfks": Phase="Running", Reason="", readiness=true. Elapsed: 10.311598ms
Apr 25 19:58:53.173: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-brfks" satisfied condition "running"
Apr 25 19:58:53.173: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-hvjkf" in namespace "emptydir-wrapper-8037" to be "running"
Apr 25 19:58:53.185: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-hvjkf": Phase="Running", Reason="", readiness=true. Elapsed: 11.527922ms
Apr 25 19:58:53.185: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-hvjkf" satisfied condition "running"
Apr 25 19:58:53.185: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-qzkk4" in namespace "emptydir-wrapper-8037" to be "running"
Apr 25 19:58:53.195: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-qzkk4": Phase="Running", Reason="", readiness=true. Elapsed: 10.503981ms
Apr 25 19:58:53.195: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-qzkk4" satisfied condition "running"
Apr 25 19:58:53.195: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-xtwqf" in namespace "emptydir-wrapper-8037" to be "running"
Apr 25 19:58:53.205: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-xtwqf": Phase="Running", Reason="", readiness=true. Elapsed: 9.480456ms
Apr 25 19:58:53.205: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-xtwqf" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672 in namespace emptydir-wrapper-8037, will wait for the garbage collector to delete the pods 04/25/23 19:58:53.205
Apr 25 19:58:53.318: INFO: Deleting ReplicationController wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672 took: 19.466749ms
Apr 25 19:58:53.419: INFO: Terminating ReplicationController wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672 pods took: 100.6885ms
STEP: Creating RC which spawns configmap-volume pods 04/25/23 19:58:55.941
Apr 25 19:58:55.972: INFO: Pod name wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45: Found 0 pods out of 5
Apr 25 19:59:00.995: INFO: Pod name wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/25/23 19:59:00.995
Apr 25 19:59:00.996: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-fqj2h" in namespace "emptydir-wrapper-8037" to be "running"
Apr 25 19:59:01.007: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-fqj2h": Phase="Running", Reason="", readiness=true. Elapsed: 11.110254ms
Apr 25 19:59:01.008: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-fqj2h" satisfied condition "running"
Apr 25 19:59:01.008: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-mfcn6" in namespace "emptydir-wrapper-8037" to be "running"
Apr 25 19:59:01.022: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-mfcn6": Phase="Running", Reason="", readiness=true. Elapsed: 13.557074ms
Apr 25 19:59:01.022: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-mfcn6" satisfied condition "running"
Apr 25 19:59:01.022: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-p64z9" in namespace "emptydir-wrapper-8037" to be "running"
Apr 25 19:59:01.033: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-p64z9": Phase="Running", Reason="", readiness=true. Elapsed: 10.76995ms
Apr 25 19:59:01.033: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-p64z9" satisfied condition "running"
Apr 25 19:59:01.033: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-ssfsx" in namespace "emptydir-wrapper-8037" to be "running"
Apr 25 19:59:01.049: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-ssfsx": Phase="Running", Reason="", readiness=true. Elapsed: 16.140429ms
Apr 25 19:59:01.049: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-ssfsx" satisfied condition "running"
Apr 25 19:59:01.049: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-w8qc5" in namespace "emptydir-wrapper-8037" to be "running"
Apr 25 19:59:01.067: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-w8qc5": Phase="Running", Reason="", readiness=true. Elapsed: 18.02267ms
Apr 25 19:59:01.067: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-w8qc5" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45 in namespace emptydir-wrapper-8037, will wait for the garbage collector to delete the pods 04/25/23 19:59:01.067
Apr 25 19:59:01.183: INFO: Deleting ReplicationController wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45 took: 43.209737ms
Apr 25 19:59:01.284: INFO: Terminating ReplicationController wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45 pods took: 101.263448ms
STEP: Cleaning up the configMaps 04/25/23 19:59:03.885
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Apr 25 19:59:05.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8037" for this suite. 04/25/23 19:59:05.085
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":84,"skipped":1608,"failed":0}
------------------------------
• [SLOW TEST] [26.178 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:58:38.924
    Apr 25 19:58:38.924: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir-wrapper 04/25/23 19:58:38.925
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:58:38.967
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:58:38.974
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 04/25/23 19:58:38.983
    STEP: Creating RC which spawns configmap-volume pods 04/25/23 19:58:39.714
    Apr 25 19:58:39.744: INFO: Pod name wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b: Found 0 pods out of 5
    Apr 25 19:58:44.774: INFO: Pod name wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/25/23 19:58:44.774
    Apr 25 19:58:44.775: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-96p9n" in namespace "emptydir-wrapper-8037" to be "running"
    Apr 25 19:58:44.790: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-96p9n": Phase="Running", Reason="", readiness=true. Elapsed: 14.066717ms
    Apr 25 19:58:44.790: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-96p9n" satisfied condition "running"
    Apr 25 19:58:44.790: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-dx66h" in namespace "emptydir-wrapper-8037" to be "running"
    Apr 25 19:58:44.830: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-dx66h": Phase="Running", Reason="", readiness=true. Elapsed: 39.785542ms
    Apr 25 19:58:44.830: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-dx66h" satisfied condition "running"
    Apr 25 19:58:44.830: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-sdk4z" in namespace "emptydir-wrapper-8037" to be "running"
    Apr 25 19:58:44.844: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-sdk4z": Phase="Running", Reason="", readiness=true. Elapsed: 13.462643ms
    Apr 25 19:58:44.844: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-sdk4z" satisfied condition "running"
    Apr 25 19:58:44.844: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-w8xrp" in namespace "emptydir-wrapper-8037" to be "running"
    Apr 25 19:58:44.871: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-w8xrp": Phase="Running", Reason="", readiness=true. Elapsed: 27.15706ms
    Apr 25 19:58:44.872: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-w8xrp" satisfied condition "running"
    Apr 25 19:58:44.872: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-z6bmm" in namespace "emptydir-wrapper-8037" to be "running"
    Apr 25 19:58:44.892: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-z6bmm": Phase="Running", Reason="", readiness=true. Elapsed: 18.478352ms
    Apr 25 19:58:44.892: INFO: Pod "wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b-z6bmm" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b in namespace emptydir-wrapper-8037, will wait for the garbage collector to delete the pods 04/25/23 19:58:44.892
    Apr 25 19:58:44.977: INFO: Deleting ReplicationController wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b took: 21.431554ms
    Apr 25 19:58:45.178: INFO: Terminating ReplicationController wrapped-volume-race-c495131f-25ce-4089-9bd1-5abbd6969f6b pods took: 201.255495ms
    STEP: Creating RC which spawns configmap-volume pods 04/25/23 19:58:48.095
    Apr 25 19:58:48.127: INFO: Pod name wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672: Found 0 pods out of 5
    Apr 25 19:58:53.151: INFO: Pod name wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/25/23 19:58:53.151
    Apr 25 19:58:53.151: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-8tpnz" in namespace "emptydir-wrapper-8037" to be "running"
    Apr 25 19:58:53.163: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-8tpnz": Phase="Running", Reason="", readiness=true. Elapsed: 11.33187ms
    Apr 25 19:58:53.163: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-8tpnz" satisfied condition "running"
    Apr 25 19:58:53.163: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-brfks" in namespace "emptydir-wrapper-8037" to be "running"
    Apr 25 19:58:53.173: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-brfks": Phase="Running", Reason="", readiness=true. Elapsed: 10.311598ms
    Apr 25 19:58:53.173: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-brfks" satisfied condition "running"
    Apr 25 19:58:53.173: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-hvjkf" in namespace "emptydir-wrapper-8037" to be "running"
    Apr 25 19:58:53.185: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-hvjkf": Phase="Running", Reason="", readiness=true. Elapsed: 11.527922ms
    Apr 25 19:58:53.185: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-hvjkf" satisfied condition "running"
    Apr 25 19:58:53.185: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-qzkk4" in namespace "emptydir-wrapper-8037" to be "running"
    Apr 25 19:58:53.195: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-qzkk4": Phase="Running", Reason="", readiness=true. Elapsed: 10.503981ms
    Apr 25 19:58:53.195: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-qzkk4" satisfied condition "running"
    Apr 25 19:58:53.195: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-xtwqf" in namespace "emptydir-wrapper-8037" to be "running"
    Apr 25 19:58:53.205: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-xtwqf": Phase="Running", Reason="", readiness=true. Elapsed: 9.480456ms
    Apr 25 19:58:53.205: INFO: Pod "wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672-xtwqf" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672 in namespace emptydir-wrapper-8037, will wait for the garbage collector to delete the pods 04/25/23 19:58:53.205
    Apr 25 19:58:53.318: INFO: Deleting ReplicationController wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672 took: 19.466749ms
    Apr 25 19:58:53.419: INFO: Terminating ReplicationController wrapped-volume-race-3e23c3ed-478e-44e4-9c20-f8de17f2b672 pods took: 100.6885ms
    STEP: Creating RC which spawns configmap-volume pods 04/25/23 19:58:55.941
    Apr 25 19:58:55.972: INFO: Pod name wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45: Found 0 pods out of 5
    Apr 25 19:59:00.995: INFO: Pod name wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/25/23 19:59:00.995
    Apr 25 19:59:00.996: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-fqj2h" in namespace "emptydir-wrapper-8037" to be "running"
    Apr 25 19:59:01.007: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-fqj2h": Phase="Running", Reason="", readiness=true. Elapsed: 11.110254ms
    Apr 25 19:59:01.008: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-fqj2h" satisfied condition "running"
    Apr 25 19:59:01.008: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-mfcn6" in namespace "emptydir-wrapper-8037" to be "running"
    Apr 25 19:59:01.022: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-mfcn6": Phase="Running", Reason="", readiness=true. Elapsed: 13.557074ms
    Apr 25 19:59:01.022: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-mfcn6" satisfied condition "running"
    Apr 25 19:59:01.022: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-p64z9" in namespace "emptydir-wrapper-8037" to be "running"
    Apr 25 19:59:01.033: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-p64z9": Phase="Running", Reason="", readiness=true. Elapsed: 10.76995ms
    Apr 25 19:59:01.033: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-p64z9" satisfied condition "running"
    Apr 25 19:59:01.033: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-ssfsx" in namespace "emptydir-wrapper-8037" to be "running"
    Apr 25 19:59:01.049: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-ssfsx": Phase="Running", Reason="", readiness=true. Elapsed: 16.140429ms
    Apr 25 19:59:01.049: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-ssfsx" satisfied condition "running"
    Apr 25 19:59:01.049: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-w8qc5" in namespace "emptydir-wrapper-8037" to be "running"
    Apr 25 19:59:01.067: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-w8qc5": Phase="Running", Reason="", readiness=true. Elapsed: 18.02267ms
    Apr 25 19:59:01.067: INFO: Pod "wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45-w8qc5" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45 in namespace emptydir-wrapper-8037, will wait for the garbage collector to delete the pods 04/25/23 19:59:01.067
    Apr 25 19:59:01.183: INFO: Deleting ReplicationController wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45 took: 43.209737ms
    Apr 25 19:59:01.284: INFO: Terminating ReplicationController wrapped-volume-race-0c6628d2-53e0-4e74-984c-a3938d0ebf45 pods took: 101.263448ms
    STEP: Cleaning up the configMaps 04/25/23 19:59:03.885
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Apr 25 19:59:05.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-8037" for this suite. 04/25/23 19:59:05.085
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:59:05.104
Apr 25 19:59:05.104: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename disruption 04/25/23 19:59:05.106
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:59:05.152
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:59:05.162
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 04/25/23 19:59:05.184
STEP: Updating PodDisruptionBudget status 04/25/23 19:59:07.21
STEP: Waiting for all pods to be running 04/25/23 19:59:07.231
Apr 25 19:59:07.281: INFO: running pods: 0 < 1
STEP: locating a running pod 04/25/23 19:59:09.294
STEP: Waiting for the pdb to be processed 04/25/23 19:59:09.385
STEP: Patching PodDisruptionBudget status 04/25/23 19:59:09.424
STEP: Waiting for the pdb to be processed 04/25/23 19:59:09.455
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 25 19:59:09.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1823" for this suite. 04/25/23 19:59:09.495
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":85,"skipped":1620,"failed":0}
------------------------------
• [4.410 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:59:05.104
    Apr 25 19:59:05.104: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename disruption 04/25/23 19:59:05.106
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:59:05.152
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:59:05.162
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 04/25/23 19:59:05.184
    STEP: Updating PodDisruptionBudget status 04/25/23 19:59:07.21
    STEP: Waiting for all pods to be running 04/25/23 19:59:07.231
    Apr 25 19:59:07.281: INFO: running pods: 0 < 1
    STEP: locating a running pod 04/25/23 19:59:09.294
    STEP: Waiting for the pdb to be processed 04/25/23 19:59:09.385
    STEP: Patching PodDisruptionBudget status 04/25/23 19:59:09.424
    STEP: Waiting for the pdb to be processed 04/25/23 19:59:09.455
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 25 19:59:09.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-1823" for this suite. 04/25/23 19:59:09.495
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:59:09.529
Apr 25 19:59:09.529: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename pods 04/25/23 19:59:09.53
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:59:09.578
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:59:09.587
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 04/25/23 19:59:09.597
STEP: submitting the pod to kubernetes 04/25/23 19:59:09.598
Apr 25 19:59:09.620: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4" in namespace "pods-8626" to be "running and ready"
Apr 25 19:59:09.640: INFO: Pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4": Phase="Pending", Reason="", readiness=false. Elapsed: 19.408823ms
Apr 25 19:59:09.640: INFO: The phase of Pod pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 19:59:11.652: INFO: Pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4": Phase="Running", Reason="", readiness=true. Elapsed: 2.031898988s
Apr 25 19:59:11.653: INFO: The phase of Pod pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4 is Running (Ready = true)
Apr 25 19:59:11.653: INFO: Pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 04/25/23 19:59:11.667
STEP: updating the pod 04/25/23 19:59:11.677
Apr 25 19:59:12.205: INFO: Successfully updated pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4"
Apr 25 19:59:12.205: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4" in namespace "pods-8626" to be "terminated with reason DeadlineExceeded"
Apr 25 19:59:12.218: INFO: Pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4": Phase="Running", Reason="", readiness=true. Elapsed: 12.763154ms
Apr 25 19:59:14.230: INFO: Pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4": Phase="Running", Reason="", readiness=true. Elapsed: 2.025073152s
Apr 25 19:59:16.229: INFO: Pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.023863549s
Apr 25 19:59:16.229: INFO: Pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 25 19:59:16.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8626" for this suite. 04/25/23 19:59:16.251
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":86,"skipped":1635,"failed":0}
------------------------------
• [SLOW TEST] [6.748 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:59:09.529
    Apr 25 19:59:09.529: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename pods 04/25/23 19:59:09.53
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:59:09.578
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:59:09.587
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 04/25/23 19:59:09.597
    STEP: submitting the pod to kubernetes 04/25/23 19:59:09.598
    Apr 25 19:59:09.620: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4" in namespace "pods-8626" to be "running and ready"
    Apr 25 19:59:09.640: INFO: Pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4": Phase="Pending", Reason="", readiness=false. Elapsed: 19.408823ms
    Apr 25 19:59:09.640: INFO: The phase of Pod pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 19:59:11.652: INFO: Pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4": Phase="Running", Reason="", readiness=true. Elapsed: 2.031898988s
    Apr 25 19:59:11.653: INFO: The phase of Pod pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4 is Running (Ready = true)
    Apr 25 19:59:11.653: INFO: Pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 04/25/23 19:59:11.667
    STEP: updating the pod 04/25/23 19:59:11.677
    Apr 25 19:59:12.205: INFO: Successfully updated pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4"
    Apr 25 19:59:12.205: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4" in namespace "pods-8626" to be "terminated with reason DeadlineExceeded"
    Apr 25 19:59:12.218: INFO: Pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4": Phase="Running", Reason="", readiness=true. Elapsed: 12.763154ms
    Apr 25 19:59:14.230: INFO: Pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4": Phase="Running", Reason="", readiness=true. Elapsed: 2.025073152s
    Apr 25 19:59:16.229: INFO: Pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.023863549s
    Apr 25 19:59:16.229: INFO: Pod "pod-update-activedeadlineseconds-2f2930aa-079f-41ef-ba72-3c9fcf92bec4" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 25 19:59:16.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8626" for this suite. 04/25/23 19:59:16.251
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:59:16.28
Apr 25 19:59:16.280: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename replication-controller 04/25/23 19:59:16.281
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:59:16.322
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:59:16.332
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 04/25/23 19:59:16.342
STEP: When the matched label of one of its pods change 04/25/23 19:59:16.355
Apr 25 19:59:16.365: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 25 19:59:21.377: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 04/25/23 19:59:21.44
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 25 19:59:22.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9820" for this suite. 04/25/23 19:59:22.519
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":87,"skipped":1660,"failed":0}
------------------------------
• [SLOW TEST] [6.291 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:59:16.28
    Apr 25 19:59:16.280: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename replication-controller 04/25/23 19:59:16.281
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:59:16.322
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:59:16.332
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 04/25/23 19:59:16.342
    STEP: When the matched label of one of its pods change 04/25/23 19:59:16.355
    Apr 25 19:59:16.365: INFO: Pod name pod-release: Found 0 pods out of 1
    Apr 25 19:59:21.377: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 04/25/23 19:59:21.44
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 25 19:59:22.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-9820" for this suite. 04/25/23 19:59:22.519
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 19:59:22.576
Apr 25 19:59:22.577: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-probe 04/25/23 19:59:22.579
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:59:22.626
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:59:22.637
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 25 20:00:22.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9244" for this suite. 04/25/23 20:00:22.705
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":88,"skipped":1684,"failed":0}
------------------------------
• [SLOW TEST] [60.147 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 19:59:22.576
    Apr 25 19:59:22.577: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-probe 04/25/23 19:59:22.579
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 19:59:22.626
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 19:59:22.637
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 25 20:00:22.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9244" for this suite. 04/25/23 20:00:22.705
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:00:22.725
Apr 25 20:00:22.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename dns 04/25/23 20:00:22.728
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:00:22.773
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:00:22.782
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5840.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5840.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 04/25/23 20:00:22.791
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5840.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5840.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 04/25/23 20:00:22.792
STEP: creating a pod to probe /etc/hosts 04/25/23 20:00:22.792
STEP: submitting the pod to kubernetes 04/25/23 20:00:22.792
Apr 25 20:00:22.813: INFO: Waiting up to 15m0s for pod "dns-test-f3ffc81d-7f2f-4a89-9f9b-f21af75b9cbe" in namespace "dns-5840" to be "running"
Apr 25 20:00:22.829: INFO: Pod "dns-test-f3ffc81d-7f2f-4a89-9f9b-f21af75b9cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 15.19ms
Apr 25 20:00:24.841: INFO: Pod "dns-test-f3ffc81d-7f2f-4a89-9f9b-f21af75b9cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027495558s
Apr 25 20:00:26.841: INFO: Pod "dns-test-f3ffc81d-7f2f-4a89-9f9b-f21af75b9cbe": Phase="Running", Reason="", readiness=true. Elapsed: 4.027441778s
Apr 25 20:00:26.842: INFO: Pod "dns-test-f3ffc81d-7f2f-4a89-9f9b-f21af75b9cbe" satisfied condition "running"
STEP: retrieving the pod 04/25/23 20:00:26.842
STEP: looking for the results for each expected name from probers 04/25/23 20:00:26.853
Apr 25 20:00:26.967: INFO: DNS probes using dns-5840/dns-test-f3ffc81d-7f2f-4a89-9f9b-f21af75b9cbe succeeded

STEP: deleting the pod 04/25/23 20:00:26.967
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 25 20:00:27.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5840" for this suite. 04/25/23 20:00:27.048
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":89,"skipped":1689,"failed":0}
------------------------------
• [4.342 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:00:22.725
    Apr 25 20:00:22.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename dns 04/25/23 20:00:22.728
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:00:22.773
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:00:22.782
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5840.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5840.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     04/25/23 20:00:22.791
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5840.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5840.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     04/25/23 20:00:22.792
    STEP: creating a pod to probe /etc/hosts 04/25/23 20:00:22.792
    STEP: submitting the pod to kubernetes 04/25/23 20:00:22.792
    Apr 25 20:00:22.813: INFO: Waiting up to 15m0s for pod "dns-test-f3ffc81d-7f2f-4a89-9f9b-f21af75b9cbe" in namespace "dns-5840" to be "running"
    Apr 25 20:00:22.829: INFO: Pod "dns-test-f3ffc81d-7f2f-4a89-9f9b-f21af75b9cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 15.19ms
    Apr 25 20:00:24.841: INFO: Pod "dns-test-f3ffc81d-7f2f-4a89-9f9b-f21af75b9cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027495558s
    Apr 25 20:00:26.841: INFO: Pod "dns-test-f3ffc81d-7f2f-4a89-9f9b-f21af75b9cbe": Phase="Running", Reason="", readiness=true. Elapsed: 4.027441778s
    Apr 25 20:00:26.842: INFO: Pod "dns-test-f3ffc81d-7f2f-4a89-9f9b-f21af75b9cbe" satisfied condition "running"
    STEP: retrieving the pod 04/25/23 20:00:26.842
    STEP: looking for the results for each expected name from probers 04/25/23 20:00:26.853
    Apr 25 20:00:26.967: INFO: DNS probes using dns-5840/dns-test-f3ffc81d-7f2f-4a89-9f9b-f21af75b9cbe succeeded

    STEP: deleting the pod 04/25/23 20:00:26.967
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 25 20:00:27.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-5840" for this suite. 04/25/23 20:00:27.048
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:00:27.072
Apr 25 20:00:27.073: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename deployment 04/25/23 20:00:27.075
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:00:27.148
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:00:27.158
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Apr 25 20:00:27.168: INFO: Creating deployment "webserver-deployment"
Apr 25 20:00:27.184: INFO: Waiting for observed generation 1
Apr 25 20:00:29.238: INFO: Waiting for all required pods to come up
Apr 25 20:00:29.257: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 04/25/23 20:00:29.257
Apr 25 20:00:29.257: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-zzvh2" in namespace "deployment-2829" to be "running"
Apr 25 20:00:29.258: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-76xm4" in namespace "deployment-2829" to be "running"
Apr 25 20:00:29.258: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-6pg2l" in namespace "deployment-2829" to be "running"
Apr 25 20:00:29.258: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-dnch8" in namespace "deployment-2829" to be "running"
Apr 25 20:00:29.258: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-sszlr" in namespace "deployment-2829" to be "running"
Apr 25 20:00:29.258: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-ggscd" in namespace "deployment-2829" to be "running"
Apr 25 20:00:29.258: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-hdxjx" in namespace "deployment-2829" to be "running"
Apr 25 20:00:29.257: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-dc7qb" in namespace "deployment-2829" to be "running"
Apr 25 20:00:29.268: INFO: Pod "webserver-deployment-845c8977d9-dc7qb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.079931ms
Apr 25 20:00:29.272: INFO: Pod "webserver-deployment-845c8977d9-dnch8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.888765ms
Apr 25 20:00:29.272: INFO: Pod "webserver-deployment-845c8977d9-ggscd": Phase="Pending", Reason="", readiness=false. Elapsed: 13.832852ms
Apr 25 20:00:29.272: INFO: Pod "webserver-deployment-845c8977d9-hdxjx": Phase="Pending", Reason="", readiness=false. Elapsed: 13.819239ms
Apr 25 20:00:29.272: INFO: Pod "webserver-deployment-845c8977d9-sszlr": Phase="Pending", Reason="", readiness=false. Elapsed: 14.107805ms
Apr 25 20:00:29.272: INFO: Pod "webserver-deployment-845c8977d9-76xm4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.509219ms
Apr 25 20:00:29.272: INFO: Pod "webserver-deployment-845c8977d9-6pg2l": Phase="Pending", Reason="", readiness=false. Elapsed: 14.562179ms
Apr 25 20:00:29.272: INFO: Pod "webserver-deployment-845c8977d9-zzvh2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.977228ms
Apr 25 20:00:31.283: INFO: Pod "webserver-deployment-845c8977d9-dc7qb": Phase="Running", Reason="", readiness=true. Elapsed: 2.024734999s
Apr 25 20:00:31.283: INFO: Pod "webserver-deployment-845c8977d9-dc7qb" satisfied condition "running"
Apr 25 20:00:31.285: INFO: Pod "webserver-deployment-845c8977d9-6pg2l": Phase="Running", Reason="", readiness=true. Elapsed: 2.027084728s
Apr 25 20:00:31.285: INFO: Pod "webserver-deployment-845c8977d9-6pg2l" satisfied condition "running"
Apr 25 20:00:31.287: INFO: Pod "webserver-deployment-845c8977d9-76xm4": Phase="Running", Reason="", readiness=true. Elapsed: 2.029544592s
Apr 25 20:00:31.287: INFO: Pod "webserver-deployment-845c8977d9-76xm4" satisfied condition "running"
Apr 25 20:00:31.288: INFO: Pod "webserver-deployment-845c8977d9-hdxjx": Phase="Running", Reason="", readiness=true. Elapsed: 2.029836926s
Apr 25 20:00:31.288: INFO: Pod "webserver-deployment-845c8977d9-hdxjx" satisfied condition "running"
Apr 25 20:00:31.289: INFO: Pod "webserver-deployment-845c8977d9-sszlr": Phase="Running", Reason="", readiness=true. Elapsed: 2.030741967s
Apr 25 20:00:31.289: INFO: Pod "webserver-deployment-845c8977d9-sszlr" satisfied condition "running"
Apr 25 20:00:31.289: INFO: Pod "webserver-deployment-845c8977d9-dnch8": Phase="Running", Reason="", readiness=true. Elapsed: 2.031145769s
Apr 25 20:00:31.289: INFO: Pod "webserver-deployment-845c8977d9-dnch8" satisfied condition "running"
Apr 25 20:00:31.289: INFO: Pod "webserver-deployment-845c8977d9-ggscd": Phase="Running", Reason="", readiness=true. Elapsed: 2.031494166s
Apr 25 20:00:31.290: INFO: Pod "webserver-deployment-845c8977d9-zzvh2": Phase="Running", Reason="", readiness=true. Elapsed: 2.032118571s
Apr 25 20:00:31.290: INFO: Pod "webserver-deployment-845c8977d9-zzvh2" satisfied condition "running"
Apr 25 20:00:31.290: INFO: Pod "webserver-deployment-845c8977d9-ggscd" satisfied condition "running"
Apr 25 20:00:31.290: INFO: Waiting for deployment "webserver-deployment" to complete
Apr 25 20:00:31.313: INFO: Updating deployment "webserver-deployment" with a non-existent image
Apr 25 20:00:31.339: INFO: Updating deployment webserver-deployment
Apr 25 20:00:31.339: INFO: Waiting for observed generation 2
Apr 25 20:00:33.367: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 25 20:00:33.378: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 25 20:00:33.392: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 25 20:00:33.424: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 25 20:00:33.424: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 25 20:00:33.435: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 25 20:00:33.455: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Apr 25 20:00:33.455: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Apr 25 20:00:33.479: INFO: Updating deployment webserver-deployment
Apr 25 20:00:33.479: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Apr 25 20:00:33.501: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 25 20:00:33.513: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 25 20:00:33.635: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-2829  16f729ea-66b6-4833-919c-2db99075cc3f 25245 3 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002b60b28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-04-25 20:00:31 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-25 20:00:33 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Apr 25 20:00:33.655: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-2829  7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 25234 3 2023-04-25 20:00:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 16f729ea-66b6-4833-919c-2db99075cc3f 0xc002b60f57 0xc002b60f58}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"16f729ea-66b6-4833-919c-2db99075cc3f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002b60ff8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 25 20:00:33.655: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Apr 25 20:00:33.655: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-2829  72a09120-a352-48bb-a26f-9e8b9672ee29 25295 3 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 16f729ea-66b6-4833-919c-2db99075cc3f 0xc002b61057 0xc002b61058}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"16f729ea-66b6-4833-919c-2db99075cc3f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002b610e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Apr 25 20:00:33.685: INFO: Pod "webserver-deployment-69b7448995-265x4" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-265x4 webserver-deployment-69b7448995- deployment-2829  d0df6746-6346-40c4-ba9d-df1816ea4b5d 25291 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc0030eb777 0xc0030eb778}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bz624,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bz624,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.136,PodIP:,StartTime:2023-04-25 20:00:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.686: INFO: Pod "webserver-deployment-69b7448995-4ttvv" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-4ttvv webserver-deployment-69b7448995- deployment-2829  aa7c3fad-155f-45d5-a544-e7a7ae55c80a 25281 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc0030eb967 0xc0030eb968}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6ssnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6ssnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.686: INFO: Pod "webserver-deployment-69b7448995-6nswp" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-6nswp webserver-deployment-69b7448995- deployment-2829  e30eec93-819a-4e39-a50c-91c1c0969161 25263 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc0030ebae0 0xc0030ebae1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x4cc7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x4cc7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.686: INFO: Pod "webserver-deployment-69b7448995-7fm7h" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-7fm7h webserver-deployment-69b7448995- deployment-2829  c53515ef-1a54-4b3e-a5eb-e81b72e750e1 25213 0 2023-04-25 20:00:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:37dd62c85a18543e6871f47dac57bf6fa2deec1702a01a72acd253e3dd7664de cni.projectcalico.org/podIP:172.30.142.190/32 cni.projectcalico.org/podIPs:172.30.142.190/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc0030ebc50 0xc0030ebc51}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-25 20:00:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h48l7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h48l7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:,StartTime:2023-04-25 20:00:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.686: INFO: Pod "webserver-deployment-69b7448995-dbpz6" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-dbpz6 webserver-deployment-69b7448995- deployment-2829  066922da-f337-4827-8faa-53624f81b07f 25222 0 2023-04-25 20:00:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:1af3ab9b56a19f00785a753daa6fe3d66122868ec6de13d4de18b77b9fe8f4c1 cni.projectcalico.org/podIP:172.30.142.136/32 cni.projectcalico.org/podIPs:172.30.142.136/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc0030ebe57 0xc0030ebe58}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-25 20:00:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qvtjw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qvtjw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:,StartTime:2023-04-25 20:00:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.687: INFO: Pod "webserver-deployment-69b7448995-f72v4" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-f72v4 webserver-deployment-69b7448995- deployment-2829  a5a8b880-778e-4a28-8dd4-0d84c56dd791 25205 0 2023-04-25 20:00:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:316c970306a5f39bf0828dd6aa24f58e0dbacb11bdfbbbd349d2ade623d2b00d cni.projectcalico.org/podIP:172.30.226.117/32 cni.projectcalico.org/podIPs:172.30.226.117/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308c067 0xc00308c068}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-25 20:00:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gpfdd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gpfdd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:,StartTime:2023-04-25 20:00:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.687: INFO: Pod "webserver-deployment-69b7448995-jvzbt" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-jvzbt webserver-deployment-69b7448995- deployment-2829  2b01df7c-21a1-44ad-a31a-1847eeb49576 25200 0 2023-04-25 20:00:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:2fb8a54a9bd97d40c6eedb608f1b74b8aeaead9abf0e501af3af8d7272bd0f53 cni.projectcalico.org/podIP:172.30.226.114/32 cni.projectcalico.org/podIPs:172.30.226.114/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308c277 0xc00308c278}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-25 20:00:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rr6r9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rr6r9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:,StartTime:2023-04-25 20:00:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.687: INFO: Pod "webserver-deployment-69b7448995-mzwsd" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-mzwsd webserver-deployment-69b7448995- deployment-2829  f2e05f80-3163-4b21-9e54-1a705bdad28a 25202 0 2023-04-25 20:00:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:f878f4fac8600ee573ee2ae7650d28a8c2ec4c5d19d3ead70da1deb38c0959c8 cni.projectcalico.org/podIP:172.30.191.53/32 cni.projectcalico.org/podIPs:172.30.191.53/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308c4a7 0xc00308c4a8}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-25 20:00:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d7bfk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d7bfk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.136,PodIP:,StartTime:2023-04-25 20:00:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.688: INFO: Pod "webserver-deployment-69b7448995-qhfxv" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-qhfxv webserver-deployment-69b7448995- deployment-2829  089d87bf-f34e-4458-827e-fad4f35e2e0d 25302 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308c6b7 0xc00308c6b8}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8dq9m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8dq9m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.688: INFO: Pod "webserver-deployment-69b7448995-vhg4l" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-vhg4l webserver-deployment-69b7448995- deployment-2829  8fed01a6-7233-4e73-9a64-3074711ddf9e 25262 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308c830 0xc00308c831}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kgpkm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kgpkm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.688: INFO: Pod "webserver-deployment-69b7448995-wrc75" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-wrc75 webserver-deployment-69b7448995- deployment-2829  4bcfaa1f-fa8d-4dcd-b348-13d986db82cf 25285 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308c9a0 0xc00308c9a1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-blgtc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-blgtc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.689: INFO: Pod "webserver-deployment-69b7448995-xjf6k" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-xjf6k webserver-deployment-69b7448995- deployment-2829  ad8edec8-b9f4-4166-8027-0c661169de73 25289 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308cb10 0xc00308cb11}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nffpj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nffpj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.689: INFO: Pod "webserver-deployment-69b7448995-xjt9c" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-xjt9c webserver-deployment-69b7448995- deployment-2829  d551453f-9b45-480a-a2e9-4790bdf02d8a 25288 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308cc80 0xc00308cc81}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s9dhx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s9dhx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.689: INFO: Pod "webserver-deployment-845c8977d9-2zp5j" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-2zp5j webserver-deployment-845c8977d9- deployment-2829  39f226bc-65f8-49a2-9e45-7c95abfaa0ae 25254 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308cdf0 0xc00308cdf1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k88xt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k88xt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.690: INFO: Pod "webserver-deployment-845c8977d9-4w7fb" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-4w7fb webserver-deployment-845c8977d9- deployment-2829  f0e0786e-2085-4e69-beef-f607d8b6c565 25278 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308cf50 0xc00308cf51}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9vzdj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9vzdj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.690: INFO: Pod "webserver-deployment-845c8977d9-5mk7g" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-5mk7g webserver-deployment-845c8977d9- deployment-2829  4664e26d-7ac5-446d-a835-4fc3fcffaffb 25264 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308d0b0 0xc00308d0b1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vj4tl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vj4tl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.692: INFO: Pod "webserver-deployment-845c8977d9-6lmng" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-6lmng webserver-deployment-845c8977d9- deployment-2829  70297dd9-8253-4a80-9c0d-e1a662cb5c62 25085 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:016034e5b0e0f124d7c2d53e15a47e9aed5d27a0411fb4564b3de8fc1305f9fe cni.projectcalico.org/podIP:172.30.226.111/32 cni.projectcalico.org/podIPs:172.30.226.111/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308d210 0xc00308d211}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.226.111\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wdbn4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wdbn4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:172.30.226.111,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6de54075e828c26c88c1c5ca9394bac6d193b8eb2a92a3df0f24b404f0fd6f2f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.226.111,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.693: INFO: Pod "webserver-deployment-845c8977d9-76xm4" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-76xm4 webserver-deployment-845c8977d9- deployment-2829  b2cb844c-4d8d-4144-99c5-96b908bcc476 25120 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:22106ae0f86c32672633ad38bbcfba3691269855a5ebf6e59dc14c7e93932d3f cni.projectcalico.org/podIP:172.30.191.44/32 cni.projectcalico.org/podIPs:172.30.191.44/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308d447 0xc00308d448}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.191.44\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z4vcm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z4vcm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.136,PodIP:172.30.191.44,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://37fa30aba1998883e2b42b6f8f6c8b536471a496c60527185c59a6c8902a2783,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.191.44,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.693: INFO: Pod "webserver-deployment-845c8977d9-8w8hj" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-8w8hj webserver-deployment-845c8977d9- deployment-2829  cfaa5fff-d27d-4139-9d3b-c996de58343e 25260 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308d657 0xc00308d658}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xhlgm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xhlgm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.694: INFO: Pod "webserver-deployment-845c8977d9-dc7qb" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-dc7qb webserver-deployment-845c8977d9- deployment-2829  fe0f082c-f50f-437b-93d1-65ea640a6b0b 25113 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:f4bafe4a598188c5f991dd1da15571b21f96ccda37ee031a13e914c4ebecfbf9 cni.projectcalico.org/podIP:172.30.142.188/32 cni.projectcalico.org/podIPs:172.30.142.188/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308d7c0 0xc00308d7c1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.188\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zsshj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zsshj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.188,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b4ffce5bd119f8b5c820fa3ce0efab5273b1f4232a3e55ab7f0847b1c0aaeb37,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.188,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.694: INFO: Pod "webserver-deployment-845c8977d9-ddszn" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ddszn webserver-deployment-845c8977d9- deployment-2829  fa40cf7b-d9b6-4f8b-ae3e-ef35a960392c 25287 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308d9c7 0xc00308d9c8}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nx5nz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nx5nz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.695: INFO: Pod "webserver-deployment-845c8977d9-dnch8" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-dnch8 webserver-deployment-845c8977d9- deployment-2829  54838fca-8d68-4ffb-9bcb-7e93d94180e8 25123 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:8c17492c34cca21f5c4b2ebca7a167449e66ddba849523f7155e978f15ef0c9d cni.projectcalico.org/podIP:172.30.191.51/32 cni.projectcalico.org/podIPs:172.30.191.51/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308db60 0xc00308db61}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.191.51\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gfc8d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gfc8d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.136,PodIP:172.30.191.51,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://56a2cc5e43f355f74bb11911829b1518ab01f2baf0e8d98de116d713a3b260a9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.191.51,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.695: INFO: Pod "webserver-deployment-845c8977d9-ggscd" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ggscd webserver-deployment-845c8977d9- deployment-2829  0e773372-71ed-4ff9-b7f2-ea2893afe4c4 25129 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:a8dd041a6b6392845aeb6e47ab2bb294cd1ed1c4646eb90b7486deb561d4c4a7 cni.projectcalico.org/podIP:172.30.226.108/32 cni.projectcalico.org/podIPs:172.30.226.108/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308dd67 0xc00308dd68}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.226.108\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4nf9n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4nf9n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:172.30.226.108,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://98089f139ff3a7d7e0b23956a2fb5e980383c5b300fbae9d4415f4567f7a1422,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.226.108,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.695: INFO: Pod "webserver-deployment-845c8977d9-hdxjx" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-hdxjx webserver-deployment-845c8977d9- deployment-2829  86cf5aa9-3a02-401b-a71f-ff9b53072003 25107 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ca6fdc35b3ec7a6b8097fd726535451b55936d7b3c5da2bbeada872019f4e9e4 cni.projectcalico.org/podIP:172.30.142.181/32 cni.projectcalico.org/podIPs:172.30.142.181/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308df77 0xc00308df78}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.181\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6w5nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6w5nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.181,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2ae54f10fb702e558094877303b3200a492326c9f15ccc51098c927697c1a7d3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.181,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.696: INFO: Pod "webserver-deployment-845c8977d9-msmr8" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-msmr8 webserver-deployment-845c8977d9- deployment-2829  270f6c30-8300-4478-b915-881efbf3e9dd 25275 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1a187 0xc003f1a188}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-snw8z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-snw8z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:,StartTime:2023-04-25 20:00:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.696: INFO: Pod "webserver-deployment-845c8977d9-n4wn6" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-n4wn6 webserver-deployment-845c8977d9- deployment-2829  505bdd6f-8f03-4dc0-a169-439ee920573d 25261 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1a357 0xc003f1a358}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-csbjh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-csbjh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.697: INFO: Pod "webserver-deployment-845c8977d9-nr9vv" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-nr9vv webserver-deployment-845c8977d9- deployment-2829  a908e378-58ee-405f-a111-32dee50b59bb 25274 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1a4c0 0xc003f1a4c1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cslqg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cslqg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.697: INFO: Pod "webserver-deployment-845c8977d9-p8glk" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-p8glk webserver-deployment-845c8977d9- deployment-2829  49322da5-8815-4bcb-b2ae-c8e7861bcabe 25276 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1a620 0xc003f1a621}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xf7mx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xf7mx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.697: INFO: Pod "webserver-deployment-845c8977d9-phglj" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-phglj webserver-deployment-845c8977d9- deployment-2829  b99f935e-7738-41ff-ab5f-a8b013faceaf 25251 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1a790 0xc003f1a791}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-skf5d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-skf5d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.698: INFO: Pod "webserver-deployment-845c8977d9-wg9l2" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-wg9l2 webserver-deployment-845c8977d9- deployment-2829  00e614e0-70dc-4173-bf9c-09090adf7296 25090 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:abf624aade037ea54b479398a37a976de8de81f7cc45e9244c7b740311f45aa2 cni.projectcalico.org/podIP:172.30.226.113/32 cni.projectcalico.org/podIPs:172.30.226.113/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1a8f0 0xc003f1a8f1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.226.113\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4s5jm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4s5jm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:172.30.226.113,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f8eb1e2568f7388496c6963c5cc28e3fea1989eb0b62d79662d5e8cadafbb3b0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.226.113,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.699: INFO: Pod "webserver-deployment-845c8977d9-xjpcv" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-xjpcv webserver-deployment-845c8977d9- deployment-2829  efeeef94-d8d6-4c3e-bc2e-c7ecdbdfcc3c 25259 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1aaf7 0xc003f1aaf8}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vnfs8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vnfs8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.699: INFO: Pod "webserver-deployment-845c8977d9-z87gk" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-z87gk webserver-deployment-845c8977d9- deployment-2829  777cccf5-cafe-46e9-ae2d-33f7b4c5dbf8 25286 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1ac60 0xc003f1ac61}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mwf9h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mwf9h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:00:33.699: INFO: Pod "webserver-deployment-845c8977d9-zzvh2" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-zzvh2 webserver-deployment-845c8977d9- deployment-2829  4e13d4db-af5a-4244-a459-dbbfdad10351 25115 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:1ada1c6b440650f12e6e69407baeeb15cf6fea970e00c1473d333da0b503bd75 cni.projectcalico.org/podIP:172.30.191.52/32 cni.projectcalico.org/podIPs:172.30.191.52/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1ade0 0xc003f1ade1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.191.52\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7s6hh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7s6hh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.136,PodIP:172.30.191.52,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3c7ca6c5eb552e34cc9a3e8920a94e7f9a568f68d5cbe1d012b781f90e9bf92e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.191.52,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 25 20:00:33.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2829" for this suite. 04/25/23 20:00:33.721
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":90,"skipped":1718,"failed":0}
------------------------------
• [SLOW TEST] [6.669 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:00:27.072
    Apr 25 20:00:27.073: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename deployment 04/25/23 20:00:27.075
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:00:27.148
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:00:27.158
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Apr 25 20:00:27.168: INFO: Creating deployment "webserver-deployment"
    Apr 25 20:00:27.184: INFO: Waiting for observed generation 1
    Apr 25 20:00:29.238: INFO: Waiting for all required pods to come up
    Apr 25 20:00:29.257: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 04/25/23 20:00:29.257
    Apr 25 20:00:29.257: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-zzvh2" in namespace "deployment-2829" to be "running"
    Apr 25 20:00:29.258: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-76xm4" in namespace "deployment-2829" to be "running"
    Apr 25 20:00:29.258: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-6pg2l" in namespace "deployment-2829" to be "running"
    Apr 25 20:00:29.258: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-dnch8" in namespace "deployment-2829" to be "running"
    Apr 25 20:00:29.258: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-sszlr" in namespace "deployment-2829" to be "running"
    Apr 25 20:00:29.258: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-ggscd" in namespace "deployment-2829" to be "running"
    Apr 25 20:00:29.258: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-hdxjx" in namespace "deployment-2829" to be "running"
    Apr 25 20:00:29.257: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-dc7qb" in namespace "deployment-2829" to be "running"
    Apr 25 20:00:29.268: INFO: Pod "webserver-deployment-845c8977d9-dc7qb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.079931ms
    Apr 25 20:00:29.272: INFO: Pod "webserver-deployment-845c8977d9-dnch8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.888765ms
    Apr 25 20:00:29.272: INFO: Pod "webserver-deployment-845c8977d9-ggscd": Phase="Pending", Reason="", readiness=false. Elapsed: 13.832852ms
    Apr 25 20:00:29.272: INFO: Pod "webserver-deployment-845c8977d9-hdxjx": Phase="Pending", Reason="", readiness=false. Elapsed: 13.819239ms
    Apr 25 20:00:29.272: INFO: Pod "webserver-deployment-845c8977d9-sszlr": Phase="Pending", Reason="", readiness=false. Elapsed: 14.107805ms
    Apr 25 20:00:29.272: INFO: Pod "webserver-deployment-845c8977d9-76xm4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.509219ms
    Apr 25 20:00:29.272: INFO: Pod "webserver-deployment-845c8977d9-6pg2l": Phase="Pending", Reason="", readiness=false. Elapsed: 14.562179ms
    Apr 25 20:00:29.272: INFO: Pod "webserver-deployment-845c8977d9-zzvh2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.977228ms
    Apr 25 20:00:31.283: INFO: Pod "webserver-deployment-845c8977d9-dc7qb": Phase="Running", Reason="", readiness=true. Elapsed: 2.024734999s
    Apr 25 20:00:31.283: INFO: Pod "webserver-deployment-845c8977d9-dc7qb" satisfied condition "running"
    Apr 25 20:00:31.285: INFO: Pod "webserver-deployment-845c8977d9-6pg2l": Phase="Running", Reason="", readiness=true. Elapsed: 2.027084728s
    Apr 25 20:00:31.285: INFO: Pod "webserver-deployment-845c8977d9-6pg2l" satisfied condition "running"
    Apr 25 20:00:31.287: INFO: Pod "webserver-deployment-845c8977d9-76xm4": Phase="Running", Reason="", readiness=true. Elapsed: 2.029544592s
    Apr 25 20:00:31.287: INFO: Pod "webserver-deployment-845c8977d9-76xm4" satisfied condition "running"
    Apr 25 20:00:31.288: INFO: Pod "webserver-deployment-845c8977d9-hdxjx": Phase="Running", Reason="", readiness=true. Elapsed: 2.029836926s
    Apr 25 20:00:31.288: INFO: Pod "webserver-deployment-845c8977d9-hdxjx" satisfied condition "running"
    Apr 25 20:00:31.289: INFO: Pod "webserver-deployment-845c8977d9-sszlr": Phase="Running", Reason="", readiness=true. Elapsed: 2.030741967s
    Apr 25 20:00:31.289: INFO: Pod "webserver-deployment-845c8977d9-sszlr" satisfied condition "running"
    Apr 25 20:00:31.289: INFO: Pod "webserver-deployment-845c8977d9-dnch8": Phase="Running", Reason="", readiness=true. Elapsed: 2.031145769s
    Apr 25 20:00:31.289: INFO: Pod "webserver-deployment-845c8977d9-dnch8" satisfied condition "running"
    Apr 25 20:00:31.289: INFO: Pod "webserver-deployment-845c8977d9-ggscd": Phase="Running", Reason="", readiness=true. Elapsed: 2.031494166s
    Apr 25 20:00:31.290: INFO: Pod "webserver-deployment-845c8977d9-zzvh2": Phase="Running", Reason="", readiness=true. Elapsed: 2.032118571s
    Apr 25 20:00:31.290: INFO: Pod "webserver-deployment-845c8977d9-zzvh2" satisfied condition "running"
    Apr 25 20:00:31.290: INFO: Pod "webserver-deployment-845c8977d9-ggscd" satisfied condition "running"
    Apr 25 20:00:31.290: INFO: Waiting for deployment "webserver-deployment" to complete
    Apr 25 20:00:31.313: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Apr 25 20:00:31.339: INFO: Updating deployment webserver-deployment
    Apr 25 20:00:31.339: INFO: Waiting for observed generation 2
    Apr 25 20:00:33.367: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Apr 25 20:00:33.378: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Apr 25 20:00:33.392: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Apr 25 20:00:33.424: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Apr 25 20:00:33.424: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Apr 25 20:00:33.435: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Apr 25 20:00:33.455: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Apr 25 20:00:33.455: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Apr 25 20:00:33.479: INFO: Updating deployment webserver-deployment
    Apr 25 20:00:33.479: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Apr 25 20:00:33.501: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Apr 25 20:00:33.513: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 25 20:00:33.635: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-2829  16f729ea-66b6-4833-919c-2db99075cc3f 25245 3 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002b60b28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-04-25 20:00:31 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-25 20:00:33 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Apr 25 20:00:33.655: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-2829  7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 25234 3 2023-04-25 20:00:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 16f729ea-66b6-4833-919c-2db99075cc3f 0xc002b60f57 0xc002b60f58}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"16f729ea-66b6-4833-919c-2db99075cc3f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002b60ff8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 25 20:00:33.655: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Apr 25 20:00:33.655: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-2829  72a09120-a352-48bb-a26f-9e8b9672ee29 25295 3 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 16f729ea-66b6-4833-919c-2db99075cc3f 0xc002b61057 0xc002b61058}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"16f729ea-66b6-4833-919c-2db99075cc3f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002b610e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Apr 25 20:00:33.685: INFO: Pod "webserver-deployment-69b7448995-265x4" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-265x4 webserver-deployment-69b7448995- deployment-2829  d0df6746-6346-40c4-ba9d-df1816ea4b5d 25291 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc0030eb777 0xc0030eb778}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bz624,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bz624,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.136,PodIP:,StartTime:2023-04-25 20:00:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.686: INFO: Pod "webserver-deployment-69b7448995-4ttvv" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-4ttvv webserver-deployment-69b7448995- deployment-2829  aa7c3fad-155f-45d5-a544-e7a7ae55c80a 25281 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc0030eb967 0xc0030eb968}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6ssnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6ssnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.686: INFO: Pod "webserver-deployment-69b7448995-6nswp" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-6nswp webserver-deployment-69b7448995- deployment-2829  e30eec93-819a-4e39-a50c-91c1c0969161 25263 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc0030ebae0 0xc0030ebae1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x4cc7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x4cc7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.686: INFO: Pod "webserver-deployment-69b7448995-7fm7h" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-7fm7h webserver-deployment-69b7448995- deployment-2829  c53515ef-1a54-4b3e-a5eb-e81b72e750e1 25213 0 2023-04-25 20:00:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:37dd62c85a18543e6871f47dac57bf6fa2deec1702a01a72acd253e3dd7664de cni.projectcalico.org/podIP:172.30.142.190/32 cni.projectcalico.org/podIPs:172.30.142.190/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc0030ebc50 0xc0030ebc51}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-25 20:00:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h48l7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h48l7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:,StartTime:2023-04-25 20:00:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.686: INFO: Pod "webserver-deployment-69b7448995-dbpz6" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-dbpz6 webserver-deployment-69b7448995- deployment-2829  066922da-f337-4827-8faa-53624f81b07f 25222 0 2023-04-25 20:00:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:1af3ab9b56a19f00785a753daa6fe3d66122868ec6de13d4de18b77b9fe8f4c1 cni.projectcalico.org/podIP:172.30.142.136/32 cni.projectcalico.org/podIPs:172.30.142.136/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc0030ebe57 0xc0030ebe58}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-25 20:00:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qvtjw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qvtjw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:,StartTime:2023-04-25 20:00:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.687: INFO: Pod "webserver-deployment-69b7448995-f72v4" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-f72v4 webserver-deployment-69b7448995- deployment-2829  a5a8b880-778e-4a28-8dd4-0d84c56dd791 25205 0 2023-04-25 20:00:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:316c970306a5f39bf0828dd6aa24f58e0dbacb11bdfbbbd349d2ade623d2b00d cni.projectcalico.org/podIP:172.30.226.117/32 cni.projectcalico.org/podIPs:172.30.226.117/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308c067 0xc00308c068}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-25 20:00:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gpfdd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gpfdd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:,StartTime:2023-04-25 20:00:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.687: INFO: Pod "webserver-deployment-69b7448995-jvzbt" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-jvzbt webserver-deployment-69b7448995- deployment-2829  2b01df7c-21a1-44ad-a31a-1847eeb49576 25200 0 2023-04-25 20:00:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:2fb8a54a9bd97d40c6eedb608f1b74b8aeaead9abf0e501af3af8d7272bd0f53 cni.projectcalico.org/podIP:172.30.226.114/32 cni.projectcalico.org/podIPs:172.30.226.114/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308c277 0xc00308c278}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-25 20:00:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rr6r9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rr6r9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:,StartTime:2023-04-25 20:00:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.687: INFO: Pod "webserver-deployment-69b7448995-mzwsd" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-mzwsd webserver-deployment-69b7448995- deployment-2829  f2e05f80-3163-4b21-9e54-1a705bdad28a 25202 0 2023-04-25 20:00:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:f878f4fac8600ee573ee2ae7650d28a8c2ec4c5d19d3ead70da1deb38c0959c8 cni.projectcalico.org/podIP:172.30.191.53/32 cni.projectcalico.org/podIPs:172.30.191.53/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308c4a7 0xc00308c4a8}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:00:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-25 20:00:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d7bfk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d7bfk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.136,PodIP:,StartTime:2023-04-25 20:00:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.688: INFO: Pod "webserver-deployment-69b7448995-qhfxv" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-qhfxv webserver-deployment-69b7448995- deployment-2829  089d87bf-f34e-4458-827e-fad4f35e2e0d 25302 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308c6b7 0xc00308c6b8}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8dq9m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8dq9m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.688: INFO: Pod "webserver-deployment-69b7448995-vhg4l" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-vhg4l webserver-deployment-69b7448995- deployment-2829  8fed01a6-7233-4e73-9a64-3074711ddf9e 25262 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308c830 0xc00308c831}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kgpkm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kgpkm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.688: INFO: Pod "webserver-deployment-69b7448995-wrc75" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-wrc75 webserver-deployment-69b7448995- deployment-2829  4bcfaa1f-fa8d-4dcd-b348-13d986db82cf 25285 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308c9a0 0xc00308c9a1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-blgtc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-blgtc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.689: INFO: Pod "webserver-deployment-69b7448995-xjf6k" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-xjf6k webserver-deployment-69b7448995- deployment-2829  ad8edec8-b9f4-4166-8027-0c661169de73 25289 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308cb10 0xc00308cb11}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nffpj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nffpj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.689: INFO: Pod "webserver-deployment-69b7448995-xjt9c" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-xjt9c webserver-deployment-69b7448995- deployment-2829  d551453f-9b45-480a-a2e9-4790bdf02d8a 25288 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7c6c1f68-7b26-4e9d-81de-7cf188b3baf9 0xc00308cc80 0xc00308cc81}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c6c1f68-7b26-4e9d-81de-7cf188b3baf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s9dhx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s9dhx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.689: INFO: Pod "webserver-deployment-845c8977d9-2zp5j" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-2zp5j webserver-deployment-845c8977d9- deployment-2829  39f226bc-65f8-49a2-9e45-7c95abfaa0ae 25254 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308cdf0 0xc00308cdf1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k88xt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k88xt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.690: INFO: Pod "webserver-deployment-845c8977d9-4w7fb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-4w7fb webserver-deployment-845c8977d9- deployment-2829  f0e0786e-2085-4e69-beef-f607d8b6c565 25278 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308cf50 0xc00308cf51}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9vzdj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9vzdj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.690: INFO: Pod "webserver-deployment-845c8977d9-5mk7g" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-5mk7g webserver-deployment-845c8977d9- deployment-2829  4664e26d-7ac5-446d-a835-4fc3fcffaffb 25264 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308d0b0 0xc00308d0b1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vj4tl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vj4tl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.692: INFO: Pod "webserver-deployment-845c8977d9-6lmng" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-6lmng webserver-deployment-845c8977d9- deployment-2829  70297dd9-8253-4a80-9c0d-e1a662cb5c62 25085 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:016034e5b0e0f124d7c2d53e15a47e9aed5d27a0411fb4564b3de8fc1305f9fe cni.projectcalico.org/podIP:172.30.226.111/32 cni.projectcalico.org/podIPs:172.30.226.111/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308d210 0xc00308d211}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.226.111\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wdbn4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wdbn4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:172.30.226.111,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6de54075e828c26c88c1c5ca9394bac6d193b8eb2a92a3df0f24b404f0fd6f2f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.226.111,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.693: INFO: Pod "webserver-deployment-845c8977d9-76xm4" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-76xm4 webserver-deployment-845c8977d9- deployment-2829  b2cb844c-4d8d-4144-99c5-96b908bcc476 25120 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:22106ae0f86c32672633ad38bbcfba3691269855a5ebf6e59dc14c7e93932d3f cni.projectcalico.org/podIP:172.30.191.44/32 cni.projectcalico.org/podIPs:172.30.191.44/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308d447 0xc00308d448}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.191.44\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z4vcm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z4vcm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.136,PodIP:172.30.191.44,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://37fa30aba1998883e2b42b6f8f6c8b536471a496c60527185c59a6c8902a2783,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.191.44,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.693: INFO: Pod "webserver-deployment-845c8977d9-8w8hj" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-8w8hj webserver-deployment-845c8977d9- deployment-2829  cfaa5fff-d27d-4139-9d3b-c996de58343e 25260 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308d657 0xc00308d658}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xhlgm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xhlgm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.694: INFO: Pod "webserver-deployment-845c8977d9-dc7qb" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-dc7qb webserver-deployment-845c8977d9- deployment-2829  fe0f082c-f50f-437b-93d1-65ea640a6b0b 25113 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:f4bafe4a598188c5f991dd1da15571b21f96ccda37ee031a13e914c4ebecfbf9 cni.projectcalico.org/podIP:172.30.142.188/32 cni.projectcalico.org/podIPs:172.30.142.188/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308d7c0 0xc00308d7c1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.188\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zsshj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zsshj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.188,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b4ffce5bd119f8b5c820fa3ce0efab5273b1f4232a3e55ab7f0847b1c0aaeb37,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.188,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.694: INFO: Pod "webserver-deployment-845c8977d9-ddszn" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ddszn webserver-deployment-845c8977d9- deployment-2829  fa40cf7b-d9b6-4f8b-ae3e-ef35a960392c 25287 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308d9c7 0xc00308d9c8}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nx5nz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nx5nz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.695: INFO: Pod "webserver-deployment-845c8977d9-dnch8" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-dnch8 webserver-deployment-845c8977d9- deployment-2829  54838fca-8d68-4ffb-9bcb-7e93d94180e8 25123 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:8c17492c34cca21f5c4b2ebca7a167449e66ddba849523f7155e978f15ef0c9d cni.projectcalico.org/podIP:172.30.191.51/32 cni.projectcalico.org/podIPs:172.30.191.51/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308db60 0xc00308db61}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.191.51\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gfc8d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gfc8d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.136,PodIP:172.30.191.51,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://56a2cc5e43f355f74bb11911829b1518ab01f2baf0e8d98de116d713a3b260a9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.191.51,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.695: INFO: Pod "webserver-deployment-845c8977d9-ggscd" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ggscd webserver-deployment-845c8977d9- deployment-2829  0e773372-71ed-4ff9-b7f2-ea2893afe4c4 25129 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:a8dd041a6b6392845aeb6e47ab2bb294cd1ed1c4646eb90b7486deb561d4c4a7 cni.projectcalico.org/podIP:172.30.226.108/32 cni.projectcalico.org/podIPs:172.30.226.108/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308dd67 0xc00308dd68}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.226.108\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4nf9n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4nf9n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:172.30.226.108,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://98089f139ff3a7d7e0b23956a2fb5e980383c5b300fbae9d4415f4567f7a1422,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.226.108,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.695: INFO: Pod "webserver-deployment-845c8977d9-hdxjx" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-hdxjx webserver-deployment-845c8977d9- deployment-2829  86cf5aa9-3a02-401b-a71f-ff9b53072003 25107 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ca6fdc35b3ec7a6b8097fd726535451b55936d7b3c5da2bbeada872019f4e9e4 cni.projectcalico.org/podIP:172.30.142.181/32 cni.projectcalico.org/podIPs:172.30.142.181/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc00308df77 0xc00308df78}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.181\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6w5nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6w5nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.181,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2ae54f10fb702e558094877303b3200a492326c9f15ccc51098c927697c1a7d3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.181,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.696: INFO: Pod "webserver-deployment-845c8977d9-msmr8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-msmr8 webserver-deployment-845c8977d9- deployment-2829  270f6c30-8300-4478-b915-881efbf3e9dd 25275 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1a187 0xc003f1a188}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-snw8z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-snw8z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:,StartTime:2023-04-25 20:00:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.696: INFO: Pod "webserver-deployment-845c8977d9-n4wn6" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-n4wn6 webserver-deployment-845c8977d9- deployment-2829  505bdd6f-8f03-4dc0-a169-439ee920573d 25261 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1a357 0xc003f1a358}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-csbjh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-csbjh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.697: INFO: Pod "webserver-deployment-845c8977d9-nr9vv" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-nr9vv webserver-deployment-845c8977d9- deployment-2829  a908e378-58ee-405f-a111-32dee50b59bb 25274 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1a4c0 0xc003f1a4c1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cslqg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cslqg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.697: INFO: Pod "webserver-deployment-845c8977d9-p8glk" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-p8glk webserver-deployment-845c8977d9- deployment-2829  49322da5-8815-4bcb-b2ae-c8e7861bcabe 25276 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1a620 0xc003f1a621}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xf7mx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xf7mx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.697: INFO: Pod "webserver-deployment-845c8977d9-phglj" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-phglj webserver-deployment-845c8977d9- deployment-2829  b99f935e-7738-41ff-ab5f-a8b013faceaf 25251 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1a790 0xc003f1a791}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-skf5d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-skf5d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.698: INFO: Pod "webserver-deployment-845c8977d9-wg9l2" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-wg9l2 webserver-deployment-845c8977d9- deployment-2829  00e614e0-70dc-4173-bf9c-09090adf7296 25090 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:abf624aade037ea54b479398a37a976de8de81f7cc45e9244c7b740311f45aa2 cni.projectcalico.org/podIP:172.30.226.113/32 cni.projectcalico.org/podIPs:172.30.226.113/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1a8f0 0xc003f1a8f1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.226.113\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4s5jm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4s5jm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:172.30.226.113,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f8eb1e2568f7388496c6963c5cc28e3fea1989eb0b62d79662d5e8cadafbb3b0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.226.113,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.699: INFO: Pod "webserver-deployment-845c8977d9-xjpcv" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-xjpcv webserver-deployment-845c8977d9- deployment-2829  efeeef94-d8d6-4c3e-bc2e-c7ecdbdfcc3c 25259 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1aaf7 0xc003f1aaf8}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vnfs8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vnfs8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.699: INFO: Pod "webserver-deployment-845c8977d9-z87gk" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-z87gk webserver-deployment-845c8977d9- deployment-2829  777cccf5-cafe-46e9-ae2d-33f7b4c5dbf8 25286 0 2023-04-25 20:00:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1ac60 0xc003f1ac61}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mwf9h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mwf9h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:00:33.699: INFO: Pod "webserver-deployment-845c8977d9-zzvh2" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-zzvh2 webserver-deployment-845c8977d9- deployment-2829  4e13d4db-af5a-4244-a459-dbbfdad10351 25115 0 2023-04-25 20:00:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:1ada1c6b440650f12e6e69407baeeb15cf6fea970e00c1473d333da0b503bd75 cni.projectcalico.org/podIP:172.30.191.52/32 cni.projectcalico.org/podIPs:172.30.191.52/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 72a09120-a352-48bb-a26f-9e8b9672ee29 0xc003f1ade0 0xc003f1ade1}] [] [{kube-controller-manager Update v1 2023-04-25 20:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a09120-a352-48bb-a26f-9e8b9672ee29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:00:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:00:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.191.52\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7s6hh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7s6hh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:00:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.136,PodIP:172.30.191.52,StartTime:2023-04-25 20:00:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:00:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3c7ca6c5eb552e34cc9a3e8920a94e7f9a568f68d5cbe1d012b781f90e9bf92e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.191.52,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 25 20:00:33.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2829" for this suite. 04/25/23 20:00:33.721
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:00:33.755
Apr 25 20:00:33.755: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename svcaccounts 04/25/23 20:00:33.756
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:00:33.808
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:00:33.819
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  04/25/23 20:00:33.831
Apr 25 20:00:33.856: INFO: Waiting up to 5m0s for pod "test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb" in namespace "svcaccounts-9194" to be "Succeeded or Failed"
Apr 25 20:00:33.867: INFO: Pod "test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.526696ms
Apr 25 20:00:35.881: INFO: Pod "test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024661843s
Apr 25 20:00:37.888: INFO: Pod "test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031863978s
STEP: Saw pod success 04/25/23 20:00:37.889
Apr 25 20:00:37.889: INFO: Pod "test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb" satisfied condition "Succeeded or Failed"
Apr 25 20:00:37.900: INFO: Trying to get logs from node 10.10.21.190 pod test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb container agnhost-container: <nil>
STEP: delete the pod 04/25/23 20:00:37.987
Apr 25 20:00:38.013: INFO: Waiting for pod test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb to disappear
Apr 25 20:00:38.023: INFO: Pod test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 25 20:00:38.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9194" for this suite. 04/25/23 20:00:38.057
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":91,"skipped":1753,"failed":0}
------------------------------
• [4.323 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:00:33.755
    Apr 25 20:00:33.755: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename svcaccounts 04/25/23 20:00:33.756
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:00:33.808
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:00:33.819
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  04/25/23 20:00:33.831
    Apr 25 20:00:33.856: INFO: Waiting up to 5m0s for pod "test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb" in namespace "svcaccounts-9194" to be "Succeeded or Failed"
    Apr 25 20:00:33.867: INFO: Pod "test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.526696ms
    Apr 25 20:00:35.881: INFO: Pod "test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024661843s
    Apr 25 20:00:37.888: INFO: Pod "test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031863978s
    STEP: Saw pod success 04/25/23 20:00:37.889
    Apr 25 20:00:37.889: INFO: Pod "test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb" satisfied condition "Succeeded or Failed"
    Apr 25 20:00:37.900: INFO: Trying to get logs from node 10.10.21.190 pod test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 20:00:37.987
    Apr 25 20:00:38.013: INFO: Waiting for pod test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb to disappear
    Apr 25 20:00:38.023: INFO: Pod test-pod-597aeb92-410f-43f8-923b-95f8d9d101fb no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 25 20:00:38.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9194" for this suite. 04/25/23 20:00:38.057
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:00:38.081
Apr 25 20:00:38.081: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename daemonsets 04/25/23 20:00:38.083
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:00:38.122
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:00:38.131
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 04/25/23 20:00:38.218
STEP: Check that daemon pods launch on every node of the cluster. 04/25/23 20:00:38.231
Apr 25 20:00:38.254: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 20:00:38.254: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:00:39.281: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 20:00:39.281: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:00:40.306: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 25 20:00:40.306: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:00:41.285: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 25 20:00:41.285: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 04/25/23 20:00:41.295
Apr 25 20:00:41.308: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 04/25/23 20:00:41.308
Apr 25 20:00:41.329: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 04/25/23 20:00:41.33
Apr 25 20:00:41.335: INFO: Observed &DaemonSet event: ADDED
Apr 25 20:00:41.336: INFO: Observed &DaemonSet event: MODIFIED
Apr 25 20:00:41.336: INFO: Observed &DaemonSet event: MODIFIED
Apr 25 20:00:41.337: INFO: Observed &DaemonSet event: MODIFIED
Apr 25 20:00:41.338: INFO: Observed &DaemonSet event: MODIFIED
Apr 25 20:00:41.338: INFO: Found daemon set daemon-set in namespace daemonsets-1167 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 25 20:00:41.338: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 04/25/23 20:00:41.338
STEP: watching for the daemon set status to be patched 04/25/23 20:00:41.352
Apr 25 20:00:41.359: INFO: Observed &DaemonSet event: ADDED
Apr 25 20:00:41.359: INFO: Observed &DaemonSet event: MODIFIED
Apr 25 20:00:41.361: INFO: Observed &DaemonSet event: MODIFIED
Apr 25 20:00:41.361: INFO: Observed &DaemonSet event: MODIFIED
Apr 25 20:00:41.362: INFO: Observed &DaemonSet event: MODIFIED
Apr 25 20:00:41.363: INFO: Observed daemon set daemon-set in namespace daemonsets-1167 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 25 20:00:41.364: INFO: Observed &DaemonSet event: MODIFIED
Apr 25 20:00:41.364: INFO: Found daemon set daemon-set in namespace daemonsets-1167 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Apr 25 20:00:41.365: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/25/23 20:00:41.376
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1167, will wait for the garbage collector to delete the pods 04/25/23 20:00:41.376
Apr 25 20:00:41.457: INFO: Deleting DaemonSet.extensions daemon-set took: 15.85399ms
Apr 25 20:00:41.658: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.80258ms
Apr 25 20:00:44.066: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 20:00:44.067: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 25 20:00:44.075: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"25673"},"items":null}

Apr 25 20:00:44.086: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"25673"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 25 20:00:44.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1167" for this suite. 04/25/23 20:00:44.151
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":92,"skipped":1758,"failed":0}
------------------------------
• [SLOW TEST] [6.089 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:00:38.081
    Apr 25 20:00:38.081: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename daemonsets 04/25/23 20:00:38.083
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:00:38.122
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:00:38.131
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 04/25/23 20:00:38.218
    STEP: Check that daemon pods launch on every node of the cluster. 04/25/23 20:00:38.231
    Apr 25 20:00:38.254: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 20:00:38.254: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:00:39.281: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 20:00:39.281: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:00:40.306: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 25 20:00:40.306: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:00:41.285: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 25 20:00:41.285: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 04/25/23 20:00:41.295
    Apr 25 20:00:41.308: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 04/25/23 20:00:41.308
    Apr 25 20:00:41.329: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 04/25/23 20:00:41.33
    Apr 25 20:00:41.335: INFO: Observed &DaemonSet event: ADDED
    Apr 25 20:00:41.336: INFO: Observed &DaemonSet event: MODIFIED
    Apr 25 20:00:41.336: INFO: Observed &DaemonSet event: MODIFIED
    Apr 25 20:00:41.337: INFO: Observed &DaemonSet event: MODIFIED
    Apr 25 20:00:41.338: INFO: Observed &DaemonSet event: MODIFIED
    Apr 25 20:00:41.338: INFO: Found daemon set daemon-set in namespace daemonsets-1167 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 25 20:00:41.338: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 04/25/23 20:00:41.338
    STEP: watching for the daemon set status to be patched 04/25/23 20:00:41.352
    Apr 25 20:00:41.359: INFO: Observed &DaemonSet event: ADDED
    Apr 25 20:00:41.359: INFO: Observed &DaemonSet event: MODIFIED
    Apr 25 20:00:41.361: INFO: Observed &DaemonSet event: MODIFIED
    Apr 25 20:00:41.361: INFO: Observed &DaemonSet event: MODIFIED
    Apr 25 20:00:41.362: INFO: Observed &DaemonSet event: MODIFIED
    Apr 25 20:00:41.363: INFO: Observed daemon set daemon-set in namespace daemonsets-1167 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 25 20:00:41.364: INFO: Observed &DaemonSet event: MODIFIED
    Apr 25 20:00:41.364: INFO: Found daemon set daemon-set in namespace daemonsets-1167 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Apr 25 20:00:41.365: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/25/23 20:00:41.376
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1167, will wait for the garbage collector to delete the pods 04/25/23 20:00:41.376
    Apr 25 20:00:41.457: INFO: Deleting DaemonSet.extensions daemon-set took: 15.85399ms
    Apr 25 20:00:41.658: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.80258ms
    Apr 25 20:00:44.066: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 20:00:44.067: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 25 20:00:44.075: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"25673"},"items":null}

    Apr 25 20:00:44.086: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"25673"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 20:00:44.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-1167" for this suite. 04/25/23 20:00:44.151
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:00:44.179
Apr 25 20:00:44.179: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir 04/25/23 20:00:44.18
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:00:44.229
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:00:44.238
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 04/25/23 20:00:44.247
Apr 25 20:00:44.272: INFO: Waiting up to 5m0s for pod "pod-3329176c-0522-4635-88e0-5a617b015b6f" in namespace "emptydir-8447" to be "Succeeded or Failed"
Apr 25 20:00:44.285: INFO: Pod "pod-3329176c-0522-4635-88e0-5a617b015b6f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.685405ms
Apr 25 20:00:46.302: INFO: Pod "pod-3329176c-0522-4635-88e0-5a617b015b6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029797332s
Apr 25 20:00:48.297: INFO: Pod "pod-3329176c-0522-4635-88e0-5a617b015b6f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024823186s
Apr 25 20:00:50.300: INFO: Pod "pod-3329176c-0522-4635-88e0-5a617b015b6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027393239s
STEP: Saw pod success 04/25/23 20:00:50.3
Apr 25 20:00:50.300: INFO: Pod "pod-3329176c-0522-4635-88e0-5a617b015b6f" satisfied condition "Succeeded or Failed"
Apr 25 20:00:50.326: INFO: Trying to get logs from node 10.10.21.190 pod pod-3329176c-0522-4635-88e0-5a617b015b6f container test-container: <nil>
STEP: delete the pod 04/25/23 20:00:50.355
Apr 25 20:00:50.383: INFO: Waiting for pod pod-3329176c-0522-4635-88e0-5a617b015b6f to disappear
Apr 25 20:00:50.394: INFO: Pod pod-3329176c-0522-4635-88e0-5a617b015b6f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 25 20:00:50.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8447" for this suite. 04/25/23 20:00:50.416
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":93,"skipped":1771,"failed":0}
------------------------------
• [SLOW TEST] [6.256 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:00:44.179
    Apr 25 20:00:44.179: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir 04/25/23 20:00:44.18
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:00:44.229
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:00:44.238
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 04/25/23 20:00:44.247
    Apr 25 20:00:44.272: INFO: Waiting up to 5m0s for pod "pod-3329176c-0522-4635-88e0-5a617b015b6f" in namespace "emptydir-8447" to be "Succeeded or Failed"
    Apr 25 20:00:44.285: INFO: Pod "pod-3329176c-0522-4635-88e0-5a617b015b6f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.685405ms
    Apr 25 20:00:46.302: INFO: Pod "pod-3329176c-0522-4635-88e0-5a617b015b6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029797332s
    Apr 25 20:00:48.297: INFO: Pod "pod-3329176c-0522-4635-88e0-5a617b015b6f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024823186s
    Apr 25 20:00:50.300: INFO: Pod "pod-3329176c-0522-4635-88e0-5a617b015b6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027393239s
    STEP: Saw pod success 04/25/23 20:00:50.3
    Apr 25 20:00:50.300: INFO: Pod "pod-3329176c-0522-4635-88e0-5a617b015b6f" satisfied condition "Succeeded or Failed"
    Apr 25 20:00:50.326: INFO: Trying to get logs from node 10.10.21.190 pod pod-3329176c-0522-4635-88e0-5a617b015b6f container test-container: <nil>
    STEP: delete the pod 04/25/23 20:00:50.355
    Apr 25 20:00:50.383: INFO: Waiting for pod pod-3329176c-0522-4635-88e0-5a617b015b6f to disappear
    Apr 25 20:00:50.394: INFO: Pod pod-3329176c-0522-4635-88e0-5a617b015b6f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 25 20:00:50.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8447" for this suite. 04/25/23 20:00:50.416
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:00:50.45
Apr 25 20:00:50.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename gc 04/25/23 20:00:50.452
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:00:50.513
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:00:50.522
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 04/25/23 20:00:50.544
STEP: create the rc2 04/25/23 20:00:50.556
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 04/25/23 20:00:55.59
STEP: delete the rc simpletest-rc-to-be-deleted 04/25/23 20:00:56.715
STEP: wait for the rc to be deleted 04/25/23 20:00:56.742
STEP: Gathering metrics 04/25/23 20:01:01.789
W0425 20:01:01.813529      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 25 20:01:01.813: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr 25 20:01:01.813: INFO: Deleting pod "simpletest-rc-to-be-deleted-2bt67" in namespace "gc-7227"
Apr 25 20:01:02.034: INFO: Deleting pod "simpletest-rc-to-be-deleted-2fqjf" in namespace "gc-7227"
Apr 25 20:01:02.088: INFO: Deleting pod "simpletest-rc-to-be-deleted-2swpl" in namespace "gc-7227"
Apr 25 20:01:02.121: INFO: Deleting pod "simpletest-rc-to-be-deleted-44mc4" in namespace "gc-7227"
Apr 25 20:01:02.171: INFO: Deleting pod "simpletest-rc-to-be-deleted-4n5v6" in namespace "gc-7227"
Apr 25 20:01:02.229: INFO: Deleting pod "simpletest-rc-to-be-deleted-527mm" in namespace "gc-7227"
Apr 25 20:01:02.279: INFO: Deleting pod "simpletest-rc-to-be-deleted-58gc5" in namespace "gc-7227"
Apr 25 20:01:02.311: INFO: Deleting pod "simpletest-rc-to-be-deleted-5bzkw" in namespace "gc-7227"
Apr 25 20:01:02.351: INFO: Deleting pod "simpletest-rc-to-be-deleted-5m7r4" in namespace "gc-7227"
Apr 25 20:01:02.405: INFO: Deleting pod "simpletest-rc-to-be-deleted-5tfrn" in namespace "gc-7227"
Apr 25 20:01:02.439: INFO: Deleting pod "simpletest-rc-to-be-deleted-5tvtf" in namespace "gc-7227"
Apr 25 20:01:02.486: INFO: Deleting pod "simpletest-rc-to-be-deleted-694r6" in namespace "gc-7227"
Apr 25 20:01:02.514: INFO: Deleting pod "simpletest-rc-to-be-deleted-6fnkm" in namespace "gc-7227"
Apr 25 20:01:02.550: INFO: Deleting pod "simpletest-rc-to-be-deleted-6lp6c" in namespace "gc-7227"
Apr 25 20:01:02.585: INFO: Deleting pod "simpletest-rc-to-be-deleted-6sdqt" in namespace "gc-7227"
Apr 25 20:01:02.625: INFO: Deleting pod "simpletest-rc-to-be-deleted-6w8rw" in namespace "gc-7227"
Apr 25 20:01:02.693: INFO: Deleting pod "simpletest-rc-to-be-deleted-79xwn" in namespace "gc-7227"
Apr 25 20:01:02.725: INFO: Deleting pod "simpletest-rc-to-be-deleted-7ffs7" in namespace "gc-7227"
Apr 25 20:01:02.799: INFO: Deleting pod "simpletest-rc-to-be-deleted-7h847" in namespace "gc-7227"
Apr 25 20:01:02.844: INFO: Deleting pod "simpletest-rc-to-be-deleted-7qhjf" in namespace "gc-7227"
Apr 25 20:01:02.884: INFO: Deleting pod "simpletest-rc-to-be-deleted-7qvn5" in namespace "gc-7227"
Apr 25 20:01:02.918: INFO: Deleting pod "simpletest-rc-to-be-deleted-8cn4j" in namespace "gc-7227"
Apr 25 20:01:02.969: INFO: Deleting pod "simpletest-rc-to-be-deleted-8ffz9" in namespace "gc-7227"
Apr 25 20:01:03.005: INFO: Deleting pod "simpletest-rc-to-be-deleted-8hhp7" in namespace "gc-7227"
Apr 25 20:01:03.036: INFO: Deleting pod "simpletest-rc-to-be-deleted-8nm2m" in namespace "gc-7227"
Apr 25 20:01:03.079: INFO: Deleting pod "simpletest-rc-to-be-deleted-8tz7q" in namespace "gc-7227"
Apr 25 20:01:03.130: INFO: Deleting pod "simpletest-rc-to-be-deleted-8vpg5" in namespace "gc-7227"
Apr 25 20:01:03.177: INFO: Deleting pod "simpletest-rc-to-be-deleted-94rrv" in namespace "gc-7227"
Apr 25 20:01:03.213: INFO: Deleting pod "simpletest-rc-to-be-deleted-95j4r" in namespace "gc-7227"
Apr 25 20:01:03.245: INFO: Deleting pod "simpletest-rc-to-be-deleted-96sgx" in namespace "gc-7227"
Apr 25 20:01:03.281: INFO: Deleting pod "simpletest-rc-to-be-deleted-9chlk" in namespace "gc-7227"
Apr 25 20:01:03.312: INFO: Deleting pod "simpletest-rc-to-be-deleted-9jfhr" in namespace "gc-7227"
Apr 25 20:01:03.375: INFO: Deleting pod "simpletest-rc-to-be-deleted-9m8dk" in namespace "gc-7227"
Apr 25 20:01:03.416: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qq2p" in namespace "gc-7227"
Apr 25 20:01:03.446: INFO: Deleting pod "simpletest-rc-to-be-deleted-9zqmg" in namespace "gc-7227"
Apr 25 20:01:03.497: INFO: Deleting pod "simpletest-rc-to-be-deleted-b9mjx" in namespace "gc-7227"
Apr 25 20:01:03.536: INFO: Deleting pod "simpletest-rc-to-be-deleted-bbzwp" in namespace "gc-7227"
Apr 25 20:01:03.577: INFO: Deleting pod "simpletest-rc-to-be-deleted-bh8hk" in namespace "gc-7227"
Apr 25 20:01:03.624: INFO: Deleting pod "simpletest-rc-to-be-deleted-brnpj" in namespace "gc-7227"
Apr 25 20:01:03.690: INFO: Deleting pod "simpletest-rc-to-be-deleted-c4dr6" in namespace "gc-7227"
Apr 25 20:01:03.740: INFO: Deleting pod "simpletest-rc-to-be-deleted-ccbhq" in namespace "gc-7227"
Apr 25 20:01:03.792: INFO: Deleting pod "simpletest-rc-to-be-deleted-ck724" in namespace "gc-7227"
Apr 25 20:01:03.834: INFO: Deleting pod "simpletest-rc-to-be-deleted-cv6xm" in namespace "gc-7227"
Apr 25 20:01:03.860: INFO: Deleting pod "simpletest-rc-to-be-deleted-dx68n" in namespace "gc-7227"
Apr 25 20:01:03.900: INFO: Deleting pod "simpletest-rc-to-be-deleted-fcmxs" in namespace "gc-7227"
Apr 25 20:01:03.950: INFO: Deleting pod "simpletest-rc-to-be-deleted-fgh7r" in namespace "gc-7227"
Apr 25 20:01:03.982: INFO: Deleting pod "simpletest-rc-to-be-deleted-flt7q" in namespace "gc-7227"
Apr 25 20:01:04.031: INFO: Deleting pod "simpletest-rc-to-be-deleted-g2xrk" in namespace "gc-7227"
Apr 25 20:01:04.080: INFO: Deleting pod "simpletest-rc-to-be-deleted-g4c45" in namespace "gc-7227"
Apr 25 20:01:04.121: INFO: Deleting pod "simpletest-rc-to-be-deleted-gnfln" in namespace "gc-7227"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 25 20:01:04.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7227" for this suite. 04/25/23 20:01:04.171
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":94,"skipped":1796,"failed":0}
------------------------------
• [SLOW TEST] [13.735 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:00:50.45
    Apr 25 20:00:50.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename gc 04/25/23 20:00:50.452
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:00:50.513
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:00:50.522
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 04/25/23 20:00:50.544
    STEP: create the rc2 04/25/23 20:00:50.556
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 04/25/23 20:00:55.59
    STEP: delete the rc simpletest-rc-to-be-deleted 04/25/23 20:00:56.715
    STEP: wait for the rc to be deleted 04/25/23 20:00:56.742
    STEP: Gathering metrics 04/25/23 20:01:01.789
    W0425 20:01:01.813529      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 25 20:01:01.813: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Apr 25 20:01:01.813: INFO: Deleting pod "simpletest-rc-to-be-deleted-2bt67" in namespace "gc-7227"
    Apr 25 20:01:02.034: INFO: Deleting pod "simpletest-rc-to-be-deleted-2fqjf" in namespace "gc-7227"
    Apr 25 20:01:02.088: INFO: Deleting pod "simpletest-rc-to-be-deleted-2swpl" in namespace "gc-7227"
    Apr 25 20:01:02.121: INFO: Deleting pod "simpletest-rc-to-be-deleted-44mc4" in namespace "gc-7227"
    Apr 25 20:01:02.171: INFO: Deleting pod "simpletest-rc-to-be-deleted-4n5v6" in namespace "gc-7227"
    Apr 25 20:01:02.229: INFO: Deleting pod "simpletest-rc-to-be-deleted-527mm" in namespace "gc-7227"
    Apr 25 20:01:02.279: INFO: Deleting pod "simpletest-rc-to-be-deleted-58gc5" in namespace "gc-7227"
    Apr 25 20:01:02.311: INFO: Deleting pod "simpletest-rc-to-be-deleted-5bzkw" in namespace "gc-7227"
    Apr 25 20:01:02.351: INFO: Deleting pod "simpletest-rc-to-be-deleted-5m7r4" in namespace "gc-7227"
    Apr 25 20:01:02.405: INFO: Deleting pod "simpletest-rc-to-be-deleted-5tfrn" in namespace "gc-7227"
    Apr 25 20:01:02.439: INFO: Deleting pod "simpletest-rc-to-be-deleted-5tvtf" in namespace "gc-7227"
    Apr 25 20:01:02.486: INFO: Deleting pod "simpletest-rc-to-be-deleted-694r6" in namespace "gc-7227"
    Apr 25 20:01:02.514: INFO: Deleting pod "simpletest-rc-to-be-deleted-6fnkm" in namespace "gc-7227"
    Apr 25 20:01:02.550: INFO: Deleting pod "simpletest-rc-to-be-deleted-6lp6c" in namespace "gc-7227"
    Apr 25 20:01:02.585: INFO: Deleting pod "simpletest-rc-to-be-deleted-6sdqt" in namespace "gc-7227"
    Apr 25 20:01:02.625: INFO: Deleting pod "simpletest-rc-to-be-deleted-6w8rw" in namespace "gc-7227"
    Apr 25 20:01:02.693: INFO: Deleting pod "simpletest-rc-to-be-deleted-79xwn" in namespace "gc-7227"
    Apr 25 20:01:02.725: INFO: Deleting pod "simpletest-rc-to-be-deleted-7ffs7" in namespace "gc-7227"
    Apr 25 20:01:02.799: INFO: Deleting pod "simpletest-rc-to-be-deleted-7h847" in namespace "gc-7227"
    Apr 25 20:01:02.844: INFO: Deleting pod "simpletest-rc-to-be-deleted-7qhjf" in namespace "gc-7227"
    Apr 25 20:01:02.884: INFO: Deleting pod "simpletest-rc-to-be-deleted-7qvn5" in namespace "gc-7227"
    Apr 25 20:01:02.918: INFO: Deleting pod "simpletest-rc-to-be-deleted-8cn4j" in namespace "gc-7227"
    Apr 25 20:01:02.969: INFO: Deleting pod "simpletest-rc-to-be-deleted-8ffz9" in namespace "gc-7227"
    Apr 25 20:01:03.005: INFO: Deleting pod "simpletest-rc-to-be-deleted-8hhp7" in namespace "gc-7227"
    Apr 25 20:01:03.036: INFO: Deleting pod "simpletest-rc-to-be-deleted-8nm2m" in namespace "gc-7227"
    Apr 25 20:01:03.079: INFO: Deleting pod "simpletest-rc-to-be-deleted-8tz7q" in namespace "gc-7227"
    Apr 25 20:01:03.130: INFO: Deleting pod "simpletest-rc-to-be-deleted-8vpg5" in namespace "gc-7227"
    Apr 25 20:01:03.177: INFO: Deleting pod "simpletest-rc-to-be-deleted-94rrv" in namespace "gc-7227"
    Apr 25 20:01:03.213: INFO: Deleting pod "simpletest-rc-to-be-deleted-95j4r" in namespace "gc-7227"
    Apr 25 20:01:03.245: INFO: Deleting pod "simpletest-rc-to-be-deleted-96sgx" in namespace "gc-7227"
    Apr 25 20:01:03.281: INFO: Deleting pod "simpletest-rc-to-be-deleted-9chlk" in namespace "gc-7227"
    Apr 25 20:01:03.312: INFO: Deleting pod "simpletest-rc-to-be-deleted-9jfhr" in namespace "gc-7227"
    Apr 25 20:01:03.375: INFO: Deleting pod "simpletest-rc-to-be-deleted-9m8dk" in namespace "gc-7227"
    Apr 25 20:01:03.416: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qq2p" in namespace "gc-7227"
    Apr 25 20:01:03.446: INFO: Deleting pod "simpletest-rc-to-be-deleted-9zqmg" in namespace "gc-7227"
    Apr 25 20:01:03.497: INFO: Deleting pod "simpletest-rc-to-be-deleted-b9mjx" in namespace "gc-7227"
    Apr 25 20:01:03.536: INFO: Deleting pod "simpletest-rc-to-be-deleted-bbzwp" in namespace "gc-7227"
    Apr 25 20:01:03.577: INFO: Deleting pod "simpletest-rc-to-be-deleted-bh8hk" in namespace "gc-7227"
    Apr 25 20:01:03.624: INFO: Deleting pod "simpletest-rc-to-be-deleted-brnpj" in namespace "gc-7227"
    Apr 25 20:01:03.690: INFO: Deleting pod "simpletest-rc-to-be-deleted-c4dr6" in namespace "gc-7227"
    Apr 25 20:01:03.740: INFO: Deleting pod "simpletest-rc-to-be-deleted-ccbhq" in namespace "gc-7227"
    Apr 25 20:01:03.792: INFO: Deleting pod "simpletest-rc-to-be-deleted-ck724" in namespace "gc-7227"
    Apr 25 20:01:03.834: INFO: Deleting pod "simpletest-rc-to-be-deleted-cv6xm" in namespace "gc-7227"
    Apr 25 20:01:03.860: INFO: Deleting pod "simpletest-rc-to-be-deleted-dx68n" in namespace "gc-7227"
    Apr 25 20:01:03.900: INFO: Deleting pod "simpletest-rc-to-be-deleted-fcmxs" in namespace "gc-7227"
    Apr 25 20:01:03.950: INFO: Deleting pod "simpletest-rc-to-be-deleted-fgh7r" in namespace "gc-7227"
    Apr 25 20:01:03.982: INFO: Deleting pod "simpletest-rc-to-be-deleted-flt7q" in namespace "gc-7227"
    Apr 25 20:01:04.031: INFO: Deleting pod "simpletest-rc-to-be-deleted-g2xrk" in namespace "gc-7227"
    Apr 25 20:01:04.080: INFO: Deleting pod "simpletest-rc-to-be-deleted-g4c45" in namespace "gc-7227"
    Apr 25 20:01:04.121: INFO: Deleting pod "simpletest-rc-to-be-deleted-gnfln" in namespace "gc-7227"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 25 20:01:04.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7227" for this suite. 04/25/23 20:01:04.171
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:01:04.191
Apr 25 20:01:04.191: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename containers 04/25/23 20:01:04.192
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:01:04.244
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:01:04.251
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 04/25/23 20:01:04.256
Apr 25 20:01:04.288: INFO: Waiting up to 5m0s for pod "client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708" in namespace "containers-7197" to be "Succeeded or Failed"
Apr 25 20:01:04.315: INFO: Pod "client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708": Phase="Pending", Reason="", readiness=false. Elapsed: 25.979511ms
Apr 25 20:01:06.329: INFO: Pod "client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04080213s
Apr 25 20:01:08.327: INFO: Pod "client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038805882s
Apr 25 20:01:10.328: INFO: Pod "client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03974498s
STEP: Saw pod success 04/25/23 20:01:10.328
Apr 25 20:01:10.330: INFO: Pod "client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708" satisfied condition "Succeeded or Failed"
Apr 25 20:01:10.341: INFO: Trying to get logs from node 10.10.21.190 pod client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708 container agnhost-container: <nil>
STEP: delete the pod 04/25/23 20:01:10.409
Apr 25 20:01:10.447: INFO: Waiting for pod client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708 to disappear
Apr 25 20:01:10.457: INFO: Pod client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 25 20:01:10.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7197" for this suite. 04/25/23 20:01:10.471
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":95,"skipped":1815,"failed":0}
------------------------------
• [SLOW TEST] [6.297 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:01:04.191
    Apr 25 20:01:04.191: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename containers 04/25/23 20:01:04.192
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:01:04.244
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:01:04.251
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 04/25/23 20:01:04.256
    Apr 25 20:01:04.288: INFO: Waiting up to 5m0s for pod "client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708" in namespace "containers-7197" to be "Succeeded or Failed"
    Apr 25 20:01:04.315: INFO: Pod "client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708": Phase="Pending", Reason="", readiness=false. Elapsed: 25.979511ms
    Apr 25 20:01:06.329: INFO: Pod "client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04080213s
    Apr 25 20:01:08.327: INFO: Pod "client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038805882s
    Apr 25 20:01:10.328: INFO: Pod "client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03974498s
    STEP: Saw pod success 04/25/23 20:01:10.328
    Apr 25 20:01:10.330: INFO: Pod "client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708" satisfied condition "Succeeded or Failed"
    Apr 25 20:01:10.341: INFO: Trying to get logs from node 10.10.21.190 pod client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708 container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 20:01:10.409
    Apr 25 20:01:10.447: INFO: Waiting for pod client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708 to disappear
    Apr 25 20:01:10.457: INFO: Pod client-containers-c9e94df0-d0ba-4e9e-8cbf-649c707cd708 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 25 20:01:10.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-7197" for this suite. 04/25/23 20:01:10.471
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:01:10.489
Apr 25 20:01:10.489: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename deployment 04/25/23 20:01:10.495
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:01:10.555
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:01:10.562
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Apr 25 20:01:10.599: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 25 20:01:15.618: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/25/23 20:01:15.618
Apr 25 20:01:15.618: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 25 20:01:17.631: INFO: Creating deployment "test-rollover-deployment"
Apr 25 20:01:17.652: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 25 20:01:19.671: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 25 20:01:19.691: INFO: Ensure that both replica sets have 1 created replica
Apr 25 20:01:19.711: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 25 20:01:19.737: INFO: Updating deployment test-rollover-deployment
Apr 25 20:01:19.737: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 25 20:01:21.760: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 25 20:01:21.791: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 25 20:01:21.811: INFO: all replica sets need to contain the pod-template-hash label
Apr 25 20:01:21.811: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:01:23.835: INFO: all replica sets need to contain the pod-template-hash label
Apr 25 20:01:23.835: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:01:25.848: INFO: all replica sets need to contain the pod-template-hash label
Apr 25 20:01:25.849: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:01:27.832: INFO: all replica sets need to contain the pod-template-hash label
Apr 25 20:01:27.832: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:01:29.837: INFO: all replica sets need to contain the pod-template-hash label
Apr 25 20:01:29.838: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:01:31.832: INFO: 
Apr 25 20:01:31.832: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 25 20:01:31.868: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-4596  c322c2e6-8b14-47be-a7d6-18e3f0c1c7db 27840 2 2023-04-25 20:01:17 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-25 20:01:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0030eaea8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-25 20:01:17 +0000 UTC,LastTransitionTime:2023-04-25 20:01:17 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-04-25 20:01:31 +0000 UTC,LastTransitionTime:2023-04-25 20:01:17 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 25 20:01:31.880: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-4596  91a5fe69-8980-4119-96fd-aa9d5c2ae2f7 27830 2 2023-04-25 20:01:19 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment c322c2e6-8b14-47be-a7d6-18e3f0c1c7db 0xc0030eb487 0xc0030eb488}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:01:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c322c2e6-8b14-47be-a7d6-18e3f0c1c7db\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:01:31 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0030eb538 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 25 20:01:31.880: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 25 20:01:31.881: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-4596  307a6c5f-36c1-4514-a1db-fc652e55ee27 27839 2 2023-04-25 20:01:10 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment c322c2e6-8b14-47be-a7d6-18e3f0c1c7db 0xc0030eb237 0xc0030eb238}] [] [{e2e.test Update apps/v1 2023-04-25 20:01:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c322c2e6-8b14-47be-a7d6-18e3f0c1c7db\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:01:31 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0030eb2f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 25 20:01:31.882: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-4596  0bdbd20c-63bd-4f9f-a041-b3af4ee852a9 27794 2 2023-04-25 20:01:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment c322c2e6-8b14-47be-a7d6-18e3f0c1c7db 0xc0030eb367 0xc0030eb368}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:01:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c322c2e6-8b14-47be-a7d6-18e3f0c1c7db\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:01:19 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0030eb418 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 25 20:01:31.893: INFO: Pod "test-rollover-deployment-6d45fd857b-4996v" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-4996v test-rollover-deployment-6d45fd857b- deployment-4596  e9ff149a-9493-42ab-843f-d35dffba79c3 27807 0 2023-04-25 20:01:19 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:4afcf9c8064de165c1c4f8a9233c989e96cfd3da49ae6c4c207ac08fbf35738f cni.projectcalico.org/podIP:172.30.142.139/32 cni.projectcalico.org/podIPs:172.30.142.139/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 91a5fe69-8980-4119-96fd-aa9d5c2ae2f7 0xc0030eba77 0xc0030eba78}] [] [{kube-controller-manager Update v1 2023-04-25 20:01:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"91a5fe69-8980-4119-96fd-aa9d5c2ae2f7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:01:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:01:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.139\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p7n7w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p7n7w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:01:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:01:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:01:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:01:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.139,StartTime:2023-04-25 20:01:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:01:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://838c871db0b0c71e4161a0fb50969040a1a73fe40eabf2f54f14343709344228,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.139,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 25 20:01:31.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4596" for this suite. 04/25/23 20:01:31.91
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":96,"skipped":1815,"failed":0}
------------------------------
• [SLOW TEST] [21.441 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:01:10.489
    Apr 25 20:01:10.489: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename deployment 04/25/23 20:01:10.495
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:01:10.555
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:01:10.562
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Apr 25 20:01:10.599: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Apr 25 20:01:15.618: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/25/23 20:01:15.618
    Apr 25 20:01:15.618: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Apr 25 20:01:17.631: INFO: Creating deployment "test-rollover-deployment"
    Apr 25 20:01:17.652: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Apr 25 20:01:19.671: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Apr 25 20:01:19.691: INFO: Ensure that both replica sets have 1 created replica
    Apr 25 20:01:19.711: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Apr 25 20:01:19.737: INFO: Updating deployment test-rollover-deployment
    Apr 25 20:01:19.737: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Apr 25 20:01:21.760: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Apr 25 20:01:21.791: INFO: Make sure deployment "test-rollover-deployment" is complete
    Apr 25 20:01:21.811: INFO: all replica sets need to contain the pod-template-hash label
    Apr 25 20:01:21.811: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:01:23.835: INFO: all replica sets need to contain the pod-template-hash label
    Apr 25 20:01:23.835: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:01:25.848: INFO: all replica sets need to contain the pod-template-hash label
    Apr 25 20:01:25.849: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:01:27.832: INFO: all replica sets need to contain the pod-template-hash label
    Apr 25 20:01:27.832: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:01:29.837: INFO: all replica sets need to contain the pod-template-hash label
    Apr 25 20:01:29.838: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 1, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 1, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:01:31.832: INFO: 
    Apr 25 20:01:31.832: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 25 20:01:31.868: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-4596  c322c2e6-8b14-47be-a7d6-18e3f0c1c7db 27840 2 2023-04-25 20:01:17 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-25 20:01:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0030eaea8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-25 20:01:17 +0000 UTC,LastTransitionTime:2023-04-25 20:01:17 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-04-25 20:01:31 +0000 UTC,LastTransitionTime:2023-04-25 20:01:17 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 25 20:01:31.880: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-4596  91a5fe69-8980-4119-96fd-aa9d5c2ae2f7 27830 2 2023-04-25 20:01:19 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment c322c2e6-8b14-47be-a7d6-18e3f0c1c7db 0xc0030eb487 0xc0030eb488}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:01:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c322c2e6-8b14-47be-a7d6-18e3f0c1c7db\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:01:31 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0030eb538 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 25 20:01:31.880: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Apr 25 20:01:31.881: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-4596  307a6c5f-36c1-4514-a1db-fc652e55ee27 27839 2 2023-04-25 20:01:10 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment c322c2e6-8b14-47be-a7d6-18e3f0c1c7db 0xc0030eb237 0xc0030eb238}] [] [{e2e.test Update apps/v1 2023-04-25 20:01:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c322c2e6-8b14-47be-a7d6-18e3f0c1c7db\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:01:31 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0030eb2f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 25 20:01:31.882: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-4596  0bdbd20c-63bd-4f9f-a041-b3af4ee852a9 27794 2 2023-04-25 20:01:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment c322c2e6-8b14-47be-a7d6-18e3f0c1c7db 0xc0030eb367 0xc0030eb368}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:01:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c322c2e6-8b14-47be-a7d6-18e3f0c1c7db\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:01:19 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0030eb418 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 25 20:01:31.893: INFO: Pod "test-rollover-deployment-6d45fd857b-4996v" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-4996v test-rollover-deployment-6d45fd857b- deployment-4596  e9ff149a-9493-42ab-843f-d35dffba79c3 27807 0 2023-04-25 20:01:19 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:4afcf9c8064de165c1c4f8a9233c989e96cfd3da49ae6c4c207ac08fbf35738f cni.projectcalico.org/podIP:172.30.142.139/32 cni.projectcalico.org/podIPs:172.30.142.139/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 91a5fe69-8980-4119-96fd-aa9d5c2ae2f7 0xc0030eba77 0xc0030eba78}] [] [{kube-controller-manager Update v1 2023-04-25 20:01:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"91a5fe69-8980-4119-96fd-aa9d5c2ae2f7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:01:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:01:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.139\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p7n7w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p7n7w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:01:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:01:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:01:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:01:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.139,StartTime:2023-04-25 20:01:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:01:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://838c871db0b0c71e4161a0fb50969040a1a73fe40eabf2f54f14343709344228,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.139,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 25 20:01:31.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-4596" for this suite. 04/25/23 20:01:31.91
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:01:31.94
Apr 25 20:01:31.940: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename daemonsets 04/25/23 20:01:31.943
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:01:31.986
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:01:31.994
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 04/25/23 20:01:32.116
STEP: Check that daemon pods launch on every node of the cluster. 04/25/23 20:01:32.142
Apr 25 20:01:32.164: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 20:01:32.164: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:01:33.196: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 20:01:33.196: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:01:34.192: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 25 20:01:34.192: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 04/25/23 20:01:34.204
Apr 25 20:01:34.258: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 25 20:01:34.258: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:01:35.286: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 25 20:01:35.286: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:01:36.287: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 25 20:01:36.287: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:01:37.284: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 25 20:01:37.284: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:01:38.287: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 25 20:01:38.287: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:01:39.289: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 25 20:01:39.289: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/25/23 20:01:39.299
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5609, will wait for the garbage collector to delete the pods 04/25/23 20:01:39.299
Apr 25 20:01:39.407: INFO: Deleting DaemonSet.extensions daemon-set took: 47.095499ms
Apr 25 20:01:39.508: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.24291ms
Apr 25 20:01:41.919: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 20:01:41.920: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 25 20:01:41.927: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"27989"},"items":null}

Apr 25 20:01:41.936: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"27989"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 25 20:01:41.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5609" for this suite. 04/25/23 20:01:41.991
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":97,"skipped":1834,"failed":0}
------------------------------
• [SLOW TEST] [10.068 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:01:31.94
    Apr 25 20:01:31.940: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename daemonsets 04/25/23 20:01:31.943
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:01:31.986
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:01:31.994
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 04/25/23 20:01:32.116
    STEP: Check that daemon pods launch on every node of the cluster. 04/25/23 20:01:32.142
    Apr 25 20:01:32.164: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 20:01:32.164: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:01:33.196: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 20:01:33.196: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:01:34.192: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 25 20:01:34.192: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 04/25/23 20:01:34.204
    Apr 25 20:01:34.258: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 25 20:01:34.258: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:01:35.286: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 25 20:01:35.286: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:01:36.287: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 25 20:01:36.287: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:01:37.284: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 25 20:01:37.284: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:01:38.287: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 25 20:01:38.287: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:01:39.289: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 25 20:01:39.289: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/25/23 20:01:39.299
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5609, will wait for the garbage collector to delete the pods 04/25/23 20:01:39.299
    Apr 25 20:01:39.407: INFO: Deleting DaemonSet.extensions daemon-set took: 47.095499ms
    Apr 25 20:01:39.508: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.24291ms
    Apr 25 20:01:41.919: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 20:01:41.920: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 25 20:01:41.927: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"27989"},"items":null}

    Apr 25 20:01:41.936: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"27989"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 20:01:41.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-5609" for this suite. 04/25/23 20:01:41.991
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:01:42.009
Apr 25 20:01:42.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 20:01:42.012
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:01:42.059
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:01:42.065
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 04/25/23 20:01:42.072
Apr 25 20:01:42.072: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Apr 25 20:01:42.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 create -f -'
Apr 25 20:01:43.054: INFO: stderr: ""
Apr 25 20:01:43.054: INFO: stdout: "service/agnhost-replica created\n"
Apr 25 20:01:43.054: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Apr 25 20:01:43.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 create -f -'
Apr 25 20:01:43.854: INFO: stderr: ""
Apr 25 20:01:43.854: INFO: stdout: "service/agnhost-primary created\n"
Apr 25 20:01:43.854: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 25 20:01:43.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 create -f -'
Apr 25 20:01:44.185: INFO: stderr: ""
Apr 25 20:01:44.185: INFO: stdout: "service/frontend created\n"
Apr 25 20:01:44.185: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Apr 25 20:01:44.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 create -f -'
Apr 25 20:01:45.200: INFO: stderr: ""
Apr 25 20:01:45.201: INFO: stdout: "deployment.apps/frontend created\n"
Apr 25 20:01:45.201: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 25 20:01:45.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 create -f -'
Apr 25 20:01:45.555: INFO: stderr: ""
Apr 25 20:01:45.555: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Apr 25 20:01:45.555: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 25 20:01:45.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 create -f -'
Apr 25 20:01:45.906: INFO: stderr: ""
Apr 25 20:01:45.906: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 04/25/23 20:01:45.906
Apr 25 20:01:45.906: INFO: Waiting for all frontend pods to be Running.
Apr 25 20:01:50.959: INFO: Waiting for frontend to serve content.
Apr 25 20:01:51.034: INFO: Trying to add a new entry to the guestbook.
Apr 25 20:01:51.130: INFO: Verifying that added entry can be retrieved.
Apr 25 20:01:51.199: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
STEP: using delete to clean up resources 04/25/23 20:01:56.236
Apr 25 20:01:56.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 delete --grace-period=0 --force -f -'
Apr 25 20:01:56.435: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 20:01:56.435: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 04/25/23 20:01:56.435
Apr 25 20:01:56.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 delete --grace-period=0 --force -f -'
Apr 25 20:01:56.609: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 20:01:56.609: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 04/25/23 20:01:56.609
Apr 25 20:01:56.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 delete --grace-period=0 --force -f -'
Apr 25 20:01:56.771: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 20:01:56.772: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 04/25/23 20:01:56.772
Apr 25 20:01:56.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 delete --grace-period=0 --force -f -'
Apr 25 20:01:56.926: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 20:01:56.926: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 04/25/23 20:01:56.926
Apr 25 20:01:56.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 delete --grace-period=0 --force -f -'
Apr 25 20:01:57.137: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 20:01:57.137: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 04/25/23 20:01:57.137
Apr 25 20:01:57.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 delete --grace-period=0 --force -f -'
Apr 25 20:01:57.280: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 20:01:57.280: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 20:01:57.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3457" for this suite. 04/25/23 20:01:57.302
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":98,"skipped":1835,"failed":0}
------------------------------
• [SLOW TEST] [15.319 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:01:42.009
    Apr 25 20:01:42.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 20:01:42.012
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:01:42.059
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:01:42.065
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 04/25/23 20:01:42.072
    Apr 25 20:01:42.072: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Apr 25 20:01:42.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 create -f -'
    Apr 25 20:01:43.054: INFO: stderr: ""
    Apr 25 20:01:43.054: INFO: stdout: "service/agnhost-replica created\n"
    Apr 25 20:01:43.054: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Apr 25 20:01:43.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 create -f -'
    Apr 25 20:01:43.854: INFO: stderr: ""
    Apr 25 20:01:43.854: INFO: stdout: "service/agnhost-primary created\n"
    Apr 25 20:01:43.854: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Apr 25 20:01:43.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 create -f -'
    Apr 25 20:01:44.185: INFO: stderr: ""
    Apr 25 20:01:44.185: INFO: stdout: "service/frontend created\n"
    Apr 25 20:01:44.185: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Apr 25 20:01:44.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 create -f -'
    Apr 25 20:01:45.200: INFO: stderr: ""
    Apr 25 20:01:45.201: INFO: stdout: "deployment.apps/frontend created\n"
    Apr 25 20:01:45.201: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Apr 25 20:01:45.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 create -f -'
    Apr 25 20:01:45.555: INFO: stderr: ""
    Apr 25 20:01:45.555: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Apr 25 20:01:45.555: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Apr 25 20:01:45.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 create -f -'
    Apr 25 20:01:45.906: INFO: stderr: ""
    Apr 25 20:01:45.906: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 04/25/23 20:01:45.906
    Apr 25 20:01:45.906: INFO: Waiting for all frontend pods to be Running.
    Apr 25 20:01:50.959: INFO: Waiting for frontend to serve content.
    Apr 25 20:01:51.034: INFO: Trying to add a new entry to the guestbook.
    Apr 25 20:01:51.130: INFO: Verifying that added entry can be retrieved.
    Apr 25 20:01:51.199: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
    STEP: using delete to clean up resources 04/25/23 20:01:56.236
    Apr 25 20:01:56.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 delete --grace-period=0 --force -f -'
    Apr 25 20:01:56.435: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 25 20:01:56.435: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 04/25/23 20:01:56.435
    Apr 25 20:01:56.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 delete --grace-period=0 --force -f -'
    Apr 25 20:01:56.609: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 25 20:01:56.609: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 04/25/23 20:01:56.609
    Apr 25 20:01:56.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 delete --grace-period=0 --force -f -'
    Apr 25 20:01:56.771: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 25 20:01:56.772: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 04/25/23 20:01:56.772
    Apr 25 20:01:56.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 delete --grace-period=0 --force -f -'
    Apr 25 20:01:56.926: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 25 20:01:56.926: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 04/25/23 20:01:56.926
    Apr 25 20:01:56.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 delete --grace-period=0 --force -f -'
    Apr 25 20:01:57.137: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 25 20:01:57.137: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 04/25/23 20:01:57.137
    Apr 25 20:01:57.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3457 delete --grace-period=0 --force -f -'
    Apr 25 20:01:57.280: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 25 20:01:57.280: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 20:01:57.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3457" for this suite. 04/25/23 20:01:57.302
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:01:57.332
Apr 25 20:01:57.332: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename replication-controller 04/25/23 20:01:57.346
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:01:57.48
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:01:57.504
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Apr 25 20:01:57.514: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 04/25/23 20:01:57.565
STEP: Checking rc "condition-test" has the desired failure condition set 04/25/23 20:01:57.577
STEP: Scaling down rc "condition-test" to satisfy pod quota 04/25/23 20:01:58.596
Apr 25 20:01:58.687: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 04/25/23 20:01:58.687
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 25 20:01:59.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7666" for this suite. 04/25/23 20:01:59.726
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":99,"skipped":1842,"failed":0}
------------------------------
• [2.416 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:01:57.332
    Apr 25 20:01:57.332: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename replication-controller 04/25/23 20:01:57.346
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:01:57.48
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:01:57.504
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Apr 25 20:01:57.514: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 04/25/23 20:01:57.565
    STEP: Checking rc "condition-test" has the desired failure condition set 04/25/23 20:01:57.577
    STEP: Scaling down rc "condition-test" to satisfy pod quota 04/25/23 20:01:58.596
    Apr 25 20:01:58.687: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 04/25/23 20:01:58.687
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 25 20:01:59.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-7666" for this suite. 04/25/23 20:01:59.726
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:01:59.759
Apr 25 20:01:59.760: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename job 04/25/23 20:01:59.762
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:01:59.922
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:01:59.957
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 04/25/23 20:01:59.994
STEP: Ensuring active pods == parallelism 04/25/23 20:02:00.02
STEP: delete a job 04/25/23 20:02:02.038
STEP: deleting Job.batch foo in namespace job-9355, will wait for the garbage collector to delete the pods 04/25/23 20:02:02.039
Apr 25 20:02:02.214: INFO: Deleting Job.batch foo took: 92.679503ms
Apr 25 20:02:02.315: INFO: Terminating Job.batch foo pods took: 100.458565ms
STEP: Ensuring job was deleted 04/25/23 20:02:35.316
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 25 20:02:35.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9355" for this suite. 04/25/23 20:02:35.342
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":100,"skipped":1853,"failed":0}
------------------------------
• [SLOW TEST] [35.631 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:01:59.759
    Apr 25 20:01:59.760: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename job 04/25/23 20:01:59.762
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:01:59.922
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:01:59.957
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 04/25/23 20:01:59.994
    STEP: Ensuring active pods == parallelism 04/25/23 20:02:00.02
    STEP: delete a job 04/25/23 20:02:02.038
    STEP: deleting Job.batch foo in namespace job-9355, will wait for the garbage collector to delete the pods 04/25/23 20:02:02.039
    Apr 25 20:02:02.214: INFO: Deleting Job.batch foo took: 92.679503ms
    Apr 25 20:02:02.315: INFO: Terminating Job.batch foo pods took: 100.458565ms
    STEP: Ensuring job was deleted 04/25/23 20:02:35.316
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 25 20:02:35.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9355" for this suite. 04/25/23 20:02:35.342
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:02:35.393
Apr 25 20:02:35.393: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 20:02:35.405
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:02:35.454
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:02:35.486
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 20:02:35.558
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:02:35.832
STEP: Deploying the webhook pod 04/25/23 20:02:35.851
STEP: Wait for the deployment to be ready 04/25/23 20:02:35.931
Apr 25 20:02:35.986: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 25 20:02:38.016: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 2, 36, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 2, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 2, 36, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 2, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/25/23 20:02:40.058
STEP: Verifying the service has paired with the endpoint 04/25/23 20:02:40.088
Apr 25 20:02:41.089: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/25/23 20:02:41.119
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/25/23 20:02:41.237
STEP: Creating a dummy validating-webhook-configuration object 04/25/23 20:02:41.402
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 04/25/23 20:02:41.447
STEP: Creating a dummy mutating-webhook-configuration object 04/25/23 20:02:41.467
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 04/25/23 20:02:41.49
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:02:41.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6885" for this suite. 04/25/23 20:02:41.61
STEP: Destroying namespace "webhook-6885-markers" for this suite. 04/25/23 20:02:41.662
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":101,"skipped":1856,"failed":0}
------------------------------
• [SLOW TEST] [6.475 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:02:35.393
    Apr 25 20:02:35.393: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 20:02:35.405
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:02:35.454
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:02:35.486
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 20:02:35.558
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:02:35.832
    STEP: Deploying the webhook pod 04/25/23 20:02:35.851
    STEP: Wait for the deployment to be ready 04/25/23 20:02:35.931
    Apr 25 20:02:35.986: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 25 20:02:38.016: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 2, 36, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 2, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 2, 36, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 2, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/25/23 20:02:40.058
    STEP: Verifying the service has paired with the endpoint 04/25/23 20:02:40.088
    Apr 25 20:02:41.089: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/25/23 20:02:41.119
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/25/23 20:02:41.237
    STEP: Creating a dummy validating-webhook-configuration object 04/25/23 20:02:41.402
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 04/25/23 20:02:41.447
    STEP: Creating a dummy mutating-webhook-configuration object 04/25/23 20:02:41.467
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 04/25/23 20:02:41.49
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:02:41.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6885" for this suite. 04/25/23 20:02:41.61
    STEP: Destroying namespace "webhook-6885-markers" for this suite. 04/25/23 20:02:41.662
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:02:41.88
Apr 25 20:02:41.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 20:02:41.882
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:02:41.995
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:02:42.011
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 20:02:42.145
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:02:42.986
STEP: Deploying the webhook pod 04/25/23 20:02:43.012
STEP: Wait for the deployment to be ready 04/25/23 20:02:43.069
Apr 25 20:02:43.097: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 25 20:02:45.138: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 2, 43, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 2, 43, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 2, 43, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 2, 43, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/25/23 20:02:47.154
STEP: Verifying the service has paired with the endpoint 04/25/23 20:02:47.184
Apr 25 20:02:48.187: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 04/25/23 20:02:48.197
STEP: Creating a custom resource definition that should be denied by the webhook 04/25/23 20:02:48.27
Apr 25 20:02:48.271: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:02:48.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4418" for this suite. 04/25/23 20:02:48.363
STEP: Destroying namespace "webhook-4418-markers" for this suite. 04/25/23 20:02:48.383
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":102,"skipped":1871,"failed":0}
------------------------------
• [SLOW TEST] [6.732 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:02:41.88
    Apr 25 20:02:41.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 20:02:41.882
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:02:41.995
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:02:42.011
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 20:02:42.145
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:02:42.986
    STEP: Deploying the webhook pod 04/25/23 20:02:43.012
    STEP: Wait for the deployment to be ready 04/25/23 20:02:43.069
    Apr 25 20:02:43.097: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 25 20:02:45.138: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 2, 43, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 2, 43, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 2, 43, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 2, 43, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/25/23 20:02:47.154
    STEP: Verifying the service has paired with the endpoint 04/25/23 20:02:47.184
    Apr 25 20:02:48.187: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 04/25/23 20:02:48.197
    STEP: Creating a custom resource definition that should be denied by the webhook 04/25/23 20:02:48.27
    Apr 25 20:02:48.271: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:02:48.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4418" for this suite. 04/25/23 20:02:48.363
    STEP: Destroying namespace "webhook-4418-markers" for this suite. 04/25/23 20:02:48.383
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:02:48.615
Apr 25 20:02:48.616: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename ingressclass 04/25/23 20:02:48.62
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:02:48.667
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:02:48.676
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 04/25/23 20:02:48.686
STEP: getting /apis/networking.k8s.io 04/25/23 20:02:48.692
STEP: getting /apis/networking.k8s.iov1 04/25/23 20:02:48.695
STEP: creating 04/25/23 20:02:48.698
STEP: getting 04/25/23 20:02:48.731
STEP: listing 04/25/23 20:02:48.744
STEP: watching 04/25/23 20:02:48.754
Apr 25 20:02:48.755: INFO: starting watch
STEP: patching 04/25/23 20:02:48.758
STEP: updating 04/25/23 20:02:48.77
Apr 25 20:02:48.782: INFO: waiting for watch events with expected annotations
Apr 25 20:02:48.782: INFO: saw patched and updated annotations
STEP: deleting 04/25/23 20:02:48.783
STEP: deleting a collection 04/25/23 20:02:48.827
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Apr 25 20:02:48.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-3105" for this suite. 04/25/23 20:02:48.927
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":103,"skipped":1896,"failed":0}
------------------------------
• [0.365 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:02:48.615
    Apr 25 20:02:48.616: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename ingressclass 04/25/23 20:02:48.62
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:02:48.667
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:02:48.676
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 04/25/23 20:02:48.686
    STEP: getting /apis/networking.k8s.io 04/25/23 20:02:48.692
    STEP: getting /apis/networking.k8s.iov1 04/25/23 20:02:48.695
    STEP: creating 04/25/23 20:02:48.698
    STEP: getting 04/25/23 20:02:48.731
    STEP: listing 04/25/23 20:02:48.744
    STEP: watching 04/25/23 20:02:48.754
    Apr 25 20:02:48.755: INFO: starting watch
    STEP: patching 04/25/23 20:02:48.758
    STEP: updating 04/25/23 20:02:48.77
    Apr 25 20:02:48.782: INFO: waiting for watch events with expected annotations
    Apr 25 20:02:48.782: INFO: saw patched and updated annotations
    STEP: deleting 04/25/23 20:02:48.783
    STEP: deleting a collection 04/25/23 20:02:48.827
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Apr 25 20:02:48.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-3105" for this suite. 04/25/23 20:02:48.927
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:02:48.988
Apr 25 20:02:48.989: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename job 04/25/23 20:02:48.991
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:02:49.029
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:02:49.035
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 04/25/23 20:02:49.042
STEP: Ensuring job reaches completions 04/25/23 20:02:49.072
STEP: Ensuring pods with index for job exist 04/25/23 20:02:59.083
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 25 20:02:59.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-485" for this suite. 04/25/23 20:02:59.112
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":104,"skipped":1902,"failed":0}
------------------------------
• [SLOW TEST] [10.141 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:02:48.988
    Apr 25 20:02:48.989: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename job 04/25/23 20:02:48.991
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:02:49.029
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:02:49.035
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 04/25/23 20:02:49.042
    STEP: Ensuring job reaches completions 04/25/23 20:02:49.072
    STEP: Ensuring pods with index for job exist 04/25/23 20:02:59.083
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 25 20:02:59.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-485" for this suite. 04/25/23 20:02:59.112
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:02:59.134
Apr 25 20:02:59.134: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 20:02:59.136
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:02:59.184
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:02:59.19
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 04/25/23 20:02:59.197
Apr 25 20:02:59.217: INFO: Waiting up to 5m0s for pod "downward-api-8e396994-a952-41c7-a743-c797dd426ad2" in namespace "downward-api-9905" to be "Succeeded or Failed"
Apr 25 20:02:59.238: INFO: Pod "downward-api-8e396994-a952-41c7-a743-c797dd426ad2": Phase="Pending", Reason="", readiness=false. Elapsed: 19.986646ms
Apr 25 20:03:01.254: INFO: Pod "downward-api-8e396994-a952-41c7-a743-c797dd426ad2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035522276s
Apr 25 20:03:03.256: INFO: Pod "downward-api-8e396994-a952-41c7-a743-c797dd426ad2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037917506s
Apr 25 20:03:05.250: INFO: Pod "downward-api-8e396994-a952-41c7-a743-c797dd426ad2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031436305s
STEP: Saw pod success 04/25/23 20:03:05.25
Apr 25 20:03:05.250: INFO: Pod "downward-api-8e396994-a952-41c7-a743-c797dd426ad2" satisfied condition "Succeeded or Failed"
Apr 25 20:03:05.261: INFO: Trying to get logs from node 10.10.21.190 pod downward-api-8e396994-a952-41c7-a743-c797dd426ad2 container dapi-container: <nil>
STEP: delete the pod 04/25/23 20:03:05.347
Apr 25 20:03:05.382: INFO: Waiting for pod downward-api-8e396994-a952-41c7-a743-c797dd426ad2 to disappear
Apr 25 20:03:05.401: INFO: Pod downward-api-8e396994-a952-41c7-a743-c797dd426ad2 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 25 20:03:05.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9905" for this suite. 04/25/23 20:03:05.416
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":105,"skipped":1910,"failed":0}
------------------------------
• [SLOW TEST] [6.308 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:02:59.134
    Apr 25 20:02:59.134: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 20:02:59.136
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:02:59.184
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:02:59.19
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 04/25/23 20:02:59.197
    Apr 25 20:02:59.217: INFO: Waiting up to 5m0s for pod "downward-api-8e396994-a952-41c7-a743-c797dd426ad2" in namespace "downward-api-9905" to be "Succeeded or Failed"
    Apr 25 20:02:59.238: INFO: Pod "downward-api-8e396994-a952-41c7-a743-c797dd426ad2": Phase="Pending", Reason="", readiness=false. Elapsed: 19.986646ms
    Apr 25 20:03:01.254: INFO: Pod "downward-api-8e396994-a952-41c7-a743-c797dd426ad2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035522276s
    Apr 25 20:03:03.256: INFO: Pod "downward-api-8e396994-a952-41c7-a743-c797dd426ad2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037917506s
    Apr 25 20:03:05.250: INFO: Pod "downward-api-8e396994-a952-41c7-a743-c797dd426ad2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031436305s
    STEP: Saw pod success 04/25/23 20:03:05.25
    Apr 25 20:03:05.250: INFO: Pod "downward-api-8e396994-a952-41c7-a743-c797dd426ad2" satisfied condition "Succeeded or Failed"
    Apr 25 20:03:05.261: INFO: Trying to get logs from node 10.10.21.190 pod downward-api-8e396994-a952-41c7-a743-c797dd426ad2 container dapi-container: <nil>
    STEP: delete the pod 04/25/23 20:03:05.347
    Apr 25 20:03:05.382: INFO: Waiting for pod downward-api-8e396994-a952-41c7-a743-c797dd426ad2 to disappear
    Apr 25 20:03:05.401: INFO: Pod downward-api-8e396994-a952-41c7-a743-c797dd426ad2 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 25 20:03:05.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9905" for this suite. 04/25/23 20:03:05.416
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:03:05.444
Apr 25 20:03:05.444: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 20:03:05.444
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:03:05.516
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:03:05.523
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 04/25/23 20:03:05.53
Apr 25 20:03:05.532: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:03:08.584: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:03:21.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4085" for this suite. 04/25/23 20:03:21.839
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":106,"skipped":1923,"failed":0}
------------------------------
• [SLOW TEST] [16.417 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:03:05.444
    Apr 25 20:03:05.444: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 20:03:05.444
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:03:05.516
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:03:05.523
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 04/25/23 20:03:05.53
    Apr 25 20:03:05.532: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:03:08.584: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:03:21.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4085" for this suite. 04/25/23 20:03:21.839
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:03:21.873
Apr 25 20:03:21.874: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 20:03:21.875
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:03:21.919
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:03:21.933
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Apr 25 20:03:21.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/25/23 20:03:24.834
Apr 25 20:03:24.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-4514 --namespace=crd-publish-openapi-4514 create -f -'
Apr 25 20:03:25.764: INFO: stderr: ""
Apr 25 20:03:25.764: INFO: stdout: "e2e-test-crd-publish-openapi-5052-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 25 20:03:25.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-4514 --namespace=crd-publish-openapi-4514 delete e2e-test-crd-publish-openapi-5052-crds test-cr'
Apr 25 20:03:25.907: INFO: stderr: ""
Apr 25 20:03:25.907: INFO: stdout: "e2e-test-crd-publish-openapi-5052-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Apr 25 20:03:25.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-4514 --namespace=crd-publish-openapi-4514 apply -f -'
Apr 25 20:03:26.673: INFO: stderr: ""
Apr 25 20:03:26.674: INFO: stdout: "e2e-test-crd-publish-openapi-5052-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 25 20:03:26.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-4514 --namespace=crd-publish-openapi-4514 delete e2e-test-crd-publish-openapi-5052-crds test-cr'
Apr 25 20:03:26.916: INFO: stderr: ""
Apr 25 20:03:26.916: INFO: stdout: "e2e-test-crd-publish-openapi-5052-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 04/25/23 20:03:26.916
Apr 25 20:03:26.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-4514 explain e2e-test-crd-publish-openapi-5052-crds'
Apr 25 20:03:27.574: INFO: stderr: ""
Apr 25 20:03:27.574: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5052-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:03:30.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4514" for this suite. 04/25/23 20:03:30.525
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":107,"skipped":1969,"failed":0}
------------------------------
• [SLOW TEST] [8.672 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:03:21.873
    Apr 25 20:03:21.874: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 20:03:21.875
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:03:21.919
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:03:21.933
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Apr 25 20:03:21.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/25/23 20:03:24.834
    Apr 25 20:03:24.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-4514 --namespace=crd-publish-openapi-4514 create -f -'
    Apr 25 20:03:25.764: INFO: stderr: ""
    Apr 25 20:03:25.764: INFO: stdout: "e2e-test-crd-publish-openapi-5052-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Apr 25 20:03:25.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-4514 --namespace=crd-publish-openapi-4514 delete e2e-test-crd-publish-openapi-5052-crds test-cr'
    Apr 25 20:03:25.907: INFO: stderr: ""
    Apr 25 20:03:25.907: INFO: stdout: "e2e-test-crd-publish-openapi-5052-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Apr 25 20:03:25.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-4514 --namespace=crd-publish-openapi-4514 apply -f -'
    Apr 25 20:03:26.673: INFO: stderr: ""
    Apr 25 20:03:26.674: INFO: stdout: "e2e-test-crd-publish-openapi-5052-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Apr 25 20:03:26.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-4514 --namespace=crd-publish-openapi-4514 delete e2e-test-crd-publish-openapi-5052-crds test-cr'
    Apr 25 20:03:26.916: INFO: stderr: ""
    Apr 25 20:03:26.916: INFO: stdout: "e2e-test-crd-publish-openapi-5052-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 04/25/23 20:03:26.916
    Apr 25 20:03:26.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-4514 explain e2e-test-crd-publish-openapi-5052-crds'
    Apr 25 20:03:27.574: INFO: stderr: ""
    Apr 25 20:03:27.574: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5052-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:03:30.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4514" for this suite. 04/25/23 20:03:30.525
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:03:30.555
Apr 25 20:03:30.555: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename statefulset 04/25/23 20:03:30.557
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:03:30.6
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:03:30.611
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9985 04/25/23 20:03:30.621
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-9985 04/25/23 20:03:30.637
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9985 04/25/23 20:03:30.655
Apr 25 20:03:30.667: INFO: Found 0 stateful pods, waiting for 1
Apr 25 20:03:40.681: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 04/25/23 20:03:40.681
Apr 25 20:03:40.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-9985 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 25 20:03:41.031: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 25 20:03:41.031: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 25 20:03:41.031: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 25 20:03:41.044: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 25 20:03:51.061: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 20:03:51.061: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 20:03:51.109: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 25 20:03:51.109: INFO: ss-0  10.10.21.190  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:30 +0000 UTC  }]
Apr 25 20:03:51.110: INFO: 
Apr 25 20:03:51.110: INFO: StatefulSet ss has not reached scale 3, at 1
Apr 25 20:03:52.124: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988350948s
Apr 25 20:03:53.142: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.973404132s
Apr 25 20:03:54.155: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.95562155s
Apr 25 20:03:55.170: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.942586812s
Apr 25 20:03:56.185: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.927969611s
Apr 25 20:03:57.199: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.912624879s
Apr 25 20:03:58.213: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.898950277s
Apr 25 20:03:59.232: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.884446267s
Apr 25 20:04:00.250: INFO: Verifying statefulset ss doesn't scale past 3 for another 864.697997ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9985 04/25/23 20:04:01.251
Apr 25 20:04:01.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-9985 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 25 20:04:01.653: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 25 20:04:01.653: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 25 20:04:01.653: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 25 20:04:01.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-9985 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 25 20:04:02.019: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 25 20:04:02.019: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 25 20:04:02.019: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 25 20:04:02.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-9985 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 25 20:04:02.360: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 25 20:04:02.360: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 25 20:04:02.360: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 25 20:04:02.372: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 20:04:02.372: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 20:04:02.372: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 04/25/23 20:04:02.372
Apr 25 20:04:02.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-9985 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 25 20:04:02.758: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 25 20:04:02.758: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 25 20:04:02.758: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 25 20:04:02.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-9985 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 25 20:04:03.077: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 25 20:04:03.077: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 25 20:04:03.077: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 25 20:04:03.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-9985 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 25 20:04:03.407: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 25 20:04:03.407: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 25 20:04:03.407: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 25 20:04:03.407: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 20:04:03.418: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 25 20:04:13.443: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 20:04:13.443: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 20:04:13.443: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 20:04:13.483: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 25 20:04:13.483: INFO: ss-0  10.10.21.190  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:30 +0000 UTC  }]
Apr 25 20:04:13.483: INFO: ss-1  10.10.21.161  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  }]
Apr 25 20:04:13.483: INFO: ss-2  10.10.21.136  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  }]
Apr 25 20:04:13.483: INFO: 
Apr 25 20:04:13.483: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 25 20:04:14.498: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 25 20:04:14.498: INFO: ss-0  10.10.21.190  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:30 +0000 UTC  }]
Apr 25 20:04:14.498: INFO: ss-1  10.10.21.161  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  }]
Apr 25 20:04:14.498: INFO: ss-2  10.10.21.136  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  }]
Apr 25 20:04:14.498: INFO: 
Apr 25 20:04:14.498: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 25 20:04:15.511: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.965976958s
Apr 25 20:04:16.522: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.954012996s
Apr 25 20:04:17.533: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.942711124s
Apr 25 20:04:18.544: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.932099302s
Apr 25 20:04:19.558: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.920656954s
Apr 25 20:04:20.572: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.906623267s
Apr 25 20:04:21.594: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.892859264s
Apr 25 20:04:22.605: INFO: Verifying statefulset ss doesn't scale past 0 for another 870.42552ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9985 04/25/23 20:04:23.605
Apr 25 20:04:23.617: INFO: Scaling statefulset ss to 0
Apr 25 20:04:23.649: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 25 20:04:23.660: INFO: Deleting all statefulset in ns statefulset-9985
Apr 25 20:04:23.671: INFO: Scaling statefulset ss to 0
Apr 25 20:04:23.703: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 20:04:23.713: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 25 20:04:23.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9985" for this suite. 04/25/23 20:04:23.779
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":108,"skipped":1982,"failed":0}
------------------------------
• [SLOW TEST] [53.266 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:03:30.555
    Apr 25 20:03:30.555: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename statefulset 04/25/23 20:03:30.557
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:03:30.6
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:03:30.611
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9985 04/25/23 20:03:30.621
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-9985 04/25/23 20:03:30.637
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9985 04/25/23 20:03:30.655
    Apr 25 20:03:30.667: INFO: Found 0 stateful pods, waiting for 1
    Apr 25 20:03:40.681: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 04/25/23 20:03:40.681
    Apr 25 20:03:40.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-9985 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 25 20:03:41.031: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 25 20:03:41.031: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 25 20:03:41.031: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 25 20:03:41.044: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Apr 25 20:03:51.061: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 25 20:03:51.061: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 25 20:03:51.109: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
    Apr 25 20:03:51.109: INFO: ss-0  10.10.21.190  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:30 +0000 UTC  }]
    Apr 25 20:03:51.110: INFO: 
    Apr 25 20:03:51.110: INFO: StatefulSet ss has not reached scale 3, at 1
    Apr 25 20:03:52.124: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988350948s
    Apr 25 20:03:53.142: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.973404132s
    Apr 25 20:03:54.155: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.95562155s
    Apr 25 20:03:55.170: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.942586812s
    Apr 25 20:03:56.185: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.927969611s
    Apr 25 20:03:57.199: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.912624879s
    Apr 25 20:03:58.213: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.898950277s
    Apr 25 20:03:59.232: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.884446267s
    Apr 25 20:04:00.250: INFO: Verifying statefulset ss doesn't scale past 3 for another 864.697997ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9985 04/25/23 20:04:01.251
    Apr 25 20:04:01.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-9985 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 25 20:04:01.653: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 25 20:04:01.653: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 25 20:04:01.653: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 25 20:04:01.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-9985 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 25 20:04:02.019: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Apr 25 20:04:02.019: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 25 20:04:02.019: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 25 20:04:02.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-9985 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 25 20:04:02.360: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Apr 25 20:04:02.360: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 25 20:04:02.360: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 25 20:04:02.372: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 25 20:04:02.372: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 25 20:04:02.372: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 04/25/23 20:04:02.372
    Apr 25 20:04:02.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-9985 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 25 20:04:02.758: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 25 20:04:02.758: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 25 20:04:02.758: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 25 20:04:02.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-9985 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 25 20:04:03.077: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 25 20:04:03.077: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 25 20:04:03.077: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 25 20:04:03.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-9985 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 25 20:04:03.407: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 25 20:04:03.407: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 25 20:04:03.407: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 25 20:04:03.407: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 25 20:04:03.418: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Apr 25 20:04:13.443: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 25 20:04:13.443: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Apr 25 20:04:13.443: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Apr 25 20:04:13.483: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
    Apr 25 20:04:13.483: INFO: ss-0  10.10.21.190  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:30 +0000 UTC  }]
    Apr 25 20:04:13.483: INFO: ss-1  10.10.21.161  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  }]
    Apr 25 20:04:13.483: INFO: ss-2  10.10.21.136  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  }]
    Apr 25 20:04:13.483: INFO: 
    Apr 25 20:04:13.483: INFO: StatefulSet ss has not reached scale 0, at 3
    Apr 25 20:04:14.498: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
    Apr 25 20:04:14.498: INFO: ss-0  10.10.21.190  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:30 +0000 UTC  }]
    Apr 25 20:04:14.498: INFO: ss-1  10.10.21.161  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  }]
    Apr 25 20:04:14.498: INFO: ss-2  10.10.21.136  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:04:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:03:51 +0000 UTC  }]
    Apr 25 20:04:14.498: INFO: 
    Apr 25 20:04:14.498: INFO: StatefulSet ss has not reached scale 0, at 3
    Apr 25 20:04:15.511: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.965976958s
    Apr 25 20:04:16.522: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.954012996s
    Apr 25 20:04:17.533: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.942711124s
    Apr 25 20:04:18.544: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.932099302s
    Apr 25 20:04:19.558: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.920656954s
    Apr 25 20:04:20.572: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.906623267s
    Apr 25 20:04:21.594: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.892859264s
    Apr 25 20:04:22.605: INFO: Verifying statefulset ss doesn't scale past 0 for another 870.42552ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9985 04/25/23 20:04:23.605
    Apr 25 20:04:23.617: INFO: Scaling statefulset ss to 0
    Apr 25 20:04:23.649: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 25 20:04:23.660: INFO: Deleting all statefulset in ns statefulset-9985
    Apr 25 20:04:23.671: INFO: Scaling statefulset ss to 0
    Apr 25 20:04:23.703: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 25 20:04:23.713: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 25 20:04:23.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9985" for this suite. 04/25/23 20:04:23.779
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2179
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:04:23.825
Apr 25 20:04:23.825: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 20:04:23.831
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:04:23.908
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:04:23.92
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2179
STEP: creating service in namespace services-334 04/25/23 20:04:23.932
STEP: creating service affinity-clusterip-transition in namespace services-334 04/25/23 20:04:23.932
STEP: creating replication controller affinity-clusterip-transition in namespace services-334 04/25/23 20:04:23.989
I0425 20:04:24.005558      23 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-334, replica count: 3
I0425 20:04:27.058169      23 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 25 20:04:27.083: INFO: Creating new exec pod
Apr 25 20:04:27.105: INFO: Waiting up to 5m0s for pod "execpod-affinitybwt6x" in namespace "services-334" to be "running"
Apr 25 20:04:27.117: INFO: Pod "execpod-affinitybwt6x": Phase="Pending", Reason="", readiness=false. Elapsed: 12.107549ms
Apr 25 20:04:29.129: INFO: Pod "execpod-affinitybwt6x": Phase="Running", Reason="", readiness=true. Elapsed: 2.024676574s
Apr 25 20:04:29.130: INFO: Pod "execpod-affinitybwt6x" satisfied condition "running"
Apr 25 20:04:30.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-334 exec execpod-affinitybwt6x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Apr 25 20:04:30.486: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Apr 25 20:04:30.486: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 20:04:30.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-334 exec execpod-affinitybwt6x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.131.254 80'
Apr 25 20:04:30.846: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.131.254 80\nConnection to 172.21.131.254 80 port [tcp/http] succeeded!\n"
Apr 25 20:04:30.846: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 20:04:30.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-334 exec execpod-affinitybwt6x -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.131.254:80/ ; done'
Apr 25 20:04:31.392: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n"
Apr 25 20:04:31.392: INFO: stdout: "\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss"
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:05:01.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-334 exec execpod-affinitybwt6x -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.131.254:80/ ; done'
Apr 25 20:05:01.967: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n"
Apr 25 20:05:01.967: INFO: stdout: "\naffinity-clusterip-transition-ch7v4\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-ch7v4\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-ch7v4\naffinity-clusterip-transition-ch7v4\naffinity-clusterip-transition-ch7v4\naffinity-clusterip-transition-ch7v4\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-ch7v4\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss"
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-ch7v4
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-ch7v4
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-ch7v4
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-ch7v4
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-ch7v4
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-ch7v4
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-ch7v4
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-bsnss
Apr 25 20:05:02.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-334 exec execpod-affinitybwt6x -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.131.254:80/ ; done'
Apr 25 20:05:02.596: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n"
Apr 25 20:05:02.596: INFO: stdout: "\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz"
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
Apr 25 20:05:02.596: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-334, will wait for the garbage collector to delete the pods 04/25/23 20:05:02.671
Apr 25 20:05:02.753: INFO: Deleting ReplicationController affinity-clusterip-transition took: 17.309644ms
Apr 25 20:05:02.954: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 201.068287ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 20:05:05.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-334" for this suite. 04/25/23 20:05:05.631
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":109,"skipped":1982,"failed":0}
------------------------------
• [SLOW TEST] [41.825 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2179

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:04:23.825
    Apr 25 20:04:23.825: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 20:04:23.831
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:04:23.908
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:04:23.92
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2179
    STEP: creating service in namespace services-334 04/25/23 20:04:23.932
    STEP: creating service affinity-clusterip-transition in namespace services-334 04/25/23 20:04:23.932
    STEP: creating replication controller affinity-clusterip-transition in namespace services-334 04/25/23 20:04:23.989
    I0425 20:04:24.005558      23 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-334, replica count: 3
    I0425 20:04:27.058169      23 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 25 20:04:27.083: INFO: Creating new exec pod
    Apr 25 20:04:27.105: INFO: Waiting up to 5m0s for pod "execpod-affinitybwt6x" in namespace "services-334" to be "running"
    Apr 25 20:04:27.117: INFO: Pod "execpod-affinitybwt6x": Phase="Pending", Reason="", readiness=false. Elapsed: 12.107549ms
    Apr 25 20:04:29.129: INFO: Pod "execpod-affinitybwt6x": Phase="Running", Reason="", readiness=true. Elapsed: 2.024676574s
    Apr 25 20:04:29.130: INFO: Pod "execpod-affinitybwt6x" satisfied condition "running"
    Apr 25 20:04:30.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-334 exec execpod-affinitybwt6x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Apr 25 20:04:30.486: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Apr 25 20:04:30.486: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 20:04:30.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-334 exec execpod-affinitybwt6x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.131.254 80'
    Apr 25 20:04:30.846: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.131.254 80\nConnection to 172.21.131.254 80 port [tcp/http] succeeded!\n"
    Apr 25 20:04:30.846: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 20:04:30.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-334 exec execpod-affinitybwt6x -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.131.254:80/ ; done'
    Apr 25 20:04:31.392: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n"
    Apr 25 20:04:31.392: INFO: stdout: "\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss"
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:04:31.392: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:05:01.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-334 exec execpod-affinitybwt6x -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.131.254:80/ ; done'
    Apr 25 20:05:01.967: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n"
    Apr 25 20:05:01.967: INFO: stdout: "\naffinity-clusterip-transition-ch7v4\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-ch7v4\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-ch7v4\naffinity-clusterip-transition-ch7v4\naffinity-clusterip-transition-ch7v4\naffinity-clusterip-transition-ch7v4\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-ch7v4\naffinity-clusterip-transition-bsnss\naffinity-clusterip-transition-bsnss"
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-ch7v4
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-ch7v4
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-ch7v4
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-ch7v4
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-ch7v4
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-ch7v4
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-ch7v4
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:05:01.967: INFO: Received response from host: affinity-clusterip-transition-bsnss
    Apr 25 20:05:02.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-334 exec execpod-affinitybwt6x -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.131.254:80/ ; done'
    Apr 25 20:05:02.596: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.131.254:80/\n"
    Apr 25 20:05:02.596: INFO: stdout: "\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz\naffinity-clusterip-transition-2d4fz"
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Received response from host: affinity-clusterip-transition-2d4fz
    Apr 25 20:05:02.596: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-334, will wait for the garbage collector to delete the pods 04/25/23 20:05:02.671
    Apr 25 20:05:02.753: INFO: Deleting ReplicationController affinity-clusterip-transition took: 17.309644ms
    Apr 25 20:05:02.954: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 201.068287ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 20:05:05.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-334" for this suite. 04/25/23 20:05:05.631
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:05:05.653
Apr 25 20:05:05.653: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename pods 04/25/23 20:05:05.655
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:05.738
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:05.749
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Apr 25 20:05:05.759: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: creating the pod 04/25/23 20:05:05.76
STEP: submitting the pod to kubernetes 04/25/23 20:05:05.76
Apr 25 20:05:05.782: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-68879f40-7c51-47eb-ac41-f4a476f49989" in namespace "pods-2144" to be "running and ready"
Apr 25 20:05:05.798: INFO: Pod "pod-logs-websocket-68879f40-7c51-47eb-ac41-f4a476f49989": Phase="Pending", Reason="", readiness=false. Elapsed: 15.526145ms
Apr 25 20:05:05.798: INFO: The phase of Pod pod-logs-websocket-68879f40-7c51-47eb-ac41-f4a476f49989 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:05:07.811: INFO: Pod "pod-logs-websocket-68879f40-7c51-47eb-ac41-f4a476f49989": Phase="Running", Reason="", readiness=true. Elapsed: 2.028228427s
Apr 25 20:05:07.811: INFO: The phase of Pod pod-logs-websocket-68879f40-7c51-47eb-ac41-f4a476f49989 is Running (Ready = true)
Apr 25 20:05:07.811: INFO: Pod "pod-logs-websocket-68879f40-7c51-47eb-ac41-f4a476f49989" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 25 20:05:07.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2144" for this suite. 04/25/23 20:05:07.96
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":110,"skipped":2013,"failed":0}
------------------------------
• [2.326 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:05:05.653
    Apr 25 20:05:05.653: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename pods 04/25/23 20:05:05.655
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:05.738
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:05.749
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Apr 25 20:05:05.759: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: creating the pod 04/25/23 20:05:05.76
    STEP: submitting the pod to kubernetes 04/25/23 20:05:05.76
    Apr 25 20:05:05.782: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-68879f40-7c51-47eb-ac41-f4a476f49989" in namespace "pods-2144" to be "running and ready"
    Apr 25 20:05:05.798: INFO: Pod "pod-logs-websocket-68879f40-7c51-47eb-ac41-f4a476f49989": Phase="Pending", Reason="", readiness=false. Elapsed: 15.526145ms
    Apr 25 20:05:05.798: INFO: The phase of Pod pod-logs-websocket-68879f40-7c51-47eb-ac41-f4a476f49989 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:05:07.811: INFO: Pod "pod-logs-websocket-68879f40-7c51-47eb-ac41-f4a476f49989": Phase="Running", Reason="", readiness=true. Elapsed: 2.028228427s
    Apr 25 20:05:07.811: INFO: The phase of Pod pod-logs-websocket-68879f40-7c51-47eb-ac41-f4a476f49989 is Running (Ready = true)
    Apr 25 20:05:07.811: INFO: Pod "pod-logs-websocket-68879f40-7c51-47eb-ac41-f4a476f49989" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 25 20:05:07.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2144" for this suite. 04/25/23 20:05:07.96
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:05:07.992
Apr 25 20:05:07.992: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 20:05:07.994
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:08.049
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:08.088
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 20:05:08.139
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:05:08.494
STEP: Deploying the webhook pod 04/25/23 20:05:08.517
STEP: Wait for the deployment to be ready 04/25/23 20:05:08.557
Apr 25 20:05:08.593: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/25/23 20:05:10.63
STEP: Verifying the service has paired with the endpoint 04/25/23 20:05:10.672
Apr 25 20:05:11.673: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 04/25/23 20:05:11.686
STEP: Updating a mutating webhook configuration's rules to not include the create operation 04/25/23 20:05:11.782
STEP: Creating a configMap that should not be mutated 04/25/23 20:05:11.798
STEP: Patching a mutating webhook configuration's rules to include the create operation 04/25/23 20:05:11.832
STEP: Creating a configMap that should be mutated 04/25/23 20:05:11.847
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:05:11.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7970" for this suite. 04/25/23 20:05:11.989
STEP: Destroying namespace "webhook-7970-markers" for this suite. 04/25/23 20:05:12.007
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":111,"skipped":2034,"failed":0}
------------------------------
• [4.179 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:05:07.992
    Apr 25 20:05:07.992: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 20:05:07.994
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:08.049
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:08.088
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 20:05:08.139
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:05:08.494
    STEP: Deploying the webhook pod 04/25/23 20:05:08.517
    STEP: Wait for the deployment to be ready 04/25/23 20:05:08.557
    Apr 25 20:05:08.593: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/25/23 20:05:10.63
    STEP: Verifying the service has paired with the endpoint 04/25/23 20:05:10.672
    Apr 25 20:05:11.673: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 04/25/23 20:05:11.686
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 04/25/23 20:05:11.782
    STEP: Creating a configMap that should not be mutated 04/25/23 20:05:11.798
    STEP: Patching a mutating webhook configuration's rules to include the create operation 04/25/23 20:05:11.832
    STEP: Creating a configMap that should be mutated 04/25/23 20:05:11.847
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:05:11.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7970" for this suite. 04/25/23 20:05:11.989
    STEP: Destroying namespace "webhook-7970-markers" for this suite. 04/25/23 20:05:12.007
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:05:12.173
Apr 25 20:05:12.173: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename deployment 04/25/23 20:05:12.174
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:12.226
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:12.236
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Apr 25 20:05:12.281: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 25 20:05:17.298: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/25/23 20:05:17.298
Apr 25 20:05:17.298: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 04/25/23 20:05:17.341
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 25 20:05:19.420: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-6638  5ffef13f-4a30-4c8a-8db8-ad38ed4bda0c 29473 1 2023-04-25 20:05:17 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-25 20:05:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:05:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0043810c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-25 20:05:17 +0000 UTC,LastTransitionTime:2023-04-25 20:05:17 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2023-04-25 20:05:19 +0000 UTC,LastTransitionTime:2023-04-25 20:05:17 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 25 20:05:19.432: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-6638  ac9c2ace-3a99-4afe-a366-457799d442c3 29463 1 2023-04-25 20:05:17 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 5ffef13f-4a30-4c8a-8db8-ad38ed4bda0c 0xc00424ddf7 0xc00424ddf8}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:05:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ffef13f-4a30-4c8a-8db8-ad38ed4bda0c\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:05:19 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00424dea8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 25 20:05:19.444: INFO: Pod "test-cleanup-deployment-69cb9c5497-j74kq" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-j74kq test-cleanup-deployment-69cb9c5497- deployment-6638  b57c77d7-ea17-4767-a294-cd02724c6e29 29462 0 2023-04-25 20:05:17 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:dbfbc72090ac30342f4bd2a812e2b59d422612058f35822b48edb34106347bad cni.projectcalico.org/podIP:172.30.142.181/32 cni.projectcalico.org/podIPs:172.30.142.181/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 ac9c2ace-3a99-4afe-a366-457799d442c3 0xc0043aa337 0xc0043aa338}] [] [{kube-controller-manager Update v1 2023-04-25 20:05:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac9c2ace-3a99-4afe-a366-457799d442c3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:05:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:05:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.181\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tfnbq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tfnbq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:05:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:05:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:05:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:05:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.181,StartTime:2023-04-25 20:05:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:05:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://8726337fcc887642eb36bfafd3ab3584e25c57aa7a36a22a74e920450def4e61,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.181,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 25 20:05:19.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6638" for this suite. 04/25/23 20:05:19.464
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":112,"skipped":2056,"failed":0}
------------------------------
• [SLOW TEST] [7.316 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:05:12.173
    Apr 25 20:05:12.173: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename deployment 04/25/23 20:05:12.174
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:12.226
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:12.236
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Apr 25 20:05:12.281: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Apr 25 20:05:17.298: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/25/23 20:05:17.298
    Apr 25 20:05:17.298: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 04/25/23 20:05:17.341
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 25 20:05:19.420: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-6638  5ffef13f-4a30-4c8a-8db8-ad38ed4bda0c 29473 1 2023-04-25 20:05:17 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-25 20:05:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:05:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0043810c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-25 20:05:17 +0000 UTC,LastTransitionTime:2023-04-25 20:05:17 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2023-04-25 20:05:19 +0000 UTC,LastTransitionTime:2023-04-25 20:05:17 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 25 20:05:19.432: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-6638  ac9c2ace-3a99-4afe-a366-457799d442c3 29463 1 2023-04-25 20:05:17 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 5ffef13f-4a30-4c8a-8db8-ad38ed4bda0c 0xc00424ddf7 0xc00424ddf8}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:05:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ffef13f-4a30-4c8a-8db8-ad38ed4bda0c\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:05:19 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00424dea8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 25 20:05:19.444: INFO: Pod "test-cleanup-deployment-69cb9c5497-j74kq" is available:
    &Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-j74kq test-cleanup-deployment-69cb9c5497- deployment-6638  b57c77d7-ea17-4767-a294-cd02724c6e29 29462 0 2023-04-25 20:05:17 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:dbfbc72090ac30342f4bd2a812e2b59d422612058f35822b48edb34106347bad cni.projectcalico.org/podIP:172.30.142.181/32 cni.projectcalico.org/podIPs:172.30.142.181/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 ac9c2ace-3a99-4afe-a366-457799d442c3 0xc0043aa337 0xc0043aa338}] [] [{kube-controller-manager Update v1 2023-04-25 20:05:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac9c2ace-3a99-4afe-a366-457799d442c3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:05:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:05:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.181\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tfnbq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tfnbq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:05:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:05:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:05:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:05:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.181,StartTime:2023-04-25 20:05:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:05:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://8726337fcc887642eb36bfafd3ab3584e25c57aa7a36a22a74e920450def4e61,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.181,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 25 20:05:19.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-6638" for this suite. 04/25/23 20:05:19.464
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:05:19.496
Apr 25 20:05:19.497: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename daemonsets 04/25/23 20:05:19.499
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:19.541
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:19.556
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 04/25/23 20:05:19.642
STEP: Check that daemon pods launch on every node of the cluster. 04/25/23 20:05:19.697
Apr 25 20:05:19.729: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 20:05:19.729: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:05:20.758: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 20:05:20.758: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:05:21.763: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 25 20:05:21.763: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 04/25/23 20:05:21.775
STEP: DeleteCollection of the DaemonSets 04/25/23 20:05:21.791
STEP: Verify that ReplicaSets have been deleted 04/25/23 20:05:21.845
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Apr 25 20:05:21.896: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29531"},"items":null}

Apr 25 20:05:21.925: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29534"},"items":[{"metadata":{"name":"daemon-set-56crb","generateName":"daemon-set-","namespace":"daemonsets-4491","uid":"83cf71f6-4d0f-4989-81cd-bd35543a65fe","resourceVersion":"29533","creationTimestamp":"2023-04-25T20:05:19Z","deletionTimestamp":"2023-04-25T20:05:51Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"3a2b3a0758d6f9db2a71905ba2294f502dc091cf7684e276b40116cc34f3b321","cni.projectcalico.org/podIP":"172.30.226.106/32","cni.projectcalico.org/podIPs":"172.30.226.106/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"34e1f476-6541-48a8-b83a-08653cad0e62","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:19Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"34e1f476-6541-48a8-b83a-08653cad0e62\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:21Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.226.106\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-22cl6","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-22cl6","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.10.21.161","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.10.21.161"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:19Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:21Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:21Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:19Z"}],"hostIP":"10.10.21.161","podIP":"172.30.226.106","podIPs":[{"ip":"172.30.226.106"}],"startTime":"2023-04-25T20:05:19Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-25T20:05:20Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://ba6a55b45855e97dfffe64681c01f1b7574e955d46d94a1ae2c312923b5a315c","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-7kvjv","generateName":"daemon-set-","namespace":"daemonsets-4491","uid":"dcddb1c5-0d86-4cce-bd5f-0c8190b6656a","resourceVersion":"29531","creationTimestamp":"2023-04-25T20:05:19Z","deletionTimestamp":"2023-04-25T20:05:51Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"a932ceeca17b1aa583fdb70c084340ab504f2564786e633f6eb9018c6d29d8f8","cni.projectcalico.org/podIP":"172.30.142.186/32","cni.projectcalico.org/podIPs":"172.30.142.186/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"34e1f476-6541-48a8-b83a-08653cad0e62","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:19Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"34e1f476-6541-48a8-b83a-08653cad0e62\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.186\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-prmdk","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-prmdk","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.10.21.190","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.10.21.190"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:19Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:20Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:20Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:19Z"}],"hostIP":"10.10.21.190","podIP":"172.30.142.186","podIPs":[{"ip":"172.30.142.186"}],"startTime":"2023-04-25T20:05:19Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-25T20:05:20Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://273afdd84c33f802acf6a846f955ebcf06a66e9214793c95652327b767f1f236","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-nf5rd","generateName":"daemon-set-","namespace":"daemonsets-4491","uid":"063dfde4-dcf3-4422-8307-584d0c8cb9e6","resourceVersion":"29532","creationTimestamp":"2023-04-25T20:05:19Z","deletionTimestamp":"2023-04-25T20:05:51Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"f4e729dc08f528e2129142f94dda4a885720cde878a4ea9df2f162b1b0739528","cni.projectcalico.org/podIP":"172.30.191.21/32","cni.projectcalico.org/podIPs":"172.30.191.21/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"34e1f476-6541-48a8-b83a-08653cad0e62","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:19Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"34e1f476-6541-48a8-b83a-08653cad0e62\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:21Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.191.21\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-8hrnx","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-8hrnx","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.10.21.136","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.10.21.136"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:19Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:21Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:21Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:19Z"}],"hostIP":"10.10.21.136","podIP":"172.30.191.21","podIPs":[{"ip":"172.30.191.21"}],"startTime":"2023-04-25T20:05:19Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-25T20:05:20Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://0294e1f67116f18ae2822f434b39c5bf231bb3b15865c62bcba050c0bf8cd21e","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 25 20:05:21.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4491" for this suite. 04/25/23 20:05:22
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":113,"skipped":2061,"failed":0}
------------------------------
• [2.524 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:05:19.496
    Apr 25 20:05:19.497: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename daemonsets 04/25/23 20:05:19.499
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:19.541
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:19.556
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 04/25/23 20:05:19.642
    STEP: Check that daemon pods launch on every node of the cluster. 04/25/23 20:05:19.697
    Apr 25 20:05:19.729: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 20:05:19.729: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:05:20.758: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 20:05:20.758: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:05:21.763: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 25 20:05:21.763: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 04/25/23 20:05:21.775
    STEP: DeleteCollection of the DaemonSets 04/25/23 20:05:21.791
    STEP: Verify that ReplicaSets have been deleted 04/25/23 20:05:21.845
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Apr 25 20:05:21.896: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29531"},"items":null}

    Apr 25 20:05:21.925: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29534"},"items":[{"metadata":{"name":"daemon-set-56crb","generateName":"daemon-set-","namespace":"daemonsets-4491","uid":"83cf71f6-4d0f-4989-81cd-bd35543a65fe","resourceVersion":"29533","creationTimestamp":"2023-04-25T20:05:19Z","deletionTimestamp":"2023-04-25T20:05:51Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"3a2b3a0758d6f9db2a71905ba2294f502dc091cf7684e276b40116cc34f3b321","cni.projectcalico.org/podIP":"172.30.226.106/32","cni.projectcalico.org/podIPs":"172.30.226.106/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"34e1f476-6541-48a8-b83a-08653cad0e62","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:19Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"34e1f476-6541-48a8-b83a-08653cad0e62\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:21Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.226.106\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-22cl6","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-22cl6","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.10.21.161","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.10.21.161"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:19Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:21Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:21Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:19Z"}],"hostIP":"10.10.21.161","podIP":"172.30.226.106","podIPs":[{"ip":"172.30.226.106"}],"startTime":"2023-04-25T20:05:19Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-25T20:05:20Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://ba6a55b45855e97dfffe64681c01f1b7574e955d46d94a1ae2c312923b5a315c","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-7kvjv","generateName":"daemon-set-","namespace":"daemonsets-4491","uid":"dcddb1c5-0d86-4cce-bd5f-0c8190b6656a","resourceVersion":"29531","creationTimestamp":"2023-04-25T20:05:19Z","deletionTimestamp":"2023-04-25T20:05:51Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"a932ceeca17b1aa583fdb70c084340ab504f2564786e633f6eb9018c6d29d8f8","cni.projectcalico.org/podIP":"172.30.142.186/32","cni.projectcalico.org/podIPs":"172.30.142.186/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"34e1f476-6541-48a8-b83a-08653cad0e62","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:19Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"34e1f476-6541-48a8-b83a-08653cad0e62\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.186\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-prmdk","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-prmdk","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.10.21.190","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.10.21.190"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:19Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:20Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:20Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:19Z"}],"hostIP":"10.10.21.190","podIP":"172.30.142.186","podIPs":[{"ip":"172.30.142.186"}],"startTime":"2023-04-25T20:05:19Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-25T20:05:20Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://273afdd84c33f802acf6a846f955ebcf06a66e9214793c95652327b767f1f236","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-nf5rd","generateName":"daemon-set-","namespace":"daemonsets-4491","uid":"063dfde4-dcf3-4422-8307-584d0c8cb9e6","resourceVersion":"29532","creationTimestamp":"2023-04-25T20:05:19Z","deletionTimestamp":"2023-04-25T20:05:51Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"f4e729dc08f528e2129142f94dda4a885720cde878a4ea9df2f162b1b0739528","cni.projectcalico.org/podIP":"172.30.191.21/32","cni.projectcalico.org/podIPs":"172.30.191.21/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"34e1f476-6541-48a8-b83a-08653cad0e62","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:19Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"34e1f476-6541-48a8-b83a-08653cad0e62\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-25T20:05:21Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.191.21\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-8hrnx","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-8hrnx","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.10.21.136","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.10.21.136"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:19Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:21Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:21Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-25T20:05:19Z"}],"hostIP":"10.10.21.136","podIP":"172.30.191.21","podIPs":[{"ip":"172.30.191.21"}],"startTime":"2023-04-25T20:05:19Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-25T20:05:20Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://0294e1f67116f18ae2822f434b39c5bf231bb3b15865c62bcba050c0bf8cd21e","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 20:05:21.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4491" for this suite. 04/25/23 20:05:22
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:05:22.024
Apr 25 20:05:22.025: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename resourcequota 04/25/23 20:05:22.027
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:22.075
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:22.086
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 04/25/23 20:05:22.097
STEP: Creating a ResourceQuota 04/25/23 20:05:27.109
STEP: Ensuring resource quota status is calculated 04/25/23 20:05:27.123
STEP: Creating a ReplicaSet 04/25/23 20:05:29.137
STEP: Ensuring resource quota status captures replicaset creation 04/25/23 20:05:29.161
STEP: Deleting a ReplicaSet 04/25/23 20:05:31.173
STEP: Ensuring resource quota status released usage 04/25/23 20:05:31.197
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 25 20:05:33.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6596" for this suite. 04/25/23 20:05:33.229
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":114,"skipped":2074,"failed":0}
------------------------------
• [SLOW TEST] [11.223 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:05:22.024
    Apr 25 20:05:22.025: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename resourcequota 04/25/23 20:05:22.027
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:22.075
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:22.086
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 04/25/23 20:05:22.097
    STEP: Creating a ResourceQuota 04/25/23 20:05:27.109
    STEP: Ensuring resource quota status is calculated 04/25/23 20:05:27.123
    STEP: Creating a ReplicaSet 04/25/23 20:05:29.137
    STEP: Ensuring resource quota status captures replicaset creation 04/25/23 20:05:29.161
    STEP: Deleting a ReplicaSet 04/25/23 20:05:31.173
    STEP: Ensuring resource quota status released usage 04/25/23 20:05:31.197
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 25 20:05:33.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6596" for this suite. 04/25/23 20:05:33.229
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:05:33.254
Apr 25 20:05:33.255: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename podtemplate 04/25/23 20:05:33.259
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:33.324
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:33.335
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Apr 25 20:05:33.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-2806" for this suite. 04/25/23 20:05:33.462
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":115,"skipped":2084,"failed":0}
------------------------------
• [0.226 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:05:33.254
    Apr 25 20:05:33.255: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename podtemplate 04/25/23 20:05:33.259
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:33.324
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:33.335
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Apr 25 20:05:33.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-2806" for this suite. 04/25/23 20:05:33.462
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:05:33.49
Apr 25 20:05:33.491: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 20:05:33.495
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:33.542
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:33.554
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-9128 04/25/23 20:05:33.564
STEP: changing the ExternalName service to type=ClusterIP 04/25/23 20:05:33.585
STEP: creating replication controller externalname-service in namespace services-9128 04/25/23 20:05:33.632
I0425 20:05:33.662041      23 runners.go:193] Created replication controller with name: externalname-service, namespace: services-9128, replica count: 2
I0425 20:05:36.713927      23 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 25 20:05:36.714: INFO: Creating new exec pod
Apr 25 20:05:36.734: INFO: Waiting up to 5m0s for pod "execpodddh96" in namespace "services-9128" to be "running"
Apr 25 20:05:36.745: INFO: Pod "execpodddh96": Phase="Pending", Reason="", readiness=false. Elapsed: 9.927524ms
Apr 25 20:05:38.759: INFO: Pod "execpodddh96": Phase="Running", Reason="", readiness=true. Elapsed: 2.023853654s
Apr 25 20:05:38.759: INFO: Pod "execpodddh96" satisfied condition "running"
Apr 25 20:05:39.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-9128 exec execpodddh96 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 25 20:05:40.095: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 25 20:05:40.096: INFO: stdout: ""
Apr 25 20:05:41.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-9128 exec execpodddh96 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 25 20:05:41.449: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 25 20:05:41.450: INFO: stdout: "externalname-service-xwwrm"
Apr 25 20:05:41.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-9128 exec execpodddh96 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.221.103 80'
Apr 25 20:05:41.799: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.221.103 80\nConnection to 172.21.221.103 80 port [tcp/http] succeeded!\n"
Apr 25 20:05:41.799: INFO: stdout: "externalname-service-xwwrm"
Apr 25 20:05:41.799: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 20:05:41.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9128" for this suite. 04/25/23 20:05:41.879
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":116,"skipped":2088,"failed":0}
------------------------------
• [SLOW TEST] [8.412 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:05:33.49
    Apr 25 20:05:33.491: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 20:05:33.495
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:33.542
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:33.554
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-9128 04/25/23 20:05:33.564
    STEP: changing the ExternalName service to type=ClusterIP 04/25/23 20:05:33.585
    STEP: creating replication controller externalname-service in namespace services-9128 04/25/23 20:05:33.632
    I0425 20:05:33.662041      23 runners.go:193] Created replication controller with name: externalname-service, namespace: services-9128, replica count: 2
    I0425 20:05:36.713927      23 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 25 20:05:36.714: INFO: Creating new exec pod
    Apr 25 20:05:36.734: INFO: Waiting up to 5m0s for pod "execpodddh96" in namespace "services-9128" to be "running"
    Apr 25 20:05:36.745: INFO: Pod "execpodddh96": Phase="Pending", Reason="", readiness=false. Elapsed: 9.927524ms
    Apr 25 20:05:38.759: INFO: Pod "execpodddh96": Phase="Running", Reason="", readiness=true. Elapsed: 2.023853654s
    Apr 25 20:05:38.759: INFO: Pod "execpodddh96" satisfied condition "running"
    Apr 25 20:05:39.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-9128 exec execpodddh96 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 25 20:05:40.095: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 25 20:05:40.096: INFO: stdout: ""
    Apr 25 20:05:41.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-9128 exec execpodddh96 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 25 20:05:41.449: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 25 20:05:41.450: INFO: stdout: "externalname-service-xwwrm"
    Apr 25 20:05:41.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-9128 exec execpodddh96 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.221.103 80'
    Apr 25 20:05:41.799: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.221.103 80\nConnection to 172.21.221.103 80 port [tcp/http] succeeded!\n"
    Apr 25 20:05:41.799: INFO: stdout: "externalname-service-xwwrm"
    Apr 25 20:05:41.799: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 20:05:41.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9128" for this suite. 04/25/23 20:05:41.879
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:05:41.908
Apr 25 20:05:41.908: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename var-expansion 04/25/23 20:05:41.912
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:41.956
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:41.968
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 04/25/23 20:05:41.979
Apr 25 20:05:42.006: INFO: Waiting up to 5m0s for pod "var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23" in namespace "var-expansion-2173" to be "Succeeded or Failed"
Apr 25 20:05:42.033: INFO: Pod "var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23": Phase="Pending", Reason="", readiness=false. Elapsed: 27.424594ms
Apr 25 20:05:44.049: INFO: Pod "var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043164599s
Apr 25 20:05:46.046: INFO: Pod "var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039829928s
Apr 25 20:05:48.046: INFO: Pod "var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039752779s
STEP: Saw pod success 04/25/23 20:05:48.046
Apr 25 20:05:48.046: INFO: Pod "var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23" satisfied condition "Succeeded or Failed"
Apr 25 20:05:48.057: INFO: Trying to get logs from node 10.10.21.190 pod var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23 container dapi-container: <nil>
STEP: delete the pod 04/25/23 20:05:48.129
Apr 25 20:05:48.162: INFO: Waiting for pod var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23 to disappear
Apr 25 20:05:48.173: INFO: Pod var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 25 20:05:48.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2173" for this suite. 04/25/23 20:05:48.192
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":117,"skipped":2117,"failed":0}
------------------------------
• [SLOW TEST] [6.302 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:05:41.908
    Apr 25 20:05:41.908: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename var-expansion 04/25/23 20:05:41.912
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:41.956
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:41.968
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 04/25/23 20:05:41.979
    Apr 25 20:05:42.006: INFO: Waiting up to 5m0s for pod "var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23" in namespace "var-expansion-2173" to be "Succeeded or Failed"
    Apr 25 20:05:42.033: INFO: Pod "var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23": Phase="Pending", Reason="", readiness=false. Elapsed: 27.424594ms
    Apr 25 20:05:44.049: INFO: Pod "var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043164599s
    Apr 25 20:05:46.046: INFO: Pod "var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039829928s
    Apr 25 20:05:48.046: INFO: Pod "var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039752779s
    STEP: Saw pod success 04/25/23 20:05:48.046
    Apr 25 20:05:48.046: INFO: Pod "var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23" satisfied condition "Succeeded or Failed"
    Apr 25 20:05:48.057: INFO: Trying to get logs from node 10.10.21.190 pod var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23 container dapi-container: <nil>
    STEP: delete the pod 04/25/23 20:05:48.129
    Apr 25 20:05:48.162: INFO: Waiting for pod var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23 to disappear
    Apr 25 20:05:48.173: INFO: Pod var-expansion-811abdaa-1630-497c-bdc1-b36e02efca23 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 25 20:05:48.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2173" for this suite. 04/25/23 20:05:48.192
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:05:48.216
Apr 25 20:05:48.217: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename resourcequota 04/25/23 20:05:48.217
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:48.27
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:48.283
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 04/25/23 20:05:48.292
STEP: Creating a ResourceQuota 04/25/23 20:05:53.308
STEP: Ensuring resource quota status is calculated 04/25/23 20:05:53.32
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 25 20:05:55.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2664" for this suite. 04/25/23 20:05:55.352
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":118,"skipped":2153,"failed":0}
------------------------------
• [SLOW TEST] [7.155 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:05:48.216
    Apr 25 20:05:48.217: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename resourcequota 04/25/23 20:05:48.217
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:48.27
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:48.283
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 04/25/23 20:05:48.292
    STEP: Creating a ResourceQuota 04/25/23 20:05:53.308
    STEP: Ensuring resource quota status is calculated 04/25/23 20:05:53.32
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 25 20:05:55.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2664" for this suite. 04/25/23 20:05:55.352
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:05:55.375
Apr 25 20:05:55.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename init-container 04/25/23 20:05:55.377
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:55.427
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:55.44
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 04/25/23 20:05:55.451
Apr 25 20:05:55.452: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 25 20:05:59.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8877" for this suite. 04/25/23 20:05:59.294
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":119,"skipped":2168,"failed":0}
------------------------------
• [3.941 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:05:55.375
    Apr 25 20:05:55.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename init-container 04/25/23 20:05:55.377
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:55.427
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:55.44
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 04/25/23 20:05:55.451
    Apr 25 20:05:55.452: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 25 20:05:59.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-8877" for this suite. 04/25/23 20:05:59.294
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:05:59.325
Apr 25 20:05:59.325: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename var-expansion 04/25/23 20:05:59.328
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:59.399
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:59.409
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 04/25/23 20:05:59.418
Apr 25 20:05:59.439: INFO: Waiting up to 2m0s for pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146" in namespace "var-expansion-3716" to be "running"
Apr 25 20:05:59.451: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 11.452682ms
Apr 25 20:06:01.467: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027466243s
Apr 25 20:06:03.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024418617s
Apr 25 20:06:05.472: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 6.032354929s
Apr 25 20:06:07.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 8.023691299s
Apr 25 20:06:09.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 10.023660974s
Apr 25 20:06:11.466: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 12.026812984s
Apr 25 20:06:13.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 14.024564303s
Apr 25 20:06:15.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 16.023355523s
Apr 25 20:06:17.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 18.024610276s
Apr 25 20:06:19.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 20.024626307s
Apr 25 20:06:21.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 22.023308911s
Apr 25 20:06:23.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 24.025556463s
Apr 25 20:06:25.494: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 26.054314791s
Apr 25 20:06:27.467: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 28.027427367s
Apr 25 20:06:29.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 30.025274563s
Apr 25 20:06:31.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 32.025688186s
Apr 25 20:06:33.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 34.024894065s
Apr 25 20:06:35.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 36.024450765s
Apr 25 20:06:37.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 38.024640023s
Apr 25 20:06:39.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 40.025053807s
Apr 25 20:06:41.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 42.025161996s
Apr 25 20:06:43.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 44.023810539s
Apr 25 20:06:45.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 46.023285859s
Apr 25 20:06:47.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 48.023584835s
Apr 25 20:06:49.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 50.025503737s
Apr 25 20:06:51.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 52.023747988s
Apr 25 20:06:53.462: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 54.022837747s
Apr 25 20:06:55.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 56.023176653s
Apr 25 20:06:57.466: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 58.026642639s
Apr 25 20:06:59.466: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.026524297s
Apr 25 20:07:01.466: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.026198141s
Apr 25 20:07:03.473: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.033050894s
Apr 25 20:07:05.474: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.03399797s
Apr 25 20:07:07.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.024661468s
Apr 25 20:07:09.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.024246966s
Apr 25 20:07:11.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.023374269s
Apr 25 20:07:13.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.024113205s
Apr 25 20:07:15.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.02495176s
Apr 25 20:07:17.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.02410804s
Apr 25 20:07:19.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.024581995s
Apr 25 20:07:21.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.025471921s
Apr 25 20:07:23.467: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.027578162s
Apr 25 20:07:25.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.024199217s
Apr 25 20:07:27.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.023988799s
Apr 25 20:07:29.462: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.022760483s
Apr 25 20:07:31.495: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.05512915s
Apr 25 20:07:33.462: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.02261557s
Apr 25 20:07:35.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.023767182s
Apr 25 20:07:37.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.025102999s
Apr 25 20:07:39.466: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.026791848s
Apr 25 20:07:41.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.024232216s
Apr 25 20:07:43.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.024035554s
Apr 25 20:07:45.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.023969481s
Apr 25 20:07:47.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.02430433s
Apr 25 20:07:49.467: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.026989051s
Apr 25 20:07:51.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.025472845s
Apr 25 20:07:53.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.024867538s
Apr 25 20:07:55.466: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.02617168s
Apr 25 20:07:57.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.023904881s
Apr 25 20:07:59.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.02377258s
Apr 25 20:07:59.476: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.036571397s
STEP: updating the pod 04/25/23 20:07:59.476
Apr 25 20:08:00.008: INFO: Successfully updated pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146"
STEP: waiting for pod running 04/25/23 20:08:00.008
Apr 25 20:08:00.008: INFO: Waiting up to 2m0s for pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146" in namespace "var-expansion-3716" to be "running"
Apr 25 20:08:00.019: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 10.928444ms
Apr 25 20:08:02.032: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Running", Reason="", readiness=true. Elapsed: 2.024278314s
Apr 25 20:08:02.033: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146" satisfied condition "running"
STEP: deleting the pod gracefully 04/25/23 20:08:02.033
Apr 25 20:08:02.033: INFO: Deleting pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146" in namespace "var-expansion-3716"
Apr 25 20:08:02.051: INFO: Wait up to 5m0s for pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 25 20:08:34.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3716" for this suite. 04/25/23 20:08:34.122
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":120,"skipped":2198,"failed":0}
------------------------------
• [SLOW TEST] [154.819 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:05:59.325
    Apr 25 20:05:59.325: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename var-expansion 04/25/23 20:05:59.328
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:05:59.399
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:05:59.409
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 04/25/23 20:05:59.418
    Apr 25 20:05:59.439: INFO: Waiting up to 2m0s for pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146" in namespace "var-expansion-3716" to be "running"
    Apr 25 20:05:59.451: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 11.452682ms
    Apr 25 20:06:01.467: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027466243s
    Apr 25 20:06:03.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024418617s
    Apr 25 20:06:05.472: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 6.032354929s
    Apr 25 20:06:07.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 8.023691299s
    Apr 25 20:06:09.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 10.023660974s
    Apr 25 20:06:11.466: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 12.026812984s
    Apr 25 20:06:13.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 14.024564303s
    Apr 25 20:06:15.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 16.023355523s
    Apr 25 20:06:17.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 18.024610276s
    Apr 25 20:06:19.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 20.024626307s
    Apr 25 20:06:21.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 22.023308911s
    Apr 25 20:06:23.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 24.025556463s
    Apr 25 20:06:25.494: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 26.054314791s
    Apr 25 20:06:27.467: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 28.027427367s
    Apr 25 20:06:29.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 30.025274563s
    Apr 25 20:06:31.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 32.025688186s
    Apr 25 20:06:33.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 34.024894065s
    Apr 25 20:06:35.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 36.024450765s
    Apr 25 20:06:37.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 38.024640023s
    Apr 25 20:06:39.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 40.025053807s
    Apr 25 20:06:41.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 42.025161996s
    Apr 25 20:06:43.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 44.023810539s
    Apr 25 20:06:45.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 46.023285859s
    Apr 25 20:06:47.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 48.023584835s
    Apr 25 20:06:49.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 50.025503737s
    Apr 25 20:06:51.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 52.023747988s
    Apr 25 20:06:53.462: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 54.022837747s
    Apr 25 20:06:55.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 56.023176653s
    Apr 25 20:06:57.466: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 58.026642639s
    Apr 25 20:06:59.466: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.026524297s
    Apr 25 20:07:01.466: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.026198141s
    Apr 25 20:07:03.473: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.033050894s
    Apr 25 20:07:05.474: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.03399797s
    Apr 25 20:07:07.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.024661468s
    Apr 25 20:07:09.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.024246966s
    Apr 25 20:07:11.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.023374269s
    Apr 25 20:07:13.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.024113205s
    Apr 25 20:07:15.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.02495176s
    Apr 25 20:07:17.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.02410804s
    Apr 25 20:07:19.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.024581995s
    Apr 25 20:07:21.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.025471921s
    Apr 25 20:07:23.467: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.027578162s
    Apr 25 20:07:25.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.024199217s
    Apr 25 20:07:27.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.023988799s
    Apr 25 20:07:29.462: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.022760483s
    Apr 25 20:07:31.495: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.05512915s
    Apr 25 20:07:33.462: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.02261557s
    Apr 25 20:07:35.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.023767182s
    Apr 25 20:07:37.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.025102999s
    Apr 25 20:07:39.466: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.026791848s
    Apr 25 20:07:41.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.024232216s
    Apr 25 20:07:43.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.024035554s
    Apr 25 20:07:45.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.023969481s
    Apr 25 20:07:47.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.02430433s
    Apr 25 20:07:49.467: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.026989051s
    Apr 25 20:07:51.465: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.025472845s
    Apr 25 20:07:53.464: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.024867538s
    Apr 25 20:07:55.466: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.02617168s
    Apr 25 20:07:57.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.023904881s
    Apr 25 20:07:59.463: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.02377258s
    Apr 25 20:07:59.476: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.036571397s
    STEP: updating the pod 04/25/23 20:07:59.476
    Apr 25 20:08:00.008: INFO: Successfully updated pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146"
    STEP: waiting for pod running 04/25/23 20:08:00.008
    Apr 25 20:08:00.008: INFO: Waiting up to 2m0s for pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146" in namespace "var-expansion-3716" to be "running"
    Apr 25 20:08:00.019: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Pending", Reason="", readiness=false. Elapsed: 10.928444ms
    Apr 25 20:08:02.032: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146": Phase="Running", Reason="", readiness=true. Elapsed: 2.024278314s
    Apr 25 20:08:02.033: INFO: Pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146" satisfied condition "running"
    STEP: deleting the pod gracefully 04/25/23 20:08:02.033
    Apr 25 20:08:02.033: INFO: Deleting pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146" in namespace "var-expansion-3716"
    Apr 25 20:08:02.051: INFO: Wait up to 5m0s for pod "var-expansion-35e73b5b-74e9-4ba5-82b8-de78a1636146" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 25 20:08:34.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3716" for this suite. 04/25/23 20:08:34.122
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:08:34.144
Apr 25 20:08:34.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename sysctl 04/25/23 20:08:34.148
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:08:34.194
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:08:34.207
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 04/25/23 20:08:34.219
STEP: Watching for error events or started pod 04/25/23 20:08:34.261
STEP: Waiting for pod completion 04/25/23 20:08:36.274
Apr 25 20:08:36.274: INFO: Waiting up to 3m0s for pod "sysctl-d4fc2ecb-b7f5-4626-bbed-adcbacdbfe6e" in namespace "sysctl-3988" to be "completed"
Apr 25 20:08:36.285: INFO: Pod "sysctl-d4fc2ecb-b7f5-4626-bbed-adcbacdbfe6e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.992573ms
Apr 25 20:08:38.300: INFO: Pod "sysctl-d4fc2ecb-b7f5-4626-bbed-adcbacdbfe6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025229833s
Apr 25 20:08:38.300: INFO: Pod "sysctl-d4fc2ecb-b7f5-4626-bbed-adcbacdbfe6e" satisfied condition "completed"
STEP: Checking that the pod succeeded 04/25/23 20:08:38.311
STEP: Getting logs from the pod 04/25/23 20:08:38.311
STEP: Checking that the sysctl is actually updated 04/25/23 20:08:38.423
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 25 20:08:38.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-3988" for this suite. 04/25/23 20:08:38.471
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":121,"skipped":2198,"failed":0}
------------------------------
• [4.354 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:08:34.144
    Apr 25 20:08:34.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename sysctl 04/25/23 20:08:34.148
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:08:34.194
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:08:34.207
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 04/25/23 20:08:34.219
    STEP: Watching for error events or started pod 04/25/23 20:08:34.261
    STEP: Waiting for pod completion 04/25/23 20:08:36.274
    Apr 25 20:08:36.274: INFO: Waiting up to 3m0s for pod "sysctl-d4fc2ecb-b7f5-4626-bbed-adcbacdbfe6e" in namespace "sysctl-3988" to be "completed"
    Apr 25 20:08:36.285: INFO: Pod "sysctl-d4fc2ecb-b7f5-4626-bbed-adcbacdbfe6e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.992573ms
    Apr 25 20:08:38.300: INFO: Pod "sysctl-d4fc2ecb-b7f5-4626-bbed-adcbacdbfe6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025229833s
    Apr 25 20:08:38.300: INFO: Pod "sysctl-d4fc2ecb-b7f5-4626-bbed-adcbacdbfe6e" satisfied condition "completed"
    STEP: Checking that the pod succeeded 04/25/23 20:08:38.311
    STEP: Getting logs from the pod 04/25/23 20:08:38.311
    STEP: Checking that the sysctl is actually updated 04/25/23 20:08:38.423
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 25 20:08:38.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-3988" for this suite. 04/25/23 20:08:38.471
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:08:38.506
Apr 25 20:08:38.506: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 20:08:38.508
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:08:38.556
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:08:38.566
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 04/25/23 20:08:38.578
Apr 25 20:08:38.623: INFO: Waiting up to 5m0s for pod "annotationupdate8c30fb0f-460d-48cf-b9ec-31d6f08993b7" in namespace "downward-api-4777" to be "running and ready"
Apr 25 20:08:38.665: INFO: Pod "annotationupdate8c30fb0f-460d-48cf-b9ec-31d6f08993b7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.119389ms
Apr 25 20:08:38.666: INFO: The phase of Pod annotationupdate8c30fb0f-460d-48cf-b9ec-31d6f08993b7 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:08:40.684: INFO: Pod "annotationupdate8c30fb0f-460d-48cf-b9ec-31d6f08993b7": Phase="Running", Reason="", readiness=true. Elapsed: 2.060436282s
Apr 25 20:08:40.684: INFO: The phase of Pod annotationupdate8c30fb0f-460d-48cf-b9ec-31d6f08993b7 is Running (Ready = true)
Apr 25 20:08:40.684: INFO: Pod "annotationupdate8c30fb0f-460d-48cf-b9ec-31d6f08993b7" satisfied condition "running and ready"
Apr 25 20:08:41.331: INFO: Successfully updated pod "annotationupdate8c30fb0f-460d-48cf-b9ec-31d6f08993b7"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 25 20:08:45.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4777" for this suite. 04/25/23 20:08:45.464
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":122,"skipped":2207,"failed":0}
------------------------------
• [SLOW TEST] [6.978 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:08:38.506
    Apr 25 20:08:38.506: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 20:08:38.508
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:08:38.556
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:08:38.566
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 04/25/23 20:08:38.578
    Apr 25 20:08:38.623: INFO: Waiting up to 5m0s for pod "annotationupdate8c30fb0f-460d-48cf-b9ec-31d6f08993b7" in namespace "downward-api-4777" to be "running and ready"
    Apr 25 20:08:38.665: INFO: Pod "annotationupdate8c30fb0f-460d-48cf-b9ec-31d6f08993b7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.119389ms
    Apr 25 20:08:38.666: INFO: The phase of Pod annotationupdate8c30fb0f-460d-48cf-b9ec-31d6f08993b7 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:08:40.684: INFO: Pod "annotationupdate8c30fb0f-460d-48cf-b9ec-31d6f08993b7": Phase="Running", Reason="", readiness=true. Elapsed: 2.060436282s
    Apr 25 20:08:40.684: INFO: The phase of Pod annotationupdate8c30fb0f-460d-48cf-b9ec-31d6f08993b7 is Running (Ready = true)
    Apr 25 20:08:40.684: INFO: Pod "annotationupdate8c30fb0f-460d-48cf-b9ec-31d6f08993b7" satisfied condition "running and ready"
    Apr 25 20:08:41.331: INFO: Successfully updated pod "annotationupdate8c30fb0f-460d-48cf-b9ec-31d6f08993b7"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 25 20:08:45.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4777" for this suite. 04/25/23 20:08:45.464
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:08:45.487
Apr 25 20:08:45.487: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 20:08:45.488
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:08:45.531
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:08:45.541
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 04/25/23 20:08:45.552
Apr 25 20:08:45.574: INFO: Waiting up to 5m0s for pod "downward-api-f729c20a-ec7a-46c3-ba12-083676015764" in namespace "downward-api-5197" to be "Succeeded or Failed"
Apr 25 20:08:45.586: INFO: Pod "downward-api-f729c20a-ec7a-46c3-ba12-083676015764": Phase="Pending", Reason="", readiness=false. Elapsed: 11.868723ms
Apr 25 20:08:47.600: INFO: Pod "downward-api-f729c20a-ec7a-46c3-ba12-083676015764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026409998s
Apr 25 20:08:49.600: INFO: Pod "downward-api-f729c20a-ec7a-46c3-ba12-083676015764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026398158s
STEP: Saw pod success 04/25/23 20:08:49.6
Apr 25 20:08:49.601: INFO: Pod "downward-api-f729c20a-ec7a-46c3-ba12-083676015764" satisfied condition "Succeeded or Failed"
Apr 25 20:08:49.614: INFO: Trying to get logs from node 10.10.21.190 pod downward-api-f729c20a-ec7a-46c3-ba12-083676015764 container dapi-container: <nil>
STEP: delete the pod 04/25/23 20:08:49.649
Apr 25 20:08:49.715: INFO: Waiting for pod downward-api-f729c20a-ec7a-46c3-ba12-083676015764 to disappear
Apr 25 20:08:49.728: INFO: Pod downward-api-f729c20a-ec7a-46c3-ba12-083676015764 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 25 20:08:49.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5197" for this suite. 04/25/23 20:08:49.752
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":123,"skipped":2209,"failed":0}
------------------------------
• [4.287 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:08:45.487
    Apr 25 20:08:45.487: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 20:08:45.488
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:08:45.531
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:08:45.541
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 04/25/23 20:08:45.552
    Apr 25 20:08:45.574: INFO: Waiting up to 5m0s for pod "downward-api-f729c20a-ec7a-46c3-ba12-083676015764" in namespace "downward-api-5197" to be "Succeeded or Failed"
    Apr 25 20:08:45.586: INFO: Pod "downward-api-f729c20a-ec7a-46c3-ba12-083676015764": Phase="Pending", Reason="", readiness=false. Elapsed: 11.868723ms
    Apr 25 20:08:47.600: INFO: Pod "downward-api-f729c20a-ec7a-46c3-ba12-083676015764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026409998s
    Apr 25 20:08:49.600: INFO: Pod "downward-api-f729c20a-ec7a-46c3-ba12-083676015764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026398158s
    STEP: Saw pod success 04/25/23 20:08:49.6
    Apr 25 20:08:49.601: INFO: Pod "downward-api-f729c20a-ec7a-46c3-ba12-083676015764" satisfied condition "Succeeded or Failed"
    Apr 25 20:08:49.614: INFO: Trying to get logs from node 10.10.21.190 pod downward-api-f729c20a-ec7a-46c3-ba12-083676015764 container dapi-container: <nil>
    STEP: delete the pod 04/25/23 20:08:49.649
    Apr 25 20:08:49.715: INFO: Waiting for pod downward-api-f729c20a-ec7a-46c3-ba12-083676015764 to disappear
    Apr 25 20:08:49.728: INFO: Pod downward-api-f729c20a-ec7a-46c3-ba12-083676015764 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 25 20:08:49.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5197" for this suite. 04/25/23 20:08:49.752
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:08:49.787
Apr 25 20:08:49.787: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename gc 04/25/23 20:08:49.788
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:08:49.855
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:08:49.867
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 04/25/23 20:08:49.879
STEP: Wait for the Deployment to create new ReplicaSet 04/25/23 20:08:49.899
STEP: delete the deployment 04/25/23 20:08:50.426
STEP: wait for all rs to be garbage collected 04/25/23 20:08:50.444
STEP: expected 0 rs, got 1 rs 04/25/23 20:08:50.467
STEP: expected 0 pods, got 2 pods 04/25/23 20:08:50.481
STEP: Gathering metrics 04/25/23 20:08:51.042
W0425 20:08:51.119560      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 25 20:08:51.119: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 25 20:08:51.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1651" for this suite. 04/25/23 20:08:51.142
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":124,"skipped":2228,"failed":0}
------------------------------
• [1.375 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:08:49.787
    Apr 25 20:08:49.787: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename gc 04/25/23 20:08:49.788
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:08:49.855
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:08:49.867
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 04/25/23 20:08:49.879
    STEP: Wait for the Deployment to create new ReplicaSet 04/25/23 20:08:49.899
    STEP: delete the deployment 04/25/23 20:08:50.426
    STEP: wait for all rs to be garbage collected 04/25/23 20:08:50.444
    STEP: expected 0 rs, got 1 rs 04/25/23 20:08:50.467
    STEP: expected 0 pods, got 2 pods 04/25/23 20:08:50.481
    STEP: Gathering metrics 04/25/23 20:08:51.042
    W0425 20:08:51.119560      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 25 20:08:51.119: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 25 20:08:51.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1651" for this suite. 04/25/23 20:08:51.142
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:08:51.163
Apr 25 20:08:51.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubelet-test 04/25/23 20:08:51.166
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:08:51.212
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:08:51.224
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Apr 25 20:08:51.258: INFO: Waiting up to 5m0s for pod "busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd" in namespace "kubelet-test-6298" to be "running and ready"
Apr 25 20:08:51.270: INFO: Pod "busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd": Phase="Pending", Reason="", readiness=false. Elapsed: 11.537703ms
Apr 25 20:08:51.270: INFO: The phase of Pod busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:08:53.283: INFO: Pod "busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd": Phase="Running", Reason="", readiness=true. Elapsed: 2.024682783s
Apr 25 20:08:53.283: INFO: The phase of Pod busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd is Running (Ready = true)
Apr 25 20:08:53.284: INFO: Pod "busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 25 20:08:53.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6298" for this suite. 04/25/23 20:08:53.338
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":125,"skipped":2234,"failed":0}
------------------------------
• [2.275 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:08:51.163
    Apr 25 20:08:51.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubelet-test 04/25/23 20:08:51.166
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:08:51.212
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:08:51.224
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Apr 25 20:08:51.258: INFO: Waiting up to 5m0s for pod "busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd" in namespace "kubelet-test-6298" to be "running and ready"
    Apr 25 20:08:51.270: INFO: Pod "busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd": Phase="Pending", Reason="", readiness=false. Elapsed: 11.537703ms
    Apr 25 20:08:51.270: INFO: The phase of Pod busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:08:53.283: INFO: Pod "busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd": Phase="Running", Reason="", readiness=true. Elapsed: 2.024682783s
    Apr 25 20:08:53.283: INFO: The phase of Pod busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd is Running (Ready = true)
    Apr 25 20:08:53.284: INFO: Pod "busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 25 20:08:53.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-6298" for this suite. 04/25/23 20:08:53.338
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:08:53.456
Apr 25 20:08:53.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename sched-pred 04/25/23 20:08:53.458
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:08:53.529
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:08:53.543
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 25 20:08:53.554: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 25 20:08:53.589: INFO: Waiting for terminating namespaces to be deleted...
Apr 25 20:08:53.602: INFO: 
Logging pods the apiserver thinks is on node 10.10.21.136 before test
Apr 25 20:08:53.630: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-nzg9s from ibm-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.630: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
Apr 25 20:08:53.630: INFO: calico-node-q95vg from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.630: INFO: 	Container calico-node ready: true, restart count 0
Apr 25 20:08:53.630: INFO: calico-typha-677688fdc5-5f8fr from kube-system started at 2023-04-25 17:14:29 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.630: INFO: 	Container calico-typha ready: true, restart count 0
Apr 25 20:08:53.630: INFO: coredns-6754846f95-cn7xr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.630: INFO: 	Container coredns ready: true, restart count 0
Apr 25 20:08:53.630: INFO: coredns-6754846f95-dnk45 from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.630: INFO: 	Container coredns ready: true, restart count 0
Apr 25 20:08:53.630: INFO: ibm-keepalived-watcher-p87jk from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.630: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 25 20:08:53.630: INFO: ibm-master-proxy-static-10.10.21.136 from kube-system started at 2023-04-25 17:13:57 +0000 UTC (2 container statuses recorded)
Apr 25 20:08:53.630: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 25 20:08:53.630: INFO: 	Container pause ready: true, restart count 0
Apr 25 20:08:53.630: INFO: ibmcloud-block-storage-driver-fm7g7 from kube-system started at 2023-04-25 17:14:07 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.630: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Apr 25 20:08:53.630: INFO: konnectivity-agent-mv6tj from kube-system started at 2023-04-25 17:26:45 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.630: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 25 20:08:53.630: INFO: metrics-server-c785bfcff-b2n5l from kube-system started at 2023-04-25 18:05:55 +0000 UTC (3 container statuses recorded)
Apr 25 20:08:53.630: INFO: 	Container config-watcher ready: true, restart count 0
Apr 25 20:08:53.630: INFO: 	Container metrics-server ready: true, restart count 0
Apr 25 20:08:53.630: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr 25 20:08:53.630: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-p575r from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.630: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 25 20:08:53.630: INFO: sonobuoy from sonobuoy started at 2023-04-25 19:35:04 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.630: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 25 20:08:53.630: INFO: sonobuoy-e2e-job-38c24e91f58b4d35 from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 20:08:53.630: INFO: 	Container e2e ready: true, restart count 0
Apr 25 20:08:53.630: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 20:08:53.630: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-88nhh from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 20:08:53.630: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 20:08:53.630: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 25 20:08:53.630: INFO: 
Logging pods the apiserver thinks is on node 10.10.21.161 before test
Apr 25 20:08:53.662: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-g4ql4 from ibm-system started at 2023-04-25 17:18:17 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.662: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
Apr 25 20:08:53.662: INFO: calico-kube-controllers-5754dfd4dd-jfqrl from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.662: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 25 20:08:53.662: INFO: calico-node-mqpqg from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.662: INFO: 	Container calico-node ready: true, restart count 0
Apr 25 20:08:53.662: INFO: calico-typha-677688fdc5-bt4pk from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.662: INFO: 	Container calico-typha ready: true, restart count 0
Apr 25 20:08:53.662: INFO: coredns-6754846f95-8fzmk from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.663: INFO: 	Container coredns ready: true, restart count 0
Apr 25 20:08:53.663: INFO: coredns-autoscaler-669cf746f6-hnjbg from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.663: INFO: 	Container autoscaler ready: true, restart count 0
Apr 25 20:08:53.663: INFO: dashboard-metrics-scraper-c964d5594-wvstn from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.663: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 25 20:08:53.663: INFO: ibm-file-plugin-84d44c69b5-kz8hc from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.663: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Apr 25 20:08:53.663: INFO: ibm-keepalived-watcher-9dj6q from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.663: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 25 20:08:53.663: INFO: ibm-master-proxy-static-10.10.21.161 from kube-system started at 2023-04-25 17:13:31 +0000 UTC (2 container statuses recorded)
Apr 25 20:08:53.663: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 25 20:08:53.663: INFO: 	Container pause ready: true, restart count 0
Apr 25 20:08:53.663: INFO: ibm-storage-watcher-65957667f-vtkpm from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.663: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Apr 25 20:08:53.663: INFO: ibmcloud-block-storage-driver-wstqs from kube-system started at 2023-04-25 17:13:40 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.663: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Apr 25 20:08:53.663: INFO: ibmcloud-block-storage-plugin-6d48895c6b-bh5sb from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.663: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Apr 25 20:08:53.663: INFO: ingress-cluster-healthcheck-6f7f6b87df-nfchz from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.663: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Apr 25 20:08:53.663: INFO: konnectivity-agent-ghrrh from kube-system started at 2023-04-25 17:26:42 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.663: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 25 20:08:53.664: INFO: kubernetes-dashboard-55c4d56798-pm8jr from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.664: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 25 20:08:53.664: INFO: metrics-server-c785bfcff-jltfr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (3 container statuses recorded)
Apr 25 20:08:53.664: INFO: 	Container config-watcher ready: true, restart count 0
Apr 25 20:08:53.664: INFO: 	Container metrics-server ready: true, restart count 0
Apr 25 20:08:53.664: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr 25 20:08:53.664: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-bvz72 from kube-system started at 2023-04-25 17:18:07 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.664: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 25 20:08:53.664: INFO: snapshot-controller-c5c6dddff-2s9qq from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.664: INFO: 	Container snapshot-controller ready: true, restart count 0
Apr 25 20:08:53.664: INFO: snapshot-controller-c5c6dddff-55rkz from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.664: INFO: 	Container snapshot-controller ready: true, restart count 0
Apr 25 20:08:53.664: INFO: snapshot-controller-c5c6dddff-mxcw7 from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.664: INFO: 	Container snapshot-controller ready: true, restart count 0
Apr 25 20:08:53.664: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-w68zf from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 20:08:53.664: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 20:08:53.664: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 25 20:08:53.664: INFO: 
Logging pods the apiserver thinks is on node 10.10.21.190 before test
Apr 25 20:08:53.685: INFO: calico-node-4mqrc from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.685: INFO: 	Container calico-node ready: true, restart count 0
Apr 25 20:08:53.685: INFO: calico-typha-677688fdc5-hps7h from kube-system started at 2023-04-25 19:37:43 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.685: INFO: 	Container calico-typha ready: true, restart count 0
Apr 25 20:08:53.685: INFO: ibm-keepalived-watcher-r8lvr from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.685: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 25 20:08:53.685: INFO: ibm-master-proxy-static-10.10.21.190 from kube-system started at 2023-04-25 17:14:39 +0000 UTC (2 container statuses recorded)
Apr 25 20:08:53.685: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 25 20:08:53.685: INFO: 	Container pause ready: true, restart count 0
Apr 25 20:08:53.685: INFO: ibmcloud-block-storage-driver-gpzl6 from kube-system started at 2023-04-25 17:14:49 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.685: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Apr 25 20:08:53.685: INFO: konnectivity-agent-hkzc4 from kube-system started at 2023-04-25 17:26:39 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.685: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 25 20:08:53.685: INFO: busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd from kubelet-test-6298 started at 2023-04-25 20:08:51 +0000 UTC (1 container statuses recorded)
Apr 25 20:08:53.685: INFO: 	Container busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd ready: true, restart count 0
Apr 25 20:08:53.686: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-gq2qk from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 20:08:53.686: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 20:08:53.686: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node 10.10.21.136 04/25/23 20:08:53.742
STEP: verifying the node has the label node 10.10.21.161 04/25/23 20:08:53.783
STEP: verifying the node has the label node 10.10.21.190 04/25/23 20:08:53.817
Apr 25 20:08:53.854: INFO: Pod ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-g4ql4 requesting resource cpu=5m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-nzg9s requesting resource cpu=5m on Node 10.10.21.136
Apr 25 20:08:53.854: INFO: Pod calico-kube-controllers-5754dfd4dd-jfqrl requesting resource cpu=10m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod calico-node-4mqrc requesting resource cpu=250m on Node 10.10.21.190
Apr 25 20:08:53.854: INFO: Pod calico-node-mqpqg requesting resource cpu=250m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod calico-node-q95vg requesting resource cpu=250m on Node 10.10.21.136
Apr 25 20:08:53.854: INFO: Pod calico-typha-677688fdc5-5f8fr requesting resource cpu=250m on Node 10.10.21.136
Apr 25 20:08:53.854: INFO: Pod calico-typha-677688fdc5-bt4pk requesting resource cpu=250m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod calico-typha-677688fdc5-hps7h requesting resource cpu=250m on Node 10.10.21.190
Apr 25 20:08:53.854: INFO: Pod coredns-6754846f95-8fzmk requesting resource cpu=100m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod coredns-6754846f95-cn7xr requesting resource cpu=100m on Node 10.10.21.136
Apr 25 20:08:53.854: INFO: Pod coredns-6754846f95-dnk45 requesting resource cpu=100m on Node 10.10.21.136
Apr 25 20:08:53.854: INFO: Pod coredns-autoscaler-669cf746f6-hnjbg requesting resource cpu=1m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod dashboard-metrics-scraper-c964d5594-wvstn requesting resource cpu=1m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod ibm-file-plugin-84d44c69b5-kz8hc requesting resource cpu=50m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod ibm-keepalived-watcher-9dj6q requesting resource cpu=5m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod ibm-keepalived-watcher-p87jk requesting resource cpu=5m on Node 10.10.21.136
Apr 25 20:08:53.854: INFO: Pod ibm-keepalived-watcher-r8lvr requesting resource cpu=5m on Node 10.10.21.190
Apr 25 20:08:53.854: INFO: Pod ibm-master-proxy-static-10.10.21.136 requesting resource cpu=25m on Node 10.10.21.136
Apr 25 20:08:53.854: INFO: Pod ibm-master-proxy-static-10.10.21.161 requesting resource cpu=25m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod ibm-master-proxy-static-10.10.21.190 requesting resource cpu=25m on Node 10.10.21.190
Apr 25 20:08:53.854: INFO: Pod ibm-storage-watcher-65957667f-vtkpm requesting resource cpu=50m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod ibmcloud-block-storage-driver-fm7g7 requesting resource cpu=50m on Node 10.10.21.136
Apr 25 20:08:53.854: INFO: Pod ibmcloud-block-storage-driver-gpzl6 requesting resource cpu=50m on Node 10.10.21.190
Apr 25 20:08:53.854: INFO: Pod ibmcloud-block-storage-driver-wstqs requesting resource cpu=50m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod ibmcloud-block-storage-plugin-6d48895c6b-bh5sb requesting resource cpu=50m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod ingress-cluster-healthcheck-6f7f6b87df-nfchz requesting resource cpu=10m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod konnectivity-agent-ghrrh requesting resource cpu=10m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod konnectivity-agent-hkzc4 requesting resource cpu=10m on Node 10.10.21.190
Apr 25 20:08:53.854: INFO: Pod konnectivity-agent-mv6tj requesting resource cpu=10m on Node 10.10.21.136
Apr 25 20:08:53.854: INFO: Pod kubernetes-dashboard-55c4d56798-pm8jr requesting resource cpu=50m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod metrics-server-c785bfcff-b2n5l requesting resource cpu=126m on Node 10.10.21.136
Apr 25 20:08:53.854: INFO: Pod metrics-server-c785bfcff-jltfr requesting resource cpu=126m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-bvz72 requesting resource cpu=20m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-p575r requesting resource cpu=20m on Node 10.10.21.136
Apr 25 20:08:53.854: INFO: Pod snapshot-controller-c5c6dddff-2s9qq requesting resource cpu=10m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod snapshot-controller-c5c6dddff-55rkz requesting resource cpu=10m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod snapshot-controller-c5c6dddff-mxcw7 requesting resource cpu=10m on Node 10.10.21.161
Apr 25 20:08:53.854: INFO: Pod busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd requesting resource cpu=0m on Node 10.10.21.190
Apr 25 20:08:53.854: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.10.21.136
Apr 25 20:08:53.854: INFO: Pod sonobuoy-e2e-job-38c24e91f58b4d35 requesting resource cpu=0m on Node 10.10.21.136
Apr 25 20:08:53.854: INFO: Pod sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-88nhh requesting resource cpu=0m on Node 10.10.21.136
Apr 25 20:08:53.854: INFO: Pod sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-gq2qk requesting resource cpu=0m on Node 10.10.21.190
Apr 25 20:08:53.854: INFO: Pod sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-w68zf requesting resource cpu=0m on Node 10.10.21.161
STEP: Starting Pods to consume most of the cluster CPU. 04/25/23 20:08:53.854
Apr 25 20:08:53.855: INFO: Creating a pod which consumes cpu=2078m on Node 10.10.21.136
Apr 25 20:08:53.876: INFO: Creating a pod which consumes cpu=1971m on Node 10.10.21.161
Apr 25 20:08:53.891: INFO: Creating a pod which consumes cpu=2324m on Node 10.10.21.190
Apr 25 20:08:53.905: INFO: Waiting up to 5m0s for pod "filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a" in namespace "sched-pred-8486" to be "running"
Apr 25 20:08:53.921: INFO: Pod "filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a": Phase="Pending", Reason="", readiness=false. Elapsed: 15.937741ms
Apr 25 20:08:55.934: INFO: Pod "filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a": Phase="Running", Reason="", readiness=true. Elapsed: 2.029021163s
Apr 25 20:08:55.934: INFO: Pod "filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a" satisfied condition "running"
Apr 25 20:08:55.934: INFO: Waiting up to 5m0s for pod "filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979" in namespace "sched-pred-8486" to be "running"
Apr 25 20:08:55.947: INFO: Pod "filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979": Phase="Running", Reason="", readiness=true. Elapsed: 12.954465ms
Apr 25 20:08:55.947: INFO: Pod "filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979" satisfied condition "running"
Apr 25 20:08:55.948: INFO: Waiting up to 5m0s for pod "filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc" in namespace "sched-pred-8486" to be "running"
Apr 25 20:08:55.960: INFO: Pod "filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc": Phase="Pending", Reason="", readiness=false. Elapsed: 12.227232ms
Apr 25 20:08:57.974: INFO: Pod "filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc": Phase="Running", Reason="", readiness=true. Elapsed: 2.02587646s
Apr 25 20:08:57.974: INFO: Pod "filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 04/25/23 20:08:57.974
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979.17594664a620b095], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8486/filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979 to 10.10.21.161] 04/25/23 20:08:57.988
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979.17594664e0c2d6a4], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/25/23 20:08:57.988
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979.17594664e2cc89c6], Reason = [Created], Message = [Created container filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979] 04/25/23 20:08:57.989
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979.17594664eb942583], Reason = [Started], Message = [Started container filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979] 04/25/23 20:08:57.989
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc.17594664a755968e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8486/filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc to 10.10.21.190] 04/25/23 20:08:57.989
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc.17594664e2bc4776], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/25/23 20:08:57.989
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc.17594664e452df4b], Reason = [Created], Message = [Created container filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc] 04/25/23 20:08:57.989
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc.17594664ed439251], Reason = [Started], Message = [Started container filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc] 04/25/23 20:08:57.989
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a.17594664a5530327], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8486/filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a to 10.10.21.136] 04/25/23 20:08:57.99
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a.17594664dd8ec8ce], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/25/23 20:08:57.99
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a.17594664df715159], Reason = [Created], Message = [Created container filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a] 04/25/23 20:08:57.99
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a.17594664e6a5bb28], Reason = [Started], Message = [Started container filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a] 04/25/23 20:08:57.99
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.175946659b766f39], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 04/25/23 20:08:58.024
STEP: removing the label node off the node 10.10.21.136 04/25/23 20:08:59.034
STEP: verifying the node doesn't have the label node 04/25/23 20:08:59.069
STEP: removing the label node off the node 10.10.21.161 04/25/23 20:08:59.09
STEP: verifying the node doesn't have the label node 04/25/23 20:08:59.126
STEP: removing the label node off the node 10.10.21.190 04/25/23 20:08:59.143
STEP: verifying the node doesn't have the label node 04/25/23 20:08:59.18
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 25 20:08:59.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8486" for this suite. 04/25/23 20:08:59.215
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":126,"skipped":2262,"failed":0}
------------------------------
• [SLOW TEST] [5.775 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:08:53.456
    Apr 25 20:08:53.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename sched-pred 04/25/23 20:08:53.458
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:08:53.529
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:08:53.543
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 25 20:08:53.554: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 25 20:08:53.589: INFO: Waiting for terminating namespaces to be deleted...
    Apr 25 20:08:53.602: INFO: 
    Logging pods the apiserver thinks is on node 10.10.21.136 before test
    Apr 25 20:08:53.630: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-nzg9s from ibm-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.630: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: calico-node-q95vg from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.630: INFO: 	Container calico-node ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: calico-typha-677688fdc5-5f8fr from kube-system started at 2023-04-25 17:14:29 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.630: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: coredns-6754846f95-cn7xr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.630: INFO: 	Container coredns ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: coredns-6754846f95-dnk45 from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.630: INFO: 	Container coredns ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: ibm-keepalived-watcher-p87jk from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.630: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: ibm-master-proxy-static-10.10.21.136 from kube-system started at 2023-04-25 17:13:57 +0000 UTC (2 container statuses recorded)
    Apr 25 20:08:53.630: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: 	Container pause ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: ibmcloud-block-storage-driver-fm7g7 from kube-system started at 2023-04-25 17:14:07 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.630: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: konnectivity-agent-mv6tj from kube-system started at 2023-04-25 17:26:45 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.630: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: metrics-server-c785bfcff-b2n5l from kube-system started at 2023-04-25 18:05:55 +0000 UTC (3 container statuses recorded)
    Apr 25 20:08:53.630: INFO: 	Container config-watcher ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-p575r from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.630: INFO: 	Container nginx-ingress ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: sonobuoy from sonobuoy started at 2023-04-25 19:35:04 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.630: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: sonobuoy-e2e-job-38c24e91f58b4d35 from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 20:08:53.630: INFO: 	Container e2e ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-88nhh from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 20:08:53.630: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 25 20:08:53.630: INFO: 
    Logging pods the apiserver thinks is on node 10.10.21.161 before test
    Apr 25 20:08:53.662: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-g4ql4 from ibm-system started at 2023-04-25 17:18:17 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.662: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
    Apr 25 20:08:53.662: INFO: calico-kube-controllers-5754dfd4dd-jfqrl from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.662: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Apr 25 20:08:53.662: INFO: calico-node-mqpqg from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.662: INFO: 	Container calico-node ready: true, restart count 0
    Apr 25 20:08:53.662: INFO: calico-typha-677688fdc5-bt4pk from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.662: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 25 20:08:53.662: INFO: coredns-6754846f95-8fzmk from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.663: INFO: 	Container coredns ready: true, restart count 0
    Apr 25 20:08:53.663: INFO: coredns-autoscaler-669cf746f6-hnjbg from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.663: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 25 20:08:53.663: INFO: dashboard-metrics-scraper-c964d5594-wvstn from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.663: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Apr 25 20:08:53.663: INFO: ibm-file-plugin-84d44c69b5-kz8hc from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.663: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Apr 25 20:08:53.663: INFO: ibm-keepalived-watcher-9dj6q from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.663: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Apr 25 20:08:53.663: INFO: ibm-master-proxy-static-10.10.21.161 from kube-system started at 2023-04-25 17:13:31 +0000 UTC (2 container statuses recorded)
    Apr 25 20:08:53.663: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Apr 25 20:08:53.663: INFO: 	Container pause ready: true, restart count 0
    Apr 25 20:08:53.663: INFO: ibm-storage-watcher-65957667f-vtkpm from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.663: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Apr 25 20:08:53.663: INFO: ibmcloud-block-storage-driver-wstqs from kube-system started at 2023-04-25 17:13:40 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.663: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Apr 25 20:08:53.663: INFO: ibmcloud-block-storage-plugin-6d48895c6b-bh5sb from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.663: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Apr 25 20:08:53.663: INFO: ingress-cluster-healthcheck-6f7f6b87df-nfchz from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.663: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Apr 25 20:08:53.663: INFO: konnectivity-agent-ghrrh from kube-system started at 2023-04-25 17:26:42 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.663: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Apr 25 20:08:53.664: INFO: kubernetes-dashboard-55c4d56798-pm8jr from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.664: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Apr 25 20:08:53.664: INFO: metrics-server-c785bfcff-jltfr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (3 container statuses recorded)
    Apr 25 20:08:53.664: INFO: 	Container config-watcher ready: true, restart count 0
    Apr 25 20:08:53.664: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 25 20:08:53.664: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Apr 25 20:08:53.664: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-bvz72 from kube-system started at 2023-04-25 17:18:07 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.664: INFO: 	Container nginx-ingress ready: true, restart count 0
    Apr 25 20:08:53.664: INFO: snapshot-controller-c5c6dddff-2s9qq from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.664: INFO: 	Container snapshot-controller ready: true, restart count 0
    Apr 25 20:08:53.664: INFO: snapshot-controller-c5c6dddff-55rkz from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.664: INFO: 	Container snapshot-controller ready: true, restart count 0
    Apr 25 20:08:53.664: INFO: snapshot-controller-c5c6dddff-mxcw7 from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.664: INFO: 	Container snapshot-controller ready: true, restart count 0
    Apr 25 20:08:53.664: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-w68zf from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 20:08:53.664: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 20:08:53.664: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 25 20:08:53.664: INFO: 
    Logging pods the apiserver thinks is on node 10.10.21.190 before test
    Apr 25 20:08:53.685: INFO: calico-node-4mqrc from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.685: INFO: 	Container calico-node ready: true, restart count 0
    Apr 25 20:08:53.685: INFO: calico-typha-677688fdc5-hps7h from kube-system started at 2023-04-25 19:37:43 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.685: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 25 20:08:53.685: INFO: ibm-keepalived-watcher-r8lvr from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.685: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Apr 25 20:08:53.685: INFO: ibm-master-proxy-static-10.10.21.190 from kube-system started at 2023-04-25 17:14:39 +0000 UTC (2 container statuses recorded)
    Apr 25 20:08:53.685: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Apr 25 20:08:53.685: INFO: 	Container pause ready: true, restart count 0
    Apr 25 20:08:53.685: INFO: ibmcloud-block-storage-driver-gpzl6 from kube-system started at 2023-04-25 17:14:49 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.685: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Apr 25 20:08:53.685: INFO: konnectivity-agent-hkzc4 from kube-system started at 2023-04-25 17:26:39 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.685: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Apr 25 20:08:53.685: INFO: busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd from kubelet-test-6298 started at 2023-04-25 20:08:51 +0000 UTC (1 container statuses recorded)
    Apr 25 20:08:53.685: INFO: 	Container busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd ready: true, restart count 0
    Apr 25 20:08:53.686: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-gq2qk from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 20:08:53.686: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 20:08:53.686: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node 10.10.21.136 04/25/23 20:08:53.742
    STEP: verifying the node has the label node 10.10.21.161 04/25/23 20:08:53.783
    STEP: verifying the node has the label node 10.10.21.190 04/25/23 20:08:53.817
    Apr 25 20:08:53.854: INFO: Pod ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-g4ql4 requesting resource cpu=5m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-nzg9s requesting resource cpu=5m on Node 10.10.21.136
    Apr 25 20:08:53.854: INFO: Pod calico-kube-controllers-5754dfd4dd-jfqrl requesting resource cpu=10m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod calico-node-4mqrc requesting resource cpu=250m on Node 10.10.21.190
    Apr 25 20:08:53.854: INFO: Pod calico-node-mqpqg requesting resource cpu=250m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod calico-node-q95vg requesting resource cpu=250m on Node 10.10.21.136
    Apr 25 20:08:53.854: INFO: Pod calico-typha-677688fdc5-5f8fr requesting resource cpu=250m on Node 10.10.21.136
    Apr 25 20:08:53.854: INFO: Pod calico-typha-677688fdc5-bt4pk requesting resource cpu=250m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod calico-typha-677688fdc5-hps7h requesting resource cpu=250m on Node 10.10.21.190
    Apr 25 20:08:53.854: INFO: Pod coredns-6754846f95-8fzmk requesting resource cpu=100m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod coredns-6754846f95-cn7xr requesting resource cpu=100m on Node 10.10.21.136
    Apr 25 20:08:53.854: INFO: Pod coredns-6754846f95-dnk45 requesting resource cpu=100m on Node 10.10.21.136
    Apr 25 20:08:53.854: INFO: Pod coredns-autoscaler-669cf746f6-hnjbg requesting resource cpu=1m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod dashboard-metrics-scraper-c964d5594-wvstn requesting resource cpu=1m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod ibm-file-plugin-84d44c69b5-kz8hc requesting resource cpu=50m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod ibm-keepalived-watcher-9dj6q requesting resource cpu=5m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod ibm-keepalived-watcher-p87jk requesting resource cpu=5m on Node 10.10.21.136
    Apr 25 20:08:53.854: INFO: Pod ibm-keepalived-watcher-r8lvr requesting resource cpu=5m on Node 10.10.21.190
    Apr 25 20:08:53.854: INFO: Pod ibm-master-proxy-static-10.10.21.136 requesting resource cpu=25m on Node 10.10.21.136
    Apr 25 20:08:53.854: INFO: Pod ibm-master-proxy-static-10.10.21.161 requesting resource cpu=25m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod ibm-master-proxy-static-10.10.21.190 requesting resource cpu=25m on Node 10.10.21.190
    Apr 25 20:08:53.854: INFO: Pod ibm-storage-watcher-65957667f-vtkpm requesting resource cpu=50m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod ibmcloud-block-storage-driver-fm7g7 requesting resource cpu=50m on Node 10.10.21.136
    Apr 25 20:08:53.854: INFO: Pod ibmcloud-block-storage-driver-gpzl6 requesting resource cpu=50m on Node 10.10.21.190
    Apr 25 20:08:53.854: INFO: Pod ibmcloud-block-storage-driver-wstqs requesting resource cpu=50m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod ibmcloud-block-storage-plugin-6d48895c6b-bh5sb requesting resource cpu=50m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod ingress-cluster-healthcheck-6f7f6b87df-nfchz requesting resource cpu=10m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod konnectivity-agent-ghrrh requesting resource cpu=10m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod konnectivity-agent-hkzc4 requesting resource cpu=10m on Node 10.10.21.190
    Apr 25 20:08:53.854: INFO: Pod konnectivity-agent-mv6tj requesting resource cpu=10m on Node 10.10.21.136
    Apr 25 20:08:53.854: INFO: Pod kubernetes-dashboard-55c4d56798-pm8jr requesting resource cpu=50m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod metrics-server-c785bfcff-b2n5l requesting resource cpu=126m on Node 10.10.21.136
    Apr 25 20:08:53.854: INFO: Pod metrics-server-c785bfcff-jltfr requesting resource cpu=126m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-bvz72 requesting resource cpu=20m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-p575r requesting resource cpu=20m on Node 10.10.21.136
    Apr 25 20:08:53.854: INFO: Pod snapshot-controller-c5c6dddff-2s9qq requesting resource cpu=10m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod snapshot-controller-c5c6dddff-55rkz requesting resource cpu=10m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod snapshot-controller-c5c6dddff-mxcw7 requesting resource cpu=10m on Node 10.10.21.161
    Apr 25 20:08:53.854: INFO: Pod busybox-scheduling-fe488c7a-f964-46c4-ac8f-735feae641cd requesting resource cpu=0m on Node 10.10.21.190
    Apr 25 20:08:53.854: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.10.21.136
    Apr 25 20:08:53.854: INFO: Pod sonobuoy-e2e-job-38c24e91f58b4d35 requesting resource cpu=0m on Node 10.10.21.136
    Apr 25 20:08:53.854: INFO: Pod sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-88nhh requesting resource cpu=0m on Node 10.10.21.136
    Apr 25 20:08:53.854: INFO: Pod sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-gq2qk requesting resource cpu=0m on Node 10.10.21.190
    Apr 25 20:08:53.854: INFO: Pod sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-w68zf requesting resource cpu=0m on Node 10.10.21.161
    STEP: Starting Pods to consume most of the cluster CPU. 04/25/23 20:08:53.854
    Apr 25 20:08:53.855: INFO: Creating a pod which consumes cpu=2078m on Node 10.10.21.136
    Apr 25 20:08:53.876: INFO: Creating a pod which consumes cpu=1971m on Node 10.10.21.161
    Apr 25 20:08:53.891: INFO: Creating a pod which consumes cpu=2324m on Node 10.10.21.190
    Apr 25 20:08:53.905: INFO: Waiting up to 5m0s for pod "filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a" in namespace "sched-pred-8486" to be "running"
    Apr 25 20:08:53.921: INFO: Pod "filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a": Phase="Pending", Reason="", readiness=false. Elapsed: 15.937741ms
    Apr 25 20:08:55.934: INFO: Pod "filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a": Phase="Running", Reason="", readiness=true. Elapsed: 2.029021163s
    Apr 25 20:08:55.934: INFO: Pod "filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a" satisfied condition "running"
    Apr 25 20:08:55.934: INFO: Waiting up to 5m0s for pod "filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979" in namespace "sched-pred-8486" to be "running"
    Apr 25 20:08:55.947: INFO: Pod "filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979": Phase="Running", Reason="", readiness=true. Elapsed: 12.954465ms
    Apr 25 20:08:55.947: INFO: Pod "filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979" satisfied condition "running"
    Apr 25 20:08:55.948: INFO: Waiting up to 5m0s for pod "filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc" in namespace "sched-pred-8486" to be "running"
    Apr 25 20:08:55.960: INFO: Pod "filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc": Phase="Pending", Reason="", readiness=false. Elapsed: 12.227232ms
    Apr 25 20:08:57.974: INFO: Pod "filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc": Phase="Running", Reason="", readiness=true. Elapsed: 2.02587646s
    Apr 25 20:08:57.974: INFO: Pod "filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 04/25/23 20:08:57.974
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979.17594664a620b095], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8486/filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979 to 10.10.21.161] 04/25/23 20:08:57.988
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979.17594664e0c2d6a4], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/25/23 20:08:57.988
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979.17594664e2cc89c6], Reason = [Created], Message = [Created container filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979] 04/25/23 20:08:57.989
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979.17594664eb942583], Reason = [Started], Message = [Started container filler-pod-052388df-65cc-4caf-90e5-f3b9b746e979] 04/25/23 20:08:57.989
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc.17594664a755968e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8486/filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc to 10.10.21.190] 04/25/23 20:08:57.989
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc.17594664e2bc4776], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/25/23 20:08:57.989
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc.17594664e452df4b], Reason = [Created], Message = [Created container filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc] 04/25/23 20:08:57.989
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc.17594664ed439251], Reason = [Started], Message = [Started container filler-pod-c4ef403c-213f-419f-b2e3-7fa7fe9de6bc] 04/25/23 20:08:57.989
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a.17594664a5530327], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8486/filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a to 10.10.21.136] 04/25/23 20:08:57.99
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a.17594664dd8ec8ce], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/25/23 20:08:57.99
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a.17594664df715159], Reason = [Created], Message = [Created container filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a] 04/25/23 20:08:57.99
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a.17594664e6a5bb28], Reason = [Started], Message = [Started container filler-pod-e886cf7c-15f8-4d44-947c-defb5699b77a] 04/25/23 20:08:57.99
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.175946659b766f39], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 04/25/23 20:08:58.024
    STEP: removing the label node off the node 10.10.21.136 04/25/23 20:08:59.034
    STEP: verifying the node doesn't have the label node 04/25/23 20:08:59.069
    STEP: removing the label node off the node 10.10.21.161 04/25/23 20:08:59.09
    STEP: verifying the node doesn't have the label node 04/25/23 20:08:59.126
    STEP: removing the label node off the node 10.10.21.190 04/25/23 20:08:59.143
    STEP: verifying the node doesn't have the label node 04/25/23 20:08:59.18
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 20:08:59.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8486" for this suite. 04/25/23 20:08:59.215
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:08:59.232
Apr 25 20:08:59.233: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename deployment 04/25/23 20:08:59.236
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:08:59.287
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:08:59.297
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 04/25/23 20:08:59.331
Apr 25 20:08:59.331: INFO: Creating simple deployment test-deployment-9vpvt
Apr 25 20:08:59.373: INFO: deployment "test-deployment-9vpvt" doesn't have the required revision set
STEP: Getting /status 04/25/23 20:09:01.423
Apr 25 20:09:01.437: INFO: Deployment test-deployment-9vpvt has Conditions: [{Available True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:09:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9vpvt-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 04/25/23 20:09:01.437
Apr 25 20:09:01.464: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 9, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 9, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 9, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 8, 59, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-9vpvt-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 04/25/23 20:09:01.465
Apr 25 20:09:01.472: INFO: Observed &Deployment event: ADDED
Apr 25 20:09:01.472: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9vpvt-777898ffcc"}
Apr 25 20:09:01.473: INFO: Observed &Deployment event: MODIFIED
Apr 25 20:09:01.473: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9vpvt-777898ffcc"}
Apr 25 20:09:01.473: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 25 20:09:01.474: INFO: Observed &Deployment event: MODIFIED
Apr 25 20:09:01.474: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 25 20:09:01.474: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-9vpvt-777898ffcc" is progressing.}
Apr 25 20:09:01.475: INFO: Observed &Deployment event: MODIFIED
Apr 25 20:09:01.475: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:09:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 25 20:09:01.475: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9vpvt-777898ffcc" has successfully progressed.}
Apr 25 20:09:01.476: INFO: Observed &Deployment event: MODIFIED
Apr 25 20:09:01.476: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:09:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 25 20:09:01.476: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9vpvt-777898ffcc" has successfully progressed.}
Apr 25 20:09:01.476: INFO: Found Deployment test-deployment-9vpvt in namespace deployment-6761 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 25 20:09:01.476: INFO: Deployment test-deployment-9vpvt has an updated status
STEP: patching the Statefulset Status 04/25/23 20:09:01.476
Apr 25 20:09:01.477: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 25 20:09:01.500: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 04/25/23 20:09:01.5
Apr 25 20:09:01.507: INFO: Observed &Deployment event: ADDED
Apr 25 20:09:01.507: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9vpvt-777898ffcc"}
Apr 25 20:09:01.508: INFO: Observed &Deployment event: MODIFIED
Apr 25 20:09:01.508: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9vpvt-777898ffcc"}
Apr 25 20:09:01.508: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 25 20:09:01.508: INFO: Observed &Deployment event: MODIFIED
Apr 25 20:09:01.508: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 25 20:09:01.508: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-9vpvt-777898ffcc" is progressing.}
Apr 25 20:09:01.509: INFO: Observed &Deployment event: MODIFIED
Apr 25 20:09:01.509: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:09:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 25 20:09:01.509: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9vpvt-777898ffcc" has successfully progressed.}
Apr 25 20:09:01.510: INFO: Observed &Deployment event: MODIFIED
Apr 25 20:09:01.512: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:09:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 25 20:09:01.512: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9vpvt-777898ffcc" has successfully progressed.}
Apr 25 20:09:01.512: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 25 20:09:01.513: INFO: Observed &Deployment event: MODIFIED
Apr 25 20:09:01.513: INFO: Found deployment test-deployment-9vpvt in namespace deployment-6761 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Apr 25 20:09:01.514: INFO: Deployment test-deployment-9vpvt has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 25 20:09:01.525: INFO: Deployment "test-deployment-9vpvt":
&Deployment{ObjectMeta:{test-deployment-9vpvt  deployment-6761  41f5d7c6-a144-4bc6-b239-a1b6902902a6 30329 1 2023-04-25 20:08:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-25 20:08:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-04-25 20:09:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-04-25 20:09:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049b6f28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-9vpvt-777898ffcc",LastUpdateTime:2023-04-25 20:09:01 +0000 UTC,LastTransitionTime:2023-04-25 20:09:01 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 25 20:09:01.548: INFO: New ReplicaSet "test-deployment-9vpvt-777898ffcc" of Deployment "test-deployment-9vpvt":
&ReplicaSet{ObjectMeta:{test-deployment-9vpvt-777898ffcc  deployment-6761  e480a3be-ae5b-4028-aad7-ff8a443abbd3 30325 1 2023-04-25 20:08:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-9vpvt 41f5d7c6-a144-4bc6-b239-a1b6902902a6 0xc003b2d800 0xc003b2d801}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:08:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"41f5d7c6-a144-4bc6-b239-a1b6902902a6\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:09:01 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b2d9e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 25 20:09:01.562: INFO: Pod "test-deployment-9vpvt-777898ffcc-6zjxp" is available:
&Pod{ObjectMeta:{test-deployment-9vpvt-777898ffcc-6zjxp test-deployment-9vpvt-777898ffcc- deployment-6761  e0276c1d-7b79-4651-b46e-188ac166711e 30324 0 2023-04-25 20:08:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:64c633c309bf3eda4d43e611afb0797b696fd2685da7050461933b8cdc32409a cni.projectcalico.org/podIP:172.30.142.155/32 cni.projectcalico.org/podIPs:172.30.142.155/32] [{apps/v1 ReplicaSet test-deployment-9vpvt-777898ffcc e480a3be-ae5b-4028-aad7-ff8a443abbd3 0xc00529cfd0 0xc00529cfd1}] [] [{kube-controller-manager Update v1 2023-04-25 20:08:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e480a3be-ae5b-4028-aad7-ff8a443abbd3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:09:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:09:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.155\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4g59c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4g59c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:08:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:09:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:09:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:08:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.155,StartTime:2023-04-25 20:08:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:09:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e9c402e7fb78467709191e6efb58b6edcbc0fc88b222eaa12c9ee3fc2f73cbbe,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.155,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 25 20:09:01.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6761" for this suite. 04/25/23 20:09:01.583
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":127,"skipped":2265,"failed":0}
------------------------------
• [2.369 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:08:59.232
    Apr 25 20:08:59.233: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename deployment 04/25/23 20:08:59.236
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:08:59.287
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:08:59.297
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 04/25/23 20:08:59.331
    Apr 25 20:08:59.331: INFO: Creating simple deployment test-deployment-9vpvt
    Apr 25 20:08:59.373: INFO: deployment "test-deployment-9vpvt" doesn't have the required revision set
    STEP: Getting /status 04/25/23 20:09:01.423
    Apr 25 20:09:01.437: INFO: Deployment test-deployment-9vpvt has Conditions: [{Available True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:09:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9vpvt-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 04/25/23 20:09:01.437
    Apr 25 20:09:01.464: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 9, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 9, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 9, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 8, 59, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-9vpvt-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 04/25/23 20:09:01.465
    Apr 25 20:09:01.472: INFO: Observed &Deployment event: ADDED
    Apr 25 20:09:01.472: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9vpvt-777898ffcc"}
    Apr 25 20:09:01.473: INFO: Observed &Deployment event: MODIFIED
    Apr 25 20:09:01.473: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9vpvt-777898ffcc"}
    Apr 25 20:09:01.473: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 25 20:09:01.474: INFO: Observed &Deployment event: MODIFIED
    Apr 25 20:09:01.474: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 25 20:09:01.474: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-9vpvt-777898ffcc" is progressing.}
    Apr 25 20:09:01.475: INFO: Observed &Deployment event: MODIFIED
    Apr 25 20:09:01.475: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:09:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 25 20:09:01.475: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9vpvt-777898ffcc" has successfully progressed.}
    Apr 25 20:09:01.476: INFO: Observed &Deployment event: MODIFIED
    Apr 25 20:09:01.476: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:09:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 25 20:09:01.476: INFO: Observed Deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9vpvt-777898ffcc" has successfully progressed.}
    Apr 25 20:09:01.476: INFO: Found Deployment test-deployment-9vpvt in namespace deployment-6761 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 25 20:09:01.476: INFO: Deployment test-deployment-9vpvt has an updated status
    STEP: patching the Statefulset Status 04/25/23 20:09:01.476
    Apr 25 20:09:01.477: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 25 20:09:01.500: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 04/25/23 20:09:01.5
    Apr 25 20:09:01.507: INFO: Observed &Deployment event: ADDED
    Apr 25 20:09:01.507: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9vpvt-777898ffcc"}
    Apr 25 20:09:01.508: INFO: Observed &Deployment event: MODIFIED
    Apr 25 20:09:01.508: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9vpvt-777898ffcc"}
    Apr 25 20:09:01.508: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 25 20:09:01.508: INFO: Observed &Deployment event: MODIFIED
    Apr 25 20:09:01.508: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 25 20:09:01.508: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:08:59 +0000 UTC 2023-04-25 20:08:59 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-9vpvt-777898ffcc" is progressing.}
    Apr 25 20:09:01.509: INFO: Observed &Deployment event: MODIFIED
    Apr 25 20:09:01.509: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:09:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 25 20:09:01.509: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9vpvt-777898ffcc" has successfully progressed.}
    Apr 25 20:09:01.510: INFO: Observed &Deployment event: MODIFIED
    Apr 25 20:09:01.512: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:09:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 25 20:09:01.512: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-25 20:09:01 +0000 UTC 2023-04-25 20:08:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9vpvt-777898ffcc" has successfully progressed.}
    Apr 25 20:09:01.512: INFO: Observed deployment test-deployment-9vpvt in namespace deployment-6761 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 25 20:09:01.513: INFO: Observed &Deployment event: MODIFIED
    Apr 25 20:09:01.513: INFO: Found deployment test-deployment-9vpvt in namespace deployment-6761 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Apr 25 20:09:01.514: INFO: Deployment test-deployment-9vpvt has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 25 20:09:01.525: INFO: Deployment "test-deployment-9vpvt":
    &Deployment{ObjectMeta:{test-deployment-9vpvt  deployment-6761  41f5d7c6-a144-4bc6-b239-a1b6902902a6 30329 1 2023-04-25 20:08:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-25 20:08:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-04-25 20:09:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-04-25 20:09:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049b6f28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-9vpvt-777898ffcc",LastUpdateTime:2023-04-25 20:09:01 +0000 UTC,LastTransitionTime:2023-04-25 20:09:01 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 25 20:09:01.548: INFO: New ReplicaSet "test-deployment-9vpvt-777898ffcc" of Deployment "test-deployment-9vpvt":
    &ReplicaSet{ObjectMeta:{test-deployment-9vpvt-777898ffcc  deployment-6761  e480a3be-ae5b-4028-aad7-ff8a443abbd3 30325 1 2023-04-25 20:08:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-9vpvt 41f5d7c6-a144-4bc6-b239-a1b6902902a6 0xc003b2d800 0xc003b2d801}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:08:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"41f5d7c6-a144-4bc6-b239-a1b6902902a6\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:09:01 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b2d9e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 25 20:09:01.562: INFO: Pod "test-deployment-9vpvt-777898ffcc-6zjxp" is available:
    &Pod{ObjectMeta:{test-deployment-9vpvt-777898ffcc-6zjxp test-deployment-9vpvt-777898ffcc- deployment-6761  e0276c1d-7b79-4651-b46e-188ac166711e 30324 0 2023-04-25 20:08:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:64c633c309bf3eda4d43e611afb0797b696fd2685da7050461933b8cdc32409a cni.projectcalico.org/podIP:172.30.142.155/32 cni.projectcalico.org/podIPs:172.30.142.155/32] [{apps/v1 ReplicaSet test-deployment-9vpvt-777898ffcc e480a3be-ae5b-4028-aad7-ff8a443abbd3 0xc00529cfd0 0xc00529cfd1}] [] [{kube-controller-manager Update v1 2023-04-25 20:08:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e480a3be-ae5b-4028-aad7-ff8a443abbd3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:09:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:09:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.155\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4g59c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4g59c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:08:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:09:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:09:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:08:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.155,StartTime:2023-04-25 20:08:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:09:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e9c402e7fb78467709191e6efb58b6edcbc0fc88b222eaa12c9ee3fc2f73cbbe,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.155,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 25 20:09:01.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-6761" for this suite. 04/25/23 20:09:01.583
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:09:01.614
Apr 25 20:09:01.615: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename secrets 04/25/23 20:09:01.616
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:09:01.672
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:09:01.683
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-da39c131-85c2-463a-a70b-32991103bd62 04/25/23 20:09:01.696
STEP: Creating a pod to test consume secrets 04/25/23 20:09:01.709
Apr 25 20:09:01.734: INFO: Waiting up to 5m0s for pod "pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a" in namespace "secrets-8334" to be "Succeeded or Failed"
Apr 25 20:09:01.774: INFO: Pod "pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a": Phase="Pending", Reason="", readiness=false. Elapsed: 39.461008ms
Apr 25 20:09:03.789: INFO: Pod "pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054762387s
Apr 25 20:09:05.792: INFO: Pod "pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058208179s
STEP: Saw pod success 04/25/23 20:09:05.792
Apr 25 20:09:05.793: INFO: Pod "pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a" satisfied condition "Succeeded or Failed"
Apr 25 20:09:05.805: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a container secret-volume-test: <nil>
STEP: delete the pod 04/25/23 20:09:05.839
Apr 25 20:09:05.884: INFO: Waiting for pod pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a to disappear
Apr 25 20:09:05.897: INFO: Pod pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 25 20:09:05.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8334" for this suite. 04/25/23 20:09:05.916
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":128,"skipped":2274,"failed":0}
------------------------------
• [4.321 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:09:01.614
    Apr 25 20:09:01.615: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename secrets 04/25/23 20:09:01.616
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:09:01.672
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:09:01.683
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-da39c131-85c2-463a-a70b-32991103bd62 04/25/23 20:09:01.696
    STEP: Creating a pod to test consume secrets 04/25/23 20:09:01.709
    Apr 25 20:09:01.734: INFO: Waiting up to 5m0s for pod "pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a" in namespace "secrets-8334" to be "Succeeded or Failed"
    Apr 25 20:09:01.774: INFO: Pod "pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a": Phase="Pending", Reason="", readiness=false. Elapsed: 39.461008ms
    Apr 25 20:09:03.789: INFO: Pod "pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054762387s
    Apr 25 20:09:05.792: INFO: Pod "pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058208179s
    STEP: Saw pod success 04/25/23 20:09:05.792
    Apr 25 20:09:05.793: INFO: Pod "pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a" satisfied condition "Succeeded or Failed"
    Apr 25 20:09:05.805: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a container secret-volume-test: <nil>
    STEP: delete the pod 04/25/23 20:09:05.839
    Apr 25 20:09:05.884: INFO: Waiting for pod pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a to disappear
    Apr 25 20:09:05.897: INFO: Pod pod-secrets-e988bb91-ef2e-4300-81a1-4bd9588dec3a no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 25 20:09:05.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8334" for this suite. 04/25/23 20:09:05.916
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:09:05.936
Apr 25 20:09:05.938: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename configmap 04/25/23 20:09:05.94
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:09:05.985
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:09:05.997
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-1ad92e00-d445-4870-8dcd-10aac438ffff 04/25/23 20:09:06.01
STEP: Creating a pod to test consume configMaps 04/25/23 20:09:06.026
Apr 25 20:09:06.055: INFO: Waiting up to 5m0s for pod "pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae" in namespace "configmap-4893" to be "Succeeded or Failed"
Apr 25 20:09:06.067: INFO: Pod "pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae": Phase="Pending", Reason="", readiness=false. Elapsed: 11.355234ms
Apr 25 20:09:08.080: INFO: Pod "pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0243037s
Apr 25 20:09:10.080: INFO: Pod "pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024534394s
STEP: Saw pod success 04/25/23 20:09:10.08
Apr 25 20:09:10.080: INFO: Pod "pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae" satisfied condition "Succeeded or Failed"
Apr 25 20:09:10.094: INFO: Trying to get logs from node 10.10.21.161 pod pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae container agnhost-container: <nil>
STEP: delete the pod 04/25/23 20:09:10.186
Apr 25 20:09:10.229: INFO: Waiting for pod pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae to disappear
Apr 25 20:09:10.242: INFO: Pod pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 25 20:09:10.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4893" for this suite. 04/25/23 20:09:10.259
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":129,"skipped":2274,"failed":0}
------------------------------
• [4.343 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:09:05.936
    Apr 25 20:09:05.938: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename configmap 04/25/23 20:09:05.94
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:09:05.985
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:09:05.997
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-1ad92e00-d445-4870-8dcd-10aac438ffff 04/25/23 20:09:06.01
    STEP: Creating a pod to test consume configMaps 04/25/23 20:09:06.026
    Apr 25 20:09:06.055: INFO: Waiting up to 5m0s for pod "pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae" in namespace "configmap-4893" to be "Succeeded or Failed"
    Apr 25 20:09:06.067: INFO: Pod "pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae": Phase="Pending", Reason="", readiness=false. Elapsed: 11.355234ms
    Apr 25 20:09:08.080: INFO: Pod "pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0243037s
    Apr 25 20:09:10.080: INFO: Pod "pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024534394s
    STEP: Saw pod success 04/25/23 20:09:10.08
    Apr 25 20:09:10.080: INFO: Pod "pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae" satisfied condition "Succeeded or Failed"
    Apr 25 20:09:10.094: INFO: Trying to get logs from node 10.10.21.161 pod pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 20:09:10.186
    Apr 25 20:09:10.229: INFO: Waiting for pod pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae to disappear
    Apr 25 20:09:10.242: INFO: Pod pod-configmaps-35778566-50e3-4247-80d3-061ae7abadae no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 25 20:09:10.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4893" for this suite. 04/25/23 20:09:10.259
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:09:10.284
Apr 25 20:09:10.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename sched-preemption 04/25/23 20:09:10.287
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:09:10.327
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:09:10.342
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 25 20:09:10.417: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 25 20:10:10.539: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:10:10.552
Apr 25 20:10:10.553: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename sched-preemption-path 04/25/23 20:10:10.554
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:10:10.602
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:10:10.612
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Apr 25 20:10:10.684: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Apr 25 20:10:10.696: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Apr 25 20:10:10.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-2335" for this suite. 04/25/23 20:10:10.779
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 25 20:10:10.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-689" for this suite. 04/25/23 20:10:10.853
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":130,"skipped":2276,"failed":0}
------------------------------
• [SLOW TEST] [60.719 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:09:10.284
    Apr 25 20:09:10.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename sched-preemption 04/25/23 20:09:10.287
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:09:10.327
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:09:10.342
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 25 20:09:10.417: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 25 20:10:10.539: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:10:10.552
    Apr 25 20:10:10.553: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename sched-preemption-path 04/25/23 20:10:10.554
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:10:10.602
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:10:10.612
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Apr 25 20:10:10.684: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Apr 25 20:10:10.696: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Apr 25 20:10:10.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-2335" for this suite. 04/25/23 20:10:10.779
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 20:10:10.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-689" for this suite. 04/25/23 20:10:10.853
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:10:11.008
Apr 25 20:10:11.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename tables 04/25/23 20:10:11.01
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:10:11.058
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:10:11.068
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Apr 25 20:10:11.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9434" for this suite. 04/25/23 20:10:11.104
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":131,"skipped":2290,"failed":0}
------------------------------
• [0.115 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:10:11.008
    Apr 25 20:10:11.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename tables 04/25/23 20:10:11.01
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:10:11.058
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:10:11.068
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Apr 25 20:10:11.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-9434" for this suite. 04/25/23 20:10:11.104
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:10:11.129
Apr 25 20:10:11.130: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:10:11.133
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:10:11.194
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:10:11.204
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-7e4da965-0fff-43b5-b119-6533d9a71a3f 04/25/23 20:10:11.228
STEP: Creating configMap with name cm-test-opt-upd-d549d58c-036a-4065-a294-89131f556da5 04/25/23 20:10:11.24
STEP: Creating the pod 04/25/23 20:10:11.263
Apr 25 20:10:11.299: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c" in namespace "projected-2380" to be "running and ready"
Apr 25 20:10:11.341: INFO: Pod "pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c": Phase="Pending", Reason="", readiness=false. Elapsed: 41.721905ms
Apr 25 20:10:11.341: INFO: The phase of Pod pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:10:13.355: INFO: Pod "pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055742636s
Apr 25 20:10:13.355: INFO: The phase of Pod pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:10:15.354: INFO: Pod "pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c": Phase="Running", Reason="", readiness=true. Elapsed: 4.054787284s
Apr 25 20:10:15.354: INFO: The phase of Pod pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c is Running (Ready = true)
Apr 25 20:10:15.354: INFO: Pod "pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-7e4da965-0fff-43b5-b119-6533d9a71a3f 04/25/23 20:10:15.467
STEP: Updating configmap cm-test-opt-upd-d549d58c-036a-4065-a294-89131f556da5 04/25/23 20:10:15.487
STEP: Creating configMap with name cm-test-opt-create-5f31efd5-b620-4096-b9cd-b699b32b8ebc 04/25/23 20:10:15.501
STEP: waiting to observe update in volume 04/25/23 20:10:15.513
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 25 20:11:35.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2380" for this suite. 04/25/23 20:11:35.135
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":132,"skipped":2290,"failed":0}
------------------------------
• [SLOW TEST] [84.024 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:10:11.129
    Apr 25 20:10:11.130: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:10:11.133
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:10:11.194
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:10:11.204
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-7e4da965-0fff-43b5-b119-6533d9a71a3f 04/25/23 20:10:11.228
    STEP: Creating configMap with name cm-test-opt-upd-d549d58c-036a-4065-a294-89131f556da5 04/25/23 20:10:11.24
    STEP: Creating the pod 04/25/23 20:10:11.263
    Apr 25 20:10:11.299: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c" in namespace "projected-2380" to be "running and ready"
    Apr 25 20:10:11.341: INFO: Pod "pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c": Phase="Pending", Reason="", readiness=false. Elapsed: 41.721905ms
    Apr 25 20:10:11.341: INFO: The phase of Pod pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:10:13.355: INFO: Pod "pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055742636s
    Apr 25 20:10:13.355: INFO: The phase of Pod pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:10:15.354: INFO: Pod "pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c": Phase="Running", Reason="", readiness=true. Elapsed: 4.054787284s
    Apr 25 20:10:15.354: INFO: The phase of Pod pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c is Running (Ready = true)
    Apr 25 20:10:15.354: INFO: Pod "pod-projected-configmaps-aeed01ad-0a09-4681-b748-feafe1b24f4c" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-7e4da965-0fff-43b5-b119-6533d9a71a3f 04/25/23 20:10:15.467
    STEP: Updating configmap cm-test-opt-upd-d549d58c-036a-4065-a294-89131f556da5 04/25/23 20:10:15.487
    STEP: Creating configMap with name cm-test-opt-create-5f31efd5-b620-4096-b9cd-b699b32b8ebc 04/25/23 20:10:15.501
    STEP: waiting to observe update in volume 04/25/23 20:10:15.513
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 25 20:11:35.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2380" for this suite. 04/25/23 20:11:35.135
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:11:35.161
Apr 25 20:11:35.162: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-runtime 04/25/23 20:11:35.163
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:35.208
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:35.22
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 04/25/23 20:11:35.231
STEP: wait for the container to reach Succeeded 04/25/23 20:11:35.254
STEP: get the container status 04/25/23 20:11:39.327
STEP: the container should be terminated 04/25/23 20:11:39.339
STEP: the termination message should be set 04/25/23 20:11:39.339
Apr 25 20:11:39.340: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 04/25/23 20:11:39.34
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 25 20:11:39.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2281" for this suite. 04/25/23 20:11:39.406
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":133,"skipped":2306,"failed":0}
------------------------------
• [4.263 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:11:35.161
    Apr 25 20:11:35.162: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-runtime 04/25/23 20:11:35.163
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:35.208
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:35.22
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 04/25/23 20:11:35.231
    STEP: wait for the container to reach Succeeded 04/25/23 20:11:35.254
    STEP: get the container status 04/25/23 20:11:39.327
    STEP: the container should be terminated 04/25/23 20:11:39.339
    STEP: the termination message should be set 04/25/23 20:11:39.339
    Apr 25 20:11:39.340: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 04/25/23 20:11:39.34
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 25 20:11:39.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-2281" for this suite. 04/25/23 20:11:39.406
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:11:39.427
Apr 25 20:11:39.427: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename runtimeclass 04/25/23 20:11:39.428
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:39.495
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:39.505
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-3127-delete-me 04/25/23 20:11:39.528
STEP: Waiting for the RuntimeClass to disappear 04/25/23 20:11:39.55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 25 20:11:39.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-3127" for this suite. 04/25/23 20:11:39.593
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":134,"skipped":2316,"failed":0}
------------------------------
• [0.185 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:11:39.427
    Apr 25 20:11:39.427: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename runtimeclass 04/25/23 20:11:39.428
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:39.495
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:39.505
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-3127-delete-me 04/25/23 20:11:39.528
    STEP: Waiting for the RuntimeClass to disappear 04/25/23 20:11:39.55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 25 20:11:39.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-3127" for this suite. 04/25/23 20:11:39.593
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:11:39.617
Apr 25 20:11:39.617: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename events 04/25/23 20:11:39.621
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:39.666
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:39.676
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 04/25/23 20:11:39.688
STEP: listing all events in all namespaces 04/25/23 20:11:39.711
STEP: patching the test event 04/25/23 20:11:39.73
STEP: fetching the test event 04/25/23 20:11:39.753
STEP: updating the test event 04/25/23 20:11:39.769
STEP: getting the test event 04/25/23 20:11:39.832
STEP: deleting the test event 04/25/23 20:11:39.844
STEP: listing all events in all namespaces 04/25/23 20:11:39.875
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Apr 25 20:11:39.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9519" for this suite. 04/25/23 20:11:39.904
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":135,"skipped":2319,"failed":0}
------------------------------
• [0.305 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:11:39.617
    Apr 25 20:11:39.617: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename events 04/25/23 20:11:39.621
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:39.666
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:39.676
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 04/25/23 20:11:39.688
    STEP: listing all events in all namespaces 04/25/23 20:11:39.711
    STEP: patching the test event 04/25/23 20:11:39.73
    STEP: fetching the test event 04/25/23 20:11:39.753
    STEP: updating the test event 04/25/23 20:11:39.769
    STEP: getting the test event 04/25/23 20:11:39.832
    STEP: deleting the test event 04/25/23 20:11:39.844
    STEP: listing all events in all namespaces 04/25/23 20:11:39.875
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Apr 25 20:11:39.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-9519" for this suite. 04/25/23 20:11:39.904
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:11:39.928
Apr 25 20:11:39.929: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 04/25/23 20:11:39.931
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:39.976
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:39.986
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 04/25/23 20:11:39.997
STEP: Creating hostNetwork=false pod 04/25/23 20:11:39.998
Apr 25 20:11:40.021: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-5614" to be "running and ready"
Apr 25 20:11:40.035: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.512064ms
Apr 25 20:11:40.035: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:11:42.056: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.03481305s
Apr 25 20:11:42.056: INFO: The phase of Pod test-pod is Running (Ready = true)
Apr 25 20:11:42.056: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 04/25/23 20:11:42.069
Apr 25 20:11:42.087: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-5614" to be "running and ready"
Apr 25 20:11:42.101: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.768419ms
Apr 25 20:11:42.101: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:11:44.115: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.027553314s
Apr 25 20:11:44.115: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Apr 25 20:11:44.115: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 04/25/23 20:11:44.127
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 04/25/23 20:11:44.127
Apr 25 20:11:44.128: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:11:44.128: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:11:44.130: INFO: ExecWithOptions: Clientset creation
Apr 25 20:11:44.130: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 25 20:11:44.355: INFO: Exec stderr: ""
Apr 25 20:11:44.355: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:11:44.355: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:11:44.357: INFO: ExecWithOptions: Clientset creation
Apr 25 20:11:44.357: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 25 20:11:44.607: INFO: Exec stderr: ""
Apr 25 20:11:44.607: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:11:44.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:11:44.609: INFO: ExecWithOptions: Clientset creation
Apr 25 20:11:44.609: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 25 20:11:44.826: INFO: Exec stderr: ""
Apr 25 20:11:44.827: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:11:44.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:11:44.830: INFO: ExecWithOptions: Clientset creation
Apr 25 20:11:44.830: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 25 20:11:45.045: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 04/25/23 20:11:45.046
Apr 25 20:11:45.047: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:11:45.047: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:11:45.050: INFO: ExecWithOptions: Clientset creation
Apr 25 20:11:45.050: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Apr 25 20:11:45.239: INFO: Exec stderr: ""
Apr 25 20:11:45.239: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:11:45.239: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:11:45.242: INFO: ExecWithOptions: Clientset creation
Apr 25 20:11:45.242: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Apr 25 20:11:45.456: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 04/25/23 20:11:45.456
Apr 25 20:11:45.457: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:11:45.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:11:45.459: INFO: ExecWithOptions: Clientset creation
Apr 25 20:11:45.459: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 25 20:11:45.655: INFO: Exec stderr: ""
Apr 25 20:11:45.655: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:11:45.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:11:45.656: INFO: ExecWithOptions: Clientset creation
Apr 25 20:11:45.656: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 25 20:11:45.887: INFO: Exec stderr: ""
Apr 25 20:11:45.887: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:11:45.887: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:11:45.889: INFO: ExecWithOptions: Clientset creation
Apr 25 20:11:45.889: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 25 20:11:46.107: INFO: Exec stderr: ""
Apr 25 20:11:46.107: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:11:46.107: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:11:46.110: INFO: ExecWithOptions: Clientset creation
Apr 25 20:11:46.110: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 25 20:11:46.321: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Apr 25 20:11:46.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5614" for this suite. 04/25/23 20:11:46.342
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":136,"skipped":2331,"failed":0}
------------------------------
• [SLOW TEST] [6.437 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:11:39.928
    Apr 25 20:11:39.929: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 04/25/23 20:11:39.931
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:39.976
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:39.986
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 04/25/23 20:11:39.997
    STEP: Creating hostNetwork=false pod 04/25/23 20:11:39.998
    Apr 25 20:11:40.021: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-5614" to be "running and ready"
    Apr 25 20:11:40.035: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.512064ms
    Apr 25 20:11:40.035: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:11:42.056: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.03481305s
    Apr 25 20:11:42.056: INFO: The phase of Pod test-pod is Running (Ready = true)
    Apr 25 20:11:42.056: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 04/25/23 20:11:42.069
    Apr 25 20:11:42.087: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-5614" to be "running and ready"
    Apr 25 20:11:42.101: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.768419ms
    Apr 25 20:11:42.101: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:11:44.115: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.027553314s
    Apr 25 20:11:44.115: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Apr 25 20:11:44.115: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 04/25/23 20:11:44.127
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 04/25/23 20:11:44.127
    Apr 25 20:11:44.128: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:11:44.128: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:11:44.130: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:11:44.130: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 25 20:11:44.355: INFO: Exec stderr: ""
    Apr 25 20:11:44.355: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:11:44.355: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:11:44.357: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:11:44.357: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 25 20:11:44.607: INFO: Exec stderr: ""
    Apr 25 20:11:44.607: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:11:44.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:11:44.609: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:11:44.609: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 25 20:11:44.826: INFO: Exec stderr: ""
    Apr 25 20:11:44.827: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:11:44.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:11:44.830: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:11:44.830: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 25 20:11:45.045: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 04/25/23 20:11:45.046
    Apr 25 20:11:45.047: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:11:45.047: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:11:45.050: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:11:45.050: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Apr 25 20:11:45.239: INFO: Exec stderr: ""
    Apr 25 20:11:45.239: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:11:45.239: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:11:45.242: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:11:45.242: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Apr 25 20:11:45.456: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 04/25/23 20:11:45.456
    Apr 25 20:11:45.457: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:11:45.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:11:45.459: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:11:45.459: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 25 20:11:45.655: INFO: Exec stderr: ""
    Apr 25 20:11:45.655: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:11:45.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:11:45.656: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:11:45.656: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 25 20:11:45.887: INFO: Exec stderr: ""
    Apr 25 20:11:45.887: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:11:45.887: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:11:45.889: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:11:45.889: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 25 20:11:46.107: INFO: Exec stderr: ""
    Apr 25 20:11:46.107: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5614 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:11:46.107: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:11:46.110: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:11:46.110: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5614/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 25 20:11:46.321: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Apr 25 20:11:46.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-5614" for this suite. 04/25/23 20:11:46.342
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:11:46.378
Apr 25 20:11:46.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 20:11:46.38
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:46.443
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:46.452
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 20:11:46.502
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:11:46.958
STEP: Deploying the webhook pod 04/25/23 20:11:47.008
STEP: Wait for the deployment to be ready 04/25/23 20:11:47.037
Apr 25 20:11:47.066: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/25/23 20:11:49.104
STEP: Verifying the service has paired with the endpoint 04/25/23 20:11:49.135
Apr 25 20:11:50.136: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 04/25/23 20:11:50.15
STEP: Creating a configMap that does not comply to the validation webhook rules 04/25/23 20:11:50.249
STEP: Updating a validating webhook configuration's rules to not include the create operation 04/25/23 20:11:50.331
STEP: Creating a configMap that does not comply to the validation webhook rules 04/25/23 20:11:50.357
STEP: Patching a validating webhook configuration's rules to include the create operation 04/25/23 20:11:50.388
STEP: Creating a configMap that does not comply to the validation webhook rules 04/25/23 20:11:50.411
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:11:50.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3521" for this suite. 04/25/23 20:11:50.46
STEP: Destroying namespace "webhook-3521-markers" for this suite. 04/25/23 20:11:50.478
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":137,"skipped":2383,"failed":0}
------------------------------
• [4.259 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:11:46.378
    Apr 25 20:11:46.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 20:11:46.38
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:46.443
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:46.452
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 20:11:46.502
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:11:46.958
    STEP: Deploying the webhook pod 04/25/23 20:11:47.008
    STEP: Wait for the deployment to be ready 04/25/23 20:11:47.037
    Apr 25 20:11:47.066: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/25/23 20:11:49.104
    STEP: Verifying the service has paired with the endpoint 04/25/23 20:11:49.135
    Apr 25 20:11:50.136: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 04/25/23 20:11:50.15
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/25/23 20:11:50.249
    STEP: Updating a validating webhook configuration's rules to not include the create operation 04/25/23 20:11:50.331
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/25/23 20:11:50.357
    STEP: Patching a validating webhook configuration's rules to include the create operation 04/25/23 20:11:50.388
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/25/23 20:11:50.411
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:11:50.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3521" for this suite. 04/25/23 20:11:50.46
    STEP: Destroying namespace "webhook-3521-markers" for this suite. 04/25/23 20:11:50.478
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:11:50.639
Apr 25 20:11:50.639: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 20:11:50.643
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:50.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:50.77
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 04/25/23 20:11:50.782
Apr 25 20:11:50.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-1888 cluster-info'
Apr 25 20:11:50.913: INFO: stderr: ""
Apr 25 20:11:50.913: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 20:11:50.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1888" for this suite. 04/25/23 20:11:50.93
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":138,"skipped":2383,"failed":0}
------------------------------
• [0.311 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:11:50.639
    Apr 25 20:11:50.639: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 20:11:50.643
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:50.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:50.77
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 04/25/23 20:11:50.782
    Apr 25 20:11:50.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-1888 cluster-info'
    Apr 25 20:11:50.913: INFO: stderr: ""
    Apr 25 20:11:50.913: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 20:11:50.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1888" for this suite. 04/25/23 20:11:50.93
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:11:50.959
Apr 25 20:11:50.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 20:11:50.962
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:51.03
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:51.041
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 04/25/23 20:11:51.053
Apr 25 20:11:51.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-6863 create -f -'
Apr 25 20:11:51.428: INFO: stderr: ""
Apr 25 20:11:51.428: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/25/23 20:11:51.428
Apr 25 20:11:52.450: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 25 20:11:52.450: INFO: Found 0 / 1
Apr 25 20:11:53.444: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 25 20:11:53.444: INFO: Found 1 / 1
Apr 25 20:11:53.444: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 04/25/23 20:11:53.444
Apr 25 20:11:53.457: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 25 20:11:53.457: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 25 20:11:53.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-6863 patch pod agnhost-primary-zrvcs -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 25 20:11:53.632: INFO: stderr: ""
Apr 25 20:11:53.632: INFO: stdout: "pod/agnhost-primary-zrvcs patched\n"
STEP: checking annotations 04/25/23 20:11:53.632
Apr 25 20:11:53.647: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 25 20:11:53.647: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 20:11:53.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6863" for this suite. 04/25/23 20:11:53.678
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":139,"skipped":2429,"failed":0}
------------------------------
• [2.748 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:11:50.959
    Apr 25 20:11:50.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 20:11:50.962
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:51.03
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:51.041
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 04/25/23 20:11:51.053
    Apr 25 20:11:51.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-6863 create -f -'
    Apr 25 20:11:51.428: INFO: stderr: ""
    Apr 25 20:11:51.428: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/25/23 20:11:51.428
    Apr 25 20:11:52.450: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 25 20:11:52.450: INFO: Found 0 / 1
    Apr 25 20:11:53.444: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 25 20:11:53.444: INFO: Found 1 / 1
    Apr 25 20:11:53.444: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 04/25/23 20:11:53.444
    Apr 25 20:11:53.457: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 25 20:11:53.457: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 25 20:11:53.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-6863 patch pod agnhost-primary-zrvcs -p {"metadata":{"annotations":{"x":"y"}}}'
    Apr 25 20:11:53.632: INFO: stderr: ""
    Apr 25 20:11:53.632: INFO: stdout: "pod/agnhost-primary-zrvcs patched\n"
    STEP: checking annotations 04/25/23 20:11:53.632
    Apr 25 20:11:53.647: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 25 20:11:53.647: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 20:11:53.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6863" for this suite. 04/25/23 20:11:53.678
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:11:53.711
Apr 25 20:11:53.712: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename csistoragecapacity 04/25/23 20:11:53.715
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:53.759
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:53.768
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 04/25/23 20:11:53.78
STEP: getting /apis/storage.k8s.io 04/25/23 20:11:53.789
STEP: getting /apis/storage.k8s.io/v1 04/25/23 20:11:53.794
STEP: creating 04/25/23 20:11:53.799
STEP: watching 04/25/23 20:11:53.845
Apr 25 20:11:53.845: INFO: starting watch
STEP: getting 04/25/23 20:11:53.866
STEP: listing in namespace 04/25/23 20:11:53.879
STEP: listing across namespaces 04/25/23 20:11:53.891
STEP: patching 04/25/23 20:11:53.902
STEP: updating 04/25/23 20:11:53.916
Apr 25 20:11:53.929: INFO: waiting for watch events with expected annotations in namespace
Apr 25 20:11:53.929: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 04/25/23 20:11:53.93
STEP: deleting a collection 04/25/23 20:11:53.973
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Apr 25 20:11:54.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-5248" for this suite. 04/25/23 20:11:54.069
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":140,"skipped":2436,"failed":0}
------------------------------
• [0.380 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:11:53.711
    Apr 25 20:11:53.712: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename csistoragecapacity 04/25/23 20:11:53.715
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:53.759
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:53.768
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 04/25/23 20:11:53.78
    STEP: getting /apis/storage.k8s.io 04/25/23 20:11:53.789
    STEP: getting /apis/storage.k8s.io/v1 04/25/23 20:11:53.794
    STEP: creating 04/25/23 20:11:53.799
    STEP: watching 04/25/23 20:11:53.845
    Apr 25 20:11:53.845: INFO: starting watch
    STEP: getting 04/25/23 20:11:53.866
    STEP: listing in namespace 04/25/23 20:11:53.879
    STEP: listing across namespaces 04/25/23 20:11:53.891
    STEP: patching 04/25/23 20:11:53.902
    STEP: updating 04/25/23 20:11:53.916
    Apr 25 20:11:53.929: INFO: waiting for watch events with expected annotations in namespace
    Apr 25 20:11:53.929: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 04/25/23 20:11:53.93
    STEP: deleting a collection 04/25/23 20:11:53.973
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Apr 25 20:11:54.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-5248" for this suite. 04/25/23 20:11:54.069
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:11:54.098
Apr 25 20:11:54.098: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-probe 04/25/23 20:11:54.101
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:54.148
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:54.16
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c in namespace container-probe-8593 04/25/23 20:11:54.171
Apr 25 20:11:54.193: INFO: Waiting up to 5m0s for pod "busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c" in namespace "container-probe-8593" to be "not pending"
Apr 25 20:11:54.210: INFO: Pod "busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.857195ms
Apr 25 20:11:56.225: INFO: Pod "busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c": Phase="Running", Reason="", readiness=true. Elapsed: 2.030993688s
Apr 25 20:11:56.225: INFO: Pod "busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c" satisfied condition "not pending"
Apr 25 20:11:56.225: INFO: Started pod busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c in namespace container-probe-8593
STEP: checking the pod's current state and verifying that restartCount is present 04/25/23 20:11:56.225
Apr 25 20:11:56.238: INFO: Initial restart count of pod busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c is 0
Apr 25 20:12:46.704: INFO: Restart count of pod container-probe-8593/busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c is now 1 (50.466022293s elapsed)
STEP: deleting the pod 04/25/23 20:12:46.704
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 25 20:12:46.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8593" for this suite. 04/25/23 20:12:46.764
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":141,"skipped":2462,"failed":0}
------------------------------
• [SLOW TEST] [52.685 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:11:54.098
    Apr 25 20:11:54.098: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-probe 04/25/23 20:11:54.101
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:11:54.148
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:11:54.16
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c in namespace container-probe-8593 04/25/23 20:11:54.171
    Apr 25 20:11:54.193: INFO: Waiting up to 5m0s for pod "busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c" in namespace "container-probe-8593" to be "not pending"
    Apr 25 20:11:54.210: INFO: Pod "busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.857195ms
    Apr 25 20:11:56.225: INFO: Pod "busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c": Phase="Running", Reason="", readiness=true. Elapsed: 2.030993688s
    Apr 25 20:11:56.225: INFO: Pod "busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c" satisfied condition "not pending"
    Apr 25 20:11:56.225: INFO: Started pod busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c in namespace container-probe-8593
    STEP: checking the pod's current state and verifying that restartCount is present 04/25/23 20:11:56.225
    Apr 25 20:11:56.238: INFO: Initial restart count of pod busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c is 0
    Apr 25 20:12:46.704: INFO: Restart count of pod container-probe-8593/busybox-40f3bc8b-5db5-429f-9c3c-ab8f72f3a89c is now 1 (50.466022293s elapsed)
    STEP: deleting the pod 04/25/23 20:12:46.704
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 25 20:12:46.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8593" for this suite. 04/25/23 20:12:46.764
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:12:46.791
Apr 25 20:12:46.791: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 20:12:46.793
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:12:46.857
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:12:46.869
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 20:12:46.92
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:12:47.303
STEP: Deploying the webhook pod 04/25/23 20:12:47.327
STEP: Wait for the deployment to be ready 04/25/23 20:12:47.36
Apr 25 20:12:47.385: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/25/23 20:12:49.421
STEP: Verifying the service has paired with the endpoint 04/25/23 20:12:49.464
Apr 25 20:12:50.466: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 04/25/23 20:12:50.643
STEP: Creating a configMap that should be mutated 04/25/23 20:12:50.725
STEP: Deleting the collection of validation webhooks 04/25/23 20:12:50.886
STEP: Creating a configMap that should not be mutated 04/25/23 20:12:51.064
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:12:51.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8564" for this suite. 04/25/23 20:12:51.109
STEP: Destroying namespace "webhook-8564-markers" for this suite. 04/25/23 20:12:51.127
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":142,"skipped":2465,"failed":0}
------------------------------
• [4.481 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:12:46.791
    Apr 25 20:12:46.791: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 20:12:46.793
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:12:46.857
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:12:46.869
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 20:12:46.92
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:12:47.303
    STEP: Deploying the webhook pod 04/25/23 20:12:47.327
    STEP: Wait for the deployment to be ready 04/25/23 20:12:47.36
    Apr 25 20:12:47.385: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/25/23 20:12:49.421
    STEP: Verifying the service has paired with the endpoint 04/25/23 20:12:49.464
    Apr 25 20:12:50.466: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 04/25/23 20:12:50.643
    STEP: Creating a configMap that should be mutated 04/25/23 20:12:50.725
    STEP: Deleting the collection of validation webhooks 04/25/23 20:12:50.886
    STEP: Creating a configMap that should not be mutated 04/25/23 20:12:51.064
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:12:51.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8564" for this suite. 04/25/23 20:12:51.109
    STEP: Destroying namespace "webhook-8564-markers" for this suite. 04/25/23 20:12:51.127
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:12:51.286
Apr 25 20:12:51.286: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-lifecycle-hook 04/25/23 20:12:51.288
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:12:51.349
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:12:51.361
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/25/23 20:12:51.395
Apr 25 20:12:51.418: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9419" to be "running and ready"
Apr 25 20:12:51.432: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 13.857412ms
Apr 25 20:12:51.432: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:12:53.447: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.028797589s
Apr 25 20:12:53.447: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 25 20:12:53.447: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 04/25/23 20:12:53.459
Apr 25 20:12:53.474: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-9419" to be "running and ready"
Apr 25 20:12:53.487: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 12.233181ms
Apr 25 20:12:53.487: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:12:55.500: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.025128869s
Apr 25 20:12:55.500: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Apr 25 20:12:55.500: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 04/25/23 20:12:55.513
Apr 25 20:12:55.536: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 25 20:12:55.550: INFO: Pod pod-with-prestop-http-hook still exists
Apr 25 20:12:57.551: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 25 20:12:57.564: INFO: Pod pod-with-prestop-http-hook still exists
Apr 25 20:12:59.550: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 25 20:12:59.564: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 04/25/23 20:12:59.564
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 25 20:12:59.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9419" for this suite. 04/25/23 20:12:59.612
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":143,"skipped":2469,"failed":0}
------------------------------
• [SLOW TEST] [8.346 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:12:51.286
    Apr 25 20:12:51.286: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/25/23 20:12:51.288
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:12:51.349
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:12:51.361
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/25/23 20:12:51.395
    Apr 25 20:12:51.418: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9419" to be "running and ready"
    Apr 25 20:12:51.432: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 13.857412ms
    Apr 25 20:12:51.432: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:12:53.447: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.028797589s
    Apr 25 20:12:53.447: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 25 20:12:53.447: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 04/25/23 20:12:53.459
    Apr 25 20:12:53.474: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-9419" to be "running and ready"
    Apr 25 20:12:53.487: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 12.233181ms
    Apr 25 20:12:53.487: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:12:55.500: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.025128869s
    Apr 25 20:12:55.500: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Apr 25 20:12:55.500: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 04/25/23 20:12:55.513
    Apr 25 20:12:55.536: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 25 20:12:55.550: INFO: Pod pod-with-prestop-http-hook still exists
    Apr 25 20:12:57.551: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 25 20:12:57.564: INFO: Pod pod-with-prestop-http-hook still exists
    Apr 25 20:12:59.550: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 25 20:12:59.564: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 04/25/23 20:12:59.564
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 25 20:12:59.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-9419" for this suite. 04/25/23 20:12:59.612
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:12:59.639
Apr 25 20:12:59.640: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename security-context 04/25/23 20:12:59.643
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:12:59.689
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:12:59.702
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/25/23 20:12:59.712
Apr 25 20:12:59.734: INFO: Waiting up to 5m0s for pod "security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810" in namespace "security-context-8067" to be "Succeeded or Failed"
Apr 25 20:12:59.748: INFO: Pod "security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810": Phase="Pending", Reason="", readiness=false. Elapsed: 13.018925ms
Apr 25 20:13:01.761: INFO: Pod "security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02653357s
Apr 25 20:13:03.762: INFO: Pod "security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027343959s
STEP: Saw pod success 04/25/23 20:13:03.762
Apr 25 20:13:03.762: INFO: Pod "security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810" satisfied condition "Succeeded or Failed"
Apr 25 20:13:03.774: INFO: Trying to get logs from node 10.10.21.190 pod security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810 container test-container: <nil>
STEP: delete the pod 04/25/23 20:13:03.806
Apr 25 20:13:03.844: INFO: Waiting for pod security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810 to disappear
Apr 25 20:13:03.856: INFO: Pod security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 25 20:13:03.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-8067" for this suite. 04/25/23 20:13:03.874
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":144,"skipped":2502,"failed":0}
------------------------------
• [4.278 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:12:59.639
    Apr 25 20:12:59.640: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename security-context 04/25/23 20:12:59.643
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:12:59.689
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:12:59.702
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/25/23 20:12:59.712
    Apr 25 20:12:59.734: INFO: Waiting up to 5m0s for pod "security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810" in namespace "security-context-8067" to be "Succeeded or Failed"
    Apr 25 20:12:59.748: INFO: Pod "security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810": Phase="Pending", Reason="", readiness=false. Elapsed: 13.018925ms
    Apr 25 20:13:01.761: INFO: Pod "security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02653357s
    Apr 25 20:13:03.762: INFO: Pod "security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027343959s
    STEP: Saw pod success 04/25/23 20:13:03.762
    Apr 25 20:13:03.762: INFO: Pod "security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810" satisfied condition "Succeeded or Failed"
    Apr 25 20:13:03.774: INFO: Trying to get logs from node 10.10.21.190 pod security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810 container test-container: <nil>
    STEP: delete the pod 04/25/23 20:13:03.806
    Apr 25 20:13:03.844: INFO: Waiting for pod security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810 to disappear
    Apr 25 20:13:03.856: INFO: Pod security-context-b21ac7e5-8276-4e27-9df0-8e5f20e2f810 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 25 20:13:03.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-8067" for this suite. 04/25/23 20:13:03.874
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:13:03.927
Apr 25 20:13:03.928: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename deployment 04/25/23 20:13:03.93
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:13:03.975
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:13:03.984
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Apr 25 20:13:03.995: INFO: Creating simple deployment test-new-deployment
Apr 25 20:13:04.042: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource 04/25/23 20:13:06.088
STEP: updating a scale subresource 04/25/23 20:13:06.098
STEP: verifying the deployment Spec.Replicas was modified 04/25/23 20:13:06.138
STEP: Patch a scale subresource 04/25/23 20:13:06.15
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 25 20:13:06.197: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-4434  3a6679a7-89d8-41a7-8ab1-523657ea8088 31280 3 2023-04-25 20:13:03 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-04-25 20:13:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005c28c58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-04-25 20:13:05 +0000 UTC,LastTransitionTime:2023-04-25 20:13:04 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-25 20:13:06 +0000 UTC,LastTransitionTime:2023-04-25 20:13:06 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 25 20:13:06.213: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-4434  b4f1d311-0096-4a3c-a236-916348325945 31283 3 2023-04-25 20:13:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 3a6679a7-89d8-41a7-8ab1-523657ea8088 0xc005c29097 0xc005c29098}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a6679a7-89d8-41a7-8ab1-523657ea8088\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:13:06 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005c29128 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 25 20:13:06.229: INFO: Pod "test-new-deployment-845c8977d9-67r66" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-67r66 test-new-deployment-845c8977d9- deployment-4434  ac040da4-0d5e-4e06-a63e-00f7b735b21f 31261 0 2023-04-25 20:13:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:451240170fa3cffccacc1546cdf8e4f226c962d3974009519c93f3a921ed7005 cni.projectcalico.org/podIP:172.30.142.156/32 cni.projectcalico.org/podIPs:172.30.142.156/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b4f1d311-0096-4a3c-a236-916348325945 0xc003e13297 0xc003e13298}] [] [{calico Update v1 2023-04-25 20:13:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-04-25 20:13:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4f1d311-0096-4a3c-a236-916348325945\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:13:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.156\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tj9xk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tj9xk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.156,StartTime:2023-04-25 20:13:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:13:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b69bd34068e97b9baef2c995e020a5be8f6b500425eaaa6e4157a1fd11b9e8cc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.156,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:13:06.230: INFO: Pod "test-new-deployment-845c8977d9-hf6hs" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-hf6hs test-new-deployment-845c8977d9- deployment-4434  160153fd-d1c6-4412-ad07-1c736d807050 31286 0 2023-04-25 20:13:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b4f1d311-0096-4a3c-a236-916348325945 0xc003e13497 0xc003e13498}] [] [{kube-controller-manager Update v1 2023-04-25 20:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4f1d311-0096-4a3c-a236-916348325945\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-55mw5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-55mw5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:13:06.231: INFO: Pod "test-new-deployment-845c8977d9-rpbx7" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-rpbx7 test-new-deployment-845c8977d9- deployment-4434  b0a27747-8f5b-4138-95f9-1e837d83624b 31284 0 2023-04-25 20:13:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b4f1d311-0096-4a3c-a236-916348325945 0xc003e135d7 0xc003e135d8}] [] [{kube-controller-manager Update v1 2023-04-25 20:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4f1d311-0096-4a3c-a236-916348325945\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:13:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g6j26,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g6j26,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:,StartTime:2023-04-25 20:13:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 25 20:13:06.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4434" for this suite. 04/25/23 20:13:06.255
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":145,"skipped":2526,"failed":0}
------------------------------
• [2.353 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:13:03.927
    Apr 25 20:13:03.928: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename deployment 04/25/23 20:13:03.93
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:13:03.975
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:13:03.984
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Apr 25 20:13:03.995: INFO: Creating simple deployment test-new-deployment
    Apr 25 20:13:04.042: INFO: deployment "test-new-deployment" doesn't have the required revision set
    STEP: getting scale subresource 04/25/23 20:13:06.088
    STEP: updating a scale subresource 04/25/23 20:13:06.098
    STEP: verifying the deployment Spec.Replicas was modified 04/25/23 20:13:06.138
    STEP: Patch a scale subresource 04/25/23 20:13:06.15
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 25 20:13:06.197: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-4434  3a6679a7-89d8-41a7-8ab1-523657ea8088 31280 3 2023-04-25 20:13:03 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-04-25 20:13:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005c28c58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-04-25 20:13:05 +0000 UTC,LastTransitionTime:2023-04-25 20:13:04 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-25 20:13:06 +0000 UTC,LastTransitionTime:2023-04-25 20:13:06 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 25 20:13:06.213: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-4434  b4f1d311-0096-4a3c-a236-916348325945 31283 3 2023-04-25 20:13:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 3a6679a7-89d8-41a7-8ab1-523657ea8088 0xc005c29097 0xc005c29098}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a6679a7-89d8-41a7-8ab1-523657ea8088\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:13:06 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005c29128 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 25 20:13:06.229: INFO: Pod "test-new-deployment-845c8977d9-67r66" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-67r66 test-new-deployment-845c8977d9- deployment-4434  ac040da4-0d5e-4e06-a63e-00f7b735b21f 31261 0 2023-04-25 20:13:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:451240170fa3cffccacc1546cdf8e4f226c962d3974009519c93f3a921ed7005 cni.projectcalico.org/podIP:172.30.142.156/32 cni.projectcalico.org/podIPs:172.30.142.156/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b4f1d311-0096-4a3c-a236-916348325945 0xc003e13297 0xc003e13298}] [] [{calico Update v1 2023-04-25 20:13:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-04-25 20:13:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4f1d311-0096-4a3c-a236-916348325945\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:13:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.156\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tj9xk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tj9xk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.156,StartTime:2023-04-25 20:13:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:13:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b69bd34068e97b9baef2c995e020a5be8f6b500425eaaa6e4157a1fd11b9e8cc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.156,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:13:06.230: INFO: Pod "test-new-deployment-845c8977d9-hf6hs" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-hf6hs test-new-deployment-845c8977d9- deployment-4434  160153fd-d1c6-4412-ad07-1c736d807050 31286 0 2023-04-25 20:13:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b4f1d311-0096-4a3c-a236-916348325945 0xc003e13497 0xc003e13498}] [] [{kube-controller-manager Update v1 2023-04-25 20:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4f1d311-0096-4a3c-a236-916348325945\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-55mw5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-55mw5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:13:06.231: INFO: Pod "test-new-deployment-845c8977d9-rpbx7" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-rpbx7 test-new-deployment-845c8977d9- deployment-4434  b0a27747-8f5b-4138-95f9-1e837d83624b 31284 0 2023-04-25 20:13:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b4f1d311-0096-4a3c-a236-916348325945 0xc003e135d7 0xc003e135d8}] [] [{kube-controller-manager Update v1 2023-04-25 20:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4f1d311-0096-4a3c-a236-916348325945\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:13:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g6j26,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g6j26,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:,StartTime:2023-04-25 20:13:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 25 20:13:06.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-4434" for this suite. 04/25/23 20:13:06.255
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:13:06.286
Apr 25 20:13:06.286: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename deployment 04/25/23 20:13:06.288
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:13:06.337
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:13:06.346
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Apr 25 20:13:06.356: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 25 20:13:06.382: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 25 20:13:11.396: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/25/23 20:13:11.397
Apr 25 20:13:11.398: INFO: Creating deployment "test-rolling-update-deployment"
Apr 25 20:13:11.412: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 25 20:13:11.435: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 25 20:13:13.460: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 25 20:13:13.471: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 13, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 13, 11, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 13, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 13, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:13:15.484: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 25 20:13:15.517: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-183  4ff24bab-0804-4a9b-af05-7634d3aa4b6f 31406 1 2023-04-25 20:13:11 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-04-25 20:13:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:13:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004d8c508 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-25 20:13:11 +0000 UTC,LastTransitionTime:2023-04-25 20:13:11 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-04-25 20:13:13 +0000 UTC,LastTransitionTime:2023-04-25 20:13:11 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 25 20:13:15.529: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-183  8baff244-d672-4d35-b438-e0b492629e9e 31396 1 2023-04-25 20:13:11 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 4ff24bab-0804-4a9b-af05-7634d3aa4b6f 0xc004d8c9e7 0xc004d8c9e8}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:13:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4ff24bab-0804-4a9b-af05-7634d3aa4b6f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:13:13 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004d8ca98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 25 20:13:15.529: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 25 20:13:15.529: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-183  4fd021ee-1c70-45f0-944c-bc4648b33e28 31405 2 2023-04-25 20:13:06 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 4ff24bab-0804-4a9b-af05-7634d3aa4b6f 0xc004d8c8b7 0xc004d8c8b8}] [] [{e2e.test Update apps/v1 2023-04-25 20:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:13:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4ff24bab-0804-4a9b-af05-7634d3aa4b6f\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:13:13 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004d8c978 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 25 20:13:15.543: INFO: Pod "test-rolling-update-deployment-78f575d8ff-pmfnz" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-pmfnz test-rolling-update-deployment-78f575d8ff- deployment-183  31d1ceeb-2eb9-4bb8-bf8c-fbc21b21e04a 31395 0 2023-04-25 20:13:11 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:330fea0327780fa9da886a81ff69dd2c7c34131f2a0373a40de267ec59e9b582 cni.projectcalico.org/podIP:172.30.142.150/32 cni.projectcalico.org/podIPs:172.30.142.150/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 8baff244-d672-4d35-b438-e0b492629e9e 0xc004d8cf07 0xc004d8cf08}] [] [{kube-controller-manager Update v1 2023-04-25 20:13:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8baff244-d672-4d35-b438-e0b492629e9e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:13:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:13:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.150\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-b4z7c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-b4z7c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.150,StartTime:2023-04-25 20:13:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:13:12 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://3fb9450700b3751e6748d79be07e3c929dda4f937848bc7757ffef8758bb4de9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.150,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 25 20:13:15.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-183" for this suite. 04/25/23 20:13:15.562
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":146,"skipped":2544,"failed":0}
------------------------------
• [SLOW TEST] [9.295 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:13:06.286
    Apr 25 20:13:06.286: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename deployment 04/25/23 20:13:06.288
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:13:06.337
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:13:06.346
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Apr 25 20:13:06.356: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Apr 25 20:13:06.382: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 25 20:13:11.396: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/25/23 20:13:11.397
    Apr 25 20:13:11.398: INFO: Creating deployment "test-rolling-update-deployment"
    Apr 25 20:13:11.412: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Apr 25 20:13:11.435: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Apr 25 20:13:13.460: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Apr 25 20:13:13.471: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 13, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 13, 11, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 13, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 13, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:13:15.484: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 25 20:13:15.517: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-183  4ff24bab-0804-4a9b-af05-7634d3aa4b6f 31406 1 2023-04-25 20:13:11 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-04-25 20:13:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:13:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004d8c508 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-25 20:13:11 +0000 UTC,LastTransitionTime:2023-04-25 20:13:11 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-04-25 20:13:13 +0000 UTC,LastTransitionTime:2023-04-25 20:13:11 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 25 20:13:15.529: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-183  8baff244-d672-4d35-b438-e0b492629e9e 31396 1 2023-04-25 20:13:11 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 4ff24bab-0804-4a9b-af05-7634d3aa4b6f 0xc004d8c9e7 0xc004d8c9e8}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:13:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4ff24bab-0804-4a9b-af05-7634d3aa4b6f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:13:13 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004d8ca98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 25 20:13:15.529: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Apr 25 20:13:15.529: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-183  4fd021ee-1c70-45f0-944c-bc4648b33e28 31405 2 2023-04-25 20:13:06 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 4ff24bab-0804-4a9b-af05-7634d3aa4b6f 0xc004d8c8b7 0xc004d8c8b8}] [] [{e2e.test Update apps/v1 2023-04-25 20:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:13:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4ff24bab-0804-4a9b-af05-7634d3aa4b6f\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:13:13 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004d8c978 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 25 20:13:15.543: INFO: Pod "test-rolling-update-deployment-78f575d8ff-pmfnz" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-pmfnz test-rolling-update-deployment-78f575d8ff- deployment-183  31d1ceeb-2eb9-4bb8-bf8c-fbc21b21e04a 31395 0 2023-04-25 20:13:11 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:330fea0327780fa9da886a81ff69dd2c7c34131f2a0373a40de267ec59e9b582 cni.projectcalico.org/podIP:172.30.142.150/32 cni.projectcalico.org/podIPs:172.30.142.150/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 8baff244-d672-4d35-b438-e0b492629e9e 0xc004d8cf07 0xc004d8cf08}] [] [{kube-controller-manager Update v1 2023-04-25 20:13:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8baff244-d672-4d35-b438-e0b492629e9e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:13:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:13:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.150\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-b4z7c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-b4z7c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:13:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.150,StartTime:2023-04-25 20:13:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:13:12 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://3fb9450700b3751e6748d79be07e3c929dda4f937848bc7757ffef8758bb4de9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.150,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 25 20:13:15.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-183" for this suite. 04/25/23 20:13:15.562
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2194
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:13:15.605
Apr 25 20:13:15.605: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 20:13:15.607
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:13:15.686
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:13:15.696
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2194
STEP: creating service in namespace services-4547 04/25/23 20:13:15.707
STEP: creating service affinity-nodeport in namespace services-4547 04/25/23 20:13:15.708
STEP: creating replication controller affinity-nodeport in namespace services-4547 04/25/23 20:13:15.8
I0425 20:13:15.818716      23 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-4547, replica count: 3
I0425 20:13:18.871742      23 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 25 20:13:18.913: INFO: Creating new exec pod
Apr 25 20:13:18.934: INFO: Waiting up to 5m0s for pod "execpod-affinitywqqch" in namespace "services-4547" to be "running"
Apr 25 20:13:18.945: INFO: Pod "execpod-affinitywqqch": Phase="Pending", Reason="", readiness=false. Elapsed: 10.836989ms
Apr 25 20:13:20.960: INFO: Pod "execpod-affinitywqqch": Phase="Running", Reason="", readiness=true. Elapsed: 2.025748286s
Apr 25 20:13:20.960: INFO: Pod "execpod-affinitywqqch" satisfied condition "running"
Apr 25 20:13:21.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-4547 exec execpod-affinitywqqch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Apr 25 20:13:22.386: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Apr 25 20:13:22.386: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 20:13:22.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-4547 exec execpod-affinitywqqch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.114.137 80'
Apr 25 20:13:22.708: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.114.137 80\nConnection to 172.21.114.137 80 port [tcp/http] succeeded!\n"
Apr 25 20:13:22.708: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 20:13:22.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-4547 exec execpod-affinitywqqch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.136 32198'
Apr 25 20:13:23.081: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.136 32198\nConnection to 10.10.21.136 32198 port [tcp/*] succeeded!\n"
Apr 25 20:13:23.082: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 20:13:23.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-4547 exec execpod-affinitywqqch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.161 32198'
Apr 25 20:13:23.426: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.161 32198\nConnection to 10.10.21.161 32198 port [tcp/*] succeeded!\n"
Apr 25 20:13:23.426: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 20:13:23.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-4547 exec execpod-affinitywqqch -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.21.136:32198/ ; done'
Apr 25 20:13:24.013: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n"
Apr 25 20:13:24.013: INFO: stdout: "\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5"
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
Apr 25 20:13:24.013: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-4547, will wait for the garbage collector to delete the pods 04/25/23 20:13:24.056
Apr 25 20:13:24.159: INFO: Deleting ReplicationController affinity-nodeport took: 19.28458ms
Apr 25 20:13:24.260: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.95056ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 20:13:26.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4547" for this suite. 04/25/23 20:13:26.848
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":147,"skipped":2616,"failed":0}
------------------------------
• [SLOW TEST] [11.264 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:13:15.605
    Apr 25 20:13:15.605: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 20:13:15.607
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:13:15.686
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:13:15.696
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2194
    STEP: creating service in namespace services-4547 04/25/23 20:13:15.707
    STEP: creating service affinity-nodeport in namespace services-4547 04/25/23 20:13:15.708
    STEP: creating replication controller affinity-nodeport in namespace services-4547 04/25/23 20:13:15.8
    I0425 20:13:15.818716      23 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-4547, replica count: 3
    I0425 20:13:18.871742      23 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 25 20:13:18.913: INFO: Creating new exec pod
    Apr 25 20:13:18.934: INFO: Waiting up to 5m0s for pod "execpod-affinitywqqch" in namespace "services-4547" to be "running"
    Apr 25 20:13:18.945: INFO: Pod "execpod-affinitywqqch": Phase="Pending", Reason="", readiness=false. Elapsed: 10.836989ms
    Apr 25 20:13:20.960: INFO: Pod "execpod-affinitywqqch": Phase="Running", Reason="", readiness=true. Elapsed: 2.025748286s
    Apr 25 20:13:20.960: INFO: Pod "execpod-affinitywqqch" satisfied condition "running"
    Apr 25 20:13:21.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-4547 exec execpod-affinitywqqch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Apr 25 20:13:22.386: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Apr 25 20:13:22.386: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 20:13:22.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-4547 exec execpod-affinitywqqch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.114.137 80'
    Apr 25 20:13:22.708: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.114.137 80\nConnection to 172.21.114.137 80 port [tcp/http] succeeded!\n"
    Apr 25 20:13:22.708: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 20:13:22.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-4547 exec execpod-affinitywqqch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.136 32198'
    Apr 25 20:13:23.081: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.136 32198\nConnection to 10.10.21.136 32198 port [tcp/*] succeeded!\n"
    Apr 25 20:13:23.082: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 20:13:23.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-4547 exec execpod-affinitywqqch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.161 32198'
    Apr 25 20:13:23.426: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.161 32198\nConnection to 10.10.21.161 32198 port [tcp/*] succeeded!\n"
    Apr 25 20:13:23.426: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 20:13:23.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-4547 exec execpod-affinitywqqch -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.21.136:32198/ ; done'
    Apr 25 20:13:24.013: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.21.136:32198/\n"
    Apr 25 20:13:24.013: INFO: stdout: "\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5\naffinity-nodeport-xd2v5"
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Received response from host: affinity-nodeport-xd2v5
    Apr 25 20:13:24.013: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-4547, will wait for the garbage collector to delete the pods 04/25/23 20:13:24.056
    Apr 25 20:13:24.159: INFO: Deleting ReplicationController affinity-nodeport took: 19.28458ms
    Apr 25 20:13:24.260: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.95056ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 20:13:26.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4547" for this suite. 04/25/23 20:13:26.848
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:13:26.875
Apr 25 20:13:26.875: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 20:13:26.878
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:13:26.929
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:13:26.942
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 20:13:26.991
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:13:27.314
STEP: Deploying the webhook pod 04/25/23 20:13:27.336
STEP: Wait for the deployment to be ready 04/25/23 20:13:27.368
Apr 25 20:13:27.398: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/25/23 20:13:29.435
STEP: Verifying the service has paired with the endpoint 04/25/23 20:13:29.464
Apr 25 20:13:30.464: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 04/25/23 20:13:30.618
STEP: Creating a configMap that does not comply to the validation webhook rules 04/25/23 20:13:30.758
STEP: Deleting the collection of validation webhooks 04/25/23 20:13:30.877
STEP: Creating a configMap that does not comply to the validation webhook rules 04/25/23 20:13:31.026
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:13:31.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3357" for this suite. 04/25/23 20:13:31.076
STEP: Destroying namespace "webhook-3357-markers" for this suite. 04/25/23 20:13:31.099
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":148,"skipped":2629,"failed":0}
------------------------------
• [4.398 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:13:26.875
    Apr 25 20:13:26.875: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 20:13:26.878
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:13:26.929
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:13:26.942
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 20:13:26.991
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:13:27.314
    STEP: Deploying the webhook pod 04/25/23 20:13:27.336
    STEP: Wait for the deployment to be ready 04/25/23 20:13:27.368
    Apr 25 20:13:27.398: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/25/23 20:13:29.435
    STEP: Verifying the service has paired with the endpoint 04/25/23 20:13:29.464
    Apr 25 20:13:30.464: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 04/25/23 20:13:30.618
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/25/23 20:13:30.758
    STEP: Deleting the collection of validation webhooks 04/25/23 20:13:30.877
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/25/23 20:13:31.026
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:13:31.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3357" for this suite. 04/25/23 20:13:31.076
    STEP: Destroying namespace "webhook-3357-markers" for this suite. 04/25/23 20:13:31.099
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:13:31.282
Apr 25 20:13:31.283: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 20:13:31.285
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:13:31.326
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:13:31.337
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Apr 25 20:13:31.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 04/25/23 20:13:35.412
Apr 25 20:13:35.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 create -f -'
Apr 25 20:13:36.325: INFO: stderr: ""
Apr 25 20:13:36.325: INFO: stdout: "e2e-test-crd-publish-openapi-989-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 25 20:13:36.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 delete e2e-test-crd-publish-openapi-989-crds test-foo'
Apr 25 20:13:36.461: INFO: stderr: ""
Apr 25 20:13:36.461: INFO: stdout: "e2e-test-crd-publish-openapi-989-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Apr 25 20:13:36.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 apply -f -'
Apr 25 20:13:37.246: INFO: stderr: ""
Apr 25 20:13:37.246: INFO: stdout: "e2e-test-crd-publish-openapi-989-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 25 20:13:37.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 delete e2e-test-crd-publish-openapi-989-crds test-foo'
Apr 25 20:13:37.382: INFO: stderr: ""
Apr 25 20:13:37.382: INFO: stdout: "e2e-test-crd-publish-openapi-989-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 04/25/23 20:13:37.382
Apr 25 20:13:37.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 create -f -'
Apr 25 20:13:38.174: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 04/25/23 20:13:38.174
Apr 25 20:13:38.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 create -f -'
Apr 25 20:13:38.504: INFO: rc: 1
Apr 25 20:13:38.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 apply -f -'
Apr 25 20:13:38.828: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 04/25/23 20:13:38.828
Apr 25 20:13:38.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 create -f -'
Apr 25 20:13:39.133: INFO: rc: 1
Apr 25 20:13:39.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 apply -f -'
Apr 25 20:13:39.513: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 04/25/23 20:13:39.513
Apr 25 20:13:39.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 explain e2e-test-crd-publish-openapi-989-crds'
Apr 25 20:13:39.832: INFO: stderr: ""
Apr 25 20:13:39.832: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-989-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 04/25/23 20:13:39.832
Apr 25 20:13:39.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 explain e2e-test-crd-publish-openapi-989-crds.metadata'
Apr 25 20:13:40.122: INFO: stderr: ""
Apr 25 20:13:40.122: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-989-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Apr 25 20:13:40.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 explain e2e-test-crd-publish-openapi-989-crds.spec'
Apr 25 20:13:40.405: INFO: stderr: ""
Apr 25 20:13:40.406: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-989-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Apr 25 20:13:40.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 explain e2e-test-crd-publish-openapi-989-crds.spec.bars'
Apr 25 20:13:40.727: INFO: stderr: ""
Apr 25 20:13:40.728: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-989-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 04/25/23 20:13:40.728
Apr 25 20:13:40.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 explain e2e-test-crd-publish-openapi-989-crds.spec.bars2'
Apr 25 20:13:41.024: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:13:44.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8259" for this suite. 04/25/23 20:13:44.148
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":149,"skipped":2630,"failed":0}
------------------------------
• [SLOW TEST] [12.893 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:13:31.282
    Apr 25 20:13:31.283: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 20:13:31.285
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:13:31.326
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:13:31.337
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Apr 25 20:13:31.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 04/25/23 20:13:35.412
    Apr 25 20:13:35.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 create -f -'
    Apr 25 20:13:36.325: INFO: stderr: ""
    Apr 25 20:13:36.325: INFO: stdout: "e2e-test-crd-publish-openapi-989-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Apr 25 20:13:36.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 delete e2e-test-crd-publish-openapi-989-crds test-foo'
    Apr 25 20:13:36.461: INFO: stderr: ""
    Apr 25 20:13:36.461: INFO: stdout: "e2e-test-crd-publish-openapi-989-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Apr 25 20:13:36.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 apply -f -'
    Apr 25 20:13:37.246: INFO: stderr: ""
    Apr 25 20:13:37.246: INFO: stdout: "e2e-test-crd-publish-openapi-989-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Apr 25 20:13:37.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 delete e2e-test-crd-publish-openapi-989-crds test-foo'
    Apr 25 20:13:37.382: INFO: stderr: ""
    Apr 25 20:13:37.382: INFO: stdout: "e2e-test-crd-publish-openapi-989-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 04/25/23 20:13:37.382
    Apr 25 20:13:37.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 create -f -'
    Apr 25 20:13:38.174: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 04/25/23 20:13:38.174
    Apr 25 20:13:38.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 create -f -'
    Apr 25 20:13:38.504: INFO: rc: 1
    Apr 25 20:13:38.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 apply -f -'
    Apr 25 20:13:38.828: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 04/25/23 20:13:38.828
    Apr 25 20:13:38.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 create -f -'
    Apr 25 20:13:39.133: INFO: rc: 1
    Apr 25 20:13:39.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 --namespace=crd-publish-openapi-8259 apply -f -'
    Apr 25 20:13:39.513: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 04/25/23 20:13:39.513
    Apr 25 20:13:39.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 explain e2e-test-crd-publish-openapi-989-crds'
    Apr 25 20:13:39.832: INFO: stderr: ""
    Apr 25 20:13:39.832: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-989-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 04/25/23 20:13:39.832
    Apr 25 20:13:39.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 explain e2e-test-crd-publish-openapi-989-crds.metadata'
    Apr 25 20:13:40.122: INFO: stderr: ""
    Apr 25 20:13:40.122: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-989-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Apr 25 20:13:40.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 explain e2e-test-crd-publish-openapi-989-crds.spec'
    Apr 25 20:13:40.405: INFO: stderr: ""
    Apr 25 20:13:40.406: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-989-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Apr 25 20:13:40.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 explain e2e-test-crd-publish-openapi-989-crds.spec.bars'
    Apr 25 20:13:40.727: INFO: stderr: ""
    Apr 25 20:13:40.728: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-989-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 04/25/23 20:13:40.728
    Apr 25 20:13:40.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-8259 explain e2e-test-crd-publish-openapi-989-crds.spec.bars2'
    Apr 25 20:13:41.024: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:13:44.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8259" for this suite. 04/25/23 20:13:44.148
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:13:44.192
Apr 25 20:13:44.192: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 20:13:44.193
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:13:44.236
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:13:44.256
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 04/25/23 20:13:44.266
Apr 25 20:13:44.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 04/25/23 20:13:56.69
Apr 25 20:13:56.691: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:14:00.680: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:14:15.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8622" for this suite. 04/25/23 20:14:15.476
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":150,"skipped":2667,"failed":0}
------------------------------
• [SLOW TEST] [31.309 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:13:44.192
    Apr 25 20:13:44.192: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 20:13:44.193
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:13:44.236
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:13:44.256
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 04/25/23 20:13:44.266
    Apr 25 20:13:44.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 04/25/23 20:13:56.69
    Apr 25 20:13:56.691: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:14:00.680: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:14:15.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8622" for this suite. 04/25/23 20:14:15.476
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3394
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:14:15.515
Apr 25 20:14:15.516: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 20:14:15.517
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:14:15.563
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:14:15.577
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3394
STEP: creating a Service 04/25/23 20:14:15.603
STEP: watching for the Service to be added 04/25/23 20:14:15.665
Apr 25 20:14:15.672: INFO: Found Service test-service-r2xpl in namespace services-9278 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Apr 25 20:14:15.674: INFO: Service test-service-r2xpl created
STEP: Getting /status 04/25/23 20:14:15.674
Apr 25 20:14:15.687: INFO: Service test-service-r2xpl has LoadBalancer: {[]}
STEP: patching the ServiceStatus 04/25/23 20:14:15.687
STEP: watching for the Service to be patched 04/25/23 20:14:15.705
Apr 25 20:14:15.713: INFO: observed Service test-service-r2xpl in namespace services-9278 with annotations: map[] & LoadBalancer: {[]}
Apr 25 20:14:15.713: INFO: Found Service test-service-r2xpl in namespace services-9278 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Apr 25 20:14:15.714: INFO: Service test-service-r2xpl has service status patched
STEP: updating the ServiceStatus 04/25/23 20:14:15.714
Apr 25 20:14:15.744: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 04/25/23 20:14:15.744
Apr 25 20:14:15.751: INFO: Observed Service test-service-r2xpl in namespace services-9278 with annotations: map[] & Conditions: {[]}
Apr 25 20:14:15.751: INFO: Observed event: &Service{ObjectMeta:{test-service-r2xpl  services-9278  963db228-ae0d-4fa8-8ea4-3d275c633f5c 31784 0 2023-04-25 20:14:15 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-04-25 20:14:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-04-25 20:14:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:172.21.13.135,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[172.21.13.135],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Apr 25 20:14:15.751: INFO: Found Service test-service-r2xpl in namespace services-9278 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 25 20:14:15.751: INFO: Service test-service-r2xpl has service status updated
STEP: patching the service 04/25/23 20:14:15.751
STEP: watching for the Service to be patched 04/25/23 20:14:15.781
Apr 25 20:14:15.787: INFO: observed Service test-service-r2xpl in namespace services-9278 with labels: map[test-service-static:true]
Apr 25 20:14:15.787: INFO: observed Service test-service-r2xpl in namespace services-9278 with labels: map[test-service-static:true]
Apr 25 20:14:15.788: INFO: observed Service test-service-r2xpl in namespace services-9278 with labels: map[test-service-static:true]
Apr 25 20:14:15.788: INFO: Found Service test-service-r2xpl in namespace services-9278 with labels: map[test-service:patched test-service-static:true]
Apr 25 20:14:15.788: INFO: Service test-service-r2xpl patched
STEP: deleting the service 04/25/23 20:14:15.788
STEP: watching for the Service to be deleted 04/25/23 20:14:15.829
Apr 25 20:14:15.835: INFO: Observed event: ADDED
Apr 25 20:14:15.835: INFO: Observed event: MODIFIED
Apr 25 20:14:15.836: INFO: Observed event: MODIFIED
Apr 25 20:14:15.836: INFO: Observed event: MODIFIED
Apr 25 20:14:15.836: INFO: Found Service test-service-r2xpl in namespace services-9278 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Apr 25 20:14:15.836: INFO: Service test-service-r2xpl deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 20:14:15.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9278" for this suite. 04/25/23 20:14:15.852
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":151,"skipped":2684,"failed":0}
------------------------------
• [0.363 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3394

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:14:15.515
    Apr 25 20:14:15.516: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 20:14:15.517
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:14:15.563
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:14:15.577
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3394
    STEP: creating a Service 04/25/23 20:14:15.603
    STEP: watching for the Service to be added 04/25/23 20:14:15.665
    Apr 25 20:14:15.672: INFO: Found Service test-service-r2xpl in namespace services-9278 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Apr 25 20:14:15.674: INFO: Service test-service-r2xpl created
    STEP: Getting /status 04/25/23 20:14:15.674
    Apr 25 20:14:15.687: INFO: Service test-service-r2xpl has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 04/25/23 20:14:15.687
    STEP: watching for the Service to be patched 04/25/23 20:14:15.705
    Apr 25 20:14:15.713: INFO: observed Service test-service-r2xpl in namespace services-9278 with annotations: map[] & LoadBalancer: {[]}
    Apr 25 20:14:15.713: INFO: Found Service test-service-r2xpl in namespace services-9278 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Apr 25 20:14:15.714: INFO: Service test-service-r2xpl has service status patched
    STEP: updating the ServiceStatus 04/25/23 20:14:15.714
    Apr 25 20:14:15.744: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 04/25/23 20:14:15.744
    Apr 25 20:14:15.751: INFO: Observed Service test-service-r2xpl in namespace services-9278 with annotations: map[] & Conditions: {[]}
    Apr 25 20:14:15.751: INFO: Observed event: &Service{ObjectMeta:{test-service-r2xpl  services-9278  963db228-ae0d-4fa8-8ea4-3d275c633f5c 31784 0 2023-04-25 20:14:15 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-04-25 20:14:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-04-25 20:14:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:172.21.13.135,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[172.21.13.135],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Apr 25 20:14:15.751: INFO: Found Service test-service-r2xpl in namespace services-9278 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 25 20:14:15.751: INFO: Service test-service-r2xpl has service status updated
    STEP: patching the service 04/25/23 20:14:15.751
    STEP: watching for the Service to be patched 04/25/23 20:14:15.781
    Apr 25 20:14:15.787: INFO: observed Service test-service-r2xpl in namespace services-9278 with labels: map[test-service-static:true]
    Apr 25 20:14:15.787: INFO: observed Service test-service-r2xpl in namespace services-9278 with labels: map[test-service-static:true]
    Apr 25 20:14:15.788: INFO: observed Service test-service-r2xpl in namespace services-9278 with labels: map[test-service-static:true]
    Apr 25 20:14:15.788: INFO: Found Service test-service-r2xpl in namespace services-9278 with labels: map[test-service:patched test-service-static:true]
    Apr 25 20:14:15.788: INFO: Service test-service-r2xpl patched
    STEP: deleting the service 04/25/23 20:14:15.788
    STEP: watching for the Service to be deleted 04/25/23 20:14:15.829
    Apr 25 20:14:15.835: INFO: Observed event: ADDED
    Apr 25 20:14:15.835: INFO: Observed event: MODIFIED
    Apr 25 20:14:15.836: INFO: Observed event: MODIFIED
    Apr 25 20:14:15.836: INFO: Observed event: MODIFIED
    Apr 25 20:14:15.836: INFO: Found Service test-service-r2xpl in namespace services-9278 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Apr 25 20:14:15.836: INFO: Service test-service-r2xpl deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 20:14:15.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9278" for this suite. 04/25/23 20:14:15.852
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:14:15.886
Apr 25 20:14:15.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename configmap 04/25/23 20:14:15.887
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:14:15.931
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:14:15.942
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-c115c6ae-addb-44e9-a85e-16766a98ce70 04/25/23 20:14:15.955
STEP: Creating a pod to test consume configMaps 04/25/23 20:14:15.968
Apr 25 20:14:16.016: INFO: Waiting up to 5m0s for pod "pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6" in namespace "configmap-116" to be "Succeeded or Failed"
Apr 25 20:14:16.031: INFO: Pod "pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.952102ms
Apr 25 20:14:18.047: INFO: Pod "pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030853439s
Apr 25 20:14:20.046: INFO: Pod "pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029881053s
STEP: Saw pod success 04/25/23 20:14:20.046
Apr 25 20:14:20.046: INFO: Pod "pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6" satisfied condition "Succeeded or Failed"
Apr 25 20:14:20.061: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6 container agnhost-container: <nil>
STEP: delete the pod 04/25/23 20:14:20.19
Apr 25 20:14:20.257: INFO: Waiting for pod pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6 to disappear
Apr 25 20:14:20.270: INFO: Pod pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 25 20:14:20.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-116" for this suite. 04/25/23 20:14:20.308
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":152,"skipped":2737,"failed":0}
------------------------------
• [4.477 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:14:15.886
    Apr 25 20:14:15.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename configmap 04/25/23 20:14:15.887
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:14:15.931
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:14:15.942
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-c115c6ae-addb-44e9-a85e-16766a98ce70 04/25/23 20:14:15.955
    STEP: Creating a pod to test consume configMaps 04/25/23 20:14:15.968
    Apr 25 20:14:16.016: INFO: Waiting up to 5m0s for pod "pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6" in namespace "configmap-116" to be "Succeeded or Failed"
    Apr 25 20:14:16.031: INFO: Pod "pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.952102ms
    Apr 25 20:14:18.047: INFO: Pod "pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030853439s
    Apr 25 20:14:20.046: INFO: Pod "pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029881053s
    STEP: Saw pod success 04/25/23 20:14:20.046
    Apr 25 20:14:20.046: INFO: Pod "pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6" satisfied condition "Succeeded or Failed"
    Apr 25 20:14:20.061: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6 container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 20:14:20.19
    Apr 25 20:14:20.257: INFO: Waiting for pod pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6 to disappear
    Apr 25 20:14:20.270: INFO: Pod pod-configmaps-49fc3e37-9dca-4404-9f82-5b6bd60603c6 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 25 20:14:20.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-116" for this suite. 04/25/23 20:14:20.308
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:14:20.37
Apr 25 20:14:20.371: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-probe 04/25/23 20:14:20.372
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:14:20.419
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:14:20.431
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-94ab3f0e-8120-481d-9b9d-80a6fed8c464 in namespace container-probe-9075 04/25/23 20:14:20.454
Apr 25 20:14:20.523: INFO: Waiting up to 5m0s for pod "busybox-94ab3f0e-8120-481d-9b9d-80a6fed8c464" in namespace "container-probe-9075" to be "not pending"
Apr 25 20:14:20.575: INFO: Pod "busybox-94ab3f0e-8120-481d-9b9d-80a6fed8c464": Phase="Pending", Reason="", readiness=false. Elapsed: 52.767346ms
Apr 25 20:14:22.589: INFO: Pod "busybox-94ab3f0e-8120-481d-9b9d-80a6fed8c464": Phase="Running", Reason="", readiness=true. Elapsed: 2.066410549s
Apr 25 20:14:22.589: INFO: Pod "busybox-94ab3f0e-8120-481d-9b9d-80a6fed8c464" satisfied condition "not pending"
Apr 25 20:14:22.589: INFO: Started pod busybox-94ab3f0e-8120-481d-9b9d-80a6fed8c464 in namespace container-probe-9075
STEP: checking the pod's current state and verifying that restartCount is present 04/25/23 20:14:22.589
Apr 25 20:14:22.603: INFO: Initial restart count of pod busybox-94ab3f0e-8120-481d-9b9d-80a6fed8c464 is 0
STEP: deleting the pod 04/25/23 20:18:22.921
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 25 20:18:22.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9075" for this suite. 04/25/23 20:18:22.994
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":153,"skipped":2745,"failed":0}
------------------------------
• [SLOW TEST] [242.666 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:14:20.37
    Apr 25 20:14:20.371: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-probe 04/25/23 20:14:20.372
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:14:20.419
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:14:20.431
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-94ab3f0e-8120-481d-9b9d-80a6fed8c464 in namespace container-probe-9075 04/25/23 20:14:20.454
    Apr 25 20:14:20.523: INFO: Waiting up to 5m0s for pod "busybox-94ab3f0e-8120-481d-9b9d-80a6fed8c464" in namespace "container-probe-9075" to be "not pending"
    Apr 25 20:14:20.575: INFO: Pod "busybox-94ab3f0e-8120-481d-9b9d-80a6fed8c464": Phase="Pending", Reason="", readiness=false. Elapsed: 52.767346ms
    Apr 25 20:14:22.589: INFO: Pod "busybox-94ab3f0e-8120-481d-9b9d-80a6fed8c464": Phase="Running", Reason="", readiness=true. Elapsed: 2.066410549s
    Apr 25 20:14:22.589: INFO: Pod "busybox-94ab3f0e-8120-481d-9b9d-80a6fed8c464" satisfied condition "not pending"
    Apr 25 20:14:22.589: INFO: Started pod busybox-94ab3f0e-8120-481d-9b9d-80a6fed8c464 in namespace container-probe-9075
    STEP: checking the pod's current state and verifying that restartCount is present 04/25/23 20:14:22.589
    Apr 25 20:14:22.603: INFO: Initial restart count of pod busybox-94ab3f0e-8120-481d-9b9d-80a6fed8c464 is 0
    STEP: deleting the pod 04/25/23 20:18:22.921
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 25 20:18:22.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9075" for this suite. 04/25/23 20:18:22.994
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:18:23.038
Apr 25 20:18:23.038: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 20:18:23.04
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:18:23.086
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:18:23.101
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 04/25/23 20:18:23.114
Apr 25 20:18:23.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 create -f -'
Apr 25 20:18:23.535: INFO: stderr: ""
Apr 25 20:18:23.535: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/25/23 20:18:23.535
Apr 25 20:18:23.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 25 20:18:23.660: INFO: stderr: ""
Apr 25 20:18:23.660: INFO: stdout: "update-demo-nautilus-fjth2 update-demo-nautilus-lsfs7 "
Apr 25 20:18:23.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods update-demo-nautilus-fjth2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 25 20:18:23.781: INFO: stderr: ""
Apr 25 20:18:23.781: INFO: stdout: ""
Apr 25 20:18:23.781: INFO: update-demo-nautilus-fjth2 is created but not running
Apr 25 20:18:28.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 25 20:18:28.921: INFO: stderr: ""
Apr 25 20:18:28.922: INFO: stdout: "update-demo-nautilus-fjth2 update-demo-nautilus-lsfs7 "
Apr 25 20:18:28.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods update-demo-nautilus-fjth2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 25 20:18:29.061: INFO: stderr: ""
Apr 25 20:18:29.062: INFO: stdout: ""
Apr 25 20:18:29.062: INFO: update-demo-nautilus-fjth2 is created but not running
Apr 25 20:18:34.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 25 20:18:34.201: INFO: stderr: ""
Apr 25 20:18:34.201: INFO: stdout: "update-demo-nautilus-fjth2 update-demo-nautilus-lsfs7 "
Apr 25 20:18:34.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods update-demo-nautilus-fjth2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 25 20:18:34.328: INFO: stderr: ""
Apr 25 20:18:34.328: INFO: stdout: "true"
Apr 25 20:18:34.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods update-demo-nautilus-fjth2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 25 20:18:34.455: INFO: stderr: ""
Apr 25 20:18:34.455: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 25 20:18:34.455: INFO: validating pod update-demo-nautilus-fjth2
Apr 25 20:18:34.577: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 20:18:34.577: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 20:18:34.577: INFO: update-demo-nautilus-fjth2 is verified up and running
Apr 25 20:18:34.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods update-demo-nautilus-lsfs7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 25 20:18:34.702: INFO: stderr: ""
Apr 25 20:18:34.702: INFO: stdout: "true"
Apr 25 20:18:34.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods update-demo-nautilus-lsfs7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 25 20:18:34.868: INFO: stderr: ""
Apr 25 20:18:34.868: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 25 20:18:34.868: INFO: validating pod update-demo-nautilus-lsfs7
Apr 25 20:18:34.915: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 20:18:34.915: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 20:18:34.915: INFO: update-demo-nautilus-lsfs7 is verified up and running
STEP: using delete to clean up resources 04/25/23 20:18:34.916
Apr 25 20:18:34.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 delete --grace-period=0 --force -f -'
Apr 25 20:18:35.044: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 20:18:35.044: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 25 20:18:35.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get rc,svc -l name=update-demo --no-headers'
Apr 25 20:18:35.180: INFO: stderr: "No resources found in kubectl-8983 namespace.\n"
Apr 25 20:18:35.181: INFO: stdout: ""
Apr 25 20:18:35.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 25 20:18:35.308: INFO: stderr: ""
Apr 25 20:18:35.308: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 20:18:35.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8983" for this suite. 04/25/23 20:18:35.326
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":154,"skipped":2768,"failed":0}
------------------------------
• [SLOW TEST] [12.312 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:18:23.038
    Apr 25 20:18:23.038: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 20:18:23.04
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:18:23.086
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:18:23.101
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 04/25/23 20:18:23.114
    Apr 25 20:18:23.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 create -f -'
    Apr 25 20:18:23.535: INFO: stderr: ""
    Apr 25 20:18:23.535: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/25/23 20:18:23.535
    Apr 25 20:18:23.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 25 20:18:23.660: INFO: stderr: ""
    Apr 25 20:18:23.660: INFO: stdout: "update-demo-nautilus-fjth2 update-demo-nautilus-lsfs7 "
    Apr 25 20:18:23.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods update-demo-nautilus-fjth2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 25 20:18:23.781: INFO: stderr: ""
    Apr 25 20:18:23.781: INFO: stdout: ""
    Apr 25 20:18:23.781: INFO: update-demo-nautilus-fjth2 is created but not running
    Apr 25 20:18:28.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 25 20:18:28.921: INFO: stderr: ""
    Apr 25 20:18:28.922: INFO: stdout: "update-demo-nautilus-fjth2 update-demo-nautilus-lsfs7 "
    Apr 25 20:18:28.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods update-demo-nautilus-fjth2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 25 20:18:29.061: INFO: stderr: ""
    Apr 25 20:18:29.062: INFO: stdout: ""
    Apr 25 20:18:29.062: INFO: update-demo-nautilus-fjth2 is created but not running
    Apr 25 20:18:34.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 25 20:18:34.201: INFO: stderr: ""
    Apr 25 20:18:34.201: INFO: stdout: "update-demo-nautilus-fjth2 update-demo-nautilus-lsfs7 "
    Apr 25 20:18:34.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods update-demo-nautilus-fjth2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 25 20:18:34.328: INFO: stderr: ""
    Apr 25 20:18:34.328: INFO: stdout: "true"
    Apr 25 20:18:34.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods update-demo-nautilus-fjth2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 25 20:18:34.455: INFO: stderr: ""
    Apr 25 20:18:34.455: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 25 20:18:34.455: INFO: validating pod update-demo-nautilus-fjth2
    Apr 25 20:18:34.577: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 25 20:18:34.577: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 25 20:18:34.577: INFO: update-demo-nautilus-fjth2 is verified up and running
    Apr 25 20:18:34.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods update-demo-nautilus-lsfs7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 25 20:18:34.702: INFO: stderr: ""
    Apr 25 20:18:34.702: INFO: stdout: "true"
    Apr 25 20:18:34.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods update-demo-nautilus-lsfs7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 25 20:18:34.868: INFO: stderr: ""
    Apr 25 20:18:34.868: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 25 20:18:34.868: INFO: validating pod update-demo-nautilus-lsfs7
    Apr 25 20:18:34.915: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 25 20:18:34.915: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 25 20:18:34.915: INFO: update-demo-nautilus-lsfs7 is verified up and running
    STEP: using delete to clean up resources 04/25/23 20:18:34.916
    Apr 25 20:18:34.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 delete --grace-period=0 --force -f -'
    Apr 25 20:18:35.044: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 25 20:18:35.044: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Apr 25 20:18:35.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get rc,svc -l name=update-demo --no-headers'
    Apr 25 20:18:35.180: INFO: stderr: "No resources found in kubectl-8983 namespace.\n"
    Apr 25 20:18:35.181: INFO: stdout: ""
    Apr 25 20:18:35.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-8983 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 25 20:18:35.308: INFO: stderr: ""
    Apr 25 20:18:35.308: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 20:18:35.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8983" for this suite. 04/25/23 20:18:35.326
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:18:35.353
Apr 25 20:18:35.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir 04/25/23 20:18:35.354
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:18:35.405
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:18:35.419
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 04/25/23 20:18:35.432
Apr 25 20:18:35.483: INFO: Waiting up to 5m0s for pod "pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa" in namespace "emptydir-2036" to be "Succeeded or Failed"
Apr 25 20:18:35.496: INFO: Pod "pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa": Phase="Pending", Reason="", readiness=false. Elapsed: 12.538096ms
Apr 25 20:18:37.555: INFO: Pod "pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072194906s
Apr 25 20:18:39.521: INFO: Pod "pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037840338s
STEP: Saw pod success 04/25/23 20:18:39.522
Apr 25 20:18:39.522: INFO: Pod "pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa" satisfied condition "Succeeded or Failed"
Apr 25 20:18:39.559: INFO: Trying to get logs from node 10.10.21.190 pod pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa container test-container: <nil>
STEP: delete the pod 04/25/23 20:18:39.679
Apr 25 20:18:39.769: INFO: Waiting for pod pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa to disappear
Apr 25 20:18:39.820: INFO: Pod pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 25 20:18:39.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2036" for this suite. 04/25/23 20:18:39.837
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":155,"skipped":2822,"failed":0}
------------------------------
• [4.507 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:18:35.353
    Apr 25 20:18:35.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir 04/25/23 20:18:35.354
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:18:35.405
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:18:35.419
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 04/25/23 20:18:35.432
    Apr 25 20:18:35.483: INFO: Waiting up to 5m0s for pod "pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa" in namespace "emptydir-2036" to be "Succeeded or Failed"
    Apr 25 20:18:35.496: INFO: Pod "pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa": Phase="Pending", Reason="", readiness=false. Elapsed: 12.538096ms
    Apr 25 20:18:37.555: INFO: Pod "pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072194906s
    Apr 25 20:18:39.521: INFO: Pod "pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037840338s
    STEP: Saw pod success 04/25/23 20:18:39.522
    Apr 25 20:18:39.522: INFO: Pod "pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa" satisfied condition "Succeeded or Failed"
    Apr 25 20:18:39.559: INFO: Trying to get logs from node 10.10.21.190 pod pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa container test-container: <nil>
    STEP: delete the pod 04/25/23 20:18:39.679
    Apr 25 20:18:39.769: INFO: Waiting for pod pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa to disappear
    Apr 25 20:18:39.820: INFO: Pod pod-7110c19c-60a8-4c34-b0b4-4b7c0bd945fa no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 25 20:18:39.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2036" for this suite. 04/25/23 20:18:39.837
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:18:39.862
Apr 25 20:18:39.862: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:18:39.865
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:18:39.909
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:18:39.924
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-52e02780-0d38-4093-bcf7-722cda43b43b 04/25/23 20:18:39.939
STEP: Creating a pod to test consume secrets 04/25/23 20:18:39.974
Apr 25 20:18:40.008: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273" in namespace "projected-1811" to be "Succeeded or Failed"
Apr 25 20:18:40.052: INFO: Pod "pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273": Phase="Pending", Reason="", readiness=false. Elapsed: 43.359799ms
Apr 25 20:18:42.069: INFO: Pod "pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060750113s
Apr 25 20:18:44.102: INFO: Pod "pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273": Phase="Pending", Reason="", readiness=false. Elapsed: 4.093088182s
Apr 25 20:18:46.093: INFO: Pod "pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.084574913s
STEP: Saw pod success 04/25/23 20:18:46.093
Apr 25 20:18:46.093: INFO: Pod "pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273" satisfied condition "Succeeded or Failed"
Apr 25 20:18:46.152: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/25/23 20:18:46.187
Apr 25 20:18:46.314: INFO: Waiting for pod pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273 to disappear
Apr 25 20:18:46.328: INFO: Pod pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 25 20:18:46.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1811" for this suite. 04/25/23 20:18:46.344
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":156,"skipped":2825,"failed":0}
------------------------------
• [SLOW TEST] [6.509 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:18:39.862
    Apr 25 20:18:39.862: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:18:39.865
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:18:39.909
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:18:39.924
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-52e02780-0d38-4093-bcf7-722cda43b43b 04/25/23 20:18:39.939
    STEP: Creating a pod to test consume secrets 04/25/23 20:18:39.974
    Apr 25 20:18:40.008: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273" in namespace "projected-1811" to be "Succeeded or Failed"
    Apr 25 20:18:40.052: INFO: Pod "pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273": Phase="Pending", Reason="", readiness=false. Elapsed: 43.359799ms
    Apr 25 20:18:42.069: INFO: Pod "pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060750113s
    Apr 25 20:18:44.102: INFO: Pod "pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273": Phase="Pending", Reason="", readiness=false. Elapsed: 4.093088182s
    Apr 25 20:18:46.093: INFO: Pod "pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.084574913s
    STEP: Saw pod success 04/25/23 20:18:46.093
    Apr 25 20:18:46.093: INFO: Pod "pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273" satisfied condition "Succeeded or Failed"
    Apr 25 20:18:46.152: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/25/23 20:18:46.187
    Apr 25 20:18:46.314: INFO: Waiting for pod pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273 to disappear
    Apr 25 20:18:46.328: INFO: Pod pod-projected-secrets-5c9c5421-ac47-49b2-b56c-2b0cde96d273 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 25 20:18:46.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1811" for this suite. 04/25/23 20:18:46.344
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:18:46.38
Apr 25 20:18:46.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-runtime 04/25/23 20:18:46.382
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:18:46.426
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:18:46.442
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 04/25/23 20:18:46.455
STEP: wait for the container to reach Succeeded 04/25/23 20:18:46.484
STEP: get the container status 04/25/23 20:18:50.567
STEP: the container should be terminated 04/25/23 20:18:50.58
STEP: the termination message should be set 04/25/23 20:18:50.58
Apr 25 20:18:50.580: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 04/25/23 20:18:50.58
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 25 20:18:50.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8648" for this suite. 04/25/23 20:18:50.671
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":157,"skipped":2847,"failed":0}
------------------------------
• [4.314 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:18:46.38
    Apr 25 20:18:46.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-runtime 04/25/23 20:18:46.382
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:18:46.426
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:18:46.442
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 04/25/23 20:18:46.455
    STEP: wait for the container to reach Succeeded 04/25/23 20:18:46.484
    STEP: get the container status 04/25/23 20:18:50.567
    STEP: the container should be terminated 04/25/23 20:18:50.58
    STEP: the termination message should be set 04/25/23 20:18:50.58
    Apr 25 20:18:50.580: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 04/25/23 20:18:50.58
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 25 20:18:50.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-8648" for this suite. 04/25/23 20:18:50.671
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:18:50.699
Apr 25 20:18:50.699: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 20:18:50.704
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:18:50.746
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:18:50.76
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 04/25/23 20:18:50.776
Apr 25 20:18:50.815: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a" in namespace "downward-api-1734" to be "Succeeded or Failed"
Apr 25 20:18:50.831: INFO: Pod "downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.901673ms
Apr 25 20:18:52.865: INFO: Pod "downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05015664s
Apr 25 20:18:54.846: INFO: Pod "downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031632614s
STEP: Saw pod success 04/25/23 20:18:54.846
Apr 25 20:18:54.847: INFO: Pod "downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a" satisfied condition "Succeeded or Failed"
Apr 25 20:18:54.888: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a container client-container: <nil>
STEP: delete the pod 04/25/23 20:18:54.914
Apr 25 20:18:54.960: INFO: Waiting for pod downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a to disappear
Apr 25 20:18:54.979: INFO: Pod downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 25 20:18:54.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1734" for this suite. 04/25/23 20:18:55.008
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":158,"skipped":2865,"failed":0}
------------------------------
• [4.334 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:18:50.699
    Apr 25 20:18:50.699: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 20:18:50.704
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:18:50.746
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:18:50.76
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 04/25/23 20:18:50.776
    Apr 25 20:18:50.815: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a" in namespace "downward-api-1734" to be "Succeeded or Failed"
    Apr 25 20:18:50.831: INFO: Pod "downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.901673ms
    Apr 25 20:18:52.865: INFO: Pod "downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05015664s
    Apr 25 20:18:54.846: INFO: Pod "downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031632614s
    STEP: Saw pod success 04/25/23 20:18:54.846
    Apr 25 20:18:54.847: INFO: Pod "downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a" satisfied condition "Succeeded or Failed"
    Apr 25 20:18:54.888: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a container client-container: <nil>
    STEP: delete the pod 04/25/23 20:18:54.914
    Apr 25 20:18:54.960: INFO: Waiting for pod downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a to disappear
    Apr 25 20:18:54.979: INFO: Pod downwardapi-volume-d2ea3f39-72e3-4345-b1f1-06efbebb4d9a no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 25 20:18:54.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1734" for this suite. 04/25/23 20:18:55.008
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:18:55.037
Apr 25 20:18:55.038: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename init-container 04/25/23 20:18:55.043
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:18:55.079
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:18:55.093
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 04/25/23 20:18:55.106
Apr 25 20:18:55.107: INFO: PodSpec: initContainers in spec.initContainers
Apr 25 20:19:44.481: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-e59163fb-b2c7-4dd9-9f0c-e31fd584e446", GenerateName:"", Namespace:"init-container-7896", SelfLink:"", UID:"552253be-d701-4256-b1cc-46dbd5bb2a66", ResourceVersion:"32392", Generation:0, CreationTimestamp:time.Date(2023, time.April, 25, 20, 18, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"106969775"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"286c674f784abd88ac5eff516ff4005d3d03a228478a86ae637f19ea74b0069b", "cni.projectcalico.org/podIP":"172.30.142.179/32", "cni.projectcalico.org/podIPs":"172.30.142.179/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 25, 20, 18, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00109d4d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 25, 20, 18, 56, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00109d500), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 25, 20, 19, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00109d530), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-ngzfg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc006e19b60), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-ngzfg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-ngzfg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-ngzfg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004024cb8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.10.21.190", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000b1c070), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004024d40)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004024d60)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004024d68), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc004024d6c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc004d6cc00), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 25, 20, 18, 55, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 25, 20, 18, 55, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 25, 20, 18, 55, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 25, 20, 18, 55, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.21.190", PodIP:"172.30.142.179", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.30.142.179"}}, StartTime:time.Date(2023, time.April, 25, 20, 18, 55, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000b1c150)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000b1c1c0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://0c46d87f88d918e378364175a3af59c1c3209d0ac684b540de813a845d6de26b", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc006e19be0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc006e19bc0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc004024def)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 25 20:19:44.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7896" for this suite. 04/25/23 20:19:44.506
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":159,"skipped":2870,"failed":0}
------------------------------
• [SLOW TEST] [49.498 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:18:55.037
    Apr 25 20:18:55.038: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename init-container 04/25/23 20:18:55.043
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:18:55.079
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:18:55.093
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 04/25/23 20:18:55.106
    Apr 25 20:18:55.107: INFO: PodSpec: initContainers in spec.initContainers
    Apr 25 20:19:44.481: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-e59163fb-b2c7-4dd9-9f0c-e31fd584e446", GenerateName:"", Namespace:"init-container-7896", SelfLink:"", UID:"552253be-d701-4256-b1cc-46dbd5bb2a66", ResourceVersion:"32392", Generation:0, CreationTimestamp:time.Date(2023, time.April, 25, 20, 18, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"106969775"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"286c674f784abd88ac5eff516ff4005d3d03a228478a86ae637f19ea74b0069b", "cni.projectcalico.org/podIP":"172.30.142.179/32", "cni.projectcalico.org/podIPs":"172.30.142.179/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 25, 20, 18, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00109d4d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 25, 20, 18, 56, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00109d500), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 25, 20, 19, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00109d530), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-ngzfg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc006e19b60), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-ngzfg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-ngzfg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-ngzfg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004024cb8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.10.21.190", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000b1c070), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004024d40)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004024d60)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004024d68), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc004024d6c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc004d6cc00), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 25, 20, 18, 55, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 25, 20, 18, 55, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 25, 20, 18, 55, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 25, 20, 18, 55, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.21.190", PodIP:"172.30.142.179", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.30.142.179"}}, StartTime:time.Date(2023, time.April, 25, 20, 18, 55, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000b1c150)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000b1c1c0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://0c46d87f88d918e378364175a3af59c1c3209d0ac684b540de813a845d6de26b", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc006e19be0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc006e19bc0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc004024def)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 25 20:19:44.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-7896" for this suite. 04/25/23 20:19:44.506
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:19:44.548
Apr 25 20:19:44.548: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename proxy 04/25/23 20:19:44.55
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:19:44.615
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:19:44.629
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Apr 25 20:19:44.644: INFO: Creating pod...
Apr 25 20:19:44.686: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-2421" to be "running"
Apr 25 20:19:44.713: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 27.393892ms
Apr 25 20:19:46.728: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.042369339s
Apr 25 20:19:46.728: INFO: Pod "agnhost" satisfied condition "running"
Apr 25 20:19:46.728: INFO: Creating service...
Apr 25 20:19:46.768: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/pods/agnhost/proxy?method=DELETE
Apr 25 20:19:46.835: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 25 20:19:46.835: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/pods/agnhost/proxy?method=OPTIONS
Apr 25 20:19:46.854: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 25 20:19:46.855: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/pods/agnhost/proxy?method=PATCH
Apr 25 20:19:46.874: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 25 20:19:46.875: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/pods/agnhost/proxy?method=POST
Apr 25 20:19:46.894: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 25 20:19:46.894: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/pods/agnhost/proxy?method=PUT
Apr 25 20:19:46.913: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 25 20:19:46.913: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/services/e2e-proxy-test-service/proxy?method=DELETE
Apr 25 20:19:46.937: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 25 20:19:46.937: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/services/e2e-proxy-test-service/proxy?method=OPTIONS
Apr 25 20:19:46.965: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 25 20:19:46.965: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/services/e2e-proxy-test-service/proxy?method=PATCH
Apr 25 20:19:47.005: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 25 20:19:47.005: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/services/e2e-proxy-test-service/proxy?method=POST
Apr 25 20:19:47.029: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 25 20:19:47.029: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/services/e2e-proxy-test-service/proxy?method=PUT
Apr 25 20:19:47.055: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 25 20:19:47.055: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/pods/agnhost/proxy?method=GET
Apr 25 20:19:47.069: INFO: http.Client request:GET StatusCode:301
Apr 25 20:19:47.069: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/services/e2e-proxy-test-service/proxy?method=GET
Apr 25 20:19:47.087: INFO: http.Client request:GET StatusCode:301
Apr 25 20:19:47.087: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/pods/agnhost/proxy?method=HEAD
Apr 25 20:19:47.102: INFO: http.Client request:HEAD StatusCode:301
Apr 25 20:19:47.102: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/services/e2e-proxy-test-service/proxy?method=HEAD
Apr 25 20:19:47.119: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Apr 25 20:19:47.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2421" for this suite. 04/25/23 20:19:47.135
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":160,"skipped":2912,"failed":0}
------------------------------
• [2.614 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:19:44.548
    Apr 25 20:19:44.548: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename proxy 04/25/23 20:19:44.55
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:19:44.615
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:19:44.629
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Apr 25 20:19:44.644: INFO: Creating pod...
    Apr 25 20:19:44.686: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-2421" to be "running"
    Apr 25 20:19:44.713: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 27.393892ms
    Apr 25 20:19:46.728: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.042369339s
    Apr 25 20:19:46.728: INFO: Pod "agnhost" satisfied condition "running"
    Apr 25 20:19:46.728: INFO: Creating service...
    Apr 25 20:19:46.768: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/pods/agnhost/proxy?method=DELETE
    Apr 25 20:19:46.835: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 25 20:19:46.835: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/pods/agnhost/proxy?method=OPTIONS
    Apr 25 20:19:46.854: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 25 20:19:46.855: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/pods/agnhost/proxy?method=PATCH
    Apr 25 20:19:46.874: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 25 20:19:46.875: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/pods/agnhost/proxy?method=POST
    Apr 25 20:19:46.894: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 25 20:19:46.894: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/pods/agnhost/proxy?method=PUT
    Apr 25 20:19:46.913: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 25 20:19:46.913: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/services/e2e-proxy-test-service/proxy?method=DELETE
    Apr 25 20:19:46.937: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 25 20:19:46.937: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Apr 25 20:19:46.965: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 25 20:19:46.965: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/services/e2e-proxy-test-service/proxy?method=PATCH
    Apr 25 20:19:47.005: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 25 20:19:47.005: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/services/e2e-proxy-test-service/proxy?method=POST
    Apr 25 20:19:47.029: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 25 20:19:47.029: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/services/e2e-proxy-test-service/proxy?method=PUT
    Apr 25 20:19:47.055: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 25 20:19:47.055: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/pods/agnhost/proxy?method=GET
    Apr 25 20:19:47.069: INFO: http.Client request:GET StatusCode:301
    Apr 25 20:19:47.069: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/services/e2e-proxy-test-service/proxy?method=GET
    Apr 25 20:19:47.087: INFO: http.Client request:GET StatusCode:301
    Apr 25 20:19:47.087: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/pods/agnhost/proxy?method=HEAD
    Apr 25 20:19:47.102: INFO: http.Client request:HEAD StatusCode:301
    Apr 25 20:19:47.102: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2421/services/e2e-proxy-test-service/proxy?method=HEAD
    Apr 25 20:19:47.119: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Apr 25 20:19:47.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-2421" for this suite. 04/25/23 20:19:47.135
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:19:47.172
Apr 25 20:19:47.172: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubelet-test 04/25/23 20:19:47.174
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:19:47.222
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:19:47.236
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 25 20:19:51.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7125" for this suite. 04/25/23 20:19:51.351
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":161,"skipped":2931,"failed":0}
------------------------------
• [4.206 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:19:47.172
    Apr 25 20:19:47.172: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubelet-test 04/25/23 20:19:47.174
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:19:47.222
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:19:47.236
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 25 20:19:51.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-7125" for this suite. 04/25/23 20:19:51.351
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:19:51.391
Apr 25 20:19:51.391: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename resourcequota 04/25/23 20:19:51.393
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:19:51.433
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:19:51.445
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 04/25/23 20:20:08.473
STEP: Creating a ResourceQuota 04/25/23 20:20:13.486
STEP: Ensuring resource quota status is calculated 04/25/23 20:20:13.501
STEP: Creating a ConfigMap 04/25/23 20:20:15.524
STEP: Ensuring resource quota status captures configMap creation 04/25/23 20:20:15.552
STEP: Deleting a ConfigMap 04/25/23 20:20:17.568
STEP: Ensuring resource quota status released usage 04/25/23 20:20:17.602
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 25 20:20:19.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9358" for this suite. 04/25/23 20:20:19.643
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":162,"skipped":2952,"failed":0}
------------------------------
• [SLOW TEST] [28.277 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:19:51.391
    Apr 25 20:19:51.391: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename resourcequota 04/25/23 20:19:51.393
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:19:51.433
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:19:51.445
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 04/25/23 20:20:08.473
    STEP: Creating a ResourceQuota 04/25/23 20:20:13.486
    STEP: Ensuring resource quota status is calculated 04/25/23 20:20:13.501
    STEP: Creating a ConfigMap 04/25/23 20:20:15.524
    STEP: Ensuring resource quota status captures configMap creation 04/25/23 20:20:15.552
    STEP: Deleting a ConfigMap 04/25/23 20:20:17.568
    STEP: Ensuring resource quota status released usage 04/25/23 20:20:17.602
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 25 20:20:19.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9358" for this suite. 04/25/23 20:20:19.643
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:20:19.668
Apr 25 20:20:19.670: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 20:20:19.673
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:20:19.714
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:20:19.73
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 04/25/23 20:20:19.746
Apr 25 20:20:19.777: INFO: Waiting up to 5m0s for pod "downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd" in namespace "downward-api-5694" to be "Succeeded or Failed"
Apr 25 20:20:19.791: INFO: Pod "downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd": Phase="Pending", Reason="", readiness=false. Elapsed: 13.927567ms
Apr 25 20:20:21.806: INFO: Pod "downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02909269s
Apr 25 20:20:23.807: INFO: Pod "downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02995569s
STEP: Saw pod success 04/25/23 20:20:23.807
Apr 25 20:20:23.807: INFO: Pod "downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd" satisfied condition "Succeeded or Failed"
Apr 25 20:20:23.823: INFO: Trying to get logs from node 10.10.21.190 pod downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd container dapi-container: <nil>
STEP: delete the pod 04/25/23 20:20:23.865
Apr 25 20:20:23.921: INFO: Waiting for pod downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd to disappear
Apr 25 20:20:23.935: INFO: Pod downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 25 20:20:23.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5694" for this suite. 04/25/23 20:20:23.953
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":163,"skipped":2952,"failed":0}
------------------------------
• [4.312 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:20:19.668
    Apr 25 20:20:19.670: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 20:20:19.673
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:20:19.714
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:20:19.73
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 04/25/23 20:20:19.746
    Apr 25 20:20:19.777: INFO: Waiting up to 5m0s for pod "downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd" in namespace "downward-api-5694" to be "Succeeded or Failed"
    Apr 25 20:20:19.791: INFO: Pod "downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd": Phase="Pending", Reason="", readiness=false. Elapsed: 13.927567ms
    Apr 25 20:20:21.806: INFO: Pod "downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02909269s
    Apr 25 20:20:23.807: INFO: Pod "downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02995569s
    STEP: Saw pod success 04/25/23 20:20:23.807
    Apr 25 20:20:23.807: INFO: Pod "downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd" satisfied condition "Succeeded or Failed"
    Apr 25 20:20:23.823: INFO: Trying to get logs from node 10.10.21.190 pod downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd container dapi-container: <nil>
    STEP: delete the pod 04/25/23 20:20:23.865
    Apr 25 20:20:23.921: INFO: Waiting for pod downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd to disappear
    Apr 25 20:20:23.935: INFO: Pod downward-api-4d6c60a3-b82d-4d96-925d-ab3a1a7e6acd no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 25 20:20:23.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5694" for this suite. 04/25/23 20:20:23.953
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:20:23.98
Apr 25 20:20:23.981: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename secrets 04/25/23 20:20:23.984
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:20:24.033
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:20:24.097
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-cce79e6a-dada-4f49-bad7-a9d194558634 04/25/23 20:20:24.141
STEP: Creating a pod to test consume secrets 04/25/23 20:20:24.162
Apr 25 20:20:24.222: INFO: Waiting up to 5m0s for pod "pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747" in namespace "secrets-2142" to be "Succeeded or Failed"
Apr 25 20:20:24.241: INFO: Pod "pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747": Phase="Pending", Reason="", readiness=false. Elapsed: 18.481373ms
Apr 25 20:20:26.271: INFO: Pod "pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048693282s
Apr 25 20:20:28.263: INFO: Pod "pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039990434s
STEP: Saw pod success 04/25/23 20:20:28.263
Apr 25 20:20:28.263: INFO: Pod "pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747" satisfied condition "Succeeded or Failed"
Apr 25 20:20:28.278: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747 container secret-volume-test: <nil>
STEP: delete the pod 04/25/23 20:20:28.308
Apr 25 20:20:28.347: INFO: Waiting for pod pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747 to disappear
Apr 25 20:20:28.365: INFO: Pod pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 25 20:20:28.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2142" for this suite. 04/25/23 20:20:28.381
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":164,"skipped":2953,"failed":0}
------------------------------
• [4.430 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:20:23.98
    Apr 25 20:20:23.981: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename secrets 04/25/23 20:20:23.984
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:20:24.033
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:20:24.097
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-cce79e6a-dada-4f49-bad7-a9d194558634 04/25/23 20:20:24.141
    STEP: Creating a pod to test consume secrets 04/25/23 20:20:24.162
    Apr 25 20:20:24.222: INFO: Waiting up to 5m0s for pod "pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747" in namespace "secrets-2142" to be "Succeeded or Failed"
    Apr 25 20:20:24.241: INFO: Pod "pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747": Phase="Pending", Reason="", readiness=false. Elapsed: 18.481373ms
    Apr 25 20:20:26.271: INFO: Pod "pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048693282s
    Apr 25 20:20:28.263: INFO: Pod "pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039990434s
    STEP: Saw pod success 04/25/23 20:20:28.263
    Apr 25 20:20:28.263: INFO: Pod "pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747" satisfied condition "Succeeded or Failed"
    Apr 25 20:20:28.278: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747 container secret-volume-test: <nil>
    STEP: delete the pod 04/25/23 20:20:28.308
    Apr 25 20:20:28.347: INFO: Waiting for pod pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747 to disappear
    Apr 25 20:20:28.365: INFO: Pod pod-secrets-c54b6dbf-3cd3-4501-a140-a95ccd29d747 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 25 20:20:28.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2142" for this suite. 04/25/23 20:20:28.381
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:20:28.412
Apr 25 20:20:28.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:20:28.416
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:20:28.454
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:20:28.467
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 04/25/23 20:20:28.483
Apr 25 20:20:28.512: INFO: Waiting up to 5m0s for pod "annotationupdateb7bc01dc-9269-4fd0-85cf-fd45a5cbb98f" in namespace "projected-1978" to be "running and ready"
Apr 25 20:20:28.528: INFO: Pod "annotationupdateb7bc01dc-9269-4fd0-85cf-fd45a5cbb98f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.030815ms
Apr 25 20:20:28.529: INFO: The phase of Pod annotationupdateb7bc01dc-9269-4fd0-85cf-fd45a5cbb98f is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:20:30.545: INFO: Pod "annotationupdateb7bc01dc-9269-4fd0-85cf-fd45a5cbb98f": Phase="Running", Reason="", readiness=true. Elapsed: 2.032816356s
Apr 25 20:20:30.545: INFO: The phase of Pod annotationupdateb7bc01dc-9269-4fd0-85cf-fd45a5cbb98f is Running (Ready = true)
Apr 25 20:20:30.545: INFO: Pod "annotationupdateb7bc01dc-9269-4fd0-85cf-fd45a5cbb98f" satisfied condition "running and ready"
Apr 25 20:20:31.134: INFO: Successfully updated pod "annotationupdateb7bc01dc-9269-4fd0-85cf-fd45a5cbb98f"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 25 20:20:35.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1978" for this suite. 04/25/23 20:20:35.241
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":165,"skipped":2956,"failed":0}
------------------------------
• [SLOW TEST] [6.862 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:20:28.412
    Apr 25 20:20:28.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:20:28.416
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:20:28.454
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:20:28.467
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 04/25/23 20:20:28.483
    Apr 25 20:20:28.512: INFO: Waiting up to 5m0s for pod "annotationupdateb7bc01dc-9269-4fd0-85cf-fd45a5cbb98f" in namespace "projected-1978" to be "running and ready"
    Apr 25 20:20:28.528: INFO: Pod "annotationupdateb7bc01dc-9269-4fd0-85cf-fd45a5cbb98f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.030815ms
    Apr 25 20:20:28.529: INFO: The phase of Pod annotationupdateb7bc01dc-9269-4fd0-85cf-fd45a5cbb98f is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:20:30.545: INFO: Pod "annotationupdateb7bc01dc-9269-4fd0-85cf-fd45a5cbb98f": Phase="Running", Reason="", readiness=true. Elapsed: 2.032816356s
    Apr 25 20:20:30.545: INFO: The phase of Pod annotationupdateb7bc01dc-9269-4fd0-85cf-fd45a5cbb98f is Running (Ready = true)
    Apr 25 20:20:30.545: INFO: Pod "annotationupdateb7bc01dc-9269-4fd0-85cf-fd45a5cbb98f" satisfied condition "running and ready"
    Apr 25 20:20:31.134: INFO: Successfully updated pod "annotationupdateb7bc01dc-9269-4fd0-85cf-fd45a5cbb98f"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 25 20:20:35.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1978" for this suite. 04/25/23 20:20:35.241
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:20:35.278
Apr 25 20:20:35.279: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename limitrange 04/25/23 20:20:35.283
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:20:35.328
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:20:35.342
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 04/25/23 20:20:35.356
STEP: Setting up watch 04/25/23 20:20:35.356
STEP: Submitting a LimitRange 04/25/23 20:20:35.491
STEP: Verifying LimitRange creation was observed 04/25/23 20:20:35.508
STEP: Fetching the LimitRange to ensure it has proper values 04/25/23 20:20:35.508
Apr 25 20:20:35.522: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 25 20:20:35.522: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 04/25/23 20:20:35.522
STEP: Ensuring Pod has resource requirements applied from LimitRange 04/25/23 20:20:35.539
Apr 25 20:20:35.554: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 25 20:20:35.554: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 04/25/23 20:20:35.554
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 04/25/23 20:20:35.596
Apr 25 20:20:35.629: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Apr 25 20:20:35.629: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 04/25/23 20:20:35.629
STEP: Failing to create a Pod with more than max resources 04/25/23 20:20:35.636
STEP: Updating a LimitRange 04/25/23 20:20:35.647
STEP: Verifying LimitRange updating is effective 04/25/23 20:20:35.669
STEP: Creating a Pod with less than former min resources 04/25/23 20:20:37.685
STEP: Failing to create a Pod with more than max resources 04/25/23 20:20:37.703
STEP: Deleting a LimitRange 04/25/23 20:20:37.713
STEP: Verifying the LimitRange was deleted 04/25/23 20:20:37.736
Apr 25 20:20:42.753: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 04/25/23 20:20:42.753
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Apr 25 20:20:42.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-2508" for this suite. 04/25/23 20:20:42.814
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":166,"skipped":2970,"failed":0}
------------------------------
• [SLOW TEST] [7.559 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:20:35.278
    Apr 25 20:20:35.279: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename limitrange 04/25/23 20:20:35.283
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:20:35.328
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:20:35.342
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 04/25/23 20:20:35.356
    STEP: Setting up watch 04/25/23 20:20:35.356
    STEP: Submitting a LimitRange 04/25/23 20:20:35.491
    STEP: Verifying LimitRange creation was observed 04/25/23 20:20:35.508
    STEP: Fetching the LimitRange to ensure it has proper values 04/25/23 20:20:35.508
    Apr 25 20:20:35.522: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Apr 25 20:20:35.522: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 04/25/23 20:20:35.522
    STEP: Ensuring Pod has resource requirements applied from LimitRange 04/25/23 20:20:35.539
    Apr 25 20:20:35.554: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Apr 25 20:20:35.554: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 04/25/23 20:20:35.554
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 04/25/23 20:20:35.596
    Apr 25 20:20:35.629: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Apr 25 20:20:35.629: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 04/25/23 20:20:35.629
    STEP: Failing to create a Pod with more than max resources 04/25/23 20:20:35.636
    STEP: Updating a LimitRange 04/25/23 20:20:35.647
    STEP: Verifying LimitRange updating is effective 04/25/23 20:20:35.669
    STEP: Creating a Pod with less than former min resources 04/25/23 20:20:37.685
    STEP: Failing to create a Pod with more than max resources 04/25/23 20:20:37.703
    STEP: Deleting a LimitRange 04/25/23 20:20:37.713
    STEP: Verifying the LimitRange was deleted 04/25/23 20:20:37.736
    Apr 25 20:20:42.753: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 04/25/23 20:20:42.753
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Apr 25 20:20:42.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-2508" for this suite. 04/25/23 20:20:42.814
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:20:42.844
Apr 25 20:20:42.844: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 20:20:42.846
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:20:42.89
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:20:42.905
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 04/25/23 20:20:42.918
Apr 25 20:20:42.956: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6" in namespace "downward-api-5947" to be "Succeeded or Failed"
Apr 25 20:20:42.972: INFO: Pod "downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6": Phase="Pending", Reason="", readiness=false. Elapsed: 16.145416ms
Apr 25 20:20:44.988: INFO: Pod "downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03250027s
Apr 25 20:20:46.993: INFO: Pod "downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037159679s
STEP: Saw pod success 04/25/23 20:20:46.993
Apr 25 20:20:46.994: INFO: Pod "downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6" satisfied condition "Succeeded or Failed"
Apr 25 20:20:47.008: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6 container client-container: <nil>
STEP: delete the pod 04/25/23 20:20:47.038
Apr 25 20:20:47.074: INFO: Waiting for pod downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6 to disappear
Apr 25 20:20:47.089: INFO: Pod downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 25 20:20:47.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5947" for this suite. 04/25/23 20:20:47.108
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":167,"skipped":2991,"failed":0}
------------------------------
• [4.291 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:20:42.844
    Apr 25 20:20:42.844: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 20:20:42.846
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:20:42.89
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:20:42.905
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 04/25/23 20:20:42.918
    Apr 25 20:20:42.956: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6" in namespace "downward-api-5947" to be "Succeeded or Failed"
    Apr 25 20:20:42.972: INFO: Pod "downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6": Phase="Pending", Reason="", readiness=false. Elapsed: 16.145416ms
    Apr 25 20:20:44.988: INFO: Pod "downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03250027s
    Apr 25 20:20:46.993: INFO: Pod "downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037159679s
    STEP: Saw pod success 04/25/23 20:20:46.993
    Apr 25 20:20:46.994: INFO: Pod "downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6" satisfied condition "Succeeded or Failed"
    Apr 25 20:20:47.008: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6 container client-container: <nil>
    STEP: delete the pod 04/25/23 20:20:47.038
    Apr 25 20:20:47.074: INFO: Waiting for pod downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6 to disappear
    Apr 25 20:20:47.089: INFO: Pod downwardapi-volume-cfbe0ea7-012d-4cfb-92f3-014ca4186dc6 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 25 20:20:47.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5947" for this suite. 04/25/23 20:20:47.108
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:20:47.139
Apr 25 20:20:47.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename dns 04/25/23 20:20:47.142
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:20:47.184
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:20:47.198
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 04/25/23 20:20:47.212
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5475 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5475;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5475 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5475;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5475.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5475.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5475.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5475.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5475.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5475.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5475.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5475.svc;check="$$(dig +notcp +noall +answer +search 28.154.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.154.28_udp@PTR;check="$$(dig +tcp +noall +answer +search 28.154.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.154.28_tcp@PTR;sleep 1; done
 04/25/23 20:20:47.277
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5475 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5475;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5475 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5475;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5475.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5475.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5475.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5475.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5475.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5475.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5475.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5475.svc;check="$$(dig +notcp +noall +answer +search 28.154.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.154.28_udp@PTR;check="$$(dig +tcp +noall +answer +search 28.154.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.154.28_tcp@PTR;sleep 1; done
 04/25/23 20:20:47.277
STEP: creating a pod to probe DNS 04/25/23 20:20:47.277
STEP: submitting the pod to kubernetes 04/25/23 20:20:47.277
Apr 25 20:20:47.306: INFO: Waiting up to 15m0s for pod "dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c" in namespace "dns-5475" to be "running"
Apr 25 20:20:47.322: INFO: Pod "dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.181458ms
Apr 25 20:20:49.338: INFO: Pod "dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031132303s
Apr 25 20:20:51.341: INFO: Pod "dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c": Phase="Running", Reason="", readiness=true. Elapsed: 4.03467765s
Apr 25 20:20:51.341: INFO: Pod "dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c" satisfied condition "running"
STEP: retrieving the pod 04/25/23 20:20:51.341
STEP: looking for the results for each expected name from probers 04/25/23 20:20:51.356
Apr 25 20:20:51.408: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:51.427: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:51.446: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:51.479: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:51.503: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:51.551: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:51.592: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:51.699: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:51.719: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:51.766: INFO: Unable to read jessie_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:51.785: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:51.811: INFO: Unable to read jessie_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:51.830: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:51.946: INFO: Lookups using dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5475 wheezy_tcp@dns-test-service.dns-5475 wheezy_udp@dns-test-service.dns-5475.svc wheezy_tcp@dns-test-service.dns-5475.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5475.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5475 jessie_tcp@dns-test-service.dns-5475 jessie_udp@dns-test-service.dns-5475.svc jessie_tcp@dns-test-service.dns-5475.svc]

Apr 25 20:20:56.967: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:56.988: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:57.008: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:57.026: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:57.050: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:57.072: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:57.216: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:57.235: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:57.255: INFO: Unable to read jessie_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:57.274: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:57.296: INFO: Unable to read jessie_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:57.319: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:20:57.444: INFO: Lookups using dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5475 wheezy_tcp@dns-test-service.dns-5475 wheezy_udp@dns-test-service.dns-5475.svc wheezy_tcp@dns-test-service.dns-5475.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5475 jessie_tcp@dns-test-service.dns-5475 jessie_udp@dns-test-service.dns-5475.svc jessie_tcp@dns-test-service.dns-5475.svc]

Apr 25 20:21:01.968: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:01.985: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:02.005: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:02.026: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:02.076: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:02.095: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:02.271: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:02.294: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:02.312: INFO: Unable to read jessie_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:02.330: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:02.352: INFO: Unable to read jessie_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:02.387: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:02.515: INFO: Lookups using dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5475 wheezy_tcp@dns-test-service.dns-5475 wheezy_udp@dns-test-service.dns-5475.svc wheezy_tcp@dns-test-service.dns-5475.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5475 jessie_tcp@dns-test-service.dns-5475 jessie_udp@dns-test-service.dns-5475.svc jessie_tcp@dns-test-service.dns-5475.svc]

Apr 25 20:21:06.970: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:06.992: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:07.014: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:07.034: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:07.056: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:07.077: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:07.221: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:07.241: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:07.261: INFO: Unable to read jessie_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:07.283: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:07.306: INFO: Unable to read jessie_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:07.326: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:07.453: INFO: Lookups using dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5475 wheezy_tcp@dns-test-service.dns-5475 wheezy_udp@dns-test-service.dns-5475.svc wheezy_tcp@dns-test-service.dns-5475.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5475 jessie_tcp@dns-test-service.dns-5475 jessie_udp@dns-test-service.dns-5475.svc jessie_tcp@dns-test-service.dns-5475.svc]

Apr 25 20:21:11.973: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:11.993: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:12.016: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:12.037: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:12.059: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:12.080: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:12.234: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:12.286: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:12.307: INFO: Unable to read jessie_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:12.326: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:12.350: INFO: Unable to read jessie_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:12.370: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:12.498: INFO: Lookups using dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5475 wheezy_tcp@dns-test-service.dns-5475 wheezy_udp@dns-test-service.dns-5475.svc wheezy_tcp@dns-test-service.dns-5475.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5475 jessie_tcp@dns-test-service.dns-5475 jessie_udp@dns-test-service.dns-5475.svc jessie_tcp@dns-test-service.dns-5475.svc]

Apr 25 20:21:16.968: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:16.987: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:17.007: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:17.027: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:17.049: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:17.070: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:17.212: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:17.234: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:17.253: INFO: Unable to read jessie_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:17.272: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:17.298: INFO: Unable to read jessie_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:17.319: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
Apr 25 20:21:17.490: INFO: Lookups using dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5475 wheezy_tcp@dns-test-service.dns-5475 wheezy_udp@dns-test-service.dns-5475.svc wheezy_tcp@dns-test-service.dns-5475.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5475 jessie_tcp@dns-test-service.dns-5475 jessie_udp@dns-test-service.dns-5475.svc jessie_tcp@dns-test-service.dns-5475.svc]

Apr 25 20:21:22.454: INFO: DNS probes using dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c succeeded

STEP: deleting the pod 04/25/23 20:21:22.454
STEP: deleting the test service 04/25/23 20:21:22.494
STEP: deleting the test headless service 04/25/23 20:21:22.589
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 25 20:21:22.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5475" for this suite. 04/25/23 20:21:22.642
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":168,"skipped":3001,"failed":0}
------------------------------
• [SLOW TEST] [35.535 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:20:47.139
    Apr 25 20:20:47.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename dns 04/25/23 20:20:47.142
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:20:47.184
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:20:47.198
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 04/25/23 20:20:47.212
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5475 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5475;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5475 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5475;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5475.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5475.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5475.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5475.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5475.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5475.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5475.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5475.svc;check="$$(dig +notcp +noall +answer +search 28.154.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.154.28_udp@PTR;check="$$(dig +tcp +noall +answer +search 28.154.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.154.28_tcp@PTR;sleep 1; done
     04/25/23 20:20:47.277
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5475 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5475;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5475 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5475;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5475.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5475.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5475.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5475.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5475.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5475.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5475.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5475.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5475.svc;check="$$(dig +notcp +noall +answer +search 28.154.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.154.28_udp@PTR;check="$$(dig +tcp +noall +answer +search 28.154.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.154.28_tcp@PTR;sleep 1; done
     04/25/23 20:20:47.277
    STEP: creating a pod to probe DNS 04/25/23 20:20:47.277
    STEP: submitting the pod to kubernetes 04/25/23 20:20:47.277
    Apr 25 20:20:47.306: INFO: Waiting up to 15m0s for pod "dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c" in namespace "dns-5475" to be "running"
    Apr 25 20:20:47.322: INFO: Pod "dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.181458ms
    Apr 25 20:20:49.338: INFO: Pod "dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031132303s
    Apr 25 20:20:51.341: INFO: Pod "dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c": Phase="Running", Reason="", readiness=true. Elapsed: 4.03467765s
    Apr 25 20:20:51.341: INFO: Pod "dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c" satisfied condition "running"
    STEP: retrieving the pod 04/25/23 20:20:51.341
    STEP: looking for the results for each expected name from probers 04/25/23 20:20:51.356
    Apr 25 20:20:51.408: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:51.427: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:51.446: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:51.479: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:51.503: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:51.551: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:51.592: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:51.699: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:51.719: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:51.766: INFO: Unable to read jessie_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:51.785: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:51.811: INFO: Unable to read jessie_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:51.830: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:51.946: INFO: Lookups using dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5475 wheezy_tcp@dns-test-service.dns-5475 wheezy_udp@dns-test-service.dns-5475.svc wheezy_tcp@dns-test-service.dns-5475.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5475.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5475 jessie_tcp@dns-test-service.dns-5475 jessie_udp@dns-test-service.dns-5475.svc jessie_tcp@dns-test-service.dns-5475.svc]

    Apr 25 20:20:56.967: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:56.988: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:57.008: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:57.026: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:57.050: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:57.072: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:57.216: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:57.235: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:57.255: INFO: Unable to read jessie_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:57.274: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:57.296: INFO: Unable to read jessie_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:57.319: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:20:57.444: INFO: Lookups using dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5475 wheezy_tcp@dns-test-service.dns-5475 wheezy_udp@dns-test-service.dns-5475.svc wheezy_tcp@dns-test-service.dns-5475.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5475 jessie_tcp@dns-test-service.dns-5475 jessie_udp@dns-test-service.dns-5475.svc jessie_tcp@dns-test-service.dns-5475.svc]

    Apr 25 20:21:01.968: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:01.985: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:02.005: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:02.026: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:02.076: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:02.095: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:02.271: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:02.294: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:02.312: INFO: Unable to read jessie_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:02.330: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:02.352: INFO: Unable to read jessie_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:02.387: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:02.515: INFO: Lookups using dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5475 wheezy_tcp@dns-test-service.dns-5475 wheezy_udp@dns-test-service.dns-5475.svc wheezy_tcp@dns-test-service.dns-5475.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5475 jessie_tcp@dns-test-service.dns-5475 jessie_udp@dns-test-service.dns-5475.svc jessie_tcp@dns-test-service.dns-5475.svc]

    Apr 25 20:21:06.970: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:06.992: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:07.014: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:07.034: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:07.056: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:07.077: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:07.221: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:07.241: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:07.261: INFO: Unable to read jessie_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:07.283: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:07.306: INFO: Unable to read jessie_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:07.326: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:07.453: INFO: Lookups using dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5475 wheezy_tcp@dns-test-service.dns-5475 wheezy_udp@dns-test-service.dns-5475.svc wheezy_tcp@dns-test-service.dns-5475.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5475 jessie_tcp@dns-test-service.dns-5475 jessie_udp@dns-test-service.dns-5475.svc jessie_tcp@dns-test-service.dns-5475.svc]

    Apr 25 20:21:11.973: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:11.993: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:12.016: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:12.037: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:12.059: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:12.080: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:12.234: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:12.286: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:12.307: INFO: Unable to read jessie_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:12.326: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:12.350: INFO: Unable to read jessie_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:12.370: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:12.498: INFO: Lookups using dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5475 wheezy_tcp@dns-test-service.dns-5475 wheezy_udp@dns-test-service.dns-5475.svc wheezy_tcp@dns-test-service.dns-5475.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5475 jessie_tcp@dns-test-service.dns-5475 jessie_udp@dns-test-service.dns-5475.svc jessie_tcp@dns-test-service.dns-5475.svc]

    Apr 25 20:21:16.968: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:16.987: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:17.007: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:17.027: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:17.049: INFO: Unable to read wheezy_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:17.070: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:17.212: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:17.234: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:17.253: INFO: Unable to read jessie_udp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:17.272: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475 from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:17.298: INFO: Unable to read jessie_udp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:17.319: INFO: Unable to read jessie_tcp@dns-test-service.dns-5475.svc from pod dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c: the server could not find the requested resource (get pods dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c)
    Apr 25 20:21:17.490: INFO: Lookups using dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5475 wheezy_tcp@dns-test-service.dns-5475 wheezy_udp@dns-test-service.dns-5475.svc wheezy_tcp@dns-test-service.dns-5475.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5475 jessie_tcp@dns-test-service.dns-5475 jessie_udp@dns-test-service.dns-5475.svc jessie_tcp@dns-test-service.dns-5475.svc]

    Apr 25 20:21:22.454: INFO: DNS probes using dns-5475/dns-test-169a91c9-6965-4c16-98f7-3edc5ad9e61c succeeded

    STEP: deleting the pod 04/25/23 20:21:22.454
    STEP: deleting the test service 04/25/23 20:21:22.494
    STEP: deleting the test headless service 04/25/23 20:21:22.589
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 25 20:21:22.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-5475" for this suite. 04/25/23 20:21:22.642
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:21:22.677
Apr 25 20:21:22.677: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename controllerrevisions 04/25/23 20:21:22.678
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:21:22.727
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:21:22.742
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-4pbms-daemon-set" 04/25/23 20:21:22.835
STEP: Check that daemon pods launch on every node of the cluster. 04/25/23 20:21:22.852
Apr 25 20:21:22.882: INFO: Number of nodes with available pods controlled by daemonset e2e-4pbms-daemon-set: 0
Apr 25 20:21:22.882: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:21:23.928: INFO: Number of nodes with available pods controlled by daemonset e2e-4pbms-daemon-set: 0
Apr 25 20:21:23.928: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:21:24.920: INFO: Number of nodes with available pods controlled by daemonset e2e-4pbms-daemon-set: 0
Apr 25 20:21:24.921: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:21:25.917: INFO: Number of nodes with available pods controlled by daemonset e2e-4pbms-daemon-set: 3
Apr 25 20:21:25.917: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-4pbms-daemon-set
STEP: Confirm DaemonSet "e2e-4pbms-daemon-set" successfully created with "daemonset-name=e2e-4pbms-daemon-set" label 04/25/23 20:21:25.951
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-4pbms-daemon-set" 04/25/23 20:21:25.994
Apr 25 20:21:26.022: INFO: Located ControllerRevision: "e2e-4pbms-daemon-set-798f7fc5b9"
STEP: Patching ControllerRevision "e2e-4pbms-daemon-set-798f7fc5b9" 04/25/23 20:21:26.035
Apr 25 20:21:26.056: INFO: e2e-4pbms-daemon-set-798f7fc5b9 has been patched
STEP: Create a new ControllerRevision 04/25/23 20:21:26.056
Apr 25 20:21:26.075: INFO: Created ControllerRevision: e2e-4pbms-daemon-set-5c9899dd97
STEP: Confirm that there are two ControllerRevisions 04/25/23 20:21:26.075
Apr 25 20:21:26.076: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 25 20:21:26.097: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-4pbms-daemon-set-798f7fc5b9" 04/25/23 20:21:26.097
STEP: Confirm that there is only one ControllerRevision 04/25/23 20:21:26.175
Apr 25 20:21:26.175: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 25 20:21:26.211: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-4pbms-daemon-set-5c9899dd97" 04/25/23 20:21:26.225
Apr 25 20:21:26.266: INFO: e2e-4pbms-daemon-set-5c9899dd97 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 04/25/23 20:21:26.266
W0425 20:21:26.287414      23 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 04/25/23 20:21:26.288
Apr 25 20:21:26.288: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 25 20:21:27.304: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 25 20:21:27.322: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-4pbms-daemon-set-5c9899dd97=updated" 04/25/23 20:21:27.322
STEP: Confirm that there is only one ControllerRevision 04/25/23 20:21:27.361
Apr 25 20:21:27.361: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 25 20:21:27.375: INFO: Found 1 ControllerRevisions
Apr 25 20:21:27.390: INFO: ControllerRevision "e2e-4pbms-daemon-set-66db76f78d" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-4pbms-daemon-set" 04/25/23 20:21:27.405
STEP: deleting DaemonSet.extensions e2e-4pbms-daemon-set in namespace controllerrevisions-7630, will wait for the garbage collector to delete the pods 04/25/23 20:21:27.406
Apr 25 20:21:27.498: INFO: Deleting DaemonSet.extensions e2e-4pbms-daemon-set took: 27.495146ms
Apr 25 20:21:27.598: INFO: Terminating DaemonSet.extensions e2e-4pbms-daemon-set pods took: 100.868688ms
Apr 25 20:21:29.313: INFO: Number of nodes with available pods controlled by daemonset e2e-4pbms-daemon-set: 0
Apr 25 20:21:29.313: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-4pbms-daemon-set
Apr 25 20:21:29.330: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"32936"},"items":null}

Apr 25 20:21:29.343: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"32936"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Apr 25 20:21:29.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-7630" for this suite. 04/25/23 20:21:29.442
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":169,"skipped":3021,"failed":0}
------------------------------
• [SLOW TEST] [6.790 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:21:22.677
    Apr 25 20:21:22.677: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename controllerrevisions 04/25/23 20:21:22.678
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:21:22.727
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:21:22.742
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-4pbms-daemon-set" 04/25/23 20:21:22.835
    STEP: Check that daemon pods launch on every node of the cluster. 04/25/23 20:21:22.852
    Apr 25 20:21:22.882: INFO: Number of nodes with available pods controlled by daemonset e2e-4pbms-daemon-set: 0
    Apr 25 20:21:22.882: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:21:23.928: INFO: Number of nodes with available pods controlled by daemonset e2e-4pbms-daemon-set: 0
    Apr 25 20:21:23.928: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:21:24.920: INFO: Number of nodes with available pods controlled by daemonset e2e-4pbms-daemon-set: 0
    Apr 25 20:21:24.921: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:21:25.917: INFO: Number of nodes with available pods controlled by daemonset e2e-4pbms-daemon-set: 3
    Apr 25 20:21:25.917: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-4pbms-daemon-set
    STEP: Confirm DaemonSet "e2e-4pbms-daemon-set" successfully created with "daemonset-name=e2e-4pbms-daemon-set" label 04/25/23 20:21:25.951
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-4pbms-daemon-set" 04/25/23 20:21:25.994
    Apr 25 20:21:26.022: INFO: Located ControllerRevision: "e2e-4pbms-daemon-set-798f7fc5b9"
    STEP: Patching ControllerRevision "e2e-4pbms-daemon-set-798f7fc5b9" 04/25/23 20:21:26.035
    Apr 25 20:21:26.056: INFO: e2e-4pbms-daemon-set-798f7fc5b9 has been patched
    STEP: Create a new ControllerRevision 04/25/23 20:21:26.056
    Apr 25 20:21:26.075: INFO: Created ControllerRevision: e2e-4pbms-daemon-set-5c9899dd97
    STEP: Confirm that there are two ControllerRevisions 04/25/23 20:21:26.075
    Apr 25 20:21:26.076: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 25 20:21:26.097: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-4pbms-daemon-set-798f7fc5b9" 04/25/23 20:21:26.097
    STEP: Confirm that there is only one ControllerRevision 04/25/23 20:21:26.175
    Apr 25 20:21:26.175: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 25 20:21:26.211: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-4pbms-daemon-set-5c9899dd97" 04/25/23 20:21:26.225
    Apr 25 20:21:26.266: INFO: e2e-4pbms-daemon-set-5c9899dd97 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 04/25/23 20:21:26.266
    W0425 20:21:26.287414      23 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 04/25/23 20:21:26.288
    Apr 25 20:21:26.288: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 25 20:21:27.304: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 25 20:21:27.322: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-4pbms-daemon-set-5c9899dd97=updated" 04/25/23 20:21:27.322
    STEP: Confirm that there is only one ControllerRevision 04/25/23 20:21:27.361
    Apr 25 20:21:27.361: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 25 20:21:27.375: INFO: Found 1 ControllerRevisions
    Apr 25 20:21:27.390: INFO: ControllerRevision "e2e-4pbms-daemon-set-66db76f78d" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-4pbms-daemon-set" 04/25/23 20:21:27.405
    STEP: deleting DaemonSet.extensions e2e-4pbms-daemon-set in namespace controllerrevisions-7630, will wait for the garbage collector to delete the pods 04/25/23 20:21:27.406
    Apr 25 20:21:27.498: INFO: Deleting DaemonSet.extensions e2e-4pbms-daemon-set took: 27.495146ms
    Apr 25 20:21:27.598: INFO: Terminating DaemonSet.extensions e2e-4pbms-daemon-set pods took: 100.868688ms
    Apr 25 20:21:29.313: INFO: Number of nodes with available pods controlled by daemonset e2e-4pbms-daemon-set: 0
    Apr 25 20:21:29.313: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-4pbms-daemon-set
    Apr 25 20:21:29.330: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"32936"},"items":null}

    Apr 25 20:21:29.343: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"32936"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 20:21:29.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-7630" for this suite. 04/25/23 20:21:29.442
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:21:29.475
Apr 25 20:21:29.476: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename pods 04/25/23 20:21:29.477
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:21:29.516
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:21:29.528
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Apr 25 20:21:29.539: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: creating the pod 04/25/23 20:21:29.54
STEP: submitting the pod to kubernetes 04/25/23 20:21:29.541
Apr 25 20:21:29.572: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-a3232dca-cdfb-4261-a0cb-4b230d8bf91a" in namespace "pods-8209" to be "running and ready"
Apr 25 20:21:29.586: INFO: Pod "pod-exec-websocket-a3232dca-cdfb-4261-a0cb-4b230d8bf91a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.077187ms
Apr 25 20:21:29.587: INFO: The phase of Pod pod-exec-websocket-a3232dca-cdfb-4261-a0cb-4b230d8bf91a is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:21:31.603: INFO: Pod "pod-exec-websocket-a3232dca-cdfb-4261-a0cb-4b230d8bf91a": Phase="Running", Reason="", readiness=true. Elapsed: 2.030801643s
Apr 25 20:21:31.603: INFO: The phase of Pod pod-exec-websocket-a3232dca-cdfb-4261-a0cb-4b230d8bf91a is Running (Ready = true)
Apr 25 20:21:31.603: INFO: Pod "pod-exec-websocket-a3232dca-cdfb-4261-a0cb-4b230d8bf91a" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 25 20:21:31.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8209" for this suite. 04/25/23 20:21:31.85
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":170,"skipped":3041,"failed":0}
------------------------------
• [2.400 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:21:29.475
    Apr 25 20:21:29.476: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename pods 04/25/23 20:21:29.477
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:21:29.516
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:21:29.528
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Apr 25 20:21:29.539: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: creating the pod 04/25/23 20:21:29.54
    STEP: submitting the pod to kubernetes 04/25/23 20:21:29.541
    Apr 25 20:21:29.572: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-a3232dca-cdfb-4261-a0cb-4b230d8bf91a" in namespace "pods-8209" to be "running and ready"
    Apr 25 20:21:29.586: INFO: Pod "pod-exec-websocket-a3232dca-cdfb-4261-a0cb-4b230d8bf91a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.077187ms
    Apr 25 20:21:29.587: INFO: The phase of Pod pod-exec-websocket-a3232dca-cdfb-4261-a0cb-4b230d8bf91a is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:21:31.603: INFO: Pod "pod-exec-websocket-a3232dca-cdfb-4261-a0cb-4b230d8bf91a": Phase="Running", Reason="", readiness=true. Elapsed: 2.030801643s
    Apr 25 20:21:31.603: INFO: The phase of Pod pod-exec-websocket-a3232dca-cdfb-4261-a0cb-4b230d8bf91a is Running (Ready = true)
    Apr 25 20:21:31.603: INFO: Pod "pod-exec-websocket-a3232dca-cdfb-4261-a0cb-4b230d8bf91a" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 25 20:21:31.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8209" for this suite. 04/25/23 20:21:31.85
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:21:31.889
Apr 25 20:21:31.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:21:31.89
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:21:31.931
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:21:31.946
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-fe30b810-1866-4320-986c-12ed0ebc5ad2 04/25/23 20:21:31.975
STEP: Creating secret with name s-test-opt-upd-6d621d65-cc3b-434a-baf7-727c3025dd58 04/25/23 20:21:31.994
STEP: Creating the pod 04/25/23 20:21:32.012
Apr 25 20:21:32.044: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb" in namespace "projected-5427" to be "running and ready"
Apr 25 20:21:32.058: INFO: Pod "pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.293841ms
Apr 25 20:21:32.058: INFO: The phase of Pod pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:21:34.075: INFO: Pod "pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03095157s
Apr 25 20:21:34.075: INFO: The phase of Pod pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:21:36.074: INFO: Pod "pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb": Phase="Running", Reason="", readiness=true. Elapsed: 4.030701858s
Apr 25 20:21:36.074: INFO: The phase of Pod pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb is Running (Ready = true)
Apr 25 20:21:36.074: INFO: Pod "pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-fe30b810-1866-4320-986c-12ed0ebc5ad2 04/25/23 20:21:36.195
STEP: Updating secret s-test-opt-upd-6d621d65-cc3b-434a-baf7-727c3025dd58 04/25/23 20:21:36.219
STEP: Creating secret with name s-test-opt-create-24a7ff2b-565f-47ae-9b5a-edb4e2fe0089 04/25/23 20:21:36.252
STEP: waiting to observe update in volume 04/25/23 20:21:36.295
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 25 20:22:39.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5427" for this suite. 04/25/23 20:22:39.777
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":171,"skipped":3080,"failed":0}
------------------------------
• [SLOW TEST] [67.916 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:21:31.889
    Apr 25 20:21:31.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:21:31.89
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:21:31.931
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:21:31.946
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-fe30b810-1866-4320-986c-12ed0ebc5ad2 04/25/23 20:21:31.975
    STEP: Creating secret with name s-test-opt-upd-6d621d65-cc3b-434a-baf7-727c3025dd58 04/25/23 20:21:31.994
    STEP: Creating the pod 04/25/23 20:21:32.012
    Apr 25 20:21:32.044: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb" in namespace "projected-5427" to be "running and ready"
    Apr 25 20:21:32.058: INFO: Pod "pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.293841ms
    Apr 25 20:21:32.058: INFO: The phase of Pod pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:21:34.075: INFO: Pod "pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03095157s
    Apr 25 20:21:34.075: INFO: The phase of Pod pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:21:36.074: INFO: Pod "pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb": Phase="Running", Reason="", readiness=true. Elapsed: 4.030701858s
    Apr 25 20:21:36.074: INFO: The phase of Pod pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb is Running (Ready = true)
    Apr 25 20:21:36.074: INFO: Pod "pod-projected-secrets-b66c8c3b-bdd9-49a9-85e0-5e152371addb" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-fe30b810-1866-4320-986c-12ed0ebc5ad2 04/25/23 20:21:36.195
    STEP: Updating secret s-test-opt-upd-6d621d65-cc3b-434a-baf7-727c3025dd58 04/25/23 20:21:36.219
    STEP: Creating secret with name s-test-opt-create-24a7ff2b-565f-47ae-9b5a-edb4e2fe0089 04/25/23 20:21:36.252
    STEP: waiting to observe update in volume 04/25/23 20:21:36.295
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 25 20:22:39.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5427" for this suite. 04/25/23 20:22:39.777
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:22:39.82
Apr 25 20:22:39.821: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename configmap 04/25/23 20:22:39.822
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:22:39.865
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:22:39.878
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-c8bc2f58-d47d-46b2-a99d-537485830ab3 04/25/23 20:22:39.896
STEP: Creating a pod to test consume configMaps 04/25/23 20:22:39.912
Apr 25 20:22:39.942: INFO: Waiting up to 5m0s for pod "pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958" in namespace "configmap-7380" to be "Succeeded or Failed"
Apr 25 20:22:39.958: INFO: Pod "pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958": Phase="Pending", Reason="", readiness=false. Elapsed: 14.869917ms
Apr 25 20:22:41.975: INFO: Pod "pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031597966s
Apr 25 20:22:43.983: INFO: Pod "pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039901154s
STEP: Saw pod success 04/25/23 20:22:43.983
Apr 25 20:22:43.983: INFO: Pod "pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958" satisfied condition "Succeeded or Failed"
Apr 25 20:22:44.000: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958 container agnhost-container: <nil>
STEP: delete the pod 04/25/23 20:22:44.038
Apr 25 20:22:44.102: INFO: Waiting for pod pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958 to disappear
Apr 25 20:22:44.130: INFO: Pod pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 25 20:22:44.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7380" for this suite. 04/25/23 20:22:44.148
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":172,"skipped":3105,"failed":0}
------------------------------
• [4.352 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:22:39.82
    Apr 25 20:22:39.821: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename configmap 04/25/23 20:22:39.822
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:22:39.865
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:22:39.878
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-c8bc2f58-d47d-46b2-a99d-537485830ab3 04/25/23 20:22:39.896
    STEP: Creating a pod to test consume configMaps 04/25/23 20:22:39.912
    Apr 25 20:22:39.942: INFO: Waiting up to 5m0s for pod "pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958" in namespace "configmap-7380" to be "Succeeded or Failed"
    Apr 25 20:22:39.958: INFO: Pod "pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958": Phase="Pending", Reason="", readiness=false. Elapsed: 14.869917ms
    Apr 25 20:22:41.975: INFO: Pod "pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031597966s
    Apr 25 20:22:43.983: INFO: Pod "pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039901154s
    STEP: Saw pod success 04/25/23 20:22:43.983
    Apr 25 20:22:43.983: INFO: Pod "pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958" satisfied condition "Succeeded or Failed"
    Apr 25 20:22:44.000: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958 container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 20:22:44.038
    Apr 25 20:22:44.102: INFO: Waiting for pod pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958 to disappear
    Apr 25 20:22:44.130: INFO: Pod pod-configmaps-38cce83f-b226-49a6-924b-78e0545f7958 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 25 20:22:44.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7380" for this suite. 04/25/23 20:22:44.148
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:22:44.174
Apr 25 20:22:44.175: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename endpointslice 04/25/23 20:22:44.178
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:22:44.221
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:22:44.234
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 04/25/23 20:22:44.247
STEP: getting /apis/discovery.k8s.io 04/25/23 20:22:44.261
STEP: getting /apis/discovery.k8s.iov1 04/25/23 20:22:44.268
STEP: creating 04/25/23 20:22:44.275
STEP: getting 04/25/23 20:22:44.329
STEP: listing 04/25/23 20:22:44.343
STEP: watching 04/25/23 20:22:44.357
Apr 25 20:22:44.357: INFO: starting watch
STEP: cluster-wide listing 04/25/23 20:22:44.363
STEP: cluster-wide watching 04/25/23 20:22:44.381
Apr 25 20:22:44.381: INFO: starting watch
STEP: patching 04/25/23 20:22:44.387
STEP: updating 04/25/23 20:22:44.408
Apr 25 20:22:44.441: INFO: waiting for watch events with expected annotations
Apr 25 20:22:44.441: INFO: saw patched and updated annotations
STEP: deleting 04/25/23 20:22:44.441
STEP: deleting a collection 04/25/23 20:22:44.501
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 25 20:22:44.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-4097" for this suite. 04/25/23 20:22:44.583
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":173,"skipped":3107,"failed":0}
------------------------------
• [0.432 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:22:44.174
    Apr 25 20:22:44.175: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename endpointslice 04/25/23 20:22:44.178
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:22:44.221
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:22:44.234
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 04/25/23 20:22:44.247
    STEP: getting /apis/discovery.k8s.io 04/25/23 20:22:44.261
    STEP: getting /apis/discovery.k8s.iov1 04/25/23 20:22:44.268
    STEP: creating 04/25/23 20:22:44.275
    STEP: getting 04/25/23 20:22:44.329
    STEP: listing 04/25/23 20:22:44.343
    STEP: watching 04/25/23 20:22:44.357
    Apr 25 20:22:44.357: INFO: starting watch
    STEP: cluster-wide listing 04/25/23 20:22:44.363
    STEP: cluster-wide watching 04/25/23 20:22:44.381
    Apr 25 20:22:44.381: INFO: starting watch
    STEP: patching 04/25/23 20:22:44.387
    STEP: updating 04/25/23 20:22:44.408
    Apr 25 20:22:44.441: INFO: waiting for watch events with expected annotations
    Apr 25 20:22:44.441: INFO: saw patched and updated annotations
    STEP: deleting 04/25/23 20:22:44.441
    STEP: deleting a collection 04/25/23 20:22:44.501
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 25 20:22:44.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-4097" for this suite. 04/25/23 20:22:44.583
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:22:44.625
Apr 25 20:22:44.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename watch 04/25/23 20:22:44.627
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:22:44.689
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:22:44.705
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 04/25/23 20:22:44.728
STEP: creating a new configmap 04/25/23 20:22:44.734
STEP: modifying the configmap once 04/25/23 20:22:44.748
STEP: changing the label value of the configmap 04/25/23 20:22:44.77
STEP: Expecting to observe a delete notification for the watched object 04/25/23 20:22:44.806
Apr 25 20:22:44.806: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9861  bf17ad80-ad78-47e5-bf90-479763f1c809 33127 0 2023-04-25 20:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-25 20:22:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 25 20:22:44.808: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9861  bf17ad80-ad78-47e5-bf90-479763f1c809 33128 0 2023-04-25 20:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-25 20:22:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 25 20:22:44.808: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9861  bf17ad80-ad78-47e5-bf90-479763f1c809 33129 0 2023-04-25 20:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-25 20:22:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 04/25/23 20:22:44.808
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 04/25/23 20:22:44.833
STEP: changing the label value of the configmap back 04/25/23 20:22:54.834
STEP: modifying the configmap a third time 04/25/23 20:22:54.861
STEP: deleting the configmap 04/25/23 20:22:54.887
STEP: Expecting to observe an add notification for the watched object when the label value was restored 04/25/23 20:22:54.905
Apr 25 20:22:54.906: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9861  bf17ad80-ad78-47e5-bf90-479763f1c809 33178 0 2023-04-25 20:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-25 20:22:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 25 20:22:54.906: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9861  bf17ad80-ad78-47e5-bf90-479763f1c809 33179 0 2023-04-25 20:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-25 20:22:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 25 20:22:54.907: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9861  bf17ad80-ad78-47e5-bf90-479763f1c809 33180 0 2023-04-25 20:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-25 20:22:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 25 20:22:54.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9861" for this suite. 04/25/23 20:22:54.936
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":174,"skipped":3147,"failed":0}
------------------------------
• [SLOW TEST] [10.343 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:22:44.625
    Apr 25 20:22:44.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename watch 04/25/23 20:22:44.627
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:22:44.689
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:22:44.705
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 04/25/23 20:22:44.728
    STEP: creating a new configmap 04/25/23 20:22:44.734
    STEP: modifying the configmap once 04/25/23 20:22:44.748
    STEP: changing the label value of the configmap 04/25/23 20:22:44.77
    STEP: Expecting to observe a delete notification for the watched object 04/25/23 20:22:44.806
    Apr 25 20:22:44.806: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9861  bf17ad80-ad78-47e5-bf90-479763f1c809 33127 0 2023-04-25 20:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-25 20:22:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 25 20:22:44.808: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9861  bf17ad80-ad78-47e5-bf90-479763f1c809 33128 0 2023-04-25 20:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-25 20:22:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 25 20:22:44.808: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9861  bf17ad80-ad78-47e5-bf90-479763f1c809 33129 0 2023-04-25 20:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-25 20:22:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 04/25/23 20:22:44.808
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 04/25/23 20:22:44.833
    STEP: changing the label value of the configmap back 04/25/23 20:22:54.834
    STEP: modifying the configmap a third time 04/25/23 20:22:54.861
    STEP: deleting the configmap 04/25/23 20:22:54.887
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 04/25/23 20:22:54.905
    Apr 25 20:22:54.906: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9861  bf17ad80-ad78-47e5-bf90-479763f1c809 33178 0 2023-04-25 20:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-25 20:22:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 25 20:22:54.906: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9861  bf17ad80-ad78-47e5-bf90-479763f1c809 33179 0 2023-04-25 20:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-25 20:22:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 25 20:22:54.907: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9861  bf17ad80-ad78-47e5-bf90-479763f1c809 33180 0 2023-04-25 20:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-25 20:22:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 25 20:22:54.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-9861" for this suite. 04/25/23 20:22:54.936
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:22:54.97
Apr 25 20:22:54.970: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename gc 04/25/23 20:22:54.973
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:22:55.017
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:22:55.03
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 04/25/23 20:22:55.05
STEP: delete the rc 04/25/23 20:23:00.084
STEP: wait for all pods to be garbage collected 04/25/23 20:23:00.113
STEP: Gathering metrics 04/25/23 20:23:05.141
W0425 20:23:05.175287      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 25 20:23:05.175: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 25 20:23:05.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7743" for this suite. 04/25/23 20:23:05.193
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":175,"skipped":3148,"failed":0}
------------------------------
• [SLOW TEST] [10.246 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:22:54.97
    Apr 25 20:22:54.970: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename gc 04/25/23 20:22:54.973
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:22:55.017
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:22:55.03
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 04/25/23 20:22:55.05
    STEP: delete the rc 04/25/23 20:23:00.084
    STEP: wait for all pods to be garbage collected 04/25/23 20:23:00.113
    STEP: Gathering metrics 04/25/23 20:23:05.141
    W0425 20:23:05.175287      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 25 20:23:05.175: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 25 20:23:05.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7743" for this suite. 04/25/23 20:23:05.193
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:23:05.226
Apr 25 20:23:05.227: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename configmap 04/25/23 20:23:05.229
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:23:05.268
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:23:05.282
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-c9f1be0d-eae9-4106-baee-13f7da3d1605 04/25/23 20:23:05.314
STEP: Creating configMap with name cm-test-opt-upd-3c5f51db-c76b-403e-ab3a-229c6cdef692 04/25/23 20:23:05.329
STEP: Creating the pod 04/25/23 20:23:05.345
Apr 25 20:23:05.408: INFO: Waiting up to 5m0s for pod "pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b" in namespace "configmap-4698" to be "running and ready"
Apr 25 20:23:05.423: INFO: Pod "pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.649279ms
Apr 25 20:23:05.423: INFO: The phase of Pod pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:23:07.445: INFO: Pod "pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036708795s
Apr 25 20:23:07.445: INFO: The phase of Pod pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:23:09.440: INFO: Pod "pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b": Phase="Running", Reason="", readiness=true. Elapsed: 4.031606859s
Apr 25 20:23:09.440: INFO: The phase of Pod pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b is Running (Ready = true)
Apr 25 20:23:09.440: INFO: Pod "pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-c9f1be0d-eae9-4106-baee-13f7da3d1605 04/25/23 20:23:09.539
STEP: Updating configmap cm-test-opt-upd-3c5f51db-c76b-403e-ab3a-229c6cdef692 04/25/23 20:23:09.567
STEP: Creating configMap with name cm-test-opt-create-061eb458-faf8-4a4f-bd24-dcd85e54fb3a 04/25/23 20:23:09.58
STEP: waiting to observe update in volume 04/25/23 20:23:09.593
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 25 20:24:29.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4698" for this suite. 04/25/23 20:24:29.53
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":176,"skipped":3166,"failed":0}
------------------------------
• [SLOW TEST] [84.337 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:23:05.226
    Apr 25 20:23:05.227: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename configmap 04/25/23 20:23:05.229
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:23:05.268
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:23:05.282
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-c9f1be0d-eae9-4106-baee-13f7da3d1605 04/25/23 20:23:05.314
    STEP: Creating configMap with name cm-test-opt-upd-3c5f51db-c76b-403e-ab3a-229c6cdef692 04/25/23 20:23:05.329
    STEP: Creating the pod 04/25/23 20:23:05.345
    Apr 25 20:23:05.408: INFO: Waiting up to 5m0s for pod "pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b" in namespace "configmap-4698" to be "running and ready"
    Apr 25 20:23:05.423: INFO: Pod "pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.649279ms
    Apr 25 20:23:05.423: INFO: The phase of Pod pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:23:07.445: INFO: Pod "pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036708795s
    Apr 25 20:23:07.445: INFO: The phase of Pod pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:23:09.440: INFO: Pod "pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b": Phase="Running", Reason="", readiness=true. Elapsed: 4.031606859s
    Apr 25 20:23:09.440: INFO: The phase of Pod pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b is Running (Ready = true)
    Apr 25 20:23:09.440: INFO: Pod "pod-configmaps-a2123c0d-80c8-4e48-8b05-e555d648026b" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-c9f1be0d-eae9-4106-baee-13f7da3d1605 04/25/23 20:23:09.539
    STEP: Updating configmap cm-test-opt-upd-3c5f51db-c76b-403e-ab3a-229c6cdef692 04/25/23 20:23:09.567
    STEP: Creating configMap with name cm-test-opt-create-061eb458-faf8-4a4f-bd24-dcd85e54fb3a 04/25/23 20:23:09.58
    STEP: waiting to observe update in volume 04/25/23 20:23:09.593
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 25 20:24:29.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4698" for this suite. 04/25/23 20:24:29.53
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:24:29.571
Apr 25 20:24:29.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 20:24:29.574
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:24:29.617
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:24:29.631
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 04/25/23 20:24:29.646
Apr 25 20:24:29.704: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8" in namespace "downward-api-6507" to be "Succeeded or Failed"
Apr 25 20:24:29.740: INFO: Pod "downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 35.738632ms
Apr 25 20:24:31.756: INFO: Pod "downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8": Phase="Running", Reason="", readiness=true. Elapsed: 2.050884387s
Apr 25 20:24:33.769: INFO: Pod "downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8": Phase="Running", Reason="", readiness=false. Elapsed: 4.064431048s
Apr 25 20:24:35.767: INFO: Pod "downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.062188605s
STEP: Saw pod success 04/25/23 20:24:35.767
Apr 25 20:24:35.767: INFO: Pod "downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8" satisfied condition "Succeeded or Failed"
Apr 25 20:24:35.781: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8 container client-container: <nil>
STEP: delete the pod 04/25/23 20:24:35.839
Apr 25 20:24:35.880: INFO: Waiting for pod downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8 to disappear
Apr 25 20:24:35.897: INFO: Pod downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 25 20:24:35.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6507" for this suite. 04/25/23 20:24:35.914
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":177,"skipped":3198,"failed":0}
------------------------------
• [SLOW TEST] [6.390 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:24:29.571
    Apr 25 20:24:29.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 20:24:29.574
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:24:29.617
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:24:29.631
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 04/25/23 20:24:29.646
    Apr 25 20:24:29.704: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8" in namespace "downward-api-6507" to be "Succeeded or Failed"
    Apr 25 20:24:29.740: INFO: Pod "downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 35.738632ms
    Apr 25 20:24:31.756: INFO: Pod "downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8": Phase="Running", Reason="", readiness=true. Elapsed: 2.050884387s
    Apr 25 20:24:33.769: INFO: Pod "downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8": Phase="Running", Reason="", readiness=false. Elapsed: 4.064431048s
    Apr 25 20:24:35.767: INFO: Pod "downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.062188605s
    STEP: Saw pod success 04/25/23 20:24:35.767
    Apr 25 20:24:35.767: INFO: Pod "downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8" satisfied condition "Succeeded or Failed"
    Apr 25 20:24:35.781: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8 container client-container: <nil>
    STEP: delete the pod 04/25/23 20:24:35.839
    Apr 25 20:24:35.880: INFO: Waiting for pod downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8 to disappear
    Apr 25 20:24:35.897: INFO: Pod downwardapi-volume-1cec6d46-2008-4858-a9f4-998fe9894ea8 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 25 20:24:35.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6507" for this suite. 04/25/23 20:24:35.914
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:24:35.973
Apr 25 20:24:35.973: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir 04/25/23 20:24:35.974
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:24:36.023
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:24:36.033
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 04/25/23 20:24:36.055
Apr 25 20:24:36.105: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-6c6948f7-2a2e-404e-8fd5-b839dc6c291e" in namespace "emptydir-8340" to be "running"
Apr 25 20:24:36.120: INFO: Pod "pod-sharedvolume-6c6948f7-2a2e-404e-8fd5-b839dc6c291e": Phase="Pending", Reason="", readiness=false. Elapsed: 15.60212ms
Apr 25 20:24:38.143: INFO: Pod "pod-sharedvolume-6c6948f7-2a2e-404e-8fd5-b839dc6c291e": Phase="Running", Reason="", readiness=false. Elapsed: 2.038216643s
Apr 25 20:24:38.143: INFO: Pod "pod-sharedvolume-6c6948f7-2a2e-404e-8fd5-b839dc6c291e" satisfied condition "running"
STEP: Reading file content from the nginx-container 04/25/23 20:24:38.143
Apr 25 20:24:38.143: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-8340 PodName:pod-sharedvolume-6c6948f7-2a2e-404e-8fd5-b839dc6c291e ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:24:38.144: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:24:38.146: INFO: ExecWithOptions: Clientset creation
Apr 25 20:24:38.146: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/emptydir-8340/pods/pod-sharedvolume-6c6948f7-2a2e-404e-8fd5-b839dc6c291e/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Apr 25 20:24:38.571: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 25 20:24:38.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8340" for this suite. 04/25/23 20:24:38.591
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":178,"skipped":3291,"failed":0}
------------------------------
• [2.652 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:24:35.973
    Apr 25 20:24:35.973: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir 04/25/23 20:24:35.974
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:24:36.023
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:24:36.033
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 04/25/23 20:24:36.055
    Apr 25 20:24:36.105: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-6c6948f7-2a2e-404e-8fd5-b839dc6c291e" in namespace "emptydir-8340" to be "running"
    Apr 25 20:24:36.120: INFO: Pod "pod-sharedvolume-6c6948f7-2a2e-404e-8fd5-b839dc6c291e": Phase="Pending", Reason="", readiness=false. Elapsed: 15.60212ms
    Apr 25 20:24:38.143: INFO: Pod "pod-sharedvolume-6c6948f7-2a2e-404e-8fd5-b839dc6c291e": Phase="Running", Reason="", readiness=false. Elapsed: 2.038216643s
    Apr 25 20:24:38.143: INFO: Pod "pod-sharedvolume-6c6948f7-2a2e-404e-8fd5-b839dc6c291e" satisfied condition "running"
    STEP: Reading file content from the nginx-container 04/25/23 20:24:38.143
    Apr 25 20:24:38.143: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-8340 PodName:pod-sharedvolume-6c6948f7-2a2e-404e-8fd5-b839dc6c291e ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:24:38.144: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:24:38.146: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:24:38.146: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/emptydir-8340/pods/pod-sharedvolume-6c6948f7-2a2e-404e-8fd5-b839dc6c291e/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Apr 25 20:24:38.571: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 25 20:24:38.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8340" for this suite. 04/25/23 20:24:38.591
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:24:38.639
Apr 25 20:24:38.640: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename var-expansion 04/25/23 20:24:38.641
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:24:38.682
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:24:38.693
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 04/25/23 20:24:38.706
STEP: waiting for pod running 04/25/23 20:24:38.742
Apr 25 20:24:38.742: INFO: Waiting up to 2m0s for pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c" in namespace "var-expansion-8667" to be "running"
Apr 25 20:24:38.755: INFO: Pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.80995ms
Apr 25 20:24:40.773: INFO: Pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030539836s
Apr 25 20:24:42.772: INFO: Pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c": Phase="Running", Reason="", readiness=true. Elapsed: 4.030008304s
Apr 25 20:24:42.772: INFO: Pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c" satisfied condition "running"
STEP: creating a file in subpath 04/25/23 20:24:42.772
Apr 25 20:24:42.786: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-8667 PodName:var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:24:42.786: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:24:42.788: INFO: ExecWithOptions: Clientset creation
Apr 25 20:24:42.788: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-8667/pods/var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 04/25/23 20:24:43.028
Apr 25 20:24:43.044: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-8667 PodName:var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:24:43.044: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:24:43.047: INFO: ExecWithOptions: Clientset creation
Apr 25 20:24:43.048: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-8667/pods/var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 04/25/23 20:24:43.353
Apr 25 20:24:43.928: INFO: Successfully updated pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c"
STEP: waiting for annotated pod running 04/25/23 20:24:43.929
Apr 25 20:24:43.929: INFO: Waiting up to 2m0s for pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c" in namespace "var-expansion-8667" to be "running"
Apr 25 20:24:43.946: INFO: Pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c": Phase="Running", Reason="", readiness=true. Elapsed: 16.64738ms
Apr 25 20:24:43.946: INFO: Pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c" satisfied condition "running"
STEP: deleting the pod gracefully 04/25/23 20:24:43.946
Apr 25 20:24:43.946: INFO: Deleting pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c" in namespace "var-expansion-8667"
Apr 25 20:24:43.971: INFO: Wait up to 5m0s for pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 25 20:25:16.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8667" for this suite. 04/25/23 20:25:16.016
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":179,"skipped":3309,"failed":0}
------------------------------
• [SLOW TEST] [37.402 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:24:38.639
    Apr 25 20:24:38.640: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename var-expansion 04/25/23 20:24:38.641
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:24:38.682
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:24:38.693
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 04/25/23 20:24:38.706
    STEP: waiting for pod running 04/25/23 20:24:38.742
    Apr 25 20:24:38.742: INFO: Waiting up to 2m0s for pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c" in namespace "var-expansion-8667" to be "running"
    Apr 25 20:24:38.755: INFO: Pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.80995ms
    Apr 25 20:24:40.773: INFO: Pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030539836s
    Apr 25 20:24:42.772: INFO: Pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c": Phase="Running", Reason="", readiness=true. Elapsed: 4.030008304s
    Apr 25 20:24:42.772: INFO: Pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c" satisfied condition "running"
    STEP: creating a file in subpath 04/25/23 20:24:42.772
    Apr 25 20:24:42.786: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-8667 PodName:var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:24:42.786: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:24:42.788: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:24:42.788: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-8667/pods/var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 04/25/23 20:24:43.028
    Apr 25 20:24:43.044: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-8667 PodName:var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:24:43.044: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:24:43.047: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:24:43.048: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-8667/pods/var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 04/25/23 20:24:43.353
    Apr 25 20:24:43.928: INFO: Successfully updated pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c"
    STEP: waiting for annotated pod running 04/25/23 20:24:43.929
    Apr 25 20:24:43.929: INFO: Waiting up to 2m0s for pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c" in namespace "var-expansion-8667" to be "running"
    Apr 25 20:24:43.946: INFO: Pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c": Phase="Running", Reason="", readiness=true. Elapsed: 16.64738ms
    Apr 25 20:24:43.946: INFO: Pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c" satisfied condition "running"
    STEP: deleting the pod gracefully 04/25/23 20:24:43.946
    Apr 25 20:24:43.946: INFO: Deleting pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c" in namespace "var-expansion-8667"
    Apr 25 20:24:43.971: INFO: Wait up to 5m0s for pod "var-expansion-a7f41803-25d4-47c9-a4f3-1b9e6c687e7c" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 25 20:25:16.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-8667" for this suite. 04/25/23 20:25:16.016
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:25:16.047
Apr 25 20:25:16.048: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename resourcequota 04/25/23 20:25:16.051
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:16.098
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:16.114
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 04/25/23 20:25:16.131
STEP: Creating a ResourceQuota 04/25/23 20:25:21.142
STEP: Ensuring resource quota status is calculated 04/25/23 20:25:21.156
STEP: Creating a Pod that fits quota 04/25/23 20:25:23.172
STEP: Ensuring ResourceQuota status captures the pod usage 04/25/23 20:25:23.258
STEP: Not allowing a pod to be created that exceeds remaining quota 04/25/23 20:25:25.275
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 04/25/23 20:25:25.286
STEP: Ensuring a pod cannot update its resource requirements 04/25/23 20:25:25.297
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 04/25/23 20:25:25.315
STEP: Deleting the pod 04/25/23 20:25:27.332
STEP: Ensuring resource quota status released the pod usage 04/25/23 20:25:27.373
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 25 20:25:29.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9369" for this suite. 04/25/23 20:25:29.4
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":180,"skipped":3309,"failed":0}
------------------------------
• [SLOW TEST] [13.376 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:25:16.047
    Apr 25 20:25:16.048: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename resourcequota 04/25/23 20:25:16.051
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:16.098
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:16.114
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 04/25/23 20:25:16.131
    STEP: Creating a ResourceQuota 04/25/23 20:25:21.142
    STEP: Ensuring resource quota status is calculated 04/25/23 20:25:21.156
    STEP: Creating a Pod that fits quota 04/25/23 20:25:23.172
    STEP: Ensuring ResourceQuota status captures the pod usage 04/25/23 20:25:23.258
    STEP: Not allowing a pod to be created that exceeds remaining quota 04/25/23 20:25:25.275
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 04/25/23 20:25:25.286
    STEP: Ensuring a pod cannot update its resource requirements 04/25/23 20:25:25.297
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 04/25/23 20:25:25.315
    STEP: Deleting the pod 04/25/23 20:25:27.332
    STEP: Ensuring resource quota status released the pod usage 04/25/23 20:25:27.373
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 25 20:25:29.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9369" for this suite. 04/25/23 20:25:29.4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:25:29.426
Apr 25 20:25:29.426: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename resourcequota 04/25/23 20:25:29.428
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:29.465
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:29.479
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 04/25/23 20:25:29.492
STEP: Creating a ResourceQuota 04/25/23 20:25:34.505
STEP: Ensuring resource quota status is calculated 04/25/23 20:25:34.536
STEP: Creating a ReplicationController 04/25/23 20:25:36.548
STEP: Ensuring resource quota status captures replication controller creation 04/25/23 20:25:36.578
STEP: Deleting a ReplicationController 04/25/23 20:25:38.591
STEP: Ensuring resource quota status released usage 04/25/23 20:25:38.607
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 25 20:25:40.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5685" for this suite. 04/25/23 20:25:40.642
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":181,"skipped":3339,"failed":0}
------------------------------
• [SLOW TEST] [11.240 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:25:29.426
    Apr 25 20:25:29.426: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename resourcequota 04/25/23 20:25:29.428
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:29.465
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:29.479
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 04/25/23 20:25:29.492
    STEP: Creating a ResourceQuota 04/25/23 20:25:34.505
    STEP: Ensuring resource quota status is calculated 04/25/23 20:25:34.536
    STEP: Creating a ReplicationController 04/25/23 20:25:36.548
    STEP: Ensuring resource quota status captures replication controller creation 04/25/23 20:25:36.578
    STEP: Deleting a ReplicationController 04/25/23 20:25:38.591
    STEP: Ensuring resource quota status released usage 04/25/23 20:25:38.607
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 25 20:25:40.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5685" for this suite. 04/25/23 20:25:40.642
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:25:40.684
Apr 25 20:25:40.685: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 20:25:40.686
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:40.725
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:40.74
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 20:25:40.793
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:25:41.15
STEP: Deploying the webhook pod 04/25/23 20:25:41.171
STEP: Wait for the deployment to be ready 04/25/23 20:25:41.213
Apr 25 20:25:41.274: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 25 20:25:43.313: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 25, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 25, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 25, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 25, 41, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/25/23 20:25:45.326
STEP: Verifying the service has paired with the endpoint 04/25/23 20:25:45.378
Apr 25 20:25:46.378: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Apr 25 20:25:46.391: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3398-crds.webhook.example.com via the AdmissionRegistration API 04/25/23 20:25:46.93
STEP: Creating a custom resource that should be mutated by the webhook 04/25/23 20:25:47.017
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:25:49.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2663" for this suite. 04/25/23 20:25:49.769
STEP: Destroying namespace "webhook-2663-markers" for this suite. 04/25/23 20:25:49.796
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":182,"skipped":3439,"failed":0}
------------------------------
• [SLOW TEST] [9.330 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:25:40.684
    Apr 25 20:25:40.685: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 20:25:40.686
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:40.725
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:40.74
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 20:25:40.793
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:25:41.15
    STEP: Deploying the webhook pod 04/25/23 20:25:41.171
    STEP: Wait for the deployment to be ready 04/25/23 20:25:41.213
    Apr 25 20:25:41.274: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 25 20:25:43.313: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 25, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 25, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 25, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 25, 41, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/25/23 20:25:45.326
    STEP: Verifying the service has paired with the endpoint 04/25/23 20:25:45.378
    Apr 25 20:25:46.378: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Apr 25 20:25:46.391: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3398-crds.webhook.example.com via the AdmissionRegistration API 04/25/23 20:25:46.93
    STEP: Creating a custom resource that should be mutated by the webhook 04/25/23 20:25:47.017
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:25:49.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2663" for this suite. 04/25/23 20:25:49.769
    STEP: Destroying namespace "webhook-2663-markers" for this suite. 04/25/23 20:25:49.796
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:25:50.022
Apr 25 20:25:50.022: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename configmap 04/25/23 20:25:50.024
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:50.068
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:50.079
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 25 20:25:50.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1875" for this suite. 04/25/23 20:25:50.225
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":183,"skipped":3486,"failed":0}
------------------------------
• [0.229 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:25:50.022
    Apr 25 20:25:50.022: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename configmap 04/25/23 20:25:50.024
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:50.068
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:50.079
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 25 20:25:50.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1875" for this suite. 04/25/23 20:25:50.225
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:25:50.252
Apr 25 20:25:50.253: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename dns 04/25/23 20:25:50.256
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:50.302
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:50.313
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 04/25/23 20:25:50.325
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7961.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7961.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 04/25/23 20:25:50.351
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7961.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7961.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 04/25/23 20:25:50.351
STEP: creating a pod to probe DNS 04/25/23 20:25:50.352
STEP: submitting the pod to kubernetes 04/25/23 20:25:50.352
Apr 25 20:25:50.380: INFO: Waiting up to 15m0s for pod "dns-test-bea64f18-473a-4081-a433-682fee4e6898" in namespace "dns-7961" to be "running"
Apr 25 20:25:50.396: INFO: Pod "dns-test-bea64f18-473a-4081-a433-682fee4e6898": Phase="Pending", Reason="", readiness=false. Elapsed: 15.197543ms
Apr 25 20:25:52.415: INFO: Pod "dns-test-bea64f18-473a-4081-a433-682fee4e6898": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034795599s
Apr 25 20:25:54.413: INFO: Pod "dns-test-bea64f18-473a-4081-a433-682fee4e6898": Phase="Running", Reason="", readiness=true. Elapsed: 4.032718683s
Apr 25 20:25:54.413: INFO: Pod "dns-test-bea64f18-473a-4081-a433-682fee4e6898" satisfied condition "running"
STEP: retrieving the pod 04/25/23 20:25:54.413
STEP: looking for the results for each expected name from probers 04/25/23 20:25:54.43
Apr 25 20:25:54.536: INFO: DNS probes using dns-7961/dns-test-bea64f18-473a-4081-a433-682fee4e6898 succeeded

STEP: deleting the pod 04/25/23 20:25:54.536
STEP: deleting the test headless service 04/25/23 20:25:54.591
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 25 20:25:54.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7961" for this suite. 04/25/23 20:25:54.645
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":184,"skipped":3486,"failed":0}
------------------------------
• [4.425 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:25:50.252
    Apr 25 20:25:50.253: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename dns 04/25/23 20:25:50.256
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:50.302
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:50.313
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 04/25/23 20:25:50.325
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7961.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7961.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     04/25/23 20:25:50.351
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7961.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7961.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     04/25/23 20:25:50.351
    STEP: creating a pod to probe DNS 04/25/23 20:25:50.352
    STEP: submitting the pod to kubernetes 04/25/23 20:25:50.352
    Apr 25 20:25:50.380: INFO: Waiting up to 15m0s for pod "dns-test-bea64f18-473a-4081-a433-682fee4e6898" in namespace "dns-7961" to be "running"
    Apr 25 20:25:50.396: INFO: Pod "dns-test-bea64f18-473a-4081-a433-682fee4e6898": Phase="Pending", Reason="", readiness=false. Elapsed: 15.197543ms
    Apr 25 20:25:52.415: INFO: Pod "dns-test-bea64f18-473a-4081-a433-682fee4e6898": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034795599s
    Apr 25 20:25:54.413: INFO: Pod "dns-test-bea64f18-473a-4081-a433-682fee4e6898": Phase="Running", Reason="", readiness=true. Elapsed: 4.032718683s
    Apr 25 20:25:54.413: INFO: Pod "dns-test-bea64f18-473a-4081-a433-682fee4e6898" satisfied condition "running"
    STEP: retrieving the pod 04/25/23 20:25:54.413
    STEP: looking for the results for each expected name from probers 04/25/23 20:25:54.43
    Apr 25 20:25:54.536: INFO: DNS probes using dns-7961/dns-test-bea64f18-473a-4081-a433-682fee4e6898 succeeded

    STEP: deleting the pod 04/25/23 20:25:54.536
    STEP: deleting the test headless service 04/25/23 20:25:54.591
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 25 20:25:54.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7961" for this suite. 04/25/23 20:25:54.645
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:25:54.685
Apr 25 20:25:54.686: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename security-context 04/25/23 20:25:54.688
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:54.732
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:54.755
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/25/23 20:25:54.77
Apr 25 20:25:54.800: INFO: Waiting up to 5m0s for pod "security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a" in namespace "security-context-140" to be "Succeeded or Failed"
Apr 25 20:25:54.815: INFO: Pod "security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.526553ms
Apr 25 20:25:56.830: INFO: Pod "security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029884046s
Apr 25 20:25:58.834: INFO: Pod "security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033451179s
STEP: Saw pod success 04/25/23 20:25:58.834
Apr 25 20:25:58.835: INFO: Pod "security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a" satisfied condition "Succeeded or Failed"
Apr 25 20:25:58.851: INFO: Trying to get logs from node 10.10.21.190 pod security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a container test-container: <nil>
STEP: delete the pod 04/25/23 20:25:58.905
Apr 25 20:25:58.940: INFO: Waiting for pod security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a to disappear
Apr 25 20:25:58.956: INFO: Pod security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 25 20:25:58.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-140" for this suite. 04/25/23 20:25:58.974
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":185,"skipped":3499,"failed":0}
------------------------------
• [4.314 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:25:54.685
    Apr 25 20:25:54.686: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename security-context 04/25/23 20:25:54.688
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:54.732
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:54.755
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/25/23 20:25:54.77
    Apr 25 20:25:54.800: INFO: Waiting up to 5m0s for pod "security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a" in namespace "security-context-140" to be "Succeeded or Failed"
    Apr 25 20:25:54.815: INFO: Pod "security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.526553ms
    Apr 25 20:25:56.830: INFO: Pod "security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029884046s
    Apr 25 20:25:58.834: INFO: Pod "security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033451179s
    STEP: Saw pod success 04/25/23 20:25:58.834
    Apr 25 20:25:58.835: INFO: Pod "security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a" satisfied condition "Succeeded or Failed"
    Apr 25 20:25:58.851: INFO: Trying to get logs from node 10.10.21.190 pod security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a container test-container: <nil>
    STEP: delete the pod 04/25/23 20:25:58.905
    Apr 25 20:25:58.940: INFO: Waiting for pod security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a to disappear
    Apr 25 20:25:58.956: INFO: Pod security-context-250eb89e-12ed-44bf-95e6-4e45a12e8d2a no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 25 20:25:58.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-140" for this suite. 04/25/23 20:25:58.974
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:25:59.01
Apr 25 20:25:59.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename events 04/25/23 20:25:59.012
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:59.055
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:59.067
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 04/25/23 20:25:59.081
Apr 25 20:25:59.100: INFO: created test-event-1
Apr 25 20:25:59.119: INFO: created test-event-2
Apr 25 20:25:59.136: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 04/25/23 20:25:59.136
STEP: delete collection of events 04/25/23 20:25:59.152
Apr 25 20:25:59.152: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 04/25/23 20:25:59.238
Apr 25 20:25:59.238: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Apr 25 20:25:59.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9791" for this suite. 04/25/23 20:25:59.272
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":186,"skipped":3521,"failed":0}
------------------------------
• [0.287 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:25:59.01
    Apr 25 20:25:59.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename events 04/25/23 20:25:59.012
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:59.055
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:59.067
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 04/25/23 20:25:59.081
    Apr 25 20:25:59.100: INFO: created test-event-1
    Apr 25 20:25:59.119: INFO: created test-event-2
    Apr 25 20:25:59.136: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 04/25/23 20:25:59.136
    STEP: delete collection of events 04/25/23 20:25:59.152
    Apr 25 20:25:59.152: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 04/25/23 20:25:59.238
    Apr 25 20:25:59.238: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Apr 25 20:25:59.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-9791" for this suite. 04/25/23 20:25:59.272
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:25:59.304
Apr 25 20:25:59.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 20:25:59.307
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:59.354
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:59.367
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Apr 25 20:25:59.384: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/25/23 20:26:03.968
Apr 25 20:26:03.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 create -f -'
Apr 25 20:26:04.855: INFO: stderr: ""
Apr 25 20:26:04.856: INFO: stdout: "e2e-test-crd-publish-openapi-7128-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 25 20:26:04.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 delete e2e-test-crd-publish-openapi-7128-crds test-cr'
Apr 25 20:26:05.020: INFO: stderr: ""
Apr 25 20:26:05.020: INFO: stdout: "e2e-test-crd-publish-openapi-7128-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Apr 25 20:26:05.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 apply -f -'
Apr 25 20:26:05.740: INFO: stderr: ""
Apr 25 20:26:05.740: INFO: stdout: "e2e-test-crd-publish-openapi-7128-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 25 20:26:05.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 delete e2e-test-crd-publish-openapi-7128-crds test-cr'
Apr 25 20:26:05.867: INFO: stderr: ""
Apr 25 20:26:05.867: INFO: stdout: "e2e-test-crd-publish-openapi-7128-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 04/25/23 20:26:05.867
Apr 25 20:26:05.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-393 explain e2e-test-crd-publish-openapi-7128-crds'
Apr 25 20:26:06.138: INFO: stderr: ""
Apr 25 20:26:06.139: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7128-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:26:10.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-393" for this suite. 04/25/23 20:26:10.284
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":187,"skipped":3530,"failed":0}
------------------------------
• [SLOW TEST] [10.998 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:25:59.304
    Apr 25 20:25:59.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 20:25:59.307
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:25:59.354
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:25:59.367
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Apr 25 20:25:59.384: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/25/23 20:26:03.968
    Apr 25 20:26:03.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 create -f -'
    Apr 25 20:26:04.855: INFO: stderr: ""
    Apr 25 20:26:04.856: INFO: stdout: "e2e-test-crd-publish-openapi-7128-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Apr 25 20:26:04.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 delete e2e-test-crd-publish-openapi-7128-crds test-cr'
    Apr 25 20:26:05.020: INFO: stderr: ""
    Apr 25 20:26:05.020: INFO: stdout: "e2e-test-crd-publish-openapi-7128-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Apr 25 20:26:05.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 apply -f -'
    Apr 25 20:26:05.740: INFO: stderr: ""
    Apr 25 20:26:05.740: INFO: stdout: "e2e-test-crd-publish-openapi-7128-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Apr 25 20:26:05.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-393 --namespace=crd-publish-openapi-393 delete e2e-test-crd-publish-openapi-7128-crds test-cr'
    Apr 25 20:26:05.867: INFO: stderr: ""
    Apr 25 20:26:05.867: INFO: stdout: "e2e-test-crd-publish-openapi-7128-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 04/25/23 20:26:05.867
    Apr 25 20:26:05.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=crd-publish-openapi-393 explain e2e-test-crd-publish-openapi-7128-crds'
    Apr 25 20:26:06.138: INFO: stderr: ""
    Apr 25 20:26:06.139: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7128-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:26:10.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-393" for this suite. 04/25/23 20:26:10.284
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:26:10.306
Apr 25 20:26:10.307: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename var-expansion 04/25/23 20:26:10.31
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:10.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:10.366
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 04/25/23 20:26:10.377
Apr 25 20:26:10.397: INFO: Waiting up to 5m0s for pod "var-expansion-78691a66-e277-43af-8f7c-3817de9a051b" in namespace "var-expansion-814" to be "Succeeded or Failed"
Apr 25 20:26:10.416: INFO: Pod "var-expansion-78691a66-e277-43af-8f7c-3817de9a051b": Phase="Pending", Reason="", readiness=false. Elapsed: 19.645845ms
Apr 25 20:26:12.427: INFO: Pod "var-expansion-78691a66-e277-43af-8f7c-3817de9a051b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030513473s
Apr 25 20:26:14.427: INFO: Pod "var-expansion-78691a66-e277-43af-8f7c-3817de9a051b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030159943s
Apr 25 20:26:16.430: INFO: Pod "var-expansion-78691a66-e277-43af-8f7c-3817de9a051b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033296319s
STEP: Saw pod success 04/25/23 20:26:16.43
Apr 25 20:26:16.431: INFO: Pod "var-expansion-78691a66-e277-43af-8f7c-3817de9a051b" satisfied condition "Succeeded or Failed"
Apr 25 20:26:16.442: INFO: Trying to get logs from node 10.10.21.190 pod var-expansion-78691a66-e277-43af-8f7c-3817de9a051b container dapi-container: <nil>
STEP: delete the pod 04/25/23 20:26:16.523
Apr 25 20:26:16.548: INFO: Waiting for pod var-expansion-78691a66-e277-43af-8f7c-3817de9a051b to disappear
Apr 25 20:26:16.559: INFO: Pod var-expansion-78691a66-e277-43af-8f7c-3817de9a051b no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 25 20:26:16.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-814" for this suite. 04/25/23 20:26:16.596
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":188,"skipped":3532,"failed":0}
------------------------------
• [SLOW TEST] [6.308 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:26:10.306
    Apr 25 20:26:10.307: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename var-expansion 04/25/23 20:26:10.31
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:10.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:10.366
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 04/25/23 20:26:10.377
    Apr 25 20:26:10.397: INFO: Waiting up to 5m0s for pod "var-expansion-78691a66-e277-43af-8f7c-3817de9a051b" in namespace "var-expansion-814" to be "Succeeded or Failed"
    Apr 25 20:26:10.416: INFO: Pod "var-expansion-78691a66-e277-43af-8f7c-3817de9a051b": Phase="Pending", Reason="", readiness=false. Elapsed: 19.645845ms
    Apr 25 20:26:12.427: INFO: Pod "var-expansion-78691a66-e277-43af-8f7c-3817de9a051b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030513473s
    Apr 25 20:26:14.427: INFO: Pod "var-expansion-78691a66-e277-43af-8f7c-3817de9a051b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030159943s
    Apr 25 20:26:16.430: INFO: Pod "var-expansion-78691a66-e277-43af-8f7c-3817de9a051b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033296319s
    STEP: Saw pod success 04/25/23 20:26:16.43
    Apr 25 20:26:16.431: INFO: Pod "var-expansion-78691a66-e277-43af-8f7c-3817de9a051b" satisfied condition "Succeeded or Failed"
    Apr 25 20:26:16.442: INFO: Trying to get logs from node 10.10.21.190 pod var-expansion-78691a66-e277-43af-8f7c-3817de9a051b container dapi-container: <nil>
    STEP: delete the pod 04/25/23 20:26:16.523
    Apr 25 20:26:16.548: INFO: Waiting for pod var-expansion-78691a66-e277-43af-8f7c-3817de9a051b to disappear
    Apr 25 20:26:16.559: INFO: Pod var-expansion-78691a66-e277-43af-8f7c-3817de9a051b no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 25 20:26:16.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-814" for this suite. 04/25/23 20:26:16.596
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:26:16.618
Apr 25 20:26:16.619: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:26:16.621
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:16.665
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:16.674
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 04/25/23 20:26:16.683
Apr 25 20:26:16.704: INFO: Waiting up to 5m0s for pod "downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720" in namespace "projected-2575" to be "Succeeded or Failed"
Apr 25 20:26:16.717: INFO: Pod "downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720": Phase="Pending", Reason="", readiness=false. Elapsed: 13.426587ms
Apr 25 20:26:18.729: INFO: Pod "downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025490208s
Apr 25 20:26:20.731: INFO: Pod "downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027124657s
STEP: Saw pod success 04/25/23 20:26:20.731
Apr 25 20:26:20.731: INFO: Pod "downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720" satisfied condition "Succeeded or Failed"
Apr 25 20:26:20.768: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720 container client-container: <nil>
STEP: delete the pod 04/25/23 20:26:20.795
Apr 25 20:26:20.823: INFO: Waiting for pod downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720 to disappear
Apr 25 20:26:20.833: INFO: Pod downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 25 20:26:20.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2575" for this suite. 04/25/23 20:26:20.849
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":189,"skipped":3552,"failed":0}
------------------------------
• [4.254 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:26:16.618
    Apr 25 20:26:16.619: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:26:16.621
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:16.665
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:16.674
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 04/25/23 20:26:16.683
    Apr 25 20:26:16.704: INFO: Waiting up to 5m0s for pod "downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720" in namespace "projected-2575" to be "Succeeded or Failed"
    Apr 25 20:26:16.717: INFO: Pod "downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720": Phase="Pending", Reason="", readiness=false. Elapsed: 13.426587ms
    Apr 25 20:26:18.729: INFO: Pod "downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025490208s
    Apr 25 20:26:20.731: INFO: Pod "downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027124657s
    STEP: Saw pod success 04/25/23 20:26:20.731
    Apr 25 20:26:20.731: INFO: Pod "downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720" satisfied condition "Succeeded or Failed"
    Apr 25 20:26:20.768: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720 container client-container: <nil>
    STEP: delete the pod 04/25/23 20:26:20.795
    Apr 25 20:26:20.823: INFO: Waiting for pod downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720 to disappear
    Apr 25 20:26:20.833: INFO: Pod downwardapi-volume-172cd703-200b-4963-a2ae-b789c1b2a720 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 25 20:26:20.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2575" for this suite. 04/25/23 20:26:20.849
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:26:20.88
Apr 25 20:26:20.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename subpath 04/25/23 20:26:20.881
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:20.925
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:20.935
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/25/23 20:26:20.956
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-hksk 04/25/23 20:26:20.987
STEP: Creating a pod to test atomic-volume-subpath 04/25/23 20:26:20.988
Apr 25 20:26:21.008: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-hksk" in namespace "subpath-2894" to be "Succeeded or Failed"
Apr 25 20:26:21.018: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Pending", Reason="", readiness=false. Elapsed: 10.091712ms
Apr 25 20:26:23.029: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 2.021670581s
Apr 25 20:26:25.030: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 4.021997917s
Apr 25 20:26:27.029: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 6.021038096s
Apr 25 20:26:29.029: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 8.021515608s
Apr 25 20:26:31.031: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 10.022975141s
Apr 25 20:26:33.030: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 12.022385074s
Apr 25 20:26:35.031: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 14.023017675s
Apr 25 20:26:37.031: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 16.023067413s
Apr 25 20:26:39.029: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 18.021410368s
Apr 25 20:26:41.031: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 20.023258589s
Apr 25 20:26:43.032: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=false. Elapsed: 22.024304967s
Apr 25 20:26:45.034: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.026638222s
STEP: Saw pod success 04/25/23 20:26:45.034
Apr 25 20:26:45.035: INFO: Pod "pod-subpath-test-configmap-hksk" satisfied condition "Succeeded or Failed"
Apr 25 20:26:45.046: INFO: Trying to get logs from node 10.10.21.190 pod pod-subpath-test-configmap-hksk container test-container-subpath-configmap-hksk: <nil>
STEP: delete the pod 04/25/23 20:26:45.084
Apr 25 20:26:45.118: INFO: Waiting for pod pod-subpath-test-configmap-hksk to disappear
Apr 25 20:26:45.129: INFO: Pod pod-subpath-test-configmap-hksk no longer exists
STEP: Deleting pod pod-subpath-test-configmap-hksk 04/25/23 20:26:45.13
Apr 25 20:26:45.130: INFO: Deleting pod "pod-subpath-test-configmap-hksk" in namespace "subpath-2894"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 25 20:26:45.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2894" for this suite. 04/25/23 20:26:45.157
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":190,"skipped":3570,"failed":0}
------------------------------
• [SLOW TEST] [24.302 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:26:20.88
    Apr 25 20:26:20.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename subpath 04/25/23 20:26:20.881
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:20.925
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:20.935
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/25/23 20:26:20.956
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-hksk 04/25/23 20:26:20.987
    STEP: Creating a pod to test atomic-volume-subpath 04/25/23 20:26:20.988
    Apr 25 20:26:21.008: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-hksk" in namespace "subpath-2894" to be "Succeeded or Failed"
    Apr 25 20:26:21.018: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Pending", Reason="", readiness=false. Elapsed: 10.091712ms
    Apr 25 20:26:23.029: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 2.021670581s
    Apr 25 20:26:25.030: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 4.021997917s
    Apr 25 20:26:27.029: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 6.021038096s
    Apr 25 20:26:29.029: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 8.021515608s
    Apr 25 20:26:31.031: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 10.022975141s
    Apr 25 20:26:33.030: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 12.022385074s
    Apr 25 20:26:35.031: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 14.023017675s
    Apr 25 20:26:37.031: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 16.023067413s
    Apr 25 20:26:39.029: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 18.021410368s
    Apr 25 20:26:41.031: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=true. Elapsed: 20.023258589s
    Apr 25 20:26:43.032: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Running", Reason="", readiness=false. Elapsed: 22.024304967s
    Apr 25 20:26:45.034: INFO: Pod "pod-subpath-test-configmap-hksk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.026638222s
    STEP: Saw pod success 04/25/23 20:26:45.034
    Apr 25 20:26:45.035: INFO: Pod "pod-subpath-test-configmap-hksk" satisfied condition "Succeeded or Failed"
    Apr 25 20:26:45.046: INFO: Trying to get logs from node 10.10.21.190 pod pod-subpath-test-configmap-hksk container test-container-subpath-configmap-hksk: <nil>
    STEP: delete the pod 04/25/23 20:26:45.084
    Apr 25 20:26:45.118: INFO: Waiting for pod pod-subpath-test-configmap-hksk to disappear
    Apr 25 20:26:45.129: INFO: Pod pod-subpath-test-configmap-hksk no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-hksk 04/25/23 20:26:45.13
    Apr 25 20:26:45.130: INFO: Deleting pod "pod-subpath-test-configmap-hksk" in namespace "subpath-2894"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 25 20:26:45.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-2894" for this suite. 04/25/23 20:26:45.157
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:26:45.187
Apr 25 20:26:45.188: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename resourcequota 04/25/23 20:26:45.191
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:45.231
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:45.24
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 04/25/23 20:26:45.248
STEP: Getting a ResourceQuota 04/25/23 20:26:45.259
STEP: Updating a ResourceQuota 04/25/23 20:26:45.269
STEP: Verifying a ResourceQuota was modified 04/25/23 20:26:45.287
STEP: Deleting a ResourceQuota 04/25/23 20:26:45.297
STEP: Verifying the deleted ResourceQuota 04/25/23 20:26:45.314
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 25 20:26:45.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5033" for this suite. 04/25/23 20:26:45.339
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":191,"skipped":3574,"failed":0}
------------------------------
• [0.170 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:26:45.187
    Apr 25 20:26:45.188: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename resourcequota 04/25/23 20:26:45.191
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:45.231
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:45.24
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 04/25/23 20:26:45.248
    STEP: Getting a ResourceQuota 04/25/23 20:26:45.259
    STEP: Updating a ResourceQuota 04/25/23 20:26:45.269
    STEP: Verifying a ResourceQuota was modified 04/25/23 20:26:45.287
    STEP: Deleting a ResourceQuota 04/25/23 20:26:45.297
    STEP: Verifying the deleted ResourceQuota 04/25/23 20:26:45.314
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 25 20:26:45.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5033" for this suite. 04/25/23 20:26:45.339
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:26:45.36
Apr 25 20:26:45.360: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename configmap 04/25/23 20:26:45.362
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:45.408
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:45.415
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-5657b17a-82b9-45f8-9c15-adaea6408e4c 04/25/23 20:26:45.437
STEP: Creating the pod 04/25/23 20:26:45.45
Apr 25 20:26:45.470: INFO: Waiting up to 5m0s for pod "pod-configmaps-fdd8f128-dbc8-4572-92a3-9fe8560f96bb" in namespace "configmap-2762" to be "running and ready"
Apr 25 20:26:45.481: INFO: Pod "pod-configmaps-fdd8f128-dbc8-4572-92a3-9fe8560f96bb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.385617ms
Apr 25 20:26:45.481: INFO: The phase of Pod pod-configmaps-fdd8f128-dbc8-4572-92a3-9fe8560f96bb is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:26:47.497: INFO: Pod "pod-configmaps-fdd8f128-dbc8-4572-92a3-9fe8560f96bb": Phase="Running", Reason="", readiness=true. Elapsed: 2.027251696s
Apr 25 20:26:47.497: INFO: The phase of Pod pod-configmaps-fdd8f128-dbc8-4572-92a3-9fe8560f96bb is Running (Ready = true)
Apr 25 20:26:47.497: INFO: Pod "pod-configmaps-fdd8f128-dbc8-4572-92a3-9fe8560f96bb" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-5657b17a-82b9-45f8-9c15-adaea6408e4c 04/25/23 20:26:47.565
STEP: waiting to observe update in volume 04/25/23 20:26:47.592
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 25 20:26:49.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2762" for this suite. 04/25/23 20:26:49.704
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":192,"skipped":3577,"failed":0}
------------------------------
• [4.363 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:26:45.36
    Apr 25 20:26:45.360: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename configmap 04/25/23 20:26:45.362
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:45.408
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:45.415
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-5657b17a-82b9-45f8-9c15-adaea6408e4c 04/25/23 20:26:45.437
    STEP: Creating the pod 04/25/23 20:26:45.45
    Apr 25 20:26:45.470: INFO: Waiting up to 5m0s for pod "pod-configmaps-fdd8f128-dbc8-4572-92a3-9fe8560f96bb" in namespace "configmap-2762" to be "running and ready"
    Apr 25 20:26:45.481: INFO: Pod "pod-configmaps-fdd8f128-dbc8-4572-92a3-9fe8560f96bb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.385617ms
    Apr 25 20:26:45.481: INFO: The phase of Pod pod-configmaps-fdd8f128-dbc8-4572-92a3-9fe8560f96bb is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:26:47.497: INFO: Pod "pod-configmaps-fdd8f128-dbc8-4572-92a3-9fe8560f96bb": Phase="Running", Reason="", readiness=true. Elapsed: 2.027251696s
    Apr 25 20:26:47.497: INFO: The phase of Pod pod-configmaps-fdd8f128-dbc8-4572-92a3-9fe8560f96bb is Running (Ready = true)
    Apr 25 20:26:47.497: INFO: Pod "pod-configmaps-fdd8f128-dbc8-4572-92a3-9fe8560f96bb" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-5657b17a-82b9-45f8-9c15-adaea6408e4c 04/25/23 20:26:47.565
    STEP: waiting to observe update in volume 04/25/23 20:26:47.592
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 25 20:26:49.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2762" for this suite. 04/25/23 20:26:49.704
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:26:49.735
Apr 25 20:26:49.735: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename podtemplate 04/25/23 20:26:49.736
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:49.796
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:49.806
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 04/25/23 20:26:49.815
Apr 25 20:26:49.828: INFO: created test-podtemplate-1
Apr 25 20:26:49.840: INFO: created test-podtemplate-2
Apr 25 20:26:49.858: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 04/25/23 20:26:49.858
STEP: delete collection of pod templates 04/25/23 20:26:49.876
Apr 25 20:26:49.877: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 04/25/23 20:26:49.929
Apr 25 20:26:49.929: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Apr 25 20:26:49.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-6473" for this suite. 04/25/23 20:26:49.958
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":193,"skipped":3633,"failed":0}
------------------------------
• [0.251 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:26:49.735
    Apr 25 20:26:49.735: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename podtemplate 04/25/23 20:26:49.736
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:49.796
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:49.806
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 04/25/23 20:26:49.815
    Apr 25 20:26:49.828: INFO: created test-podtemplate-1
    Apr 25 20:26:49.840: INFO: created test-podtemplate-2
    Apr 25 20:26:49.858: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 04/25/23 20:26:49.858
    STEP: delete collection of pod templates 04/25/23 20:26:49.876
    Apr 25 20:26:49.877: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 04/25/23 20:26:49.929
    Apr 25 20:26:49.929: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Apr 25 20:26:49.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-6473" for this suite. 04/25/23 20:26:49.958
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:26:49.991
Apr 25 20:26:49.992: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename replicaset 04/25/23 20:26:49.994
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:50.088
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:50.096
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 04/25/23 20:26:50.119
STEP: Verify that the required pods have come up. 04/25/23 20:26:50.132
Apr 25 20:26:50.142: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 25 20:26:55.155: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/25/23 20:26:55.155
STEP: Getting /status 04/25/23 20:26:55.156
Apr 25 20:26:55.169: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 04/25/23 20:26:55.169
Apr 25 20:26:55.229: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 04/25/23 20:26:55.229
Apr 25 20:26:55.236: INFO: Observed &ReplicaSet event: ADDED
Apr 25 20:26:55.236: INFO: Observed &ReplicaSet event: MODIFIED
Apr 25 20:26:55.237: INFO: Observed &ReplicaSet event: MODIFIED
Apr 25 20:26:55.238: INFO: Observed &ReplicaSet event: MODIFIED
Apr 25 20:26:55.238: INFO: Found replicaset test-rs in namespace replicaset-3923 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 25 20:26:55.238: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 04/25/23 20:26:55.238
Apr 25 20:26:55.239: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 25 20:26:55.254: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 04/25/23 20:26:55.254
Apr 25 20:26:55.260: INFO: Observed &ReplicaSet event: ADDED
Apr 25 20:26:55.261: INFO: Observed &ReplicaSet event: MODIFIED
Apr 25 20:26:55.262: INFO: Observed &ReplicaSet event: MODIFIED
Apr 25 20:26:55.263: INFO: Observed &ReplicaSet event: MODIFIED
Apr 25 20:26:55.263: INFO: Observed replicaset test-rs in namespace replicaset-3923 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 25 20:26:55.264: INFO: Observed &ReplicaSet event: MODIFIED
Apr 25 20:26:55.264: INFO: Found replicaset test-rs in namespace replicaset-3923 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Apr 25 20:26:55.264: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 25 20:26:55.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3923" for this suite. 04/25/23 20:26:55.282
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":194,"skipped":3633,"failed":0}
------------------------------
• [SLOW TEST] [5.314 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:26:49.991
    Apr 25 20:26:49.992: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename replicaset 04/25/23 20:26:49.994
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:50.088
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:50.096
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 04/25/23 20:26:50.119
    STEP: Verify that the required pods have come up. 04/25/23 20:26:50.132
    Apr 25 20:26:50.142: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 25 20:26:55.155: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/25/23 20:26:55.155
    STEP: Getting /status 04/25/23 20:26:55.156
    Apr 25 20:26:55.169: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 04/25/23 20:26:55.169
    Apr 25 20:26:55.229: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 04/25/23 20:26:55.229
    Apr 25 20:26:55.236: INFO: Observed &ReplicaSet event: ADDED
    Apr 25 20:26:55.236: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 25 20:26:55.237: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 25 20:26:55.238: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 25 20:26:55.238: INFO: Found replicaset test-rs in namespace replicaset-3923 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 25 20:26:55.238: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 04/25/23 20:26:55.238
    Apr 25 20:26:55.239: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 25 20:26:55.254: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 04/25/23 20:26:55.254
    Apr 25 20:26:55.260: INFO: Observed &ReplicaSet event: ADDED
    Apr 25 20:26:55.261: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 25 20:26:55.262: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 25 20:26:55.263: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 25 20:26:55.263: INFO: Observed replicaset test-rs in namespace replicaset-3923 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 25 20:26:55.264: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 25 20:26:55.264: INFO: Found replicaset test-rs in namespace replicaset-3923 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Apr 25 20:26:55.264: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 25 20:26:55.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-3923" for this suite. 04/25/23 20:26:55.282
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:26:55.305
Apr 25 20:26:55.306: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename runtimeclass 04/25/23 20:26:55.312
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:55.358
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:55.37
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 25 20:26:55.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7225" for this suite. 04/25/23 20:26:55.414
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":195,"skipped":3633,"failed":0}
------------------------------
• [0.132 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:26:55.305
    Apr 25 20:26:55.306: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename runtimeclass 04/25/23 20:26:55.312
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:55.358
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:55.37
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 25 20:26:55.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-7225" for this suite. 04/25/23 20:26:55.414
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:26:55.439
Apr 25 20:26:55.439: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename replication-controller 04/25/23 20:26:55.442
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:55.493
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:55.501
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 04/25/23 20:26:55.519
STEP: waiting for RC to be added 04/25/23 20:26:55.534
STEP: waiting for available Replicas 04/25/23 20:26:55.534
STEP: patching ReplicationController 04/25/23 20:26:56.832
STEP: waiting for RC to be modified 04/25/23 20:26:56.847
STEP: patching ReplicationController status 04/25/23 20:26:56.848
STEP: waiting for RC to be modified 04/25/23 20:26:56.861
STEP: waiting for available Replicas 04/25/23 20:26:56.862
STEP: fetching ReplicationController status 04/25/23 20:26:56.874
STEP: patching ReplicationController scale 04/25/23 20:26:56.887
STEP: waiting for RC to be modified 04/25/23 20:26:56.906
STEP: waiting for ReplicationController's scale to be the max amount 04/25/23 20:26:56.908
STEP: fetching ReplicationController; ensuring that it's patched 04/25/23 20:26:59.105
STEP: updating ReplicationController status 04/25/23 20:26:59.115
STEP: waiting for RC to be modified 04/25/23 20:26:59.128
STEP: listing all ReplicationControllers 04/25/23 20:26:59.13
STEP: checking that ReplicationController has expected values 04/25/23 20:26:59.142
STEP: deleting ReplicationControllers by collection 04/25/23 20:26:59.142
STEP: waiting for ReplicationController to have a DELETED watchEvent 04/25/23 20:26:59.175
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 25 20:26:59.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9138" for this suite. 04/25/23 20:26:59.293
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":196,"skipped":3635,"failed":0}
------------------------------
• [3.873 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:26:55.439
    Apr 25 20:26:55.439: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename replication-controller 04/25/23 20:26:55.442
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:55.493
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:55.501
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 04/25/23 20:26:55.519
    STEP: waiting for RC to be added 04/25/23 20:26:55.534
    STEP: waiting for available Replicas 04/25/23 20:26:55.534
    STEP: patching ReplicationController 04/25/23 20:26:56.832
    STEP: waiting for RC to be modified 04/25/23 20:26:56.847
    STEP: patching ReplicationController status 04/25/23 20:26:56.848
    STEP: waiting for RC to be modified 04/25/23 20:26:56.861
    STEP: waiting for available Replicas 04/25/23 20:26:56.862
    STEP: fetching ReplicationController status 04/25/23 20:26:56.874
    STEP: patching ReplicationController scale 04/25/23 20:26:56.887
    STEP: waiting for RC to be modified 04/25/23 20:26:56.906
    STEP: waiting for ReplicationController's scale to be the max amount 04/25/23 20:26:56.908
    STEP: fetching ReplicationController; ensuring that it's patched 04/25/23 20:26:59.105
    STEP: updating ReplicationController status 04/25/23 20:26:59.115
    STEP: waiting for RC to be modified 04/25/23 20:26:59.128
    STEP: listing all ReplicationControllers 04/25/23 20:26:59.13
    STEP: checking that ReplicationController has expected values 04/25/23 20:26:59.142
    STEP: deleting ReplicationControllers by collection 04/25/23 20:26:59.142
    STEP: waiting for ReplicationController to have a DELETED watchEvent 04/25/23 20:26:59.175
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 25 20:26:59.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-9138" for this suite. 04/25/23 20:26:59.293
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:26:59.316
Apr 25 20:26:59.317: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 20:26:59.319
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:59.362
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:59.372
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-1287 04/25/23 20:26:59.38
STEP: creating replication controller nodeport-test in namespace services-1287 04/25/23 20:26:59.426
I0425 20:26:59.438805      23 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-1287, replica count: 2
I0425 20:27:02.490143      23 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 25 20:27:02.490: INFO: Creating new exec pod
Apr 25 20:27:02.510: INFO: Waiting up to 5m0s for pod "execpod76vsc" in namespace "services-1287" to be "running"
Apr 25 20:27:02.542: INFO: Pod "execpod76vsc": Phase="Pending", Reason="", readiness=false. Elapsed: 31.535974ms
Apr 25 20:27:04.554: INFO: Pod "execpod76vsc": Phase="Running", Reason="", readiness=true. Elapsed: 2.043585707s
Apr 25 20:27:04.554: INFO: Pod "execpod76vsc" satisfied condition "running"
Apr 25 20:27:05.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Apr 25 20:27:05.944: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr 25 20:27:05.945: INFO: stdout: "nodeport-test-qsfzv"
Apr 25 20:27:05.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.115.57 80'
Apr 25 20:27:06.301: INFO: stderr: "+ + echo hostNamenc\n -v -t -w 2 172.21.115.57 80\nConnection to 172.21.115.57 80 port [tcp/http] succeeded!\n"
Apr 25 20:27:06.301: INFO: stdout: "nodeport-test-wrs48"
Apr 25 20:27:06.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.136 30517'
Apr 25 20:27:06.642: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.136 30517\nConnection to 10.10.21.136 30517 port [tcp/*] succeeded!\n"
Apr 25 20:27:06.642: INFO: stdout: ""
Apr 25 20:27:07.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.136 30517'
Apr 25 20:27:08.007: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.136 30517\nConnection to 10.10.21.136 30517 port [tcp/*] succeeded!\n"
Apr 25 20:27:08.007: INFO: stdout: ""
Apr 25 20:27:08.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.136 30517'
Apr 25 20:27:09.084: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.136 30517\nConnection to 10.10.21.136 30517 port [tcp/*] succeeded!\n"
Apr 25 20:27:09.084: INFO: stdout: ""
Apr 25 20:27:09.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.136 30517'
Apr 25 20:27:09.977: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.136 30517\nConnection to 10.10.21.136 30517 port [tcp/*] succeeded!\n"
Apr 25 20:27:09.977: INFO: stdout: ""
Apr 25 20:27:10.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.136 30517'
Apr 25 20:27:11.020: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.136 30517\nConnection to 10.10.21.136 30517 port [tcp/*] succeeded!\n"
Apr 25 20:27:11.020: INFO: stdout: "nodeport-test-qsfzv"
Apr 25 20:27:11.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.161 30517'
Apr 25 20:27:11.413: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.161 30517\nConnection to 10.10.21.161 30517 port [tcp/*] succeeded!\n"
Apr 25 20:27:11.413: INFO: stdout: ""
Apr 25 20:27:12.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.161 30517'
Apr 25 20:27:12.808: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.161 30517\nConnection to 10.10.21.161 30517 port [tcp/*] succeeded!\n"
Apr 25 20:27:12.809: INFO: stdout: "nodeport-test-wrs48"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 20:27:12.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1287" for this suite. 04/25/23 20:27:12.826
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":197,"skipped":3652,"failed":0}
------------------------------
• [SLOW TEST] [13.530 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:26:59.316
    Apr 25 20:26:59.317: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 20:26:59.319
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:26:59.362
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:26:59.372
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-1287 04/25/23 20:26:59.38
    STEP: creating replication controller nodeport-test in namespace services-1287 04/25/23 20:26:59.426
    I0425 20:26:59.438805      23 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-1287, replica count: 2
    I0425 20:27:02.490143      23 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 25 20:27:02.490: INFO: Creating new exec pod
    Apr 25 20:27:02.510: INFO: Waiting up to 5m0s for pod "execpod76vsc" in namespace "services-1287" to be "running"
    Apr 25 20:27:02.542: INFO: Pod "execpod76vsc": Phase="Pending", Reason="", readiness=false. Elapsed: 31.535974ms
    Apr 25 20:27:04.554: INFO: Pod "execpod76vsc": Phase="Running", Reason="", readiness=true. Elapsed: 2.043585707s
    Apr 25 20:27:04.554: INFO: Pod "execpod76vsc" satisfied condition "running"
    Apr 25 20:27:05.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Apr 25 20:27:05.944: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Apr 25 20:27:05.945: INFO: stdout: "nodeport-test-qsfzv"
    Apr 25 20:27:05.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.115.57 80'
    Apr 25 20:27:06.301: INFO: stderr: "+ + echo hostNamenc\n -v -t -w 2 172.21.115.57 80\nConnection to 172.21.115.57 80 port [tcp/http] succeeded!\n"
    Apr 25 20:27:06.301: INFO: stdout: "nodeport-test-wrs48"
    Apr 25 20:27:06.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.136 30517'
    Apr 25 20:27:06.642: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.136 30517\nConnection to 10.10.21.136 30517 port [tcp/*] succeeded!\n"
    Apr 25 20:27:06.642: INFO: stdout: ""
    Apr 25 20:27:07.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.136 30517'
    Apr 25 20:27:08.007: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.136 30517\nConnection to 10.10.21.136 30517 port [tcp/*] succeeded!\n"
    Apr 25 20:27:08.007: INFO: stdout: ""
    Apr 25 20:27:08.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.136 30517'
    Apr 25 20:27:09.084: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.136 30517\nConnection to 10.10.21.136 30517 port [tcp/*] succeeded!\n"
    Apr 25 20:27:09.084: INFO: stdout: ""
    Apr 25 20:27:09.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.136 30517'
    Apr 25 20:27:09.977: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.136 30517\nConnection to 10.10.21.136 30517 port [tcp/*] succeeded!\n"
    Apr 25 20:27:09.977: INFO: stdout: ""
    Apr 25 20:27:10.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.136 30517'
    Apr 25 20:27:11.020: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.136 30517\nConnection to 10.10.21.136 30517 port [tcp/*] succeeded!\n"
    Apr 25 20:27:11.020: INFO: stdout: "nodeport-test-qsfzv"
    Apr 25 20:27:11.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.161 30517'
    Apr 25 20:27:11.413: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.161 30517\nConnection to 10.10.21.161 30517 port [tcp/*] succeeded!\n"
    Apr 25 20:27:11.413: INFO: stdout: ""
    Apr 25 20:27:12.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-1287 exec execpod76vsc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.21.161 30517'
    Apr 25 20:27:12.808: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.21.161 30517\nConnection to 10.10.21.161 30517 port [tcp/*] succeeded!\n"
    Apr 25 20:27:12.809: INFO: stdout: "nodeport-test-wrs48"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 20:27:12.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1287" for this suite. 04/25/23 20:27:12.826
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:27:12.85
Apr 25 20:27:12.850: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename prestop 04/25/23 20:27:12.855
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:27:12.906
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:27:12.918
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-5613 04/25/23 20:27:12.928
STEP: Waiting for pods to come up. 04/25/23 20:27:12.95
Apr 25 20:27:12.950: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-5613" to be "running"
Apr 25 20:27:12.964: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 14.161384ms
Apr 25 20:27:14.975: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.025614662s
Apr 25 20:27:14.976: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-5613 04/25/23 20:27:14.987
Apr 25 20:27:15.001: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-5613" to be "running"
Apr 25 20:27:15.012: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 10.804336ms
Apr 25 20:27:17.025: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.023597564s
Apr 25 20:27:17.026: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 04/25/23 20:27:17.026
Apr 25 20:27:22.100: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 04/25/23 20:27:22.1
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Apr 25 20:27:22.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-5613" for this suite. 04/25/23 20:27:22.167
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":198,"skipped":3665,"failed":0}
------------------------------
• [SLOW TEST] [9.349 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:27:12.85
    Apr 25 20:27:12.850: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename prestop 04/25/23 20:27:12.855
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:27:12.906
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:27:12.918
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-5613 04/25/23 20:27:12.928
    STEP: Waiting for pods to come up. 04/25/23 20:27:12.95
    Apr 25 20:27:12.950: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-5613" to be "running"
    Apr 25 20:27:12.964: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 14.161384ms
    Apr 25 20:27:14.975: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.025614662s
    Apr 25 20:27:14.976: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-5613 04/25/23 20:27:14.987
    Apr 25 20:27:15.001: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-5613" to be "running"
    Apr 25 20:27:15.012: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 10.804336ms
    Apr 25 20:27:17.025: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.023597564s
    Apr 25 20:27:17.026: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 04/25/23 20:27:17.026
    Apr 25 20:27:22.100: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 04/25/23 20:27:22.1
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Apr 25 20:27:22.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-5613" for this suite. 04/25/23 20:27:22.167
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:27:22.21
Apr 25 20:27:22.210: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename security-context-test 04/25/23 20:27:22.212
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:27:22.269
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:27:22.279
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Apr 25 20:27:22.307: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-98a5be3d-95af-4eaa-878c-cf04b8cdb4b3" in namespace "security-context-test-3050" to be "Succeeded or Failed"
Apr 25 20:27:22.322: INFO: Pod "busybox-privileged-false-98a5be3d-95af-4eaa-878c-cf04b8cdb4b3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.639831ms
Apr 25 20:27:24.333: INFO: Pod "busybox-privileged-false-98a5be3d-95af-4eaa-878c-cf04b8cdb4b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025983391s
Apr 25 20:27:26.334: INFO: Pod "busybox-privileged-false-98a5be3d-95af-4eaa-878c-cf04b8cdb4b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02674339s
Apr 25 20:27:26.334: INFO: Pod "busybox-privileged-false-98a5be3d-95af-4eaa-878c-cf04b8cdb4b3" satisfied condition "Succeeded or Failed"
Apr 25 20:27:26.370: INFO: Got logs for pod "busybox-privileged-false-98a5be3d-95af-4eaa-878c-cf04b8cdb4b3": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 25 20:27:26.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3050" for this suite. 04/25/23 20:27:26.387
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":199,"skipped":3671,"failed":0}
------------------------------
• [4.201 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:27:22.21
    Apr 25 20:27:22.210: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename security-context-test 04/25/23 20:27:22.212
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:27:22.269
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:27:22.279
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Apr 25 20:27:22.307: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-98a5be3d-95af-4eaa-878c-cf04b8cdb4b3" in namespace "security-context-test-3050" to be "Succeeded or Failed"
    Apr 25 20:27:22.322: INFO: Pod "busybox-privileged-false-98a5be3d-95af-4eaa-878c-cf04b8cdb4b3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.639831ms
    Apr 25 20:27:24.333: INFO: Pod "busybox-privileged-false-98a5be3d-95af-4eaa-878c-cf04b8cdb4b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025983391s
    Apr 25 20:27:26.334: INFO: Pod "busybox-privileged-false-98a5be3d-95af-4eaa-878c-cf04b8cdb4b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02674339s
    Apr 25 20:27:26.334: INFO: Pod "busybox-privileged-false-98a5be3d-95af-4eaa-878c-cf04b8cdb4b3" satisfied condition "Succeeded or Failed"
    Apr 25 20:27:26.370: INFO: Got logs for pod "busybox-privileged-false-98a5be3d-95af-4eaa-878c-cf04b8cdb4b3": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 25 20:27:26.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-3050" for this suite. 04/25/23 20:27:26.387
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:27:26.415
Apr 25 20:27:26.416: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:27:26.418
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:27:26.462
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:27:26.471
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 04/25/23 20:27:26.481
Apr 25 20:27:26.500: INFO: Waiting up to 5m0s for pod "labelsupdatea3e5f318-7970-4c55-a6aa-75aef7bbc2e1" in namespace "projected-9898" to be "running and ready"
Apr 25 20:27:26.519: INFO: Pod "labelsupdatea3e5f318-7970-4c55-a6aa-75aef7bbc2e1": Phase="Pending", Reason="", readiness=false. Elapsed: 19.002314ms
Apr 25 20:27:26.519: INFO: The phase of Pod labelsupdatea3e5f318-7970-4c55-a6aa-75aef7bbc2e1 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:27:28.532: INFO: Pod "labelsupdatea3e5f318-7970-4c55-a6aa-75aef7bbc2e1": Phase="Running", Reason="", readiness=true. Elapsed: 2.03199272s
Apr 25 20:27:28.532: INFO: The phase of Pod labelsupdatea3e5f318-7970-4c55-a6aa-75aef7bbc2e1 is Running (Ready = true)
Apr 25 20:27:28.532: INFO: Pod "labelsupdatea3e5f318-7970-4c55-a6aa-75aef7bbc2e1" satisfied condition "running and ready"
Apr 25 20:27:29.101: INFO: Successfully updated pod "labelsupdatea3e5f318-7970-4c55-a6aa-75aef7bbc2e1"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 25 20:27:33.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9898" for this suite. 04/25/23 20:27:33.236
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":200,"skipped":3671,"failed":0}
------------------------------
• [SLOW TEST] [6.841 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:27:26.415
    Apr 25 20:27:26.416: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:27:26.418
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:27:26.462
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:27:26.471
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 04/25/23 20:27:26.481
    Apr 25 20:27:26.500: INFO: Waiting up to 5m0s for pod "labelsupdatea3e5f318-7970-4c55-a6aa-75aef7bbc2e1" in namespace "projected-9898" to be "running and ready"
    Apr 25 20:27:26.519: INFO: Pod "labelsupdatea3e5f318-7970-4c55-a6aa-75aef7bbc2e1": Phase="Pending", Reason="", readiness=false. Elapsed: 19.002314ms
    Apr 25 20:27:26.519: INFO: The phase of Pod labelsupdatea3e5f318-7970-4c55-a6aa-75aef7bbc2e1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:27:28.532: INFO: Pod "labelsupdatea3e5f318-7970-4c55-a6aa-75aef7bbc2e1": Phase="Running", Reason="", readiness=true. Elapsed: 2.03199272s
    Apr 25 20:27:28.532: INFO: The phase of Pod labelsupdatea3e5f318-7970-4c55-a6aa-75aef7bbc2e1 is Running (Ready = true)
    Apr 25 20:27:28.532: INFO: Pod "labelsupdatea3e5f318-7970-4c55-a6aa-75aef7bbc2e1" satisfied condition "running and ready"
    Apr 25 20:27:29.101: INFO: Successfully updated pod "labelsupdatea3e5f318-7970-4c55-a6aa-75aef7bbc2e1"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 25 20:27:33.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9898" for this suite. 04/25/23 20:27:33.236
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:27:33.257
Apr 25 20:27:33.259: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename ephemeral-containers-test 04/25/23 20:27:33.261
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:27:33.315
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:27:33.326
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 04/25/23 20:27:33.335
Apr 25 20:27:33.357: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-3404" to be "running and ready"
Apr 25 20:27:33.369: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.168734ms
Apr 25 20:27:33.369: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:27:35.405: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.048571074s
Apr 25 20:27:35.406: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Apr 25 20:27:35.406: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 04/25/23 20:27:35.416
Apr 25 20:27:35.442: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-3404" to be "container debugger running"
Apr 25 20:27:35.451: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 9.141785ms
Apr 25 20:27:37.463: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.020572702s
Apr 25 20:27:39.464: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.021689455s
Apr 25 20:27:39.464: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 04/25/23 20:27:39.464
Apr 25 20:27:39.464: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-3404 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:27:39.465: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:27:39.466: INFO: ExecWithOptions: Clientset creation
Apr 25 20:27:39.466: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/ephemeral-containers-test-3404/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Apr 25 20:27:39.714: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 25 20:27:39.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-3404" for this suite. 04/25/23 20:27:39.772
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":201,"skipped":3671,"failed":0}
------------------------------
• [SLOW TEST] [6.543 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:27:33.257
    Apr 25 20:27:33.259: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename ephemeral-containers-test 04/25/23 20:27:33.261
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:27:33.315
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:27:33.326
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 04/25/23 20:27:33.335
    Apr 25 20:27:33.357: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-3404" to be "running and ready"
    Apr 25 20:27:33.369: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.168734ms
    Apr 25 20:27:33.369: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:27:35.405: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.048571074s
    Apr 25 20:27:35.406: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Apr 25 20:27:35.406: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 04/25/23 20:27:35.416
    Apr 25 20:27:35.442: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-3404" to be "container debugger running"
    Apr 25 20:27:35.451: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 9.141785ms
    Apr 25 20:27:37.463: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.020572702s
    Apr 25 20:27:39.464: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.021689455s
    Apr 25 20:27:39.464: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 04/25/23 20:27:39.464
    Apr 25 20:27:39.464: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-3404 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:27:39.465: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:27:39.466: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:27:39.466: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/ephemeral-containers-test-3404/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Apr 25 20:27:39.714: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 25 20:27:39.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-3404" for this suite. 04/25/23 20:27:39.772
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:27:39.805
Apr 25 20:27:39.805: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename resourcequota 04/25/23 20:27:39.808
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:27:39.854
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:27:39.862
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 04/25/23 20:27:39.871
STEP: Counting existing ResourceQuota 04/25/23 20:27:44.886
STEP: Creating a ResourceQuota 04/25/23 20:27:49.899
STEP: Ensuring resource quota status is calculated 04/25/23 20:27:49.912
STEP: Creating a Secret 04/25/23 20:27:51.924
STEP: Ensuring resource quota status captures secret creation 04/25/23 20:27:51.957
STEP: Deleting a secret 04/25/23 20:27:53.969
STEP: Ensuring resource quota status released usage 04/25/23 20:27:53.988
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 25 20:27:56.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1378" for this suite. 04/25/23 20:27:56.073
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":202,"skipped":3684,"failed":0}
------------------------------
• [SLOW TEST] [16.284 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:27:39.805
    Apr 25 20:27:39.805: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename resourcequota 04/25/23 20:27:39.808
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:27:39.854
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:27:39.862
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 04/25/23 20:27:39.871
    STEP: Counting existing ResourceQuota 04/25/23 20:27:44.886
    STEP: Creating a ResourceQuota 04/25/23 20:27:49.899
    STEP: Ensuring resource quota status is calculated 04/25/23 20:27:49.912
    STEP: Creating a Secret 04/25/23 20:27:51.924
    STEP: Ensuring resource quota status captures secret creation 04/25/23 20:27:51.957
    STEP: Deleting a secret 04/25/23 20:27:53.969
    STEP: Ensuring resource quota status released usage 04/25/23 20:27:53.988
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 25 20:27:56.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-1378" for this suite. 04/25/23 20:27:56.073
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:27:56.096
Apr 25 20:27:56.097: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:27:56.099
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:27:56.166
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:27:56.175
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-47adf4f0-a934-48c7-95d1-1330f080cab0 04/25/23 20:27:56.184
STEP: Creating a pod to test consume configMaps 04/25/23 20:27:56.202
Apr 25 20:27:56.222: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70" in namespace "projected-7016" to be "Succeeded or Failed"
Apr 25 20:27:56.232: INFO: Pod "pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70": Phase="Pending", Reason="", readiness=false. Elapsed: 10.0406ms
Apr 25 20:27:58.243: INFO: Pod "pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021025221s
Apr 25 20:28:00.244: INFO: Pod "pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021257956s
STEP: Saw pod success 04/25/23 20:28:00.244
Apr 25 20:28:00.244: INFO: Pod "pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70" satisfied condition "Succeeded or Failed"
Apr 25 20:28:00.262: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70 container agnhost-container: <nil>
STEP: delete the pod 04/25/23 20:28:00.296
Apr 25 20:28:00.326: INFO: Waiting for pod pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70 to disappear
Apr 25 20:28:00.367: INFO: Pod pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 25 20:28:00.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7016" for this suite. 04/25/23 20:28:00.384
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":203,"skipped":3692,"failed":0}
------------------------------
• [4.306 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:27:56.096
    Apr 25 20:27:56.097: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:27:56.099
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:27:56.166
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:27:56.175
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-47adf4f0-a934-48c7-95d1-1330f080cab0 04/25/23 20:27:56.184
    STEP: Creating a pod to test consume configMaps 04/25/23 20:27:56.202
    Apr 25 20:27:56.222: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70" in namespace "projected-7016" to be "Succeeded or Failed"
    Apr 25 20:27:56.232: INFO: Pod "pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70": Phase="Pending", Reason="", readiness=false. Elapsed: 10.0406ms
    Apr 25 20:27:58.243: INFO: Pod "pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021025221s
    Apr 25 20:28:00.244: INFO: Pod "pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021257956s
    STEP: Saw pod success 04/25/23 20:28:00.244
    Apr 25 20:28:00.244: INFO: Pod "pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70" satisfied condition "Succeeded or Failed"
    Apr 25 20:28:00.262: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70 container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 20:28:00.296
    Apr 25 20:28:00.326: INFO: Waiting for pod pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70 to disappear
    Apr 25 20:28:00.367: INFO: Pod pod-projected-configmaps-9a9177d5-dcbf-4295-a777-b144ddf1af70 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 25 20:28:00.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7016" for this suite. 04/25/23 20:28:00.384
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:28:00.411
Apr 25 20:28:00.412: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename pods 04/25/23 20:28:00.414
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:00.454
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:00.465
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 04/25/23 20:28:00.476
Apr 25 20:28:00.499: INFO: Waiting up to 5m0s for pod "pod-97dzj" in namespace "pods-8332" to be "running"
Apr 25 20:28:00.512: INFO: Pod "pod-97dzj": Phase="Pending", Reason="", readiness=false. Elapsed: 13.531992ms
Apr 25 20:28:02.523: INFO: Pod "pod-97dzj": Phase="Running", Reason="", readiness=true. Elapsed: 2.02414999s
Apr 25 20:28:02.523: INFO: Pod "pod-97dzj" satisfied condition "running"
STEP: patching /status 04/25/23 20:28:02.523
Apr 25 20:28:02.545: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 25 20:28:02.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8332" for this suite. 04/25/23 20:28:02.572
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":204,"skipped":3714,"failed":0}
------------------------------
• [2.192 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:28:00.411
    Apr 25 20:28:00.412: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename pods 04/25/23 20:28:00.414
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:00.454
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:00.465
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 04/25/23 20:28:00.476
    Apr 25 20:28:00.499: INFO: Waiting up to 5m0s for pod "pod-97dzj" in namespace "pods-8332" to be "running"
    Apr 25 20:28:00.512: INFO: Pod "pod-97dzj": Phase="Pending", Reason="", readiness=false. Elapsed: 13.531992ms
    Apr 25 20:28:02.523: INFO: Pod "pod-97dzj": Phase="Running", Reason="", readiness=true. Elapsed: 2.02414999s
    Apr 25 20:28:02.523: INFO: Pod "pod-97dzj" satisfied condition "running"
    STEP: patching /status 04/25/23 20:28:02.523
    Apr 25 20:28:02.545: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 25 20:28:02.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8332" for this suite. 04/25/23 20:28:02.572
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:28:02.607
Apr 25 20:28:02.609: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 20:28:02.612
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:02.663
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:02.671
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 04/25/23 20:28:02.68
Apr 25 20:28:02.700: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb" in namespace "downward-api-3109" to be "Succeeded or Failed"
Apr 25 20:28:02.711: INFO: Pod "downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.559621ms
Apr 25 20:28:04.723: INFO: Pod "downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022590484s
Apr 25 20:28:06.723: INFO: Pod "downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022976796s
STEP: Saw pod success 04/25/23 20:28:06.723
Apr 25 20:28:06.723: INFO: Pod "downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb" satisfied condition "Succeeded or Failed"
Apr 25 20:28:06.734: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb container client-container: <nil>
STEP: delete the pod 04/25/23 20:28:06.792
Apr 25 20:28:06.837: INFO: Waiting for pod downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb to disappear
Apr 25 20:28:06.849: INFO: Pod downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 25 20:28:06.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3109" for this suite. 04/25/23 20:28:06.866
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":205,"skipped":3729,"failed":0}
------------------------------
• [4.277 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:28:02.607
    Apr 25 20:28:02.609: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 20:28:02.612
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:02.663
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:02.671
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 04/25/23 20:28:02.68
    Apr 25 20:28:02.700: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb" in namespace "downward-api-3109" to be "Succeeded or Failed"
    Apr 25 20:28:02.711: INFO: Pod "downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.559621ms
    Apr 25 20:28:04.723: INFO: Pod "downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022590484s
    Apr 25 20:28:06.723: INFO: Pod "downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022976796s
    STEP: Saw pod success 04/25/23 20:28:06.723
    Apr 25 20:28:06.723: INFO: Pod "downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb" satisfied condition "Succeeded or Failed"
    Apr 25 20:28:06.734: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb container client-container: <nil>
    STEP: delete the pod 04/25/23 20:28:06.792
    Apr 25 20:28:06.837: INFO: Waiting for pod downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb to disappear
    Apr 25 20:28:06.849: INFO: Pod downwardapi-volume-1c714d72-6ac1-4d27-97ca-0fc8fb41b5cb no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 25 20:28:06.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3109" for this suite. 04/25/23 20:28:06.866
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:28:06.901
Apr 25 20:28:06.901: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename hostport 04/25/23 20:28:06.902
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:06.943
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:06.951
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 04/25/23 20:28:06.977
Apr 25 20:28:07.008: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-4509" to be "running and ready"
Apr 25 20:28:07.019: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.052634ms
Apr 25 20:28:07.019: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:28:09.030: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.022176763s
Apr 25 20:28:09.030: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 25 20:28:09.030: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.10.21.161 on the node which pod1 resides and expect scheduled 04/25/23 20:28:09.03
Apr 25 20:28:09.045: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-4509" to be "running and ready"
Apr 25 20:28:09.060: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.045505ms
Apr 25 20:28:09.060: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:28:11.074: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.029288447s
Apr 25 20:28:11.075: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 25 20:28:11.075: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.10.21.161 but use UDP protocol on the node which pod2 resides 04/25/23 20:28:11.075
Apr 25 20:28:11.088: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-4509" to be "running and ready"
Apr 25 20:28:11.098: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.890435ms
Apr 25 20:28:11.098: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:28:13.108: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.019452467s
Apr 25 20:28:13.108: INFO: The phase of Pod pod3 is Running (Ready = true)
Apr 25 20:28:13.108: INFO: Pod "pod3" satisfied condition "running and ready"
Apr 25 20:28:13.120: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-4509" to be "running and ready"
Apr 25 20:28:13.129: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 8.213129ms
Apr 25 20:28:13.129: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:28:15.140: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.019854179s
Apr 25 20:28:15.140: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Apr 25 20:28:15.140: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 04/25/23 20:28:15.151
Apr 25 20:28:15.152: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.10.21.161 http://127.0.0.1:54323/hostname] Namespace:hostport-4509 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:28:15.152: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:28:15.155: INFO: ExecWithOptions: Clientset creation
Apr 25 20:28:15.155: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-4509/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.10.21.161+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.10.21.161, port: 54323 04/25/23 20:28:15.391
Apr 25 20:28:15.391: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.10.21.161:54323/hostname] Namespace:hostport-4509 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:28:15.391: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:28:15.393: INFO: ExecWithOptions: Clientset creation
Apr 25 20:28:15.393: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-4509/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.10.21.161%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.10.21.161, port: 54323 UDP 04/25/23 20:28:15.644
Apr 25 20:28:15.645: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.10.21.161 54323] Namespace:hostport-4509 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:28:15.645: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:28:15.646: INFO: ExecWithOptions: Clientset creation
Apr 25 20:28:15.646: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-4509/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.10.21.161+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Apr 25 20:28:20.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-4509" for this suite. 04/25/23 20:28:20.926
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":206,"skipped":3738,"failed":0}
------------------------------
• [SLOW TEST] [14.043 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:28:06.901
    Apr 25 20:28:06.901: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename hostport 04/25/23 20:28:06.902
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:06.943
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:06.951
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 04/25/23 20:28:06.977
    Apr 25 20:28:07.008: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-4509" to be "running and ready"
    Apr 25 20:28:07.019: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.052634ms
    Apr 25 20:28:07.019: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:28:09.030: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.022176763s
    Apr 25 20:28:09.030: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 25 20:28:09.030: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.10.21.161 on the node which pod1 resides and expect scheduled 04/25/23 20:28:09.03
    Apr 25 20:28:09.045: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-4509" to be "running and ready"
    Apr 25 20:28:09.060: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.045505ms
    Apr 25 20:28:09.060: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:28:11.074: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.029288447s
    Apr 25 20:28:11.075: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 25 20:28:11.075: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.10.21.161 but use UDP protocol on the node which pod2 resides 04/25/23 20:28:11.075
    Apr 25 20:28:11.088: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-4509" to be "running and ready"
    Apr 25 20:28:11.098: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.890435ms
    Apr 25 20:28:11.098: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:28:13.108: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.019452467s
    Apr 25 20:28:13.108: INFO: The phase of Pod pod3 is Running (Ready = true)
    Apr 25 20:28:13.108: INFO: Pod "pod3" satisfied condition "running and ready"
    Apr 25 20:28:13.120: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-4509" to be "running and ready"
    Apr 25 20:28:13.129: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 8.213129ms
    Apr 25 20:28:13.129: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:28:15.140: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.019854179s
    Apr 25 20:28:15.140: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Apr 25 20:28:15.140: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 04/25/23 20:28:15.151
    Apr 25 20:28:15.152: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.10.21.161 http://127.0.0.1:54323/hostname] Namespace:hostport-4509 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:28:15.152: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:28:15.155: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:28:15.155: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-4509/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.10.21.161+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.10.21.161, port: 54323 04/25/23 20:28:15.391
    Apr 25 20:28:15.391: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.10.21.161:54323/hostname] Namespace:hostport-4509 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:28:15.391: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:28:15.393: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:28:15.393: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-4509/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.10.21.161%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.10.21.161, port: 54323 UDP 04/25/23 20:28:15.644
    Apr 25 20:28:15.645: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.10.21.161 54323] Namespace:hostport-4509 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:28:15.645: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:28:15.646: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:28:15.646: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-4509/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.10.21.161+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Apr 25 20:28:20.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-4509" for this suite. 04/25/23 20:28:20.926
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:28:20.947
Apr 25 20:28:20.948: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 20:28:20.95
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:21.036
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:21.045
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 20:28:21.089
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:28:21.336
STEP: Deploying the webhook pod 04/25/23 20:28:21.356
STEP: Wait for the deployment to be ready 04/25/23 20:28:21.391
Apr 25 20:28:21.418: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 25 20:28:23.472: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 28, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 28, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 28, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 28, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/25/23 20:28:25.487
STEP: Verifying the service has paired with the endpoint 04/25/23 20:28:25.516
Apr 25 20:28:26.517: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 04/25/23 20:28:26.532
STEP: create a pod 04/25/23 20:28:26.676
Apr 25 20:28:26.718: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-5530" to be "running"
Apr 25 20:28:26.731: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.082387ms
Apr 25 20:28:28.743: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.025299734s
Apr 25 20:28:28.744: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 04/25/23 20:28:28.744
Apr 25 20:28:28.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=webhook-5530 attach --namespace=webhook-5530 to-be-attached-pod -i -c=container1'
Apr 25 20:28:28.960: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:28:28.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5530" for this suite. 04/25/23 20:28:28.994
STEP: Destroying namespace "webhook-5530-markers" for this suite. 04/25/23 20:28:29.013
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":207,"skipped":3739,"failed":0}
------------------------------
• [SLOW TEST] [8.193 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:28:20.947
    Apr 25 20:28:20.948: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 20:28:20.95
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:21.036
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:21.045
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 20:28:21.089
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:28:21.336
    STEP: Deploying the webhook pod 04/25/23 20:28:21.356
    STEP: Wait for the deployment to be ready 04/25/23 20:28:21.391
    Apr 25 20:28:21.418: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 25 20:28:23.472: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 28, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 28, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 28, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 28, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/25/23 20:28:25.487
    STEP: Verifying the service has paired with the endpoint 04/25/23 20:28:25.516
    Apr 25 20:28:26.517: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 04/25/23 20:28:26.532
    STEP: create a pod 04/25/23 20:28:26.676
    Apr 25 20:28:26.718: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-5530" to be "running"
    Apr 25 20:28:26.731: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.082387ms
    Apr 25 20:28:28.743: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.025299734s
    Apr 25 20:28:28.744: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 04/25/23 20:28:28.744
    Apr 25 20:28:28.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=webhook-5530 attach --namespace=webhook-5530 to-be-attached-pod -i -c=container1'
    Apr 25 20:28:28.960: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:28:28.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5530" for this suite. 04/25/23 20:28:28.994
    STEP: Destroying namespace "webhook-5530-markers" for this suite. 04/25/23 20:28:29.013
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:28:29.145
Apr 25 20:28:29.146: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 20:28:29.149
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:29.205
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:29.217
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 20:28:29.277
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:28:29.844
STEP: Deploying the webhook pod 04/25/23 20:28:29.858
STEP: Wait for the deployment to be ready 04/25/23 20:28:29.886
Apr 25 20:28:29.908: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/25/23 20:28:31.944
STEP: Verifying the service has paired with the endpoint 04/25/23 20:28:31.974
Apr 25 20:28:32.975: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 04/25/23 20:28:32.987
STEP: Registering slow webhook via the AdmissionRegistration API 04/25/23 20:28:32.987
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 04/25/23 20:28:33.058
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 04/25/23 20:28:34.083
STEP: Registering slow webhook via the AdmissionRegistration API 04/25/23 20:28:34.083
STEP: Having no error when timeout is longer than webhook latency 04/25/23 20:28:35.163
STEP: Registering slow webhook via the AdmissionRegistration API 04/25/23 20:28:35.164
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 04/25/23 20:28:40.293
STEP: Registering slow webhook via the AdmissionRegistration API 04/25/23 20:28:40.294
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:28:45.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-34" for this suite. 04/25/23 20:28:45.459
STEP: Destroying namespace "webhook-34-markers" for this suite. 04/25/23 20:28:45.485
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":208,"skipped":3744,"failed":0}
------------------------------
• [SLOW TEST] [16.533 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:28:29.145
    Apr 25 20:28:29.146: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 20:28:29.149
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:29.205
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:29.217
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 20:28:29.277
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:28:29.844
    STEP: Deploying the webhook pod 04/25/23 20:28:29.858
    STEP: Wait for the deployment to be ready 04/25/23 20:28:29.886
    Apr 25 20:28:29.908: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/25/23 20:28:31.944
    STEP: Verifying the service has paired with the endpoint 04/25/23 20:28:31.974
    Apr 25 20:28:32.975: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 04/25/23 20:28:32.987
    STEP: Registering slow webhook via the AdmissionRegistration API 04/25/23 20:28:32.987
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 04/25/23 20:28:33.058
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 04/25/23 20:28:34.083
    STEP: Registering slow webhook via the AdmissionRegistration API 04/25/23 20:28:34.083
    STEP: Having no error when timeout is longer than webhook latency 04/25/23 20:28:35.163
    STEP: Registering slow webhook via the AdmissionRegistration API 04/25/23 20:28:35.164
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 04/25/23 20:28:40.293
    STEP: Registering slow webhook via the AdmissionRegistration API 04/25/23 20:28:40.294
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:28:45.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-34" for this suite. 04/25/23 20:28:45.459
    STEP: Destroying namespace "webhook-34-markers" for this suite. 04/25/23 20:28:45.485
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:28:45.681
Apr 25 20:28:45.682: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 20:28:45.685
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:45.745
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:45.759
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 04/25/23 20:28:45.767
Apr 25 20:28:45.797: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca" in namespace "downward-api-4036" to be "Succeeded or Failed"
Apr 25 20:28:45.812: INFO: Pod "downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca": Phase="Pending", Reason="", readiness=false. Elapsed: 14.349406ms
Apr 25 20:28:47.824: INFO: Pod "downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026933432s
Apr 25 20:28:49.828: INFO: Pod "downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030910392s
STEP: Saw pod success 04/25/23 20:28:49.829
Apr 25 20:28:49.829: INFO: Pod "downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca" satisfied condition "Succeeded or Failed"
Apr 25 20:28:49.839: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca container client-container: <nil>
STEP: delete the pod 04/25/23 20:28:49.873
Apr 25 20:28:49.908: INFO: Waiting for pod downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca to disappear
Apr 25 20:28:49.918: INFO: Pod downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 25 20:28:49.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4036" for this suite. 04/25/23 20:28:49.936
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":209,"skipped":3748,"failed":0}
------------------------------
• [4.272 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:28:45.681
    Apr 25 20:28:45.682: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 20:28:45.685
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:45.745
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:45.759
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 04/25/23 20:28:45.767
    Apr 25 20:28:45.797: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca" in namespace "downward-api-4036" to be "Succeeded or Failed"
    Apr 25 20:28:45.812: INFO: Pod "downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca": Phase="Pending", Reason="", readiness=false. Elapsed: 14.349406ms
    Apr 25 20:28:47.824: INFO: Pod "downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026933432s
    Apr 25 20:28:49.828: INFO: Pod "downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030910392s
    STEP: Saw pod success 04/25/23 20:28:49.829
    Apr 25 20:28:49.829: INFO: Pod "downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca" satisfied condition "Succeeded or Failed"
    Apr 25 20:28:49.839: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca container client-container: <nil>
    STEP: delete the pod 04/25/23 20:28:49.873
    Apr 25 20:28:49.908: INFO: Waiting for pod downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca to disappear
    Apr 25 20:28:49.918: INFO: Pod downwardapi-volume-2c4c93f4-6c31-4a44-9106-232b0cfc6aca no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 25 20:28:49.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4036" for this suite. 04/25/23 20:28:49.936
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:28:49.963
Apr 25 20:28:49.964: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename secrets 04/25/23 20:28:49.966
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:50.009
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:50.019
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-e909ba6b-d45d-46ab-b246-238986989c29 04/25/23 20:28:50.03
STEP: Creating a pod to test consume secrets 04/25/23 20:28:50.044
Apr 25 20:28:50.065: INFO: Waiting up to 5m0s for pod "pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af" in namespace "secrets-361" to be "Succeeded or Failed"
Apr 25 20:28:50.075: INFO: Pod "pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af": Phase="Pending", Reason="", readiness=false. Elapsed: 9.720755ms
Apr 25 20:28:52.088: INFO: Pod "pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022502074s
Apr 25 20:28:54.089: INFO: Pod "pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02373743s
STEP: Saw pod success 04/25/23 20:28:54.089
Apr 25 20:28:54.090: INFO: Pod "pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af" satisfied condition "Succeeded or Failed"
Apr 25 20:28:54.100: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af container secret-env-test: <nil>
STEP: delete the pod 04/25/23 20:28:54.132
Apr 25 20:28:54.157: INFO: Waiting for pod pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af to disappear
Apr 25 20:28:54.168: INFO: Pod pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 25 20:28:54.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-361" for this suite. 04/25/23 20:28:54.187
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":210,"skipped":3768,"failed":0}
------------------------------
• [4.241 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:28:49.963
    Apr 25 20:28:49.964: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename secrets 04/25/23 20:28:49.966
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:50.009
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:50.019
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-e909ba6b-d45d-46ab-b246-238986989c29 04/25/23 20:28:50.03
    STEP: Creating a pod to test consume secrets 04/25/23 20:28:50.044
    Apr 25 20:28:50.065: INFO: Waiting up to 5m0s for pod "pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af" in namespace "secrets-361" to be "Succeeded or Failed"
    Apr 25 20:28:50.075: INFO: Pod "pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af": Phase="Pending", Reason="", readiness=false. Elapsed: 9.720755ms
    Apr 25 20:28:52.088: INFO: Pod "pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022502074s
    Apr 25 20:28:54.089: INFO: Pod "pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02373743s
    STEP: Saw pod success 04/25/23 20:28:54.089
    Apr 25 20:28:54.090: INFO: Pod "pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af" satisfied condition "Succeeded or Failed"
    Apr 25 20:28:54.100: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af container secret-env-test: <nil>
    STEP: delete the pod 04/25/23 20:28:54.132
    Apr 25 20:28:54.157: INFO: Waiting for pod pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af to disappear
    Apr 25 20:28:54.168: INFO: Pod pod-secrets-c4643657-7cd4-4687-a31b-12e0407c77af no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 25 20:28:54.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-361" for this suite. 04/25/23 20:28:54.187
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:28:54.211
Apr 25 20:28:54.211: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename containers 04/25/23 20:28:54.213
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:54.255
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:54.264
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 04/25/23 20:28:54.275
Apr 25 20:28:54.295: INFO: Waiting up to 5m0s for pod "client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573" in namespace "containers-3539" to be "Succeeded or Failed"
Apr 25 20:28:54.307: INFO: Pod "client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573": Phase="Pending", Reason="", readiness=false. Elapsed: 11.918009ms
Apr 25 20:28:56.332: INFO: Pod "client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036223497s
Apr 25 20:28:58.319: INFO: Pod "client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023645857s
STEP: Saw pod success 04/25/23 20:28:58.319
Apr 25 20:28:58.320: INFO: Pod "client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573" satisfied condition "Succeeded or Failed"
Apr 25 20:28:58.329: INFO: Trying to get logs from node 10.10.21.190 pod client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573 container agnhost-container: <nil>
STEP: delete the pod 04/25/23 20:28:58.357
Apr 25 20:28:58.382: INFO: Waiting for pod client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573 to disappear
Apr 25 20:28:58.393: INFO: Pod client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 25 20:28:58.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3539" for this suite. 04/25/23 20:28:58.41
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":211,"skipped":3791,"failed":0}
------------------------------
• [4.219 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:28:54.211
    Apr 25 20:28:54.211: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename containers 04/25/23 20:28:54.213
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:54.255
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:54.264
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 04/25/23 20:28:54.275
    Apr 25 20:28:54.295: INFO: Waiting up to 5m0s for pod "client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573" in namespace "containers-3539" to be "Succeeded or Failed"
    Apr 25 20:28:54.307: INFO: Pod "client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573": Phase="Pending", Reason="", readiness=false. Elapsed: 11.918009ms
    Apr 25 20:28:56.332: INFO: Pod "client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036223497s
    Apr 25 20:28:58.319: INFO: Pod "client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023645857s
    STEP: Saw pod success 04/25/23 20:28:58.319
    Apr 25 20:28:58.320: INFO: Pod "client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573" satisfied condition "Succeeded or Failed"
    Apr 25 20:28:58.329: INFO: Trying to get logs from node 10.10.21.190 pod client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573 container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 20:28:58.357
    Apr 25 20:28:58.382: INFO: Waiting for pod client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573 to disappear
    Apr 25 20:28:58.393: INFO: Pod client-containers-8fd9e8fd-deeb-4371-b3e1-471063ad1573 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 25 20:28:58.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-3539" for this suite. 04/25/23 20:28:58.41
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:28:58.441
Apr 25 20:28:58.442: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename custom-resource-definition 04/25/23 20:28:58.443
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:58.512
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:58.523
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Apr 25 20:28:58.531: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:28:59.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-932" for this suite. 04/25/23 20:28:59.178
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":212,"skipped":3802,"failed":0}
------------------------------
• [0.755 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:28:58.441
    Apr 25 20:28:58.442: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename custom-resource-definition 04/25/23 20:28:58.443
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:58.512
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:58.523
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Apr 25 20:28:58.531: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:28:59.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-932" for this suite. 04/25/23 20:28:59.178
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:28:59.198
Apr 25 20:28:59.198: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename statefulset 04/25/23 20:28:59.201
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:59.246
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:59.255
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-8586 04/25/23 20:28:59.265
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 04/25/23 20:28:59.282
STEP: Creating pod with conflicting port in namespace statefulset-8586 04/25/23 20:28:59.326
STEP: Waiting until pod test-pod will start running in namespace statefulset-8586 04/25/23 20:28:59.365
Apr 25 20:28:59.366: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-8586" to be "running"
Apr 25 20:28:59.377: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.916511ms
Apr 25 20:29:01.390: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02469593s
Apr 25 20:29:03.389: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.022868489s
Apr 25 20:29:03.389: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-8586 04/25/23 20:29:03.39
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-8586 04/25/23 20:29:03.403
Apr 25 20:29:03.442: INFO: Observed stateful pod in namespace: statefulset-8586, name: ss-0, uid: 55bd3ec1-03e6-4dae-a314-e31447aff43c, status phase: Pending. Waiting for statefulset controller to delete.
Apr 25 20:29:03.483: INFO: Observed stateful pod in namespace: statefulset-8586, name: ss-0, uid: 55bd3ec1-03e6-4dae-a314-e31447aff43c, status phase: Failed. Waiting for statefulset controller to delete.
Apr 25 20:29:03.525: INFO: Observed stateful pod in namespace: statefulset-8586, name: ss-0, uid: 55bd3ec1-03e6-4dae-a314-e31447aff43c, status phase: Failed. Waiting for statefulset controller to delete.
Apr 25 20:29:03.541: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-8586
STEP: Removing pod with conflicting port in namespace statefulset-8586 04/25/23 20:29:03.541
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-8586 and will be in running state 04/25/23 20:29:03.57
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 25 20:29:05.595: INFO: Deleting all statefulset in ns statefulset-8586
Apr 25 20:29:05.612: INFO: Scaling statefulset ss to 0
Apr 25 20:29:15.657: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 20:29:15.666: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 25 20:29:15.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8586" for this suite. 04/25/23 20:29:15.719
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":213,"skipped":3803,"failed":0}
------------------------------
• [SLOW TEST] [16.538 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:28:59.198
    Apr 25 20:28:59.198: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename statefulset 04/25/23 20:28:59.201
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:28:59.246
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:28:59.255
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-8586 04/25/23 20:28:59.265
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 04/25/23 20:28:59.282
    STEP: Creating pod with conflicting port in namespace statefulset-8586 04/25/23 20:28:59.326
    STEP: Waiting until pod test-pod will start running in namespace statefulset-8586 04/25/23 20:28:59.365
    Apr 25 20:28:59.366: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-8586" to be "running"
    Apr 25 20:28:59.377: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.916511ms
    Apr 25 20:29:01.390: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02469593s
    Apr 25 20:29:03.389: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.022868489s
    Apr 25 20:29:03.389: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-8586 04/25/23 20:29:03.39
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-8586 04/25/23 20:29:03.403
    Apr 25 20:29:03.442: INFO: Observed stateful pod in namespace: statefulset-8586, name: ss-0, uid: 55bd3ec1-03e6-4dae-a314-e31447aff43c, status phase: Pending. Waiting for statefulset controller to delete.
    Apr 25 20:29:03.483: INFO: Observed stateful pod in namespace: statefulset-8586, name: ss-0, uid: 55bd3ec1-03e6-4dae-a314-e31447aff43c, status phase: Failed. Waiting for statefulset controller to delete.
    Apr 25 20:29:03.525: INFO: Observed stateful pod in namespace: statefulset-8586, name: ss-0, uid: 55bd3ec1-03e6-4dae-a314-e31447aff43c, status phase: Failed. Waiting for statefulset controller to delete.
    Apr 25 20:29:03.541: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-8586
    STEP: Removing pod with conflicting port in namespace statefulset-8586 04/25/23 20:29:03.541
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-8586 and will be in running state 04/25/23 20:29:03.57
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 25 20:29:05.595: INFO: Deleting all statefulset in ns statefulset-8586
    Apr 25 20:29:05.612: INFO: Scaling statefulset ss to 0
    Apr 25 20:29:15.657: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 25 20:29:15.666: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 25 20:29:15.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-8586" for this suite. 04/25/23 20:29:15.719
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:29:15.739
Apr 25 20:29:15.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename events 04/25/23 20:29:15.747
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:29:15.802
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:29:15.812
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 04/25/23 20:29:15.821
STEP: get a list of Events with a label in the current namespace 04/25/23 20:29:15.865
STEP: delete a list of events 04/25/23 20:29:15.877
Apr 25 20:29:15.878: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 04/25/23 20:29:15.945
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Apr 25 20:29:15.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8736" for this suite. 04/25/23 20:29:15.975
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":214,"skipped":3808,"failed":0}
------------------------------
• [0.254 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:29:15.739
    Apr 25 20:29:15.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename events 04/25/23 20:29:15.747
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:29:15.802
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:29:15.812
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 04/25/23 20:29:15.821
    STEP: get a list of Events with a label in the current namespace 04/25/23 20:29:15.865
    STEP: delete a list of events 04/25/23 20:29:15.877
    Apr 25 20:29:15.878: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 04/25/23 20:29:15.945
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Apr 25 20:29:15.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-8736" for this suite. 04/25/23 20:29:15.975
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:29:16.002
Apr 25 20:29:16.002: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename job 04/25/23 20:29:16.004
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:29:16.042
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:29:16.052
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 04/25/23 20:29:16.061
STEP: Ensuring active pods == parallelism 04/25/23 20:29:16.083
STEP: Orphaning one of the Job's Pods 04/25/23 20:29:18.098
Apr 25 20:29:18.647: INFO: Successfully updated pod "adopt-release-7zz9x"
STEP: Checking that the Job readopts the Pod 04/25/23 20:29:18.648
Apr 25 20:29:18.649: INFO: Waiting up to 15m0s for pod "adopt-release-7zz9x" in namespace "job-5616" to be "adopted"
Apr 25 20:29:18.661: INFO: Pod "adopt-release-7zz9x": Phase="Running", Reason="", readiness=true. Elapsed: 12.16708ms
Apr 25 20:29:20.672: INFO: Pod "adopt-release-7zz9x": Phase="Running", Reason="", readiness=true. Elapsed: 2.023250283s
Apr 25 20:29:20.672: INFO: Pod "adopt-release-7zz9x" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 04/25/23 20:29:20.672
Apr 25 20:29:21.201: INFO: Successfully updated pod "adopt-release-7zz9x"
STEP: Checking that the Job releases the Pod 04/25/23 20:29:21.201
Apr 25 20:29:21.202: INFO: Waiting up to 15m0s for pod "adopt-release-7zz9x" in namespace "job-5616" to be "released"
Apr 25 20:29:21.212: INFO: Pod "adopt-release-7zz9x": Phase="Running", Reason="", readiness=true. Elapsed: 10.437675ms
Apr 25 20:29:23.224: INFO: Pod "adopt-release-7zz9x": Phase="Running", Reason="", readiness=true. Elapsed: 2.022573392s
Apr 25 20:29:23.224: INFO: Pod "adopt-release-7zz9x" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 25 20:29:23.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5616" for this suite. 04/25/23 20:29:23.253
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":215,"skipped":3832,"failed":0}
------------------------------
• [SLOW TEST] [7.270 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:29:16.002
    Apr 25 20:29:16.002: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename job 04/25/23 20:29:16.004
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:29:16.042
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:29:16.052
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 04/25/23 20:29:16.061
    STEP: Ensuring active pods == parallelism 04/25/23 20:29:16.083
    STEP: Orphaning one of the Job's Pods 04/25/23 20:29:18.098
    Apr 25 20:29:18.647: INFO: Successfully updated pod "adopt-release-7zz9x"
    STEP: Checking that the Job readopts the Pod 04/25/23 20:29:18.648
    Apr 25 20:29:18.649: INFO: Waiting up to 15m0s for pod "adopt-release-7zz9x" in namespace "job-5616" to be "adopted"
    Apr 25 20:29:18.661: INFO: Pod "adopt-release-7zz9x": Phase="Running", Reason="", readiness=true. Elapsed: 12.16708ms
    Apr 25 20:29:20.672: INFO: Pod "adopt-release-7zz9x": Phase="Running", Reason="", readiness=true. Elapsed: 2.023250283s
    Apr 25 20:29:20.672: INFO: Pod "adopt-release-7zz9x" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 04/25/23 20:29:20.672
    Apr 25 20:29:21.201: INFO: Successfully updated pod "adopt-release-7zz9x"
    STEP: Checking that the Job releases the Pod 04/25/23 20:29:21.201
    Apr 25 20:29:21.202: INFO: Waiting up to 15m0s for pod "adopt-release-7zz9x" in namespace "job-5616" to be "released"
    Apr 25 20:29:21.212: INFO: Pod "adopt-release-7zz9x": Phase="Running", Reason="", readiness=true. Elapsed: 10.437675ms
    Apr 25 20:29:23.224: INFO: Pod "adopt-release-7zz9x": Phase="Running", Reason="", readiness=true. Elapsed: 2.022573392s
    Apr 25 20:29:23.224: INFO: Pod "adopt-release-7zz9x" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 25 20:29:23.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-5616" for this suite. 04/25/23 20:29:23.253
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:29:23.286
Apr 25 20:29:23.287: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename sysctl 04/25/23 20:29:23.288
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:29:23.351
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:29:23.36
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 04/25/23 20:29:23.369
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 25 20:29:23.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-9363" for this suite. 04/25/23 20:29:23.4
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":216,"skipped":3840,"failed":0}
------------------------------
• [0.131 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:29:23.286
    Apr 25 20:29:23.287: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename sysctl 04/25/23 20:29:23.288
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:29:23.351
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:29:23.36
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 04/25/23 20:29:23.369
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 25 20:29:23.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-9363" for this suite. 04/25/23 20:29:23.4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:29:23.428
Apr 25 20:29:23.428: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-lifecycle-hook 04/25/23 20:29:23.43
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:29:23.482
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:29:23.491
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/25/23 20:29:23.516
Apr 25 20:29:23.535: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4395" to be "running and ready"
Apr 25 20:29:23.546: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 10.94951ms
Apr 25 20:29:23.546: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:29:25.556: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.021512461s
Apr 25 20:29:25.556: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 25 20:29:25.557: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 04/25/23 20:29:25.568
Apr 25 20:29:25.581: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-4395" to be "running and ready"
Apr 25 20:29:25.593: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 11.527856ms
Apr 25 20:29:25.594: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:29:27.608: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026697535s
Apr 25 20:29:27.608: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:29:29.606: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.023939816s
Apr 25 20:29:29.606: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Apr 25 20:29:29.606: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 04/25/23 20:29:29.616
STEP: delete the pod with lifecycle hook 04/25/23 20:29:29.704
Apr 25 20:29:29.746: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 25 20:29:29.759: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 25 20:29:31.760: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 25 20:29:31.770: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 25 20:29:31.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4395" for this suite. 04/25/23 20:29:31.798
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":217,"skipped":3857,"failed":0}
------------------------------
• [SLOW TEST] [8.391 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:29:23.428
    Apr 25 20:29:23.428: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/25/23 20:29:23.43
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:29:23.482
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:29:23.491
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/25/23 20:29:23.516
    Apr 25 20:29:23.535: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4395" to be "running and ready"
    Apr 25 20:29:23.546: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 10.94951ms
    Apr 25 20:29:23.546: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:29:25.556: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.021512461s
    Apr 25 20:29:25.556: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 25 20:29:25.557: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 04/25/23 20:29:25.568
    Apr 25 20:29:25.581: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-4395" to be "running and ready"
    Apr 25 20:29:25.593: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 11.527856ms
    Apr 25 20:29:25.594: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:29:27.608: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026697535s
    Apr 25 20:29:27.608: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:29:29.606: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.023939816s
    Apr 25 20:29:29.606: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Apr 25 20:29:29.606: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 04/25/23 20:29:29.616
    STEP: delete the pod with lifecycle hook 04/25/23 20:29:29.704
    Apr 25 20:29:29.746: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Apr 25 20:29:29.759: INFO: Pod pod-with-poststart-exec-hook still exists
    Apr 25 20:29:31.760: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Apr 25 20:29:31.770: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 25 20:29:31.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-4395" for this suite. 04/25/23 20:29:31.798
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:29:31.82
Apr 25 20:29:31.821: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename gc 04/25/23 20:29:31.824
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:29:31.869
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:29:31.88
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 04/25/23 20:29:31.904
STEP: delete the rc 04/25/23 20:29:36.934
STEP: wait for the rc to be deleted 04/25/23 20:29:36.954
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 04/25/23 20:29:41.965
STEP: Gathering metrics 04/25/23 20:30:11.995
W0425 20:30:12.024516      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 25 20:30:12.024: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr 25 20:30:12.024: INFO: Deleting pod "simpletest.rc-24rn9" in namespace "gc-5102"
Apr 25 20:30:12.052: INFO: Deleting pod "simpletest.rc-2l6ml" in namespace "gc-5102"
Apr 25 20:30:12.080: INFO: Deleting pod "simpletest.rc-46bn7" in namespace "gc-5102"
Apr 25 20:30:12.106: INFO: Deleting pod "simpletest.rc-4jq8r" in namespace "gc-5102"
Apr 25 20:30:12.171: INFO: Deleting pod "simpletest.rc-4rnfw" in namespace "gc-5102"
Apr 25 20:30:12.219: INFO: Deleting pod "simpletest.rc-4t4cb" in namespace "gc-5102"
Apr 25 20:30:12.264: INFO: Deleting pod "simpletest.rc-4zd7w" in namespace "gc-5102"
Apr 25 20:30:12.306: INFO: Deleting pod "simpletest.rc-4zlfx" in namespace "gc-5102"
Apr 25 20:30:12.345: INFO: Deleting pod "simpletest.rc-584fm" in namespace "gc-5102"
Apr 25 20:30:12.429: INFO: Deleting pod "simpletest.rc-5cdhf" in namespace "gc-5102"
Apr 25 20:30:12.498: INFO: Deleting pod "simpletest.rc-5fcd2" in namespace "gc-5102"
Apr 25 20:30:12.582: INFO: Deleting pod "simpletest.rc-624r2" in namespace "gc-5102"
Apr 25 20:30:12.628: INFO: Deleting pod "simpletest.rc-684rr" in namespace "gc-5102"
Apr 25 20:30:12.703: INFO: Deleting pod "simpletest.rc-6cfmv" in namespace "gc-5102"
Apr 25 20:30:12.768: INFO: Deleting pod "simpletest.rc-6h5n5" in namespace "gc-5102"
Apr 25 20:30:12.812: INFO: Deleting pod "simpletest.rc-7wjff" in namespace "gc-5102"
Apr 25 20:30:12.858: INFO: Deleting pod "simpletest.rc-847gf" in namespace "gc-5102"
Apr 25 20:30:12.914: INFO: Deleting pod "simpletest.rc-8cplj" in namespace "gc-5102"
Apr 25 20:30:12.950: INFO: Deleting pod "simpletest.rc-8jg4d" in namespace "gc-5102"
Apr 25 20:30:12.990: INFO: Deleting pod "simpletest.rc-97cxr" in namespace "gc-5102"
Apr 25 20:30:13.023: INFO: Deleting pod "simpletest.rc-9jjht" in namespace "gc-5102"
Apr 25 20:30:13.064: INFO: Deleting pod "simpletest.rc-9krzz" in namespace "gc-5102"
Apr 25 20:30:13.101: INFO: Deleting pod "simpletest.rc-9xd7x" in namespace "gc-5102"
Apr 25 20:30:13.166: INFO: Deleting pod "simpletest.rc-bcdzf" in namespace "gc-5102"
Apr 25 20:30:13.211: INFO: Deleting pod "simpletest.rc-bdpwh" in namespace "gc-5102"
Apr 25 20:30:13.273: INFO: Deleting pod "simpletest.rc-brn86" in namespace "gc-5102"
Apr 25 20:30:13.380: INFO: Deleting pod "simpletest.rc-bxvq9" in namespace "gc-5102"
Apr 25 20:30:13.425: INFO: Deleting pod "simpletest.rc-c4j9n" in namespace "gc-5102"
Apr 25 20:30:13.464: INFO: Deleting pod "simpletest.rc-cpgdp" in namespace "gc-5102"
Apr 25 20:30:13.508: INFO: Deleting pod "simpletest.rc-cv57s" in namespace "gc-5102"
Apr 25 20:30:13.594: INFO: Deleting pod "simpletest.rc-dbv2v" in namespace "gc-5102"
Apr 25 20:30:13.669: INFO: Deleting pod "simpletest.rc-dfskq" in namespace "gc-5102"
Apr 25 20:30:13.728: INFO: Deleting pod "simpletest.rc-dqvwh" in namespace "gc-5102"
Apr 25 20:30:13.775: INFO: Deleting pod "simpletest.rc-f2cw4" in namespace "gc-5102"
Apr 25 20:30:13.817: INFO: Deleting pod "simpletest.rc-f5mn2" in namespace "gc-5102"
Apr 25 20:30:13.869: INFO: Deleting pod "simpletest.rc-fgvbd" in namespace "gc-5102"
Apr 25 20:30:13.918: INFO: Deleting pod "simpletest.rc-g4xc5" in namespace "gc-5102"
Apr 25 20:30:13.963: INFO: Deleting pod "simpletest.rc-g57l9" in namespace "gc-5102"
Apr 25 20:30:14.018: INFO: Deleting pod "simpletest.rc-g7xh6" in namespace "gc-5102"
Apr 25 20:30:14.059: INFO: Deleting pod "simpletest.rc-gkwf2" in namespace "gc-5102"
Apr 25 20:30:14.112: INFO: Deleting pod "simpletest.rc-gn7wl" in namespace "gc-5102"
Apr 25 20:30:14.152: INFO: Deleting pod "simpletest.rc-gw95b" in namespace "gc-5102"
Apr 25 20:30:14.207: INFO: Deleting pod "simpletest.rc-hlsbf" in namespace "gc-5102"
Apr 25 20:30:14.258: INFO: Deleting pod "simpletest.rc-hmnl6" in namespace "gc-5102"
Apr 25 20:30:14.314: INFO: Deleting pod "simpletest.rc-j9czf" in namespace "gc-5102"
Apr 25 20:30:14.361: INFO: Deleting pod "simpletest.rc-jktts" in namespace "gc-5102"
Apr 25 20:30:14.420: INFO: Deleting pod "simpletest.rc-jthmc" in namespace "gc-5102"
Apr 25 20:30:14.525: INFO: Deleting pod "simpletest.rc-k6c7p" in namespace "gc-5102"
Apr 25 20:30:14.567: INFO: Deleting pod "simpletest.rc-k96zt" in namespace "gc-5102"
Apr 25 20:30:14.631: INFO: Deleting pod "simpletest.rc-kf6fw" in namespace "gc-5102"
Apr 25 20:30:14.689: INFO: Deleting pod "simpletest.rc-kpbtj" in namespace "gc-5102"
Apr 25 20:30:14.739: INFO: Deleting pod "simpletest.rc-kx4x7" in namespace "gc-5102"
Apr 25 20:30:14.777: INFO: Deleting pod "simpletest.rc-l88hx" in namespace "gc-5102"
Apr 25 20:30:14.836: INFO: Deleting pod "simpletest.rc-l8lh9" in namespace "gc-5102"
Apr 25 20:30:14.904: INFO: Deleting pod "simpletest.rc-l9knb" in namespace "gc-5102"
Apr 25 20:30:14.944: INFO: Deleting pod "simpletest.rc-lkx85" in namespace "gc-5102"
Apr 25 20:30:15.012: INFO: Deleting pod "simpletest.rc-lljz4" in namespace "gc-5102"
Apr 25 20:30:15.094: INFO: Deleting pod "simpletest.rc-lnfcc" in namespace "gc-5102"
Apr 25 20:30:15.137: INFO: Deleting pod "simpletest.rc-lpck2" in namespace "gc-5102"
Apr 25 20:30:15.179: INFO: Deleting pod "simpletest.rc-m76dk" in namespace "gc-5102"
Apr 25 20:30:15.261: INFO: Deleting pod "simpletest.rc-mqg8c" in namespace "gc-5102"
Apr 25 20:30:15.311: INFO: Deleting pod "simpletest.rc-n8hsc" in namespace "gc-5102"
Apr 25 20:30:15.356: INFO: Deleting pod "simpletest.rc-nh5qn" in namespace "gc-5102"
Apr 25 20:30:15.404: INFO: Deleting pod "simpletest.rc-nlp8r" in namespace "gc-5102"
Apr 25 20:30:15.454: INFO: Deleting pod "simpletest.rc-nnb67" in namespace "gc-5102"
Apr 25 20:30:15.511: INFO: Deleting pod "simpletest.rc-nr56v" in namespace "gc-5102"
Apr 25 20:30:15.643: INFO: Deleting pod "simpletest.rc-p6p2t" in namespace "gc-5102"
Apr 25 20:30:15.698: INFO: Deleting pod "simpletest.rc-pm8mp" in namespace "gc-5102"
Apr 25 20:30:15.773: INFO: Deleting pod "simpletest.rc-pmxff" in namespace "gc-5102"
Apr 25 20:30:15.861: INFO: Deleting pod "simpletest.rc-pwk4k" in namespace "gc-5102"
Apr 25 20:30:15.920: INFO: Deleting pod "simpletest.rc-pwlpj" in namespace "gc-5102"
Apr 25 20:30:15.994: INFO: Deleting pod "simpletest.rc-qm2gd" in namespace "gc-5102"
Apr 25 20:30:16.032: INFO: Deleting pod "simpletest.rc-qpshz" in namespace "gc-5102"
Apr 25 20:30:16.070: INFO: Deleting pod "simpletest.rc-qz7v8" in namespace "gc-5102"
Apr 25 20:30:16.123: INFO: Deleting pod "simpletest.rc-r2znc" in namespace "gc-5102"
Apr 25 20:30:16.203: INFO: Deleting pod "simpletest.rc-rl74p" in namespace "gc-5102"
Apr 25 20:30:16.260: INFO: Deleting pod "simpletest.rc-rpqvg" in namespace "gc-5102"
Apr 25 20:30:16.307: INFO: Deleting pod "simpletest.rc-s5fhl" in namespace "gc-5102"
Apr 25 20:30:16.373: INFO: Deleting pod "simpletest.rc-sp89j" in namespace "gc-5102"
Apr 25 20:30:16.462: INFO: Deleting pod "simpletest.rc-sp8cg" in namespace "gc-5102"
Apr 25 20:30:16.510: INFO: Deleting pod "simpletest.rc-swxgl" in namespace "gc-5102"
Apr 25 20:30:16.586: INFO: Deleting pod "simpletest.rc-tcqzc" in namespace "gc-5102"
Apr 25 20:30:16.633: INFO: Deleting pod "simpletest.rc-tpw7s" in namespace "gc-5102"
Apr 25 20:30:16.676: INFO: Deleting pod "simpletest.rc-v7gjk" in namespace "gc-5102"
Apr 25 20:30:16.736: INFO: Deleting pod "simpletest.rc-vl4g5" in namespace "gc-5102"
Apr 25 20:30:16.776: INFO: Deleting pod "simpletest.rc-vq9q8" in namespace "gc-5102"
Apr 25 20:30:16.903: INFO: Deleting pod "simpletest.rc-vqjtx" in namespace "gc-5102"
Apr 25 20:30:17.000: INFO: Deleting pod "simpletest.rc-vsqhl" in namespace "gc-5102"
Apr 25 20:30:17.065: INFO: Deleting pod "simpletest.rc-wc5zf" in namespace "gc-5102"
Apr 25 20:30:17.114: INFO: Deleting pod "simpletest.rc-wddhv" in namespace "gc-5102"
Apr 25 20:30:17.179: INFO: Deleting pod "simpletest.rc-wpzwx" in namespace "gc-5102"
Apr 25 20:30:17.225: INFO: Deleting pod "simpletest.rc-wsmlx" in namespace "gc-5102"
Apr 25 20:30:17.323: INFO: Deleting pod "simpletest.rc-z57h5" in namespace "gc-5102"
Apr 25 20:30:17.367: INFO: Deleting pod "simpletest.rc-zb92h" in namespace "gc-5102"
Apr 25 20:30:17.460: INFO: Deleting pod "simpletest.rc-zd762" in namespace "gc-5102"
Apr 25 20:30:17.523: INFO: Deleting pod "simpletest.rc-zn9ff" in namespace "gc-5102"
Apr 25 20:30:17.613: INFO: Deleting pod "simpletest.rc-znq7j" in namespace "gc-5102"
Apr 25 20:30:17.673: INFO: Deleting pod "simpletest.rc-zp672" in namespace "gc-5102"
Apr 25 20:30:17.711: INFO: Deleting pod "simpletest.rc-zq8fj" in namespace "gc-5102"
Apr 25 20:30:17.771: INFO: Deleting pod "simpletest.rc-zxwgt" in namespace "gc-5102"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 25 20:30:17.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5102" for this suite. 04/25/23 20:30:17.852
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":218,"skipped":3862,"failed":0}
------------------------------
• [SLOW TEST] [46.083 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:29:31.82
    Apr 25 20:29:31.821: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename gc 04/25/23 20:29:31.824
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:29:31.869
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:29:31.88
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 04/25/23 20:29:31.904
    STEP: delete the rc 04/25/23 20:29:36.934
    STEP: wait for the rc to be deleted 04/25/23 20:29:36.954
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 04/25/23 20:29:41.965
    STEP: Gathering metrics 04/25/23 20:30:11.995
    W0425 20:30:12.024516      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 25 20:30:12.024: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Apr 25 20:30:12.024: INFO: Deleting pod "simpletest.rc-24rn9" in namespace "gc-5102"
    Apr 25 20:30:12.052: INFO: Deleting pod "simpletest.rc-2l6ml" in namespace "gc-5102"
    Apr 25 20:30:12.080: INFO: Deleting pod "simpletest.rc-46bn7" in namespace "gc-5102"
    Apr 25 20:30:12.106: INFO: Deleting pod "simpletest.rc-4jq8r" in namespace "gc-5102"
    Apr 25 20:30:12.171: INFO: Deleting pod "simpletest.rc-4rnfw" in namespace "gc-5102"
    Apr 25 20:30:12.219: INFO: Deleting pod "simpletest.rc-4t4cb" in namespace "gc-5102"
    Apr 25 20:30:12.264: INFO: Deleting pod "simpletest.rc-4zd7w" in namespace "gc-5102"
    Apr 25 20:30:12.306: INFO: Deleting pod "simpletest.rc-4zlfx" in namespace "gc-5102"
    Apr 25 20:30:12.345: INFO: Deleting pod "simpletest.rc-584fm" in namespace "gc-5102"
    Apr 25 20:30:12.429: INFO: Deleting pod "simpletest.rc-5cdhf" in namespace "gc-5102"
    Apr 25 20:30:12.498: INFO: Deleting pod "simpletest.rc-5fcd2" in namespace "gc-5102"
    Apr 25 20:30:12.582: INFO: Deleting pod "simpletest.rc-624r2" in namespace "gc-5102"
    Apr 25 20:30:12.628: INFO: Deleting pod "simpletest.rc-684rr" in namespace "gc-5102"
    Apr 25 20:30:12.703: INFO: Deleting pod "simpletest.rc-6cfmv" in namespace "gc-5102"
    Apr 25 20:30:12.768: INFO: Deleting pod "simpletest.rc-6h5n5" in namespace "gc-5102"
    Apr 25 20:30:12.812: INFO: Deleting pod "simpletest.rc-7wjff" in namespace "gc-5102"
    Apr 25 20:30:12.858: INFO: Deleting pod "simpletest.rc-847gf" in namespace "gc-5102"
    Apr 25 20:30:12.914: INFO: Deleting pod "simpletest.rc-8cplj" in namespace "gc-5102"
    Apr 25 20:30:12.950: INFO: Deleting pod "simpletest.rc-8jg4d" in namespace "gc-5102"
    Apr 25 20:30:12.990: INFO: Deleting pod "simpletest.rc-97cxr" in namespace "gc-5102"
    Apr 25 20:30:13.023: INFO: Deleting pod "simpletest.rc-9jjht" in namespace "gc-5102"
    Apr 25 20:30:13.064: INFO: Deleting pod "simpletest.rc-9krzz" in namespace "gc-5102"
    Apr 25 20:30:13.101: INFO: Deleting pod "simpletest.rc-9xd7x" in namespace "gc-5102"
    Apr 25 20:30:13.166: INFO: Deleting pod "simpletest.rc-bcdzf" in namespace "gc-5102"
    Apr 25 20:30:13.211: INFO: Deleting pod "simpletest.rc-bdpwh" in namespace "gc-5102"
    Apr 25 20:30:13.273: INFO: Deleting pod "simpletest.rc-brn86" in namespace "gc-5102"
    Apr 25 20:30:13.380: INFO: Deleting pod "simpletest.rc-bxvq9" in namespace "gc-5102"
    Apr 25 20:30:13.425: INFO: Deleting pod "simpletest.rc-c4j9n" in namespace "gc-5102"
    Apr 25 20:30:13.464: INFO: Deleting pod "simpletest.rc-cpgdp" in namespace "gc-5102"
    Apr 25 20:30:13.508: INFO: Deleting pod "simpletest.rc-cv57s" in namespace "gc-5102"
    Apr 25 20:30:13.594: INFO: Deleting pod "simpletest.rc-dbv2v" in namespace "gc-5102"
    Apr 25 20:30:13.669: INFO: Deleting pod "simpletest.rc-dfskq" in namespace "gc-5102"
    Apr 25 20:30:13.728: INFO: Deleting pod "simpletest.rc-dqvwh" in namespace "gc-5102"
    Apr 25 20:30:13.775: INFO: Deleting pod "simpletest.rc-f2cw4" in namespace "gc-5102"
    Apr 25 20:30:13.817: INFO: Deleting pod "simpletest.rc-f5mn2" in namespace "gc-5102"
    Apr 25 20:30:13.869: INFO: Deleting pod "simpletest.rc-fgvbd" in namespace "gc-5102"
    Apr 25 20:30:13.918: INFO: Deleting pod "simpletest.rc-g4xc5" in namespace "gc-5102"
    Apr 25 20:30:13.963: INFO: Deleting pod "simpletest.rc-g57l9" in namespace "gc-5102"
    Apr 25 20:30:14.018: INFO: Deleting pod "simpletest.rc-g7xh6" in namespace "gc-5102"
    Apr 25 20:30:14.059: INFO: Deleting pod "simpletest.rc-gkwf2" in namespace "gc-5102"
    Apr 25 20:30:14.112: INFO: Deleting pod "simpletest.rc-gn7wl" in namespace "gc-5102"
    Apr 25 20:30:14.152: INFO: Deleting pod "simpletest.rc-gw95b" in namespace "gc-5102"
    Apr 25 20:30:14.207: INFO: Deleting pod "simpletest.rc-hlsbf" in namespace "gc-5102"
    Apr 25 20:30:14.258: INFO: Deleting pod "simpletest.rc-hmnl6" in namespace "gc-5102"
    Apr 25 20:30:14.314: INFO: Deleting pod "simpletest.rc-j9czf" in namespace "gc-5102"
    Apr 25 20:30:14.361: INFO: Deleting pod "simpletest.rc-jktts" in namespace "gc-5102"
    Apr 25 20:30:14.420: INFO: Deleting pod "simpletest.rc-jthmc" in namespace "gc-5102"
    Apr 25 20:30:14.525: INFO: Deleting pod "simpletest.rc-k6c7p" in namespace "gc-5102"
    Apr 25 20:30:14.567: INFO: Deleting pod "simpletest.rc-k96zt" in namespace "gc-5102"
    Apr 25 20:30:14.631: INFO: Deleting pod "simpletest.rc-kf6fw" in namespace "gc-5102"
    Apr 25 20:30:14.689: INFO: Deleting pod "simpletest.rc-kpbtj" in namespace "gc-5102"
    Apr 25 20:30:14.739: INFO: Deleting pod "simpletest.rc-kx4x7" in namespace "gc-5102"
    Apr 25 20:30:14.777: INFO: Deleting pod "simpletest.rc-l88hx" in namespace "gc-5102"
    Apr 25 20:30:14.836: INFO: Deleting pod "simpletest.rc-l8lh9" in namespace "gc-5102"
    Apr 25 20:30:14.904: INFO: Deleting pod "simpletest.rc-l9knb" in namespace "gc-5102"
    Apr 25 20:30:14.944: INFO: Deleting pod "simpletest.rc-lkx85" in namespace "gc-5102"
    Apr 25 20:30:15.012: INFO: Deleting pod "simpletest.rc-lljz4" in namespace "gc-5102"
    Apr 25 20:30:15.094: INFO: Deleting pod "simpletest.rc-lnfcc" in namespace "gc-5102"
    Apr 25 20:30:15.137: INFO: Deleting pod "simpletest.rc-lpck2" in namespace "gc-5102"
    Apr 25 20:30:15.179: INFO: Deleting pod "simpletest.rc-m76dk" in namespace "gc-5102"
    Apr 25 20:30:15.261: INFO: Deleting pod "simpletest.rc-mqg8c" in namespace "gc-5102"
    Apr 25 20:30:15.311: INFO: Deleting pod "simpletest.rc-n8hsc" in namespace "gc-5102"
    Apr 25 20:30:15.356: INFO: Deleting pod "simpletest.rc-nh5qn" in namespace "gc-5102"
    Apr 25 20:30:15.404: INFO: Deleting pod "simpletest.rc-nlp8r" in namespace "gc-5102"
    Apr 25 20:30:15.454: INFO: Deleting pod "simpletest.rc-nnb67" in namespace "gc-5102"
    Apr 25 20:30:15.511: INFO: Deleting pod "simpletest.rc-nr56v" in namespace "gc-5102"
    Apr 25 20:30:15.643: INFO: Deleting pod "simpletest.rc-p6p2t" in namespace "gc-5102"
    Apr 25 20:30:15.698: INFO: Deleting pod "simpletest.rc-pm8mp" in namespace "gc-5102"
    Apr 25 20:30:15.773: INFO: Deleting pod "simpletest.rc-pmxff" in namespace "gc-5102"
    Apr 25 20:30:15.861: INFO: Deleting pod "simpletest.rc-pwk4k" in namespace "gc-5102"
    Apr 25 20:30:15.920: INFO: Deleting pod "simpletest.rc-pwlpj" in namespace "gc-5102"
    Apr 25 20:30:15.994: INFO: Deleting pod "simpletest.rc-qm2gd" in namespace "gc-5102"
    Apr 25 20:30:16.032: INFO: Deleting pod "simpletest.rc-qpshz" in namespace "gc-5102"
    Apr 25 20:30:16.070: INFO: Deleting pod "simpletest.rc-qz7v8" in namespace "gc-5102"
    Apr 25 20:30:16.123: INFO: Deleting pod "simpletest.rc-r2znc" in namespace "gc-5102"
    Apr 25 20:30:16.203: INFO: Deleting pod "simpletest.rc-rl74p" in namespace "gc-5102"
    Apr 25 20:30:16.260: INFO: Deleting pod "simpletest.rc-rpqvg" in namespace "gc-5102"
    Apr 25 20:30:16.307: INFO: Deleting pod "simpletest.rc-s5fhl" in namespace "gc-5102"
    Apr 25 20:30:16.373: INFO: Deleting pod "simpletest.rc-sp89j" in namespace "gc-5102"
    Apr 25 20:30:16.462: INFO: Deleting pod "simpletest.rc-sp8cg" in namespace "gc-5102"
    Apr 25 20:30:16.510: INFO: Deleting pod "simpletest.rc-swxgl" in namespace "gc-5102"
    Apr 25 20:30:16.586: INFO: Deleting pod "simpletest.rc-tcqzc" in namespace "gc-5102"
    Apr 25 20:30:16.633: INFO: Deleting pod "simpletest.rc-tpw7s" in namespace "gc-5102"
    Apr 25 20:30:16.676: INFO: Deleting pod "simpletest.rc-v7gjk" in namespace "gc-5102"
    Apr 25 20:30:16.736: INFO: Deleting pod "simpletest.rc-vl4g5" in namespace "gc-5102"
    Apr 25 20:30:16.776: INFO: Deleting pod "simpletest.rc-vq9q8" in namespace "gc-5102"
    Apr 25 20:30:16.903: INFO: Deleting pod "simpletest.rc-vqjtx" in namespace "gc-5102"
    Apr 25 20:30:17.000: INFO: Deleting pod "simpletest.rc-vsqhl" in namespace "gc-5102"
    Apr 25 20:30:17.065: INFO: Deleting pod "simpletest.rc-wc5zf" in namespace "gc-5102"
    Apr 25 20:30:17.114: INFO: Deleting pod "simpletest.rc-wddhv" in namespace "gc-5102"
    Apr 25 20:30:17.179: INFO: Deleting pod "simpletest.rc-wpzwx" in namespace "gc-5102"
    Apr 25 20:30:17.225: INFO: Deleting pod "simpletest.rc-wsmlx" in namespace "gc-5102"
    Apr 25 20:30:17.323: INFO: Deleting pod "simpletest.rc-z57h5" in namespace "gc-5102"
    Apr 25 20:30:17.367: INFO: Deleting pod "simpletest.rc-zb92h" in namespace "gc-5102"
    Apr 25 20:30:17.460: INFO: Deleting pod "simpletest.rc-zd762" in namespace "gc-5102"
    Apr 25 20:30:17.523: INFO: Deleting pod "simpletest.rc-zn9ff" in namespace "gc-5102"
    Apr 25 20:30:17.613: INFO: Deleting pod "simpletest.rc-znq7j" in namespace "gc-5102"
    Apr 25 20:30:17.673: INFO: Deleting pod "simpletest.rc-zp672" in namespace "gc-5102"
    Apr 25 20:30:17.711: INFO: Deleting pod "simpletest.rc-zq8fj" in namespace "gc-5102"
    Apr 25 20:30:17.771: INFO: Deleting pod "simpletest.rc-zxwgt" in namespace "gc-5102"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 25 20:30:17.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5102" for this suite. 04/25/23 20:30:17.852
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:30:17.907
Apr 25 20:30:17.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:30:17.908
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:30:17.949
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:30:17.964
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-9a9f7dab-69e8-4ce0-99cc-20bcaf1a2dc3 04/25/23 20:30:17.976
STEP: Creating a pod to test consume secrets 04/25/23 20:30:17.996
Apr 25 20:30:18.026: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72" in namespace "projected-4937" to be "Succeeded or Failed"
Apr 25 20:30:18.039: INFO: Pod "pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72": Phase="Pending", Reason="", readiness=false. Elapsed: 13.790195ms
Apr 25 20:30:20.064: INFO: Pod "pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037911028s
Apr 25 20:30:22.056: INFO: Pod "pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030143091s
Apr 25 20:30:24.061: INFO: Pod "pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035488217s
Apr 25 20:30:26.055: INFO: Pod "pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.029700003s
STEP: Saw pod success 04/25/23 20:30:26.055
Apr 25 20:30:26.056: INFO: Pod "pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72" satisfied condition "Succeeded or Failed"
Apr 25 20:30:26.068: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/25/23 20:30:26.166
Apr 25 20:30:26.224: INFO: Waiting for pod pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72 to disappear
Apr 25 20:30:26.252: INFO: Pod pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 25 20:30:26.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4937" for this suite. 04/25/23 20:30:26.269
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":219,"skipped":3887,"failed":0}
------------------------------
• [SLOW TEST] [8.394 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:30:17.907
    Apr 25 20:30:17.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:30:17.908
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:30:17.949
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:30:17.964
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-9a9f7dab-69e8-4ce0-99cc-20bcaf1a2dc3 04/25/23 20:30:17.976
    STEP: Creating a pod to test consume secrets 04/25/23 20:30:17.996
    Apr 25 20:30:18.026: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72" in namespace "projected-4937" to be "Succeeded or Failed"
    Apr 25 20:30:18.039: INFO: Pod "pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72": Phase="Pending", Reason="", readiness=false. Elapsed: 13.790195ms
    Apr 25 20:30:20.064: INFO: Pod "pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037911028s
    Apr 25 20:30:22.056: INFO: Pod "pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030143091s
    Apr 25 20:30:24.061: INFO: Pod "pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035488217s
    Apr 25 20:30:26.055: INFO: Pod "pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.029700003s
    STEP: Saw pod success 04/25/23 20:30:26.055
    Apr 25 20:30:26.056: INFO: Pod "pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72" satisfied condition "Succeeded or Failed"
    Apr 25 20:30:26.068: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/25/23 20:30:26.166
    Apr 25 20:30:26.224: INFO: Waiting for pod pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72 to disappear
    Apr 25 20:30:26.252: INFO: Pod pod-projected-secrets-8b7c56ee-eff6-4ba4-8226-459bb1baae72 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 25 20:30:26.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4937" for this suite. 04/25/23 20:30:26.269
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:30:26.305
Apr 25 20:30:26.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename taint-single-pod 04/25/23 20:30:26.308
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:30:26.351
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:30:26.365
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Apr 25 20:30:26.378: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 25 20:31:26.506: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Apr 25 20:31:26.522: INFO: Starting informer...
STEP: Starting pod... 04/25/23 20:31:26.522
Apr 25 20:31:26.804: INFO: Pod is running on 10.10.21.190. Tainting Node
STEP: Trying to apply a taint on the Node 04/25/23 20:31:26.804
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/25/23 20:31:26.84
STEP: Waiting short time to make sure Pod is queued for deletion 04/25/23 20:31:26.854
Apr 25 20:31:26.854: INFO: Pod wasn't evicted. Proceeding
Apr 25 20:31:26.854: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/25/23 20:31:26.915
STEP: Waiting some time to make sure that toleration time passed. 04/25/23 20:31:26.927
Apr 25 20:32:41.927: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Apr 25 20:32:41.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-332" for this suite. 04/25/23 20:32:41.958
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":220,"skipped":3910,"failed":0}
------------------------------
• [SLOW TEST] [135.682 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:30:26.305
    Apr 25 20:30:26.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename taint-single-pod 04/25/23 20:30:26.308
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:30:26.351
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:30:26.365
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Apr 25 20:30:26.378: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 25 20:31:26.506: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Apr 25 20:31:26.522: INFO: Starting informer...
    STEP: Starting pod... 04/25/23 20:31:26.522
    Apr 25 20:31:26.804: INFO: Pod is running on 10.10.21.190. Tainting Node
    STEP: Trying to apply a taint on the Node 04/25/23 20:31:26.804
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/25/23 20:31:26.84
    STEP: Waiting short time to make sure Pod is queued for deletion 04/25/23 20:31:26.854
    Apr 25 20:31:26.854: INFO: Pod wasn't evicted. Proceeding
    Apr 25 20:31:26.854: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/25/23 20:31:26.915
    STEP: Waiting some time to make sure that toleration time passed. 04/25/23 20:31:26.927
    Apr 25 20:32:41.927: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 20:32:41.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-332" for this suite. 04/25/23 20:32:41.958
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:32:41.993
Apr 25 20:32:41.994: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 20:32:41.995
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:32:42.038
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:32:42.052
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 04/25/23 20:32:42.071
Apr 25 20:32:42.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-9739 api-versions'
Apr 25 20:32:42.165: INFO: stderr: ""
Apr 25 20:32:42.165: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nibm.com/v1alpha1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 20:32:42.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9739" for this suite. 04/25/23 20:32:42.209
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":221,"skipped":3937,"failed":0}
------------------------------
• [0.241 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:32:41.993
    Apr 25 20:32:41.994: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 20:32:41.995
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:32:42.038
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:32:42.052
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 04/25/23 20:32:42.071
    Apr 25 20:32:42.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-9739 api-versions'
    Apr 25 20:32:42.165: INFO: stderr: ""
    Apr 25 20:32:42.165: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nibm.com/v1alpha1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 20:32:42.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9739" for this suite. 04/25/23 20:32:42.209
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:32:42.24
Apr 25 20:32:42.241: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:32:42.243
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:32:42.29
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:32:42.303
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-d02da62a-ac39-4a07-80aa-38ff3cf43db6 04/25/23 20:32:42.316
STEP: Creating a pod to test consume secrets 04/25/23 20:32:42.334
Apr 25 20:32:42.363: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063" in namespace "projected-2260" to be "Succeeded or Failed"
Apr 25 20:32:42.378: INFO: Pod "pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063": Phase="Pending", Reason="", readiness=false. Elapsed: 14.493607ms
Apr 25 20:32:44.394: INFO: Pod "pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030924122s
Apr 25 20:32:46.393: INFO: Pod "pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029896095s
STEP: Saw pod success 04/25/23 20:32:46.393
Apr 25 20:32:46.394: INFO: Pod "pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063" satisfied condition "Succeeded or Failed"
Apr 25 20:32:46.410: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/25/23 20:32:46.52
Apr 25 20:32:46.568: INFO: Waiting for pod pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063 to disappear
Apr 25 20:32:46.584: INFO: Pod pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 25 20:32:46.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2260" for this suite. 04/25/23 20:32:46.601
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":222,"skipped":3948,"failed":0}
------------------------------
• [4.384 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:32:42.24
    Apr 25 20:32:42.241: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:32:42.243
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:32:42.29
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:32:42.303
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-d02da62a-ac39-4a07-80aa-38ff3cf43db6 04/25/23 20:32:42.316
    STEP: Creating a pod to test consume secrets 04/25/23 20:32:42.334
    Apr 25 20:32:42.363: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063" in namespace "projected-2260" to be "Succeeded or Failed"
    Apr 25 20:32:42.378: INFO: Pod "pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063": Phase="Pending", Reason="", readiness=false. Elapsed: 14.493607ms
    Apr 25 20:32:44.394: INFO: Pod "pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030924122s
    Apr 25 20:32:46.393: INFO: Pod "pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029896095s
    STEP: Saw pod success 04/25/23 20:32:46.393
    Apr 25 20:32:46.394: INFO: Pod "pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063" satisfied condition "Succeeded or Failed"
    Apr 25 20:32:46.410: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/25/23 20:32:46.52
    Apr 25 20:32:46.568: INFO: Waiting for pod pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063 to disappear
    Apr 25 20:32:46.584: INFO: Pod pod-projected-secrets-50bdee92-8048-4657-bd29-78d6a1d31063 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 25 20:32:46.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2260" for this suite. 04/25/23 20:32:46.601
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:32:46.626
Apr 25 20:32:46.627: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename sched-pred 04/25/23 20:32:46.63
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:32:46.67
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:32:46.683
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 25 20:32:46.697: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 25 20:32:46.726: INFO: Waiting for terminating namespaces to be deleted...
Apr 25 20:32:46.743: INFO: 
Logging pods the apiserver thinks is on node 10.10.21.136 before test
Apr 25 20:32:46.774: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-nzg9s from ibm-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.775: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
Apr 25 20:32:46.775: INFO: calico-node-q95vg from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.775: INFO: 	Container calico-node ready: true, restart count 0
Apr 25 20:32:46.775: INFO: calico-typha-677688fdc5-5f8fr from kube-system started at 2023-04-25 17:14:29 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.775: INFO: 	Container calico-typha ready: true, restart count 0
Apr 25 20:32:46.775: INFO: coredns-6754846f95-cn7xr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.775: INFO: 	Container coredns ready: true, restart count 0
Apr 25 20:32:46.775: INFO: coredns-6754846f95-dnk45 from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.775: INFO: 	Container coredns ready: true, restart count 0
Apr 25 20:32:46.775: INFO: ibm-keepalived-watcher-p87jk from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.775: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 25 20:32:46.775: INFO: ibm-master-proxy-static-10.10.21.136 from kube-system started at 2023-04-25 17:13:57 +0000 UTC (2 container statuses recorded)
Apr 25 20:32:46.775: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 25 20:32:46.775: INFO: 	Container pause ready: true, restart count 0
Apr 25 20:32:46.775: INFO: ibmcloud-block-storage-driver-fm7g7 from kube-system started at 2023-04-25 17:14:07 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.775: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Apr 25 20:32:46.775: INFO: konnectivity-agent-mv6tj from kube-system started at 2023-04-25 17:26:45 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.775: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 25 20:32:46.775: INFO: metrics-server-c785bfcff-b2n5l from kube-system started at 2023-04-25 18:05:55 +0000 UTC (3 container statuses recorded)
Apr 25 20:32:46.775: INFO: 	Container config-watcher ready: true, restart count 0
Apr 25 20:32:46.775: INFO: 	Container metrics-server ready: true, restart count 0
Apr 25 20:32:46.775: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr 25 20:32:46.775: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-p575r from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.775: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 25 20:32:46.775: INFO: sonobuoy from sonobuoy started at 2023-04-25 19:35:04 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.775: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 25 20:32:46.775: INFO: sonobuoy-e2e-job-38c24e91f58b4d35 from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 20:32:46.775: INFO: 	Container e2e ready: true, restart count 0
Apr 25 20:32:46.775: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 20:32:46.775: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-88nhh from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 20:32:46.775: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 20:32:46.775: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 25 20:32:46.775: INFO: 
Logging pods the apiserver thinks is on node 10.10.21.161 before test
Apr 25 20:32:46.807: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-g4ql4 from ibm-system started at 2023-04-25 17:18:17 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
Apr 25 20:32:46.808: INFO: calico-kube-controllers-5754dfd4dd-jfqrl from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 25 20:32:46.808: INFO: calico-node-mqpqg from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container calico-node ready: true, restart count 0
Apr 25 20:32:46.808: INFO: calico-typha-677688fdc5-bt4pk from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container calico-typha ready: true, restart count 0
Apr 25 20:32:46.808: INFO: coredns-6754846f95-8fzmk from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container coredns ready: true, restart count 0
Apr 25 20:32:46.808: INFO: coredns-autoscaler-669cf746f6-hnjbg from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container autoscaler ready: true, restart count 0
Apr 25 20:32:46.808: INFO: dashboard-metrics-scraper-c964d5594-wvstn from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 25 20:32:46.808: INFO: ibm-file-plugin-84d44c69b5-kz8hc from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Apr 25 20:32:46.808: INFO: ibm-keepalived-watcher-9dj6q from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 25 20:32:46.808: INFO: ibm-master-proxy-static-10.10.21.161 from kube-system started at 2023-04-25 17:13:31 +0000 UTC (2 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 25 20:32:46.808: INFO: 	Container pause ready: true, restart count 0
Apr 25 20:32:46.808: INFO: ibm-storage-watcher-65957667f-vtkpm from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Apr 25 20:32:46.808: INFO: ibmcloud-block-storage-driver-wstqs from kube-system started at 2023-04-25 17:13:40 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Apr 25 20:32:46.808: INFO: ibmcloud-block-storage-plugin-6d48895c6b-bh5sb from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Apr 25 20:32:46.808: INFO: ingress-cluster-healthcheck-6f7f6b87df-nfchz from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Apr 25 20:32:46.808: INFO: konnectivity-agent-ghrrh from kube-system started at 2023-04-25 17:26:42 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 25 20:32:46.808: INFO: kubernetes-dashboard-55c4d56798-pm8jr from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 25 20:32:46.808: INFO: metrics-server-c785bfcff-jltfr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (3 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container config-watcher ready: true, restart count 0
Apr 25 20:32:46.808: INFO: 	Container metrics-server ready: true, restart count 0
Apr 25 20:32:46.808: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr 25 20:32:46.808: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-bvz72 from kube-system started at 2023-04-25 17:18:07 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 25 20:32:46.808: INFO: snapshot-controller-c5c6dddff-2s9qq from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container snapshot-controller ready: true, restart count 0
Apr 25 20:32:46.808: INFO: snapshot-controller-c5c6dddff-55rkz from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container snapshot-controller ready: true, restart count 0
Apr 25 20:32:46.808: INFO: snapshot-controller-c5c6dddff-mxcw7 from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.808: INFO: 	Container snapshot-controller ready: true, restart count 0
Apr 25 20:32:46.809: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-w68zf from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 20:32:46.809: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 20:32:46.809: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 25 20:32:46.809: INFO: 
Logging pods the apiserver thinks is on node 10.10.21.190 before test
Apr 25 20:32:46.832: INFO: calico-node-4mqrc from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.832: INFO: 	Container calico-node ready: true, restart count 0
Apr 25 20:32:46.833: INFO: calico-typha-677688fdc5-mnnwk from kube-system started at 2023-04-25 20:31:28 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.833: INFO: 	Container calico-typha ready: true, restart count 0
Apr 25 20:32:46.833: INFO: ibm-keepalived-watcher-r8lvr from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.834: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 25 20:32:46.834: INFO: ibm-master-proxy-static-10.10.21.190 from kube-system started at 2023-04-25 17:14:39 +0000 UTC (2 container statuses recorded)
Apr 25 20:32:46.834: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 25 20:32:46.835: INFO: 	Container pause ready: true, restart count 0
Apr 25 20:32:46.835: INFO: ibmcloud-block-storage-driver-gpzl6 from kube-system started at 2023-04-25 17:14:49 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.836: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Apr 25 20:32:46.836: INFO: konnectivity-agent-hkzc4 from kube-system started at 2023-04-25 17:26:39 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.837: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 25 20:32:46.837: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-gq2qk from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 20:32:46.837: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 20:32:46.838: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 25 20:32:46.838: INFO: taint-eviction-4 from taint-single-pod-332 started at 2023-04-25 20:31:26 +0000 UTC (1 container statuses recorded)
Apr 25 20:32:46.838: INFO: 	Container pause ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/25/23 20:32:46.839
Apr 25 20:32:46.873: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-5791" to be "running"
Apr 25 20:32:46.888: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 14.90726ms
Apr 25 20:32:48.905: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031432771s
Apr 25 20:32:50.907: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.034138014s
Apr 25 20:32:50.909: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/25/23 20:32:50.923
STEP: Trying to apply a random label on the found node. 04/25/23 20:32:50.981
STEP: verifying the node has the label kubernetes.io/e2e-a230e530-8796-4f07-a971-f9f8f721466b 95 04/25/23 20:32:51.036
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 04/25/23 20:32:51.049
Apr 25 20:32:51.067: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-5791" to be "not pending"
Apr 25 20:32:51.084: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.601705ms
Apr 25 20:32:53.101: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.032678739s
Apr 25 20:32:53.101: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.10.21.190 on the node which pod4 resides and expect not scheduled 04/25/23 20:32:53.101
Apr 25 20:32:53.119: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-5791" to be "not pending"
Apr 25 20:32:53.135: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 15.707542ms
Apr 25 20:32:55.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031423262s
Apr 25 20:32:57.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030394771s
Apr 25 20:32:59.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03286454s
Apr 25 20:33:01.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.031911149s
Apr 25 20:33:03.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.033385488s
Apr 25 20:33:05.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.031746563s
Apr 25 20:33:07.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.031042511s
Apr 25 20:33:09.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.031352267s
Apr 25 20:33:11.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.031214062s
Apr 25 20:33:13.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.031019134s
Apr 25 20:33:15.153: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.034430321s
Apr 25 20:33:17.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.031147955s
Apr 25 20:33:19.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.030766646s
Apr 25 20:33:21.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.030836342s
Apr 25 20:33:23.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.031476827s
Apr 25 20:33:25.155: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.036167083s
Apr 25 20:33:27.178: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.059575245s
Apr 25 20:33:29.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.03233199s
Apr 25 20:33:31.162: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.042752192s
Apr 25 20:33:33.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.057268496s
Apr 25 20:33:35.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.031132592s
Apr 25 20:33:37.166: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.047621085s
Apr 25 20:33:39.153: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.034109457s
Apr 25 20:33:41.183: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.064283691s
Apr 25 20:33:43.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.031698105s
Apr 25 20:33:45.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.030967202s
Apr 25 20:33:47.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.032016158s
Apr 25 20:33:49.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.033089155s
Apr 25 20:33:51.183: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.064241097s
Apr 25 20:33:53.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.030760601s
Apr 25 20:33:55.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.031575974s
Apr 25 20:33:57.165: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.046396855s
Apr 25 20:33:59.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.055321541s
Apr 25 20:34:01.148: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.029164452s
Apr 25 20:34:03.154: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.034974752s
Apr 25 20:34:05.154: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.034935818s
Apr 25 20:34:07.154: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.034963269s
Apr 25 20:34:09.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.032964508s
Apr 25 20:34:11.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.032958574s
Apr 25 20:34:13.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.031892846s
Apr 25 20:34:15.162: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.043414935s
Apr 25 20:34:17.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.031438022s
Apr 25 20:34:19.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.032754913s
Apr 25 20:34:21.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.032008327s
Apr 25 20:34:23.153: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.034293611s
Apr 25 20:34:25.183: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.064275325s
Apr 25 20:34:27.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.033076391s
Apr 25 20:34:29.177: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.058204711s
Apr 25 20:34:31.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.031294677s
Apr 25 20:34:33.165: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.046140232s
Apr 25 20:34:35.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.030328824s
Apr 25 20:34:37.156: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.036692751s
Apr 25 20:34:39.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.033205507s
Apr 25 20:34:41.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.031226632s
Apr 25 20:34:43.162: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.043202806s
Apr 25 20:34:45.179: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.060347616s
Apr 25 20:34:47.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.03085658s
Apr 25 20:34:49.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.03302444s
Apr 25 20:34:51.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.030933768s
Apr 25 20:34:53.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.031323806s
Apr 25 20:34:55.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.031424261s
Apr 25 20:34:57.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.030595411s
Apr 25 20:34:59.159: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.039695945s
Apr 25 20:35:01.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.032680298s
Apr 25 20:35:03.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.029816171s
Apr 25 20:35:05.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.031093179s
Apr 25 20:35:07.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.031328472s
Apr 25 20:35:09.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.031663307s
Apr 25 20:35:11.155: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.03585944s
Apr 25 20:35:13.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.031867059s
Apr 25 20:35:15.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.030994797s
Apr 25 20:35:17.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.03300329s
Apr 25 20:35:19.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.031912249s
Apr 25 20:35:21.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.030801442s
Apr 25 20:35:23.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.032084504s
Apr 25 20:35:25.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.031530027s
Apr 25 20:35:27.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.030217459s
Apr 25 20:35:29.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.030098622s
Apr 25 20:35:31.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.030078126s
Apr 25 20:35:33.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.032562787s
Apr 25 20:35:35.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.031791461s
Apr 25 20:35:37.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.031956966s
Apr 25 20:35:39.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.031088622s
Apr 25 20:35:41.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.031774878s
Apr 25 20:35:43.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.030415668s
Apr 25 20:35:45.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.032160949s
Apr 25 20:35:47.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.032237998s
Apr 25 20:35:49.153: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.03434346s
Apr 25 20:35:51.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.031072249s
Apr 25 20:35:53.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.032496998s
Apr 25 20:35:55.158: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.039012813s
Apr 25 20:35:57.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.032236725s
Apr 25 20:35:59.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.032962695s
Apr 25 20:36:01.160: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.041271083s
Apr 25 20:36:03.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.03170076s
Apr 25 20:36:05.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.030916624s
Apr 25 20:36:07.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.030019098s
Apr 25 20:36:09.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.031773298s
Apr 25 20:36:11.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.033222961s
Apr 25 20:36:13.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.032196948s
Apr 25 20:36:15.153: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.034071482s
Apr 25 20:36:17.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.031665103s
Apr 25 20:36:19.153: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.034021208s
Apr 25 20:36:21.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.031053355s
Apr 25 20:36:23.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.032522719s
Apr 25 20:36:25.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.032021462s
Apr 25 20:36:27.158: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.038942112s
Apr 25 20:36:29.154: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.035012623s
Apr 25 20:36:31.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.030916605s
Apr 25 20:36:33.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.03209911s
Apr 25 20:36:35.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.032621963s
Apr 25 20:36:37.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.031043479s
Apr 25 20:36:39.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.030754486s
Apr 25 20:36:41.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.032983241s
Apr 25 20:36:43.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.031910032s
Apr 25 20:36:45.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.032372596s
Apr 25 20:36:47.158: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.038686844s
Apr 25 20:36:49.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.033118269s
Apr 25 20:36:51.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.031967085s
Apr 25 20:36:53.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.03329695s
Apr 25 20:36:55.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.033281656s
Apr 25 20:36:57.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.031548703s
Apr 25 20:36:59.155: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.036085839s
Apr 25 20:37:01.167: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.048557913s
Apr 25 20:37:03.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.032312108s
Apr 25 20:37:05.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.031704088s
Apr 25 20:37:07.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.031489342s
Apr 25 20:37:09.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.031771651s
Apr 25 20:37:11.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.03281557s
Apr 25 20:37:13.155: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.035750672s
Apr 25 20:37:15.171: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.051796396s
Apr 25 20:37:17.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.030264497s
Apr 25 20:37:19.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.033528412s
Apr 25 20:37:21.163: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.044524332s
Apr 25 20:37:23.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.032952716s
Apr 25 20:37:25.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.032820043s
Apr 25 20:37:27.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.030201788s
Apr 25 20:37:29.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.032237967s
Apr 25 20:37:31.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.031068296s
Apr 25 20:37:33.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.032938715s
Apr 25 20:37:35.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.030668634s
Apr 25 20:37:37.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.032358386s
Apr 25 20:37:39.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.030310659s
Apr 25 20:37:41.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.030763506s
Apr 25 20:37:43.148: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.0288481s
Apr 25 20:37:45.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.032379839s
Apr 25 20:37:47.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.030201172s
Apr 25 20:37:49.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.030676564s
Apr 25 20:37:51.156: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.037492514s
Apr 25 20:37:53.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.033113823s
Apr 25 20:37:53.165: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.04601097s
STEP: removing the label kubernetes.io/e2e-a230e530-8796-4f07-a971-f9f8f721466b off the node 10.10.21.190 04/25/23 20:37:53.165
STEP: verifying the node doesn't have the label kubernetes.io/e2e-a230e530-8796-4f07-a971-f9f8f721466b 04/25/23 20:37:53.207
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 25 20:37:53.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5791" for this suite. 04/25/23 20:37:53.248
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":223,"skipped":3950,"failed":0}
------------------------------
• [SLOW TEST] [306.654 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:32:46.626
    Apr 25 20:32:46.627: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename sched-pred 04/25/23 20:32:46.63
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:32:46.67
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:32:46.683
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 25 20:32:46.697: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 25 20:32:46.726: INFO: Waiting for terminating namespaces to be deleted...
    Apr 25 20:32:46.743: INFO: 
    Logging pods the apiserver thinks is on node 10.10.21.136 before test
    Apr 25 20:32:46.774: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-nzg9s from ibm-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.775: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: calico-node-q95vg from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.775: INFO: 	Container calico-node ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: calico-typha-677688fdc5-5f8fr from kube-system started at 2023-04-25 17:14:29 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.775: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: coredns-6754846f95-cn7xr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.775: INFO: 	Container coredns ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: coredns-6754846f95-dnk45 from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.775: INFO: 	Container coredns ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: ibm-keepalived-watcher-p87jk from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.775: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: ibm-master-proxy-static-10.10.21.136 from kube-system started at 2023-04-25 17:13:57 +0000 UTC (2 container statuses recorded)
    Apr 25 20:32:46.775: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: 	Container pause ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: ibmcloud-block-storage-driver-fm7g7 from kube-system started at 2023-04-25 17:14:07 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.775: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: konnectivity-agent-mv6tj from kube-system started at 2023-04-25 17:26:45 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.775: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: metrics-server-c785bfcff-b2n5l from kube-system started at 2023-04-25 18:05:55 +0000 UTC (3 container statuses recorded)
    Apr 25 20:32:46.775: INFO: 	Container config-watcher ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-p575r from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.775: INFO: 	Container nginx-ingress ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: sonobuoy from sonobuoy started at 2023-04-25 19:35:04 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.775: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: sonobuoy-e2e-job-38c24e91f58b4d35 from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 20:32:46.775: INFO: 	Container e2e ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-88nhh from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 20:32:46.775: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 25 20:32:46.775: INFO: 
    Logging pods the apiserver thinks is on node 10.10.21.161 before test
    Apr 25 20:32:46.807: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-g4ql4 from ibm-system started at 2023-04-25 17:18:17 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: calico-kube-controllers-5754dfd4dd-jfqrl from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: calico-node-mqpqg from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container calico-node ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: calico-typha-677688fdc5-bt4pk from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: coredns-6754846f95-8fzmk from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container coredns ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: coredns-autoscaler-669cf746f6-hnjbg from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: dashboard-metrics-scraper-c964d5594-wvstn from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: ibm-file-plugin-84d44c69b5-kz8hc from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: ibm-keepalived-watcher-9dj6q from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: ibm-master-proxy-static-10.10.21.161 from kube-system started at 2023-04-25 17:13:31 +0000 UTC (2 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: 	Container pause ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: ibm-storage-watcher-65957667f-vtkpm from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: ibmcloud-block-storage-driver-wstqs from kube-system started at 2023-04-25 17:13:40 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: ibmcloud-block-storage-plugin-6d48895c6b-bh5sb from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: ingress-cluster-healthcheck-6f7f6b87df-nfchz from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: konnectivity-agent-ghrrh from kube-system started at 2023-04-25 17:26:42 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: kubernetes-dashboard-55c4d56798-pm8jr from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: metrics-server-c785bfcff-jltfr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (3 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container config-watcher ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-bvz72 from kube-system started at 2023-04-25 17:18:07 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container nginx-ingress ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: snapshot-controller-c5c6dddff-2s9qq from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container snapshot-controller ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: snapshot-controller-c5c6dddff-55rkz from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container snapshot-controller ready: true, restart count 0
    Apr 25 20:32:46.808: INFO: snapshot-controller-c5c6dddff-mxcw7 from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.808: INFO: 	Container snapshot-controller ready: true, restart count 0
    Apr 25 20:32:46.809: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-w68zf from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 20:32:46.809: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 20:32:46.809: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 25 20:32:46.809: INFO: 
    Logging pods the apiserver thinks is on node 10.10.21.190 before test
    Apr 25 20:32:46.832: INFO: calico-node-4mqrc from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.832: INFO: 	Container calico-node ready: true, restart count 0
    Apr 25 20:32:46.833: INFO: calico-typha-677688fdc5-mnnwk from kube-system started at 2023-04-25 20:31:28 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.833: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 25 20:32:46.833: INFO: ibm-keepalived-watcher-r8lvr from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.834: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Apr 25 20:32:46.834: INFO: ibm-master-proxy-static-10.10.21.190 from kube-system started at 2023-04-25 17:14:39 +0000 UTC (2 container statuses recorded)
    Apr 25 20:32:46.834: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Apr 25 20:32:46.835: INFO: 	Container pause ready: true, restart count 0
    Apr 25 20:32:46.835: INFO: ibmcloud-block-storage-driver-gpzl6 from kube-system started at 2023-04-25 17:14:49 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.836: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Apr 25 20:32:46.836: INFO: konnectivity-agent-hkzc4 from kube-system started at 2023-04-25 17:26:39 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.837: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Apr 25 20:32:46.837: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-gq2qk from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 20:32:46.837: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 20:32:46.838: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 25 20:32:46.838: INFO: taint-eviction-4 from taint-single-pod-332 started at 2023-04-25 20:31:26 +0000 UTC (1 container statuses recorded)
    Apr 25 20:32:46.838: INFO: 	Container pause ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/25/23 20:32:46.839
    Apr 25 20:32:46.873: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-5791" to be "running"
    Apr 25 20:32:46.888: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 14.90726ms
    Apr 25 20:32:48.905: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031432771s
    Apr 25 20:32:50.907: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.034138014s
    Apr 25 20:32:50.909: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/25/23 20:32:50.923
    STEP: Trying to apply a random label on the found node. 04/25/23 20:32:50.981
    STEP: verifying the node has the label kubernetes.io/e2e-a230e530-8796-4f07-a971-f9f8f721466b 95 04/25/23 20:32:51.036
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 04/25/23 20:32:51.049
    Apr 25 20:32:51.067: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-5791" to be "not pending"
    Apr 25 20:32:51.084: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.601705ms
    Apr 25 20:32:53.101: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.032678739s
    Apr 25 20:32:53.101: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.10.21.190 on the node which pod4 resides and expect not scheduled 04/25/23 20:32:53.101
    Apr 25 20:32:53.119: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-5791" to be "not pending"
    Apr 25 20:32:53.135: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 15.707542ms
    Apr 25 20:32:55.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031423262s
    Apr 25 20:32:57.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030394771s
    Apr 25 20:32:59.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03286454s
    Apr 25 20:33:01.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.031911149s
    Apr 25 20:33:03.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.033385488s
    Apr 25 20:33:05.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.031746563s
    Apr 25 20:33:07.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.031042511s
    Apr 25 20:33:09.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.031352267s
    Apr 25 20:33:11.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.031214062s
    Apr 25 20:33:13.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.031019134s
    Apr 25 20:33:15.153: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.034430321s
    Apr 25 20:33:17.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.031147955s
    Apr 25 20:33:19.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.030766646s
    Apr 25 20:33:21.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.030836342s
    Apr 25 20:33:23.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.031476827s
    Apr 25 20:33:25.155: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.036167083s
    Apr 25 20:33:27.178: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.059575245s
    Apr 25 20:33:29.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.03233199s
    Apr 25 20:33:31.162: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.042752192s
    Apr 25 20:33:33.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.057268496s
    Apr 25 20:33:35.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.031132592s
    Apr 25 20:33:37.166: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.047621085s
    Apr 25 20:33:39.153: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.034109457s
    Apr 25 20:33:41.183: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.064283691s
    Apr 25 20:33:43.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.031698105s
    Apr 25 20:33:45.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.030967202s
    Apr 25 20:33:47.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.032016158s
    Apr 25 20:33:49.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.033089155s
    Apr 25 20:33:51.183: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.064241097s
    Apr 25 20:33:53.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.030760601s
    Apr 25 20:33:55.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.031575974s
    Apr 25 20:33:57.165: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.046396855s
    Apr 25 20:33:59.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.055321541s
    Apr 25 20:34:01.148: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.029164452s
    Apr 25 20:34:03.154: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.034974752s
    Apr 25 20:34:05.154: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.034935818s
    Apr 25 20:34:07.154: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.034963269s
    Apr 25 20:34:09.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.032964508s
    Apr 25 20:34:11.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.032958574s
    Apr 25 20:34:13.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.031892846s
    Apr 25 20:34:15.162: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.043414935s
    Apr 25 20:34:17.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.031438022s
    Apr 25 20:34:19.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.032754913s
    Apr 25 20:34:21.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.032008327s
    Apr 25 20:34:23.153: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.034293611s
    Apr 25 20:34:25.183: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.064275325s
    Apr 25 20:34:27.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.033076391s
    Apr 25 20:34:29.177: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.058204711s
    Apr 25 20:34:31.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.031294677s
    Apr 25 20:34:33.165: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.046140232s
    Apr 25 20:34:35.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.030328824s
    Apr 25 20:34:37.156: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.036692751s
    Apr 25 20:34:39.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.033205507s
    Apr 25 20:34:41.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.031226632s
    Apr 25 20:34:43.162: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.043202806s
    Apr 25 20:34:45.179: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.060347616s
    Apr 25 20:34:47.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.03085658s
    Apr 25 20:34:49.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.03302444s
    Apr 25 20:34:51.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.030933768s
    Apr 25 20:34:53.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.031323806s
    Apr 25 20:34:55.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.031424261s
    Apr 25 20:34:57.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.030595411s
    Apr 25 20:34:59.159: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.039695945s
    Apr 25 20:35:01.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.032680298s
    Apr 25 20:35:03.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.029816171s
    Apr 25 20:35:05.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.031093179s
    Apr 25 20:35:07.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.031328472s
    Apr 25 20:35:09.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.031663307s
    Apr 25 20:35:11.155: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.03585944s
    Apr 25 20:35:13.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.031867059s
    Apr 25 20:35:15.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.030994797s
    Apr 25 20:35:17.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.03300329s
    Apr 25 20:35:19.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.031912249s
    Apr 25 20:35:21.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.030801442s
    Apr 25 20:35:23.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.032084504s
    Apr 25 20:35:25.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.031530027s
    Apr 25 20:35:27.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.030217459s
    Apr 25 20:35:29.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.030098622s
    Apr 25 20:35:31.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.030078126s
    Apr 25 20:35:33.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.032562787s
    Apr 25 20:35:35.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.031791461s
    Apr 25 20:35:37.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.031956966s
    Apr 25 20:35:39.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.031088622s
    Apr 25 20:35:41.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.031774878s
    Apr 25 20:35:43.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.030415668s
    Apr 25 20:35:45.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.032160949s
    Apr 25 20:35:47.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.032237998s
    Apr 25 20:35:49.153: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.03434346s
    Apr 25 20:35:51.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.031072249s
    Apr 25 20:35:53.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.032496998s
    Apr 25 20:35:55.158: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.039012813s
    Apr 25 20:35:57.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.032236725s
    Apr 25 20:35:59.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.032962695s
    Apr 25 20:36:01.160: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.041271083s
    Apr 25 20:36:03.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.03170076s
    Apr 25 20:36:05.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.030916624s
    Apr 25 20:36:07.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.030019098s
    Apr 25 20:36:09.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.031773298s
    Apr 25 20:36:11.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.033222961s
    Apr 25 20:36:13.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.032196948s
    Apr 25 20:36:15.153: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.034071482s
    Apr 25 20:36:17.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.031665103s
    Apr 25 20:36:19.153: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.034021208s
    Apr 25 20:36:21.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.031053355s
    Apr 25 20:36:23.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.032522719s
    Apr 25 20:36:25.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.032021462s
    Apr 25 20:36:27.158: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.038942112s
    Apr 25 20:36:29.154: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.035012623s
    Apr 25 20:36:31.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.030916605s
    Apr 25 20:36:33.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.03209911s
    Apr 25 20:36:35.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.032621963s
    Apr 25 20:36:37.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.031043479s
    Apr 25 20:36:39.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.030754486s
    Apr 25 20:36:41.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.032983241s
    Apr 25 20:36:43.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.031910032s
    Apr 25 20:36:45.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.032372596s
    Apr 25 20:36:47.158: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.038686844s
    Apr 25 20:36:49.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.033118269s
    Apr 25 20:36:51.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.031967085s
    Apr 25 20:36:53.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.03329695s
    Apr 25 20:36:55.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.033281656s
    Apr 25 20:36:57.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.031548703s
    Apr 25 20:36:59.155: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.036085839s
    Apr 25 20:37:01.167: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.048557913s
    Apr 25 20:37:03.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.032312108s
    Apr 25 20:37:05.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.031704088s
    Apr 25 20:37:07.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.031489342s
    Apr 25 20:37:09.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.031771651s
    Apr 25 20:37:11.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.03281557s
    Apr 25 20:37:13.155: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.035750672s
    Apr 25 20:37:15.171: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.051796396s
    Apr 25 20:37:17.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.030264497s
    Apr 25 20:37:19.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.033528412s
    Apr 25 20:37:21.163: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.044524332s
    Apr 25 20:37:23.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.032952716s
    Apr 25 20:37:25.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.032820043s
    Apr 25 20:37:27.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.030201788s
    Apr 25 20:37:29.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.032237967s
    Apr 25 20:37:31.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.031068296s
    Apr 25 20:37:33.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.032938715s
    Apr 25 20:37:35.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.030668634s
    Apr 25 20:37:37.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.032358386s
    Apr 25 20:37:39.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.030310659s
    Apr 25 20:37:41.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.030763506s
    Apr 25 20:37:43.148: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.0288481s
    Apr 25 20:37:45.151: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.032379839s
    Apr 25 20:37:47.149: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.030201172s
    Apr 25 20:37:49.150: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.030676564s
    Apr 25 20:37:51.156: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.037492514s
    Apr 25 20:37:53.152: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.033113823s
    Apr 25 20:37:53.165: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.04601097s
    STEP: removing the label kubernetes.io/e2e-a230e530-8796-4f07-a971-f9f8f721466b off the node 10.10.21.190 04/25/23 20:37:53.165
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-a230e530-8796-4f07-a971-f9f8f721466b 04/25/23 20:37:53.207
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 20:37:53.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-5791" for this suite. 04/25/23 20:37:53.248
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:37:53.288
Apr 25 20:37:53.288: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:37:53.291
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:37:53.349
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:37:53.364
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-0a541996-1d38-4085-92b6-4f78bee827cb 04/25/23 20:37:53.378
STEP: Creating a pod to test consume configMaps 04/25/23 20:37:53.398
Apr 25 20:37:53.429: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada" in namespace "projected-3744" to be "Succeeded or Failed"
Apr 25 20:37:53.445: INFO: Pod "pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada": Phase="Pending", Reason="", readiness=false. Elapsed: 15.094127ms
Apr 25 20:37:55.462: INFO: Pod "pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031741993s
Apr 25 20:37:57.462: INFO: Pod "pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031797752s
STEP: Saw pod success 04/25/23 20:37:57.462
Apr 25 20:37:57.462: INFO: Pod "pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada" satisfied condition "Succeeded or Failed"
Apr 25 20:37:57.476: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada container agnhost-container: <nil>
STEP: delete the pod 04/25/23 20:37:57.577
Apr 25 20:37:57.616: INFO: Waiting for pod pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada to disappear
Apr 25 20:37:57.634: INFO: Pod pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 25 20:37:57.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3744" for this suite. 04/25/23 20:37:57.658
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":224,"skipped":3978,"failed":0}
------------------------------
• [4.407 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:37:53.288
    Apr 25 20:37:53.288: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:37:53.291
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:37:53.349
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:37:53.364
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-0a541996-1d38-4085-92b6-4f78bee827cb 04/25/23 20:37:53.378
    STEP: Creating a pod to test consume configMaps 04/25/23 20:37:53.398
    Apr 25 20:37:53.429: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada" in namespace "projected-3744" to be "Succeeded or Failed"
    Apr 25 20:37:53.445: INFO: Pod "pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada": Phase="Pending", Reason="", readiness=false. Elapsed: 15.094127ms
    Apr 25 20:37:55.462: INFO: Pod "pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031741993s
    Apr 25 20:37:57.462: INFO: Pod "pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031797752s
    STEP: Saw pod success 04/25/23 20:37:57.462
    Apr 25 20:37:57.462: INFO: Pod "pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada" satisfied condition "Succeeded or Failed"
    Apr 25 20:37:57.476: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 20:37:57.577
    Apr 25 20:37:57.616: INFO: Waiting for pod pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada to disappear
    Apr 25 20:37:57.634: INFO: Pod pod-projected-configmaps-86f82af0-bda1-4f43-903d-667af1d68ada no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 25 20:37:57.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3744" for this suite. 04/25/23 20:37:57.658
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:37:57.716
Apr 25 20:37:57.716: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 20:37:57.717
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:37:57.761
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:37:57.772
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/25/23 20:37:57.783
Apr 25 20:37:57.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-7205 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr 25 20:37:57.944: INFO: stderr: ""
Apr 25 20:37:57.944: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 04/25/23 20:37:57.944
Apr 25 20:37:57.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-7205 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Apr 25 20:37:58.374: INFO: stderr: ""
Apr 25 20:37:58.374: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/25/23 20:37:58.374
Apr 25 20:37:58.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-7205 delete pods e2e-test-httpd-pod'
Apr 25 20:38:00.465: INFO: stderr: ""
Apr 25 20:38:00.465: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 20:38:00.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7205" for this suite. 04/25/23 20:38:00.483
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":225,"skipped":4067,"failed":0}
------------------------------
• [2.797 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:37:57.716
    Apr 25 20:37:57.716: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 20:37:57.717
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:37:57.761
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:37:57.772
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/25/23 20:37:57.783
    Apr 25 20:37:57.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-7205 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Apr 25 20:37:57.944: INFO: stderr: ""
    Apr 25 20:37:57.944: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 04/25/23 20:37:57.944
    Apr 25 20:37:57.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-7205 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Apr 25 20:37:58.374: INFO: stderr: ""
    Apr 25 20:37:58.374: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/25/23 20:37:58.374
    Apr 25 20:37:58.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-7205 delete pods e2e-test-httpd-pod'
    Apr 25 20:38:00.465: INFO: stderr: ""
    Apr 25 20:38:00.465: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 20:38:00.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7205" for this suite. 04/25/23 20:38:00.483
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:38:00.513
Apr 25 20:38:00.513: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename containers 04/25/23 20:38:00.514
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:00.57
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:00.583
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 04/25/23 20:38:00.598
Apr 25 20:38:00.627: INFO: Waiting up to 5m0s for pod "client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356" in namespace "containers-4020" to be "Succeeded or Failed"
Apr 25 20:38:00.642: INFO: Pod "client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356": Phase="Pending", Reason="", readiness=false. Elapsed: 14.394994ms
Apr 25 20:38:02.670: INFO: Pod "client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042351236s
Apr 25 20:38:04.663: INFO: Pod "client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035911628s
STEP: Saw pod success 04/25/23 20:38:04.663
Apr 25 20:38:04.664: INFO: Pod "client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356" satisfied condition "Succeeded or Failed"
Apr 25 20:38:04.704: INFO: Trying to get logs from node 10.10.21.190 pod client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356 container agnhost-container: <nil>
STEP: delete the pod 04/25/23 20:38:04.733
Apr 25 20:38:04.770: INFO: Waiting for pod client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356 to disappear
Apr 25 20:38:04.788: INFO: Pod client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 25 20:38:04.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4020" for this suite. 04/25/23 20:38:04.803
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":226,"skipped":4072,"failed":0}
------------------------------
• [4.313 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:38:00.513
    Apr 25 20:38:00.513: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename containers 04/25/23 20:38:00.514
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:00.57
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:00.583
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 04/25/23 20:38:00.598
    Apr 25 20:38:00.627: INFO: Waiting up to 5m0s for pod "client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356" in namespace "containers-4020" to be "Succeeded or Failed"
    Apr 25 20:38:00.642: INFO: Pod "client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356": Phase="Pending", Reason="", readiness=false. Elapsed: 14.394994ms
    Apr 25 20:38:02.670: INFO: Pod "client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042351236s
    Apr 25 20:38:04.663: INFO: Pod "client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035911628s
    STEP: Saw pod success 04/25/23 20:38:04.663
    Apr 25 20:38:04.664: INFO: Pod "client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356" satisfied condition "Succeeded or Failed"
    Apr 25 20:38:04.704: INFO: Trying to get logs from node 10.10.21.190 pod client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356 container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 20:38:04.733
    Apr 25 20:38:04.770: INFO: Waiting for pod client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356 to disappear
    Apr 25 20:38:04.788: INFO: Pod client-containers-16c82f70-31bc-48c2-aadf-2cc60f56f356 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 25 20:38:04.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-4020" for this suite. 04/25/23 20:38:04.803
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:38:04.832
Apr 25 20:38:04.832: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 20:38:04.835
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:04.878
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:04.891
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-9407 04/25/23 20:38:04.903
STEP: creating service affinity-clusterip in namespace services-9407 04/25/23 20:38:04.904
STEP: creating replication controller affinity-clusterip in namespace services-9407 04/25/23 20:38:04.944
I0425 20:38:04.964643      23 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-9407, replica count: 3
I0425 20:38:08.016780      23 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 25 20:38:08.043: INFO: Creating new exec pod
Apr 25 20:38:08.062: INFO: Waiting up to 5m0s for pod "execpod-affinity7pw9r" in namespace "services-9407" to be "running"
Apr 25 20:38:08.076: INFO: Pod "execpod-affinity7pw9r": Phase="Pending", Reason="", readiness=false. Elapsed: 14.306175ms
Apr 25 20:38:10.091: INFO: Pod "execpod-affinity7pw9r": Phase="Running", Reason="", readiness=true. Elapsed: 2.029479187s
Apr 25 20:38:10.092: INFO: Pod "execpod-affinity7pw9r" satisfied condition "running"
Apr 25 20:38:11.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-9407 exec execpod-affinity7pw9r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Apr 25 20:38:11.453: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Apr 25 20:38:11.453: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 20:38:11.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-9407 exec execpod-affinity7pw9r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.255.97 80'
Apr 25 20:38:11.800: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.255.97 80\nConnection to 172.21.255.97 80 port [tcp/http] succeeded!\n"
Apr 25 20:38:11.800: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 20:38:11.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-9407 exec execpod-affinity7pw9r -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.255.97:80/ ; done'
Apr 25 20:38:12.226: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n"
Apr 25 20:38:12.226: INFO: stdout: "\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4"
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
Apr 25 20:38:12.226: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-9407, will wait for the garbage collector to delete the pods 04/25/23 20:38:12.261
Apr 25 20:38:12.348: INFO: Deleting ReplicationController affinity-clusterip took: 16.523204ms
Apr 25 20:38:12.448: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.329124ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 20:38:15.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9407" for this suite. 04/25/23 20:38:15.229
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":227,"skipped":4085,"failed":0}
------------------------------
• [SLOW TEST] [10.426 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:38:04.832
    Apr 25 20:38:04.832: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 20:38:04.835
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:04.878
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:04.891
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-9407 04/25/23 20:38:04.903
    STEP: creating service affinity-clusterip in namespace services-9407 04/25/23 20:38:04.904
    STEP: creating replication controller affinity-clusterip in namespace services-9407 04/25/23 20:38:04.944
    I0425 20:38:04.964643      23 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-9407, replica count: 3
    I0425 20:38:08.016780      23 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 25 20:38:08.043: INFO: Creating new exec pod
    Apr 25 20:38:08.062: INFO: Waiting up to 5m0s for pod "execpod-affinity7pw9r" in namespace "services-9407" to be "running"
    Apr 25 20:38:08.076: INFO: Pod "execpod-affinity7pw9r": Phase="Pending", Reason="", readiness=false. Elapsed: 14.306175ms
    Apr 25 20:38:10.091: INFO: Pod "execpod-affinity7pw9r": Phase="Running", Reason="", readiness=true. Elapsed: 2.029479187s
    Apr 25 20:38:10.092: INFO: Pod "execpod-affinity7pw9r" satisfied condition "running"
    Apr 25 20:38:11.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-9407 exec execpod-affinity7pw9r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Apr 25 20:38:11.453: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Apr 25 20:38:11.453: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 20:38:11.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-9407 exec execpod-affinity7pw9r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.255.97 80'
    Apr 25 20:38:11.800: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.255.97 80\nConnection to 172.21.255.97 80 port [tcp/http] succeeded!\n"
    Apr 25 20:38:11.800: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 20:38:11.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-9407 exec execpod-affinity7pw9r -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.255.97:80/ ; done'
    Apr 25 20:38:12.226: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.255.97:80/\n"
    Apr 25 20:38:12.226: INFO: stdout: "\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4\naffinity-clusterip-mt2x4"
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Received response from host: affinity-clusterip-mt2x4
    Apr 25 20:38:12.226: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-9407, will wait for the garbage collector to delete the pods 04/25/23 20:38:12.261
    Apr 25 20:38:12.348: INFO: Deleting ReplicationController affinity-clusterip took: 16.523204ms
    Apr 25 20:38:12.448: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.329124ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 20:38:15.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9407" for this suite. 04/25/23 20:38:15.229
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:38:15.267
Apr 25 20:38:15.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir 04/25/23 20:38:15.268
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:15.316
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:15.334
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 04/25/23 20:38:15.354
Apr 25 20:38:15.390: INFO: Waiting up to 5m0s for pod "pod-b2857adc-04b4-44ff-864e-0b67d916d1b5" in namespace "emptydir-4503" to be "Succeeded or Failed"
Apr 25 20:38:15.405: INFO: Pod "pod-b2857adc-04b4-44ff-864e-0b67d916d1b5": Phase="Pending", Reason="", readiness=false. Elapsed: 15.558173ms
Apr 25 20:38:17.420: INFO: Pod "pod-b2857adc-04b4-44ff-864e-0b67d916d1b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030306116s
Apr 25 20:38:19.422: INFO: Pod "pod-b2857adc-04b4-44ff-864e-0b67d916d1b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032503803s
STEP: Saw pod success 04/25/23 20:38:19.422
Apr 25 20:38:19.423: INFO: Pod "pod-b2857adc-04b4-44ff-864e-0b67d916d1b5" satisfied condition "Succeeded or Failed"
Apr 25 20:38:19.438: INFO: Trying to get logs from node 10.10.21.190 pod pod-b2857adc-04b4-44ff-864e-0b67d916d1b5 container test-container: <nil>
STEP: delete the pod 04/25/23 20:38:19.466
Apr 25 20:38:19.503: INFO: Waiting for pod pod-b2857adc-04b4-44ff-864e-0b67d916d1b5 to disappear
Apr 25 20:38:19.517: INFO: Pod pod-b2857adc-04b4-44ff-864e-0b67d916d1b5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 25 20:38:19.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4503" for this suite. 04/25/23 20:38:19.535
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":228,"skipped":4120,"failed":0}
------------------------------
• [4.295 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:38:15.267
    Apr 25 20:38:15.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir 04/25/23 20:38:15.268
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:15.316
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:15.334
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 04/25/23 20:38:15.354
    Apr 25 20:38:15.390: INFO: Waiting up to 5m0s for pod "pod-b2857adc-04b4-44ff-864e-0b67d916d1b5" in namespace "emptydir-4503" to be "Succeeded or Failed"
    Apr 25 20:38:15.405: INFO: Pod "pod-b2857adc-04b4-44ff-864e-0b67d916d1b5": Phase="Pending", Reason="", readiness=false. Elapsed: 15.558173ms
    Apr 25 20:38:17.420: INFO: Pod "pod-b2857adc-04b4-44ff-864e-0b67d916d1b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030306116s
    Apr 25 20:38:19.422: INFO: Pod "pod-b2857adc-04b4-44ff-864e-0b67d916d1b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032503803s
    STEP: Saw pod success 04/25/23 20:38:19.422
    Apr 25 20:38:19.423: INFO: Pod "pod-b2857adc-04b4-44ff-864e-0b67d916d1b5" satisfied condition "Succeeded or Failed"
    Apr 25 20:38:19.438: INFO: Trying to get logs from node 10.10.21.190 pod pod-b2857adc-04b4-44ff-864e-0b67d916d1b5 container test-container: <nil>
    STEP: delete the pod 04/25/23 20:38:19.466
    Apr 25 20:38:19.503: INFO: Waiting for pod pod-b2857adc-04b4-44ff-864e-0b67d916d1b5 to disappear
    Apr 25 20:38:19.517: INFO: Pod pod-b2857adc-04b4-44ff-864e-0b67d916d1b5 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 25 20:38:19.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4503" for this suite. 04/25/23 20:38:19.535
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:38:19.578
Apr 25 20:38:19.578: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename dns 04/25/23 20:38:19.58
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:19.63
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:19.642
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 04/25/23 20:38:19.656
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6103.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6103.svc.cluster.local; sleep 1; done
 04/25/23 20:38:19.672
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6103.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6103.svc.cluster.local; sleep 1; done
 04/25/23 20:38:19.672
STEP: creating a pod to probe DNS 04/25/23 20:38:19.672
STEP: submitting the pod to kubernetes 04/25/23 20:38:19.673
Apr 25 20:38:19.715: INFO: Waiting up to 15m0s for pod "dns-test-5ef9f396-771a-4d51-9412-da8ef9f2fe63" in namespace "dns-6103" to be "running"
Apr 25 20:38:19.729: INFO: Pod "dns-test-5ef9f396-771a-4d51-9412-da8ef9f2fe63": Phase="Pending", Reason="", readiness=false. Elapsed: 13.570919ms
Apr 25 20:38:21.745: INFO: Pod "dns-test-5ef9f396-771a-4d51-9412-da8ef9f2fe63": Phase="Running", Reason="", readiness=true. Elapsed: 2.029690589s
Apr 25 20:38:21.745: INFO: Pod "dns-test-5ef9f396-771a-4d51-9412-da8ef9f2fe63" satisfied condition "running"
STEP: retrieving the pod 04/25/23 20:38:21.745
STEP: looking for the results for each expected name from probers 04/25/23 20:38:21.76
Apr 25 20:38:21.847: INFO: DNS probes using dns-test-5ef9f396-771a-4d51-9412-da8ef9f2fe63 succeeded

STEP: deleting the pod 04/25/23 20:38:21.847
STEP: changing the externalName to bar.example.com 04/25/23 20:38:21.899
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6103.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6103.svc.cluster.local; sleep 1; done
 04/25/23 20:38:21.926
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6103.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6103.svc.cluster.local; sleep 1; done
 04/25/23 20:38:21.926
STEP: creating a second pod to probe DNS 04/25/23 20:38:21.928
STEP: submitting the pod to kubernetes 04/25/23 20:38:21.934
Apr 25 20:38:21.955: INFO: Waiting up to 15m0s for pod "dns-test-e8fadbfa-ce6e-4167-9b80-53d38a238b97" in namespace "dns-6103" to be "running"
Apr 25 20:38:21.972: INFO: Pod "dns-test-e8fadbfa-ce6e-4167-9b80-53d38a238b97": Phase="Pending", Reason="", readiness=false. Elapsed: 17.076512ms
Apr 25 20:38:23.988: INFO: Pod "dns-test-e8fadbfa-ce6e-4167-9b80-53d38a238b97": Phase="Running", Reason="", readiness=true. Elapsed: 2.032737378s
Apr 25 20:38:23.988: INFO: Pod "dns-test-e8fadbfa-ce6e-4167-9b80-53d38a238b97" satisfied condition "running"
STEP: retrieving the pod 04/25/23 20:38:23.988
STEP: looking for the results for each expected name from probers 04/25/23 20:38:24.003
Apr 25 20:38:24.056: INFO: File wheezy_udp@dns-test-service-3.dns-6103.svc.cluster.local from pod  dns-6103/dns-test-e8fadbfa-ce6e-4167-9b80-53d38a238b97 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 25 20:38:24.076: INFO: Lookups using dns-6103/dns-test-e8fadbfa-ce6e-4167-9b80-53d38a238b97 failed for: [wheezy_udp@dns-test-service-3.dns-6103.svc.cluster.local]

Apr 25 20:38:29.114: INFO: DNS probes using dns-test-e8fadbfa-ce6e-4167-9b80-53d38a238b97 succeeded

STEP: deleting the pod 04/25/23 20:38:29.114
STEP: changing the service to type=ClusterIP 04/25/23 20:38:29.163
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6103.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-6103.svc.cluster.local; sleep 1; done
 04/25/23 20:38:29.21
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6103.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-6103.svc.cluster.local; sleep 1; done
 04/25/23 20:38:29.21
STEP: creating a third pod to probe DNS 04/25/23 20:38:29.211
STEP: submitting the pod to kubernetes 04/25/23 20:38:29.223
Apr 25 20:38:29.241: INFO: Waiting up to 15m0s for pod "dns-test-43616ab3-2707-4a7a-ab1c-74f390e5ef94" in namespace "dns-6103" to be "running"
Apr 25 20:38:29.255: INFO: Pod "dns-test-43616ab3-2707-4a7a-ab1c-74f390e5ef94": Phase="Pending", Reason="", readiness=false. Elapsed: 14.154296ms
Apr 25 20:38:31.271: INFO: Pod "dns-test-43616ab3-2707-4a7a-ab1c-74f390e5ef94": Phase="Running", Reason="", readiness=true. Elapsed: 2.0297051s
Apr 25 20:38:31.271: INFO: Pod "dns-test-43616ab3-2707-4a7a-ab1c-74f390e5ef94" satisfied condition "running"
STEP: retrieving the pod 04/25/23 20:38:31.271
STEP: looking for the results for each expected name from probers 04/25/23 20:38:31.289
Apr 25 20:38:31.365: INFO: DNS probes using dns-test-43616ab3-2707-4a7a-ab1c-74f390e5ef94 succeeded

STEP: deleting the pod 04/25/23 20:38:31.365
STEP: deleting the test externalName service 04/25/23 20:38:31.406
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 25 20:38:31.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6103" for this suite. 04/25/23 20:38:31.463
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":229,"skipped":4174,"failed":0}
------------------------------
• [SLOW TEST] [11.916 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:38:19.578
    Apr 25 20:38:19.578: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename dns 04/25/23 20:38:19.58
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:19.63
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:19.642
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 04/25/23 20:38:19.656
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6103.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6103.svc.cluster.local; sleep 1; done
     04/25/23 20:38:19.672
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6103.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6103.svc.cluster.local; sleep 1; done
     04/25/23 20:38:19.672
    STEP: creating a pod to probe DNS 04/25/23 20:38:19.672
    STEP: submitting the pod to kubernetes 04/25/23 20:38:19.673
    Apr 25 20:38:19.715: INFO: Waiting up to 15m0s for pod "dns-test-5ef9f396-771a-4d51-9412-da8ef9f2fe63" in namespace "dns-6103" to be "running"
    Apr 25 20:38:19.729: INFO: Pod "dns-test-5ef9f396-771a-4d51-9412-da8ef9f2fe63": Phase="Pending", Reason="", readiness=false. Elapsed: 13.570919ms
    Apr 25 20:38:21.745: INFO: Pod "dns-test-5ef9f396-771a-4d51-9412-da8ef9f2fe63": Phase="Running", Reason="", readiness=true. Elapsed: 2.029690589s
    Apr 25 20:38:21.745: INFO: Pod "dns-test-5ef9f396-771a-4d51-9412-da8ef9f2fe63" satisfied condition "running"
    STEP: retrieving the pod 04/25/23 20:38:21.745
    STEP: looking for the results for each expected name from probers 04/25/23 20:38:21.76
    Apr 25 20:38:21.847: INFO: DNS probes using dns-test-5ef9f396-771a-4d51-9412-da8ef9f2fe63 succeeded

    STEP: deleting the pod 04/25/23 20:38:21.847
    STEP: changing the externalName to bar.example.com 04/25/23 20:38:21.899
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6103.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6103.svc.cluster.local; sleep 1; done
     04/25/23 20:38:21.926
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6103.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6103.svc.cluster.local; sleep 1; done
     04/25/23 20:38:21.926
    STEP: creating a second pod to probe DNS 04/25/23 20:38:21.928
    STEP: submitting the pod to kubernetes 04/25/23 20:38:21.934
    Apr 25 20:38:21.955: INFO: Waiting up to 15m0s for pod "dns-test-e8fadbfa-ce6e-4167-9b80-53d38a238b97" in namespace "dns-6103" to be "running"
    Apr 25 20:38:21.972: INFO: Pod "dns-test-e8fadbfa-ce6e-4167-9b80-53d38a238b97": Phase="Pending", Reason="", readiness=false. Elapsed: 17.076512ms
    Apr 25 20:38:23.988: INFO: Pod "dns-test-e8fadbfa-ce6e-4167-9b80-53d38a238b97": Phase="Running", Reason="", readiness=true. Elapsed: 2.032737378s
    Apr 25 20:38:23.988: INFO: Pod "dns-test-e8fadbfa-ce6e-4167-9b80-53d38a238b97" satisfied condition "running"
    STEP: retrieving the pod 04/25/23 20:38:23.988
    STEP: looking for the results for each expected name from probers 04/25/23 20:38:24.003
    Apr 25 20:38:24.056: INFO: File wheezy_udp@dns-test-service-3.dns-6103.svc.cluster.local from pod  dns-6103/dns-test-e8fadbfa-ce6e-4167-9b80-53d38a238b97 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 25 20:38:24.076: INFO: Lookups using dns-6103/dns-test-e8fadbfa-ce6e-4167-9b80-53d38a238b97 failed for: [wheezy_udp@dns-test-service-3.dns-6103.svc.cluster.local]

    Apr 25 20:38:29.114: INFO: DNS probes using dns-test-e8fadbfa-ce6e-4167-9b80-53d38a238b97 succeeded

    STEP: deleting the pod 04/25/23 20:38:29.114
    STEP: changing the service to type=ClusterIP 04/25/23 20:38:29.163
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6103.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-6103.svc.cluster.local; sleep 1; done
     04/25/23 20:38:29.21
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6103.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-6103.svc.cluster.local; sleep 1; done
     04/25/23 20:38:29.21
    STEP: creating a third pod to probe DNS 04/25/23 20:38:29.211
    STEP: submitting the pod to kubernetes 04/25/23 20:38:29.223
    Apr 25 20:38:29.241: INFO: Waiting up to 15m0s for pod "dns-test-43616ab3-2707-4a7a-ab1c-74f390e5ef94" in namespace "dns-6103" to be "running"
    Apr 25 20:38:29.255: INFO: Pod "dns-test-43616ab3-2707-4a7a-ab1c-74f390e5ef94": Phase="Pending", Reason="", readiness=false. Elapsed: 14.154296ms
    Apr 25 20:38:31.271: INFO: Pod "dns-test-43616ab3-2707-4a7a-ab1c-74f390e5ef94": Phase="Running", Reason="", readiness=true. Elapsed: 2.0297051s
    Apr 25 20:38:31.271: INFO: Pod "dns-test-43616ab3-2707-4a7a-ab1c-74f390e5ef94" satisfied condition "running"
    STEP: retrieving the pod 04/25/23 20:38:31.271
    STEP: looking for the results for each expected name from probers 04/25/23 20:38:31.289
    Apr 25 20:38:31.365: INFO: DNS probes using dns-test-43616ab3-2707-4a7a-ab1c-74f390e5ef94 succeeded

    STEP: deleting the pod 04/25/23 20:38:31.365
    STEP: deleting the test externalName service 04/25/23 20:38:31.406
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 25 20:38:31.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6103" for this suite. 04/25/23 20:38:31.463
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:38:31.497
Apr 25 20:38:31.498: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename resourcequota 04/25/23 20:38:31.504
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:31.545
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:31.557
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 04/25/23 20:38:31.569
STEP: Ensuring ResourceQuota status is calculated 04/25/23 20:38:31.587
STEP: Creating a ResourceQuota with not terminating scope 04/25/23 20:38:33.599
STEP: Ensuring ResourceQuota status is calculated 04/25/23 20:38:33.614
STEP: Creating a long running pod 04/25/23 20:38:35.627
STEP: Ensuring resource quota with not terminating scope captures the pod usage 04/25/23 20:38:35.666
STEP: Ensuring resource quota with terminating scope ignored the pod usage 04/25/23 20:38:37.677
STEP: Deleting the pod 04/25/23 20:38:39.692
STEP: Ensuring resource quota status released the pod usage 04/25/23 20:38:39.726
STEP: Creating a terminating pod 04/25/23 20:38:41.74
STEP: Ensuring resource quota with terminating scope captures the pod usage 04/25/23 20:38:41.771
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 04/25/23 20:38:43.791
STEP: Deleting the pod 04/25/23 20:38:45.805
STEP: Ensuring resource quota status released the pod usage 04/25/23 20:38:45.845
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 25 20:38:47.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4448" for this suite. 04/25/23 20:38:47.878
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":230,"skipped":4177,"failed":0}
------------------------------
• [SLOW TEST] [16.407 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:38:31.497
    Apr 25 20:38:31.498: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename resourcequota 04/25/23 20:38:31.504
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:31.545
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:31.557
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 04/25/23 20:38:31.569
    STEP: Ensuring ResourceQuota status is calculated 04/25/23 20:38:31.587
    STEP: Creating a ResourceQuota with not terminating scope 04/25/23 20:38:33.599
    STEP: Ensuring ResourceQuota status is calculated 04/25/23 20:38:33.614
    STEP: Creating a long running pod 04/25/23 20:38:35.627
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 04/25/23 20:38:35.666
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 04/25/23 20:38:37.677
    STEP: Deleting the pod 04/25/23 20:38:39.692
    STEP: Ensuring resource quota status released the pod usage 04/25/23 20:38:39.726
    STEP: Creating a terminating pod 04/25/23 20:38:41.74
    STEP: Ensuring resource quota with terminating scope captures the pod usage 04/25/23 20:38:41.771
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 04/25/23 20:38:43.791
    STEP: Deleting the pod 04/25/23 20:38:45.805
    STEP: Ensuring resource quota status released the pod usage 04/25/23 20:38:45.845
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 25 20:38:47.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4448" for this suite. 04/25/23 20:38:47.878
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:38:47.913
Apr 25 20:38:47.913: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 20:38:47.914
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:47.963
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:47.976
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 04/25/23 20:38:47.989
Apr 25 20:38:47.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3052 create -f -'
Apr 25 20:38:48.327: INFO: stderr: ""
Apr 25 20:38:48.327: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 04/25/23 20:38:48.327
Apr 25 20:38:48.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3052 diff -f -'
Apr 25 20:38:48.675: INFO: rc: 1
Apr 25 20:38:48.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3052 delete -f -'
Apr 25 20:38:48.807: INFO: stderr: ""
Apr 25 20:38:48.808: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 20:38:48.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3052" for this suite. 04/25/23 20:38:48.828
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":231,"skipped":4217,"failed":0}
------------------------------
• [0.938 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:38:47.913
    Apr 25 20:38:47.913: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 20:38:47.914
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:47.963
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:47.976
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 04/25/23 20:38:47.989
    Apr 25 20:38:47.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3052 create -f -'
    Apr 25 20:38:48.327: INFO: stderr: ""
    Apr 25 20:38:48.327: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 04/25/23 20:38:48.327
    Apr 25 20:38:48.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3052 diff -f -'
    Apr 25 20:38:48.675: INFO: rc: 1
    Apr 25 20:38:48.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3052 delete -f -'
    Apr 25 20:38:48.807: INFO: stderr: ""
    Apr 25 20:38:48.808: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 20:38:48.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3052" for this suite. 04/25/23 20:38:48.828
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:38:48.856
Apr 25 20:38:48.856: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename proxy 04/25/23 20:38:48.858
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:48.907
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:48.919
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 04/25/23 20:38:48.973
STEP: creating replication controller proxy-service-nhc2l in namespace proxy-1290 04/25/23 20:38:48.973
I0425 20:38:48.993492      23 runners.go:193] Created replication controller with name: proxy-service-nhc2l, namespace: proxy-1290, replica count: 1
I0425 20:38:50.043857      23 runners.go:193] proxy-service-nhc2l Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0425 20:38:51.045797      23 runners.go:193] proxy-service-nhc2l Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0425 20:38:52.046946      23 runners.go:193] proxy-service-nhc2l Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 25 20:38:52.063: INFO: setup took 3.122449369s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 04/25/23 20:38:52.063
Apr 25 20:38:52.142: INFO: (0) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 76.516027ms)
Apr 25 20:38:52.152: INFO: (0) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 88.173783ms)
Apr 25 20:38:52.155: INFO: (0) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 90.84087ms)
Apr 25 20:38:52.166: INFO: (0) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 101.189246ms)
Apr 25 20:38:52.167: INFO: (0) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 103.371774ms)
Apr 25 20:38:52.170: INFO: (0) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 105.145443ms)
Apr 25 20:38:52.170: INFO: (0) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 105.24369ms)
Apr 25 20:38:52.170: INFO: (0) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 105.805681ms)
Apr 25 20:38:52.170: INFO: (0) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 105.425614ms)
Apr 25 20:38:52.171: INFO: (0) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 107.145942ms)
Apr 25 20:38:52.172: INFO: (0) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 108.785838ms)
Apr 25 20:38:52.178: INFO: (0) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 113.395196ms)
Apr 25 20:38:52.178: INFO: (0) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 113.961714ms)
Apr 25 20:38:52.184: INFO: (0) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 120.223237ms)
Apr 25 20:38:52.188: INFO: (0) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 123.60963ms)
Apr 25 20:38:52.191: INFO: (0) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 126.398708ms)
Apr 25 20:38:52.298: INFO: (1) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 103.37473ms)
Apr 25 20:38:52.299: INFO: (1) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 106.67829ms)
Apr 25 20:38:52.311: INFO: (1) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 114.329737ms)
Apr 25 20:38:52.312: INFO: (1) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 119.23493ms)
Apr 25 20:38:52.312: INFO: (1) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 116.029428ms)
Apr 25 20:38:52.312: INFO: (1) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 117.947256ms)
Apr 25 20:38:52.313: INFO: (1) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 116.929319ms)
Apr 25 20:38:52.320: INFO: (1) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 127.429669ms)
Apr 25 20:38:52.321: INFO: (1) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 126.823747ms)
Apr 25 20:38:52.323: INFO: (1) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 127.773022ms)
Apr 25 20:38:52.328: INFO: (1) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 133.953305ms)
Apr 25 20:38:52.328: INFO: (1) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 131.427637ms)
Apr 25 20:38:52.329: INFO: (1) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 134.22776ms)
Apr 25 20:38:52.334: INFO: (1) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 138.877004ms)
Apr 25 20:38:52.338: INFO: (1) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 140.6861ms)
Apr 25 20:38:52.338: INFO: (1) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 142.225981ms)
Apr 25 20:38:52.352: INFO: (2) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 14.381652ms)
Apr 25 20:38:52.358: INFO: (2) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 19.295375ms)
Apr 25 20:38:52.358: INFO: (2) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 19.453961ms)
Apr 25 20:38:52.358: INFO: (2) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 19.674051ms)
Apr 25 20:38:52.361: INFO: (2) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 22.131489ms)
Apr 25 20:38:52.361: INFO: (2) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 22.648233ms)
Apr 25 20:38:52.363: INFO: (2) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 24.404534ms)
Apr 25 20:38:52.363: INFO: (2) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 24.133319ms)
Apr 25 20:38:52.364: INFO: (2) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 24.6204ms)
Apr 25 20:38:52.364: INFO: (2) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 25.062275ms)
Apr 25 20:38:52.364: INFO: (2) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 24.52173ms)
Apr 25 20:38:52.372: INFO: (2) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 33.747624ms)
Apr 25 20:38:52.373: INFO: (2) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 34.415321ms)
Apr 25 20:38:52.376: INFO: (2) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 37.288084ms)
Apr 25 20:38:52.376: INFO: (2) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 37.772201ms)
Apr 25 20:38:52.377: INFO: (2) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 37.419544ms)
Apr 25 20:38:52.394: INFO: (3) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 16.978599ms)
Apr 25 20:38:52.398: INFO: (3) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 19.605237ms)
Apr 25 20:38:52.399: INFO: (3) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 20.627924ms)
Apr 25 20:38:52.401: INFO: (3) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 22.595945ms)
Apr 25 20:38:52.401: INFO: (3) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 23.339973ms)
Apr 25 20:38:52.407: INFO: (3) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 29.003939ms)
Apr 25 20:38:52.410: INFO: (3) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 33.071861ms)
Apr 25 20:38:52.410: INFO: (3) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 33.291888ms)
Apr 25 20:38:52.411: INFO: (3) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 32.323923ms)
Apr 25 20:38:52.410: INFO: (3) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 32.393319ms)
Apr 25 20:38:52.417: INFO: (3) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 38.986267ms)
Apr 25 20:38:52.417: INFO: (3) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 38.815691ms)
Apr 25 20:38:52.421: INFO: (3) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 43.140668ms)
Apr 25 20:38:52.421: INFO: (3) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 42.991848ms)
Apr 25 20:38:52.426: INFO: (3) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 47.300665ms)
Apr 25 20:38:52.426: INFO: (3) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 47.69817ms)
Apr 25 20:38:52.441: INFO: (4) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 15.004335ms)
Apr 25 20:38:52.444: INFO: (4) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 17.59584ms)
Apr 25 20:38:52.446: INFO: (4) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 18.878744ms)
Apr 25 20:38:52.446: INFO: (4) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 19.42204ms)
Apr 25 20:38:52.446: INFO: (4) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 18.92394ms)
Apr 25 20:38:52.448: INFO: (4) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 20.704249ms)
Apr 25 20:38:52.448: INFO: (4) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 20.551007ms)
Apr 25 20:38:52.448: INFO: (4) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 20.906004ms)
Apr 25 20:38:52.448: INFO: (4) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 20.704475ms)
Apr 25 20:38:52.450: INFO: (4) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 22.037157ms)
Apr 25 20:38:52.453: INFO: (4) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 25.068397ms)
Apr 25 20:38:52.459: INFO: (4) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 32.331925ms)
Apr 25 20:38:52.460: INFO: (4) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 32.120101ms)
Apr 25 20:38:52.460: INFO: (4) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 33.471673ms)
Apr 25 20:38:52.461: INFO: (4) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 35.569655ms)
Apr 25 20:38:52.465: INFO: (4) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 38.724606ms)
Apr 25 20:38:52.483: INFO: (5) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 17.911315ms)
Apr 25 20:38:52.487: INFO: (5) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 20.914868ms)
Apr 25 20:38:52.487: INFO: (5) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 20.529966ms)
Apr 25 20:38:52.488: INFO: (5) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 21.786945ms)
Apr 25 20:38:52.488: INFO: (5) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 22.414556ms)
Apr 25 20:38:52.491: INFO: (5) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 24.732647ms)
Apr 25 20:38:52.492: INFO: (5) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 26.024652ms)
Apr 25 20:38:52.493: INFO: (5) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 26.19467ms)
Apr 25 20:38:52.493: INFO: (5) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 26.528913ms)
Apr 25 20:38:52.493: INFO: (5) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 26.841722ms)
Apr 25 20:38:52.495: INFO: (5) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 29.424412ms)
Apr 25 20:38:52.496: INFO: (5) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 30.049542ms)
Apr 25 20:38:52.498: INFO: (5) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 31.72293ms)
Apr 25 20:38:52.498: INFO: (5) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 31.903733ms)
Apr 25 20:38:52.499: INFO: (5) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 32.701971ms)
Apr 25 20:38:52.499: INFO: (5) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 32.852562ms)
Apr 25 20:38:52.526: INFO: (6) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 26.594123ms)
Apr 25 20:38:52.527: INFO: (6) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 27.724888ms)
Apr 25 20:38:52.530: INFO: (6) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 31.060679ms)
Apr 25 20:38:52.530: INFO: (6) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 30.803473ms)
Apr 25 20:38:52.534: INFO: (6) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 34.134786ms)
Apr 25 20:38:52.534: INFO: (6) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 34.515308ms)
Apr 25 20:38:52.535: INFO: (6) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 35.393885ms)
Apr 25 20:38:52.537: INFO: (6) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 37.235315ms)
Apr 25 20:38:52.537: INFO: (6) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 37.366905ms)
Apr 25 20:38:52.537: INFO: (6) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 36.89634ms)
Apr 25 20:38:52.537: INFO: (6) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 37.147887ms)
Apr 25 20:38:52.537: INFO: (6) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 37.508757ms)
Apr 25 20:38:52.542: INFO: (6) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 42.137918ms)
Apr 25 20:38:52.545: INFO: (6) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 44.862712ms)
Apr 25 20:38:52.578: INFO: (6) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 78.054797ms)
Apr 25 20:38:52.578: INFO: (6) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 78.245042ms)
Apr 25 20:38:52.595: INFO: (7) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 16.288084ms)
Apr 25 20:38:52.603: INFO: (7) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 23.634574ms)
Apr 25 20:38:52.603: INFO: (7) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 22.832022ms)
Apr 25 20:38:52.611: INFO: (7) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 31.593897ms)
Apr 25 20:38:52.611: INFO: (7) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 31.652949ms)
Apr 25 20:38:52.612: INFO: (7) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 32.391948ms)
Apr 25 20:38:52.612: INFO: (7) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 33.097086ms)
Apr 25 20:38:52.612: INFO: (7) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 32.079024ms)
Apr 25 20:38:52.615: INFO: (7) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 34.833654ms)
Apr 25 20:38:52.615: INFO: (7) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 36.16132ms)
Apr 25 20:38:52.618: INFO: (7) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 37.78974ms)
Apr 25 20:38:52.618: INFO: (7) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 38.312801ms)
Apr 25 20:38:52.619: INFO: (7) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 39.507858ms)
Apr 25 20:38:52.629: INFO: (7) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 50.097834ms)
Apr 25 20:38:52.629: INFO: (7) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 49.922489ms)
Apr 25 20:38:52.630: INFO: (7) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 50.018539ms)
Apr 25 20:38:52.647: INFO: (8) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 17.23588ms)
Apr 25 20:38:52.648: INFO: (8) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 18.037324ms)
Apr 25 20:38:52.648: INFO: (8) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 17.447269ms)
Apr 25 20:38:52.649: INFO: (8) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 19.027588ms)
Apr 25 20:38:52.661: INFO: (8) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 29.605022ms)
Apr 25 20:38:52.661: INFO: (8) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 29.940912ms)
Apr 25 20:38:52.661: INFO: (8) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 29.962069ms)
Apr 25 20:38:52.661: INFO: (8) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 30.61662ms)
Apr 25 20:38:52.661: INFO: (8) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 30.251603ms)
Apr 25 20:38:52.662: INFO: (8) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 30.116107ms)
Apr 25 20:38:52.663: INFO: (8) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 31.709617ms)
Apr 25 20:38:52.663: INFO: (8) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 31.998232ms)
Apr 25 20:38:52.665: INFO: (8) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 34.553199ms)
Apr 25 20:38:52.667: INFO: (8) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 35.40293ms)
Apr 25 20:38:52.667: INFO: (8) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 36.59507ms)
Apr 25 20:38:52.668: INFO: (8) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 38.207793ms)
Apr 25 20:38:52.685: INFO: (9) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 16.241521ms)
Apr 25 20:38:52.686: INFO: (9) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 15.814123ms)
Apr 25 20:38:52.687: INFO: (9) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 16.972084ms)
Apr 25 20:38:52.689: INFO: (9) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 18.822488ms)
Apr 25 20:38:52.693: INFO: (9) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 22.102726ms)
Apr 25 20:38:52.693: INFO: (9) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 21.876481ms)
Apr 25 20:38:52.694: INFO: (9) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 22.627938ms)
Apr 25 20:38:52.694: INFO: (9) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 23.456156ms)
Apr 25 20:38:52.695: INFO: (9) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 24.15058ms)
Apr 25 20:38:52.695: INFO: (9) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 24.017648ms)
Apr 25 20:38:52.696: INFO: (9) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 26.759943ms)
Apr 25 20:38:52.700: INFO: (9) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 29.525512ms)
Apr 25 20:38:52.702: INFO: (9) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 33.175048ms)
Apr 25 20:38:52.704: INFO: (9) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 33.651116ms)
Apr 25 20:38:52.704: INFO: (9) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 34.062939ms)
Apr 25 20:38:52.710: INFO: (9) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 39.853082ms)
Apr 25 20:38:52.727: INFO: (10) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 16.778495ms)
Apr 25 20:38:52.730: INFO: (10) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 19.346998ms)
Apr 25 20:38:52.730: INFO: (10) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 19.214569ms)
Apr 25 20:38:52.731: INFO: (10) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 20.015129ms)
Apr 25 20:38:52.730: INFO: (10) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 19.895118ms)
Apr 25 20:38:52.730: INFO: (10) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 19.470373ms)
Apr 25 20:38:52.732: INFO: (10) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 21.637357ms)
Apr 25 20:38:52.733: INFO: (10) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 21.691593ms)
Apr 25 20:38:52.734: INFO: (10) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 21.766603ms)
Apr 25 20:38:52.739: INFO: (10) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 28.077747ms)
Apr 25 20:38:52.739: INFO: (10) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 27.669043ms)
Apr 25 20:38:52.740: INFO: (10) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 29.421274ms)
Apr 25 20:38:52.742: INFO: (10) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 31.248487ms)
Apr 25 20:38:52.742: INFO: (10) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 32.031989ms)
Apr 25 20:38:52.742: INFO: (10) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 31.049327ms)
Apr 25 20:38:52.749: INFO: (10) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 38.073775ms)
Apr 25 20:38:52.765: INFO: (11) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 15.757074ms)
Apr 25 20:38:52.768: INFO: (11) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 17.219485ms)
Apr 25 20:38:52.769: INFO: (11) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 18.641028ms)
Apr 25 20:38:52.769: INFO: (11) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 18.739182ms)
Apr 25 20:38:52.776: INFO: (11) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 25.887451ms)
Apr 25 20:38:52.776: INFO: (11) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 25.974706ms)
Apr 25 20:38:52.776: INFO: (11) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 25.813785ms)
Apr 25 20:38:52.776: INFO: (11) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 25.807518ms)
Apr 25 20:38:52.773: INFO: (11) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 23.526536ms)
Apr 25 20:38:52.780: INFO: (11) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 29.197028ms)
Apr 25 20:38:52.780: INFO: (11) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 29.688145ms)
Apr 25 20:38:52.780: INFO: (11) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 29.20496ms)
Apr 25 20:38:52.780: INFO: (11) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 30.132737ms)
Apr 25 20:38:52.780: INFO: (11) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 29.972682ms)
Apr 25 20:38:52.781: INFO: (11) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 30.108875ms)
Apr 25 20:38:52.783: INFO: (11) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 33.106448ms)
Apr 25 20:38:52.801: INFO: (12) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 17.71791ms)
Apr 25 20:38:52.803: INFO: (12) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 19.743992ms)
Apr 25 20:38:52.806: INFO: (12) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 21.59105ms)
Apr 25 20:38:52.807: INFO: (12) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 23.195708ms)
Apr 25 20:38:52.807: INFO: (12) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 23.628496ms)
Apr 25 20:38:52.809: INFO: (12) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 24.906474ms)
Apr 25 20:38:52.809: INFO: (12) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 25.274393ms)
Apr 25 20:38:52.810: INFO: (12) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 25.852675ms)
Apr 25 20:38:52.810: INFO: (12) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 26.737828ms)
Apr 25 20:38:52.812: INFO: (12) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 28.173564ms)
Apr 25 20:38:52.813: INFO: (12) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 28.850637ms)
Apr 25 20:38:52.816: INFO: (12) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 31.396111ms)
Apr 25 20:38:52.816: INFO: (12) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 31.617605ms)
Apr 25 20:38:52.818: INFO: (12) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 33.363409ms)
Apr 25 20:38:52.818: INFO: (12) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 33.268483ms)
Apr 25 20:38:52.818: INFO: (12) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 34.044273ms)
Apr 25 20:38:52.834: INFO: (13) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 15.587438ms)
Apr 25 20:38:52.839: INFO: (13) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 17.968248ms)
Apr 25 20:38:52.841: INFO: (13) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 20.486169ms)
Apr 25 20:38:52.842: INFO: (13) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 22.392416ms)
Apr 25 20:38:52.842: INFO: (13) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 22.738491ms)
Apr 25 20:38:52.842: INFO: (13) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 21.736413ms)
Apr 25 20:38:52.843: INFO: (13) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 23.107837ms)
Apr 25 20:38:52.844: INFO: (13) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 24.40349ms)
Apr 25 20:38:52.845: INFO: (13) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 25.627427ms)
Apr 25 20:38:52.847: INFO: (13) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 28.423305ms)
Apr 25 20:38:52.845: INFO: (13) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 25.272297ms)
Apr 25 20:38:52.847: INFO: (13) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 26.761313ms)
Apr 25 20:38:52.849: INFO: (13) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 29.942964ms)
Apr 25 20:38:52.851: INFO: (13) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 31.358222ms)
Apr 25 20:38:52.852: INFO: (13) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 32.578612ms)
Apr 25 20:38:52.852: INFO: (13) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 32.17153ms)
Apr 25 20:38:52.875: INFO: (14) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 21.633361ms)
Apr 25 20:38:52.875: INFO: (14) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 21.465246ms)
Apr 25 20:38:52.875: INFO: (14) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 21.863223ms)
Apr 25 20:38:52.876: INFO: (14) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 22.575835ms)
Apr 25 20:38:52.876: INFO: (14) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 22.408135ms)
Apr 25 20:38:52.876: INFO: (14) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 23.429938ms)
Apr 25 20:38:52.877: INFO: (14) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 24.156845ms)
Apr 25 20:38:52.877: INFO: (14) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 24.660356ms)
Apr 25 20:38:52.878: INFO: (14) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 24.24384ms)
Apr 25 20:38:52.878: INFO: (14) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 24.684814ms)
Apr 25 20:38:52.881: INFO: (14) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 28.229859ms)
Apr 25 20:38:52.881: INFO: (14) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 27.79088ms)
Apr 25 20:38:52.884: INFO: (14) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 31.125657ms)
Apr 25 20:38:52.884: INFO: (14) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 30.955269ms)
Apr 25 20:38:52.884: INFO: (14) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 31.142074ms)
Apr 25 20:38:52.884: INFO: (14) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 30.905641ms)
Apr 25 20:38:52.900: INFO: (15) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 15.746894ms)
Apr 25 20:38:52.904: INFO: (15) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 18.149848ms)
Apr 25 20:38:52.905: INFO: (15) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 19.289169ms)
Apr 25 20:38:52.907: INFO: (15) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 21.00799ms)
Apr 25 20:38:52.907: INFO: (15) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 21.116692ms)
Apr 25 20:38:52.907: INFO: (15) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 22.053343ms)
Apr 25 20:38:52.907: INFO: (15) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 23.040577ms)
Apr 25 20:38:52.908: INFO: (15) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 23.500433ms)
Apr 25 20:38:52.908: INFO: (15) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 23.599335ms)
Apr 25 20:38:52.913: INFO: (15) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 26.611028ms)
Apr 25 20:38:52.913: INFO: (15) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 27.598877ms)
Apr 25 20:38:52.917: INFO: (15) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 31.244585ms)
Apr 25 20:38:52.921: INFO: (15) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 35.535108ms)
Apr 25 20:38:52.923: INFO: (15) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 37.408768ms)
Apr 25 20:38:52.924: INFO: (15) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 37.782526ms)
Apr 25 20:38:52.965: INFO: (15) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 80.428813ms)
Apr 25 20:38:52.986: INFO: (16) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 19.763698ms)
Apr 25 20:38:52.987: INFO: (16) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 20.555617ms)
Apr 25 20:38:52.988: INFO: (16) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 20.960206ms)
Apr 25 20:38:52.989: INFO: (16) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 22.503218ms)
Apr 25 20:38:52.989: INFO: (16) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 22.683199ms)
Apr 25 20:38:52.989: INFO: (16) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 22.909314ms)
Apr 25 20:38:52.989: INFO: (16) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 22.407285ms)
Apr 25 20:38:52.989: INFO: (16) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 23.791217ms)
Apr 25 20:38:52.990: INFO: (16) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 23.14967ms)
Apr 25 20:38:52.990: INFO: (16) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 23.396295ms)
Apr 25 20:38:52.995: INFO: (16) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 27.888216ms)
Apr 25 20:38:52.995: INFO: (16) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 28.141904ms)
Apr 25 20:38:52.996: INFO: (16) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 29.942971ms)
Apr 25 20:38:52.997: INFO: (16) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 31.347448ms)
Apr 25 20:38:52.998: INFO: (16) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 31.564302ms)
Apr 25 20:38:53.007: INFO: (16) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 40.737621ms)
Apr 25 20:38:53.027: INFO: (17) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 18.744342ms)
Apr 25 20:38:53.027: INFO: (17) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 18.634574ms)
Apr 25 20:38:53.027: INFO: (17) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 18.95222ms)
Apr 25 20:38:53.028: INFO: (17) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 19.216228ms)
Apr 25 20:38:53.029: INFO: (17) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 20.200107ms)
Apr 25 20:38:53.031: INFO: (17) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 22.464268ms)
Apr 25 20:38:53.032: INFO: (17) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 23.515225ms)
Apr 25 20:38:53.032: INFO: (17) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 24.269024ms)
Apr 25 20:38:53.033: INFO: (17) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 24.795889ms)
Apr 25 20:38:53.034: INFO: (17) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 25.424051ms)
Apr 25 20:38:53.034: INFO: (17) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 25.519632ms)
Apr 25 20:38:53.036: INFO: (17) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 27.285587ms)
Apr 25 20:38:53.040: INFO: (17) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 30.810417ms)
Apr 25 20:38:53.040: INFO: (17) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 31.354379ms)
Apr 25 20:38:53.040: INFO: (17) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 31.949816ms)
Apr 25 20:38:53.040: INFO: (17) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 32.042028ms)
Apr 25 20:38:53.059: INFO: (18) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 17.966808ms)
Apr 25 20:38:53.061: INFO: (18) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 19.78533ms)
Apr 25 20:38:53.062: INFO: (18) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 20.96054ms)
Apr 25 20:38:53.064: INFO: (18) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 21.396104ms)
Apr 25 20:38:53.065: INFO: (18) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 22.580273ms)
Apr 25 20:38:53.066: INFO: (18) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 23.439799ms)
Apr 25 20:38:53.069: INFO: (18) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 28.291577ms)
Apr 25 20:38:53.069: INFO: (18) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 27.549ms)
Apr 25 20:38:53.073: INFO: (18) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 30.900602ms)
Apr 25 20:38:53.078: INFO: (18) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 36.414691ms)
Apr 25 20:38:53.080: INFO: (18) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 37.701183ms)
Apr 25 20:38:53.080: INFO: (18) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 38.829552ms)
Apr 25 20:38:53.086: INFO: (18) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 45.047816ms)
Apr 25 20:38:53.087: INFO: (18) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 44.785104ms)
Apr 25 20:38:53.087: INFO: (18) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 45.20082ms)
Apr 25 20:38:53.087: INFO: (18) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 44.695646ms)
Apr 25 20:38:53.103: INFO: (19) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 15.047002ms)
Apr 25 20:38:53.112: INFO: (19) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 22.924741ms)
Apr 25 20:38:53.112: INFO: (19) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 23.659934ms)
Apr 25 20:38:53.113: INFO: (19) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 24.174108ms)
Apr 25 20:38:53.113: INFO: (19) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 24.220273ms)
Apr 25 20:38:53.114: INFO: (19) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 24.432104ms)
Apr 25 20:38:53.116: INFO: (19) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 27.210907ms)
Apr 25 20:38:53.117: INFO: (19) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 27.691354ms)
Apr 25 20:38:53.117: INFO: (19) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 27.762145ms)
Apr 25 20:38:53.118: INFO: (19) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 29.056629ms)
Apr 25 20:38:53.118: INFO: (19) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 29.671875ms)
Apr 25 20:38:53.119: INFO: (19) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 30.563184ms)
Apr 25 20:38:53.119: INFO: (19) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 30.360624ms)
Apr 25 20:38:53.123: INFO: (19) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 34.826066ms)
Apr 25 20:38:53.124: INFO: (19) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 34.819367ms)
Apr 25 20:38:53.125: INFO: (19) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 35.756163ms)
STEP: deleting ReplicationController proxy-service-nhc2l in namespace proxy-1290, will wait for the garbage collector to delete the pods 04/25/23 20:38:53.125
Apr 25 20:38:53.237: INFO: Deleting ReplicationController proxy-service-nhc2l took: 51.665273ms
Apr 25 20:38:53.338: INFO: Terminating ReplicationController proxy-service-nhc2l pods took: 100.713674ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Apr 25 20:38:55.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1290" for this suite. 04/25/23 20:38:55.96
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":232,"skipped":4235,"failed":0}
------------------------------
• [SLOW TEST] [7.123 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:38:48.856
    Apr 25 20:38:48.856: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename proxy 04/25/23 20:38:48.858
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:48.907
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:48.919
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 04/25/23 20:38:48.973
    STEP: creating replication controller proxy-service-nhc2l in namespace proxy-1290 04/25/23 20:38:48.973
    I0425 20:38:48.993492      23 runners.go:193] Created replication controller with name: proxy-service-nhc2l, namespace: proxy-1290, replica count: 1
    I0425 20:38:50.043857      23 runners.go:193] proxy-service-nhc2l Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0425 20:38:51.045797      23 runners.go:193] proxy-service-nhc2l Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
    I0425 20:38:52.046946      23 runners.go:193] proxy-service-nhc2l Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 25 20:38:52.063: INFO: setup took 3.122449369s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 04/25/23 20:38:52.063
    Apr 25 20:38:52.142: INFO: (0) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 76.516027ms)
    Apr 25 20:38:52.152: INFO: (0) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 88.173783ms)
    Apr 25 20:38:52.155: INFO: (0) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 90.84087ms)
    Apr 25 20:38:52.166: INFO: (0) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 101.189246ms)
    Apr 25 20:38:52.167: INFO: (0) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 103.371774ms)
    Apr 25 20:38:52.170: INFO: (0) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 105.145443ms)
    Apr 25 20:38:52.170: INFO: (0) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 105.24369ms)
    Apr 25 20:38:52.170: INFO: (0) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 105.805681ms)
    Apr 25 20:38:52.170: INFO: (0) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 105.425614ms)
    Apr 25 20:38:52.171: INFO: (0) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 107.145942ms)
    Apr 25 20:38:52.172: INFO: (0) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 108.785838ms)
    Apr 25 20:38:52.178: INFO: (0) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 113.395196ms)
    Apr 25 20:38:52.178: INFO: (0) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 113.961714ms)
    Apr 25 20:38:52.184: INFO: (0) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 120.223237ms)
    Apr 25 20:38:52.188: INFO: (0) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 123.60963ms)
    Apr 25 20:38:52.191: INFO: (0) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 126.398708ms)
    Apr 25 20:38:52.298: INFO: (1) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 103.37473ms)
    Apr 25 20:38:52.299: INFO: (1) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 106.67829ms)
    Apr 25 20:38:52.311: INFO: (1) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 114.329737ms)
    Apr 25 20:38:52.312: INFO: (1) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 119.23493ms)
    Apr 25 20:38:52.312: INFO: (1) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 116.029428ms)
    Apr 25 20:38:52.312: INFO: (1) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 117.947256ms)
    Apr 25 20:38:52.313: INFO: (1) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 116.929319ms)
    Apr 25 20:38:52.320: INFO: (1) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 127.429669ms)
    Apr 25 20:38:52.321: INFO: (1) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 126.823747ms)
    Apr 25 20:38:52.323: INFO: (1) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 127.773022ms)
    Apr 25 20:38:52.328: INFO: (1) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 133.953305ms)
    Apr 25 20:38:52.328: INFO: (1) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 131.427637ms)
    Apr 25 20:38:52.329: INFO: (1) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 134.22776ms)
    Apr 25 20:38:52.334: INFO: (1) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 138.877004ms)
    Apr 25 20:38:52.338: INFO: (1) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 140.6861ms)
    Apr 25 20:38:52.338: INFO: (1) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 142.225981ms)
    Apr 25 20:38:52.352: INFO: (2) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 14.381652ms)
    Apr 25 20:38:52.358: INFO: (2) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 19.295375ms)
    Apr 25 20:38:52.358: INFO: (2) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 19.453961ms)
    Apr 25 20:38:52.358: INFO: (2) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 19.674051ms)
    Apr 25 20:38:52.361: INFO: (2) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 22.131489ms)
    Apr 25 20:38:52.361: INFO: (2) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 22.648233ms)
    Apr 25 20:38:52.363: INFO: (2) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 24.404534ms)
    Apr 25 20:38:52.363: INFO: (2) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 24.133319ms)
    Apr 25 20:38:52.364: INFO: (2) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 24.6204ms)
    Apr 25 20:38:52.364: INFO: (2) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 25.062275ms)
    Apr 25 20:38:52.364: INFO: (2) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 24.52173ms)
    Apr 25 20:38:52.372: INFO: (2) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 33.747624ms)
    Apr 25 20:38:52.373: INFO: (2) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 34.415321ms)
    Apr 25 20:38:52.376: INFO: (2) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 37.288084ms)
    Apr 25 20:38:52.376: INFO: (2) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 37.772201ms)
    Apr 25 20:38:52.377: INFO: (2) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 37.419544ms)
    Apr 25 20:38:52.394: INFO: (3) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 16.978599ms)
    Apr 25 20:38:52.398: INFO: (3) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 19.605237ms)
    Apr 25 20:38:52.399: INFO: (3) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 20.627924ms)
    Apr 25 20:38:52.401: INFO: (3) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 22.595945ms)
    Apr 25 20:38:52.401: INFO: (3) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 23.339973ms)
    Apr 25 20:38:52.407: INFO: (3) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 29.003939ms)
    Apr 25 20:38:52.410: INFO: (3) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 33.071861ms)
    Apr 25 20:38:52.410: INFO: (3) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 33.291888ms)
    Apr 25 20:38:52.411: INFO: (3) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 32.323923ms)
    Apr 25 20:38:52.410: INFO: (3) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 32.393319ms)
    Apr 25 20:38:52.417: INFO: (3) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 38.986267ms)
    Apr 25 20:38:52.417: INFO: (3) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 38.815691ms)
    Apr 25 20:38:52.421: INFO: (3) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 43.140668ms)
    Apr 25 20:38:52.421: INFO: (3) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 42.991848ms)
    Apr 25 20:38:52.426: INFO: (3) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 47.300665ms)
    Apr 25 20:38:52.426: INFO: (3) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 47.69817ms)
    Apr 25 20:38:52.441: INFO: (4) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 15.004335ms)
    Apr 25 20:38:52.444: INFO: (4) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 17.59584ms)
    Apr 25 20:38:52.446: INFO: (4) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 18.878744ms)
    Apr 25 20:38:52.446: INFO: (4) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 19.42204ms)
    Apr 25 20:38:52.446: INFO: (4) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 18.92394ms)
    Apr 25 20:38:52.448: INFO: (4) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 20.704249ms)
    Apr 25 20:38:52.448: INFO: (4) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 20.551007ms)
    Apr 25 20:38:52.448: INFO: (4) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 20.906004ms)
    Apr 25 20:38:52.448: INFO: (4) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 20.704475ms)
    Apr 25 20:38:52.450: INFO: (4) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 22.037157ms)
    Apr 25 20:38:52.453: INFO: (4) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 25.068397ms)
    Apr 25 20:38:52.459: INFO: (4) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 32.331925ms)
    Apr 25 20:38:52.460: INFO: (4) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 32.120101ms)
    Apr 25 20:38:52.460: INFO: (4) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 33.471673ms)
    Apr 25 20:38:52.461: INFO: (4) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 35.569655ms)
    Apr 25 20:38:52.465: INFO: (4) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 38.724606ms)
    Apr 25 20:38:52.483: INFO: (5) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 17.911315ms)
    Apr 25 20:38:52.487: INFO: (5) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 20.914868ms)
    Apr 25 20:38:52.487: INFO: (5) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 20.529966ms)
    Apr 25 20:38:52.488: INFO: (5) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 21.786945ms)
    Apr 25 20:38:52.488: INFO: (5) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 22.414556ms)
    Apr 25 20:38:52.491: INFO: (5) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 24.732647ms)
    Apr 25 20:38:52.492: INFO: (5) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 26.024652ms)
    Apr 25 20:38:52.493: INFO: (5) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 26.19467ms)
    Apr 25 20:38:52.493: INFO: (5) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 26.528913ms)
    Apr 25 20:38:52.493: INFO: (5) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 26.841722ms)
    Apr 25 20:38:52.495: INFO: (5) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 29.424412ms)
    Apr 25 20:38:52.496: INFO: (5) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 30.049542ms)
    Apr 25 20:38:52.498: INFO: (5) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 31.72293ms)
    Apr 25 20:38:52.498: INFO: (5) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 31.903733ms)
    Apr 25 20:38:52.499: INFO: (5) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 32.701971ms)
    Apr 25 20:38:52.499: INFO: (5) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 32.852562ms)
    Apr 25 20:38:52.526: INFO: (6) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 26.594123ms)
    Apr 25 20:38:52.527: INFO: (6) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 27.724888ms)
    Apr 25 20:38:52.530: INFO: (6) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 31.060679ms)
    Apr 25 20:38:52.530: INFO: (6) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 30.803473ms)
    Apr 25 20:38:52.534: INFO: (6) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 34.134786ms)
    Apr 25 20:38:52.534: INFO: (6) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 34.515308ms)
    Apr 25 20:38:52.535: INFO: (6) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 35.393885ms)
    Apr 25 20:38:52.537: INFO: (6) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 37.235315ms)
    Apr 25 20:38:52.537: INFO: (6) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 37.366905ms)
    Apr 25 20:38:52.537: INFO: (6) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 36.89634ms)
    Apr 25 20:38:52.537: INFO: (6) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 37.147887ms)
    Apr 25 20:38:52.537: INFO: (6) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 37.508757ms)
    Apr 25 20:38:52.542: INFO: (6) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 42.137918ms)
    Apr 25 20:38:52.545: INFO: (6) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 44.862712ms)
    Apr 25 20:38:52.578: INFO: (6) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 78.054797ms)
    Apr 25 20:38:52.578: INFO: (6) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 78.245042ms)
    Apr 25 20:38:52.595: INFO: (7) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 16.288084ms)
    Apr 25 20:38:52.603: INFO: (7) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 23.634574ms)
    Apr 25 20:38:52.603: INFO: (7) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 22.832022ms)
    Apr 25 20:38:52.611: INFO: (7) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 31.593897ms)
    Apr 25 20:38:52.611: INFO: (7) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 31.652949ms)
    Apr 25 20:38:52.612: INFO: (7) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 32.391948ms)
    Apr 25 20:38:52.612: INFO: (7) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 33.097086ms)
    Apr 25 20:38:52.612: INFO: (7) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 32.079024ms)
    Apr 25 20:38:52.615: INFO: (7) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 34.833654ms)
    Apr 25 20:38:52.615: INFO: (7) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 36.16132ms)
    Apr 25 20:38:52.618: INFO: (7) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 37.78974ms)
    Apr 25 20:38:52.618: INFO: (7) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 38.312801ms)
    Apr 25 20:38:52.619: INFO: (7) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 39.507858ms)
    Apr 25 20:38:52.629: INFO: (7) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 50.097834ms)
    Apr 25 20:38:52.629: INFO: (7) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 49.922489ms)
    Apr 25 20:38:52.630: INFO: (7) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 50.018539ms)
    Apr 25 20:38:52.647: INFO: (8) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 17.23588ms)
    Apr 25 20:38:52.648: INFO: (8) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 18.037324ms)
    Apr 25 20:38:52.648: INFO: (8) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 17.447269ms)
    Apr 25 20:38:52.649: INFO: (8) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 19.027588ms)
    Apr 25 20:38:52.661: INFO: (8) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 29.605022ms)
    Apr 25 20:38:52.661: INFO: (8) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 29.940912ms)
    Apr 25 20:38:52.661: INFO: (8) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 29.962069ms)
    Apr 25 20:38:52.661: INFO: (8) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 30.61662ms)
    Apr 25 20:38:52.661: INFO: (8) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 30.251603ms)
    Apr 25 20:38:52.662: INFO: (8) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 30.116107ms)
    Apr 25 20:38:52.663: INFO: (8) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 31.709617ms)
    Apr 25 20:38:52.663: INFO: (8) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 31.998232ms)
    Apr 25 20:38:52.665: INFO: (8) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 34.553199ms)
    Apr 25 20:38:52.667: INFO: (8) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 35.40293ms)
    Apr 25 20:38:52.667: INFO: (8) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 36.59507ms)
    Apr 25 20:38:52.668: INFO: (8) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 38.207793ms)
    Apr 25 20:38:52.685: INFO: (9) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 16.241521ms)
    Apr 25 20:38:52.686: INFO: (9) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 15.814123ms)
    Apr 25 20:38:52.687: INFO: (9) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 16.972084ms)
    Apr 25 20:38:52.689: INFO: (9) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 18.822488ms)
    Apr 25 20:38:52.693: INFO: (9) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 22.102726ms)
    Apr 25 20:38:52.693: INFO: (9) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 21.876481ms)
    Apr 25 20:38:52.694: INFO: (9) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 22.627938ms)
    Apr 25 20:38:52.694: INFO: (9) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 23.456156ms)
    Apr 25 20:38:52.695: INFO: (9) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 24.15058ms)
    Apr 25 20:38:52.695: INFO: (9) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 24.017648ms)
    Apr 25 20:38:52.696: INFO: (9) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 26.759943ms)
    Apr 25 20:38:52.700: INFO: (9) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 29.525512ms)
    Apr 25 20:38:52.702: INFO: (9) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 33.175048ms)
    Apr 25 20:38:52.704: INFO: (9) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 33.651116ms)
    Apr 25 20:38:52.704: INFO: (9) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 34.062939ms)
    Apr 25 20:38:52.710: INFO: (9) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 39.853082ms)
    Apr 25 20:38:52.727: INFO: (10) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 16.778495ms)
    Apr 25 20:38:52.730: INFO: (10) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 19.346998ms)
    Apr 25 20:38:52.730: INFO: (10) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 19.214569ms)
    Apr 25 20:38:52.731: INFO: (10) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 20.015129ms)
    Apr 25 20:38:52.730: INFO: (10) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 19.895118ms)
    Apr 25 20:38:52.730: INFO: (10) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 19.470373ms)
    Apr 25 20:38:52.732: INFO: (10) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 21.637357ms)
    Apr 25 20:38:52.733: INFO: (10) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 21.691593ms)
    Apr 25 20:38:52.734: INFO: (10) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 21.766603ms)
    Apr 25 20:38:52.739: INFO: (10) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 28.077747ms)
    Apr 25 20:38:52.739: INFO: (10) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 27.669043ms)
    Apr 25 20:38:52.740: INFO: (10) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 29.421274ms)
    Apr 25 20:38:52.742: INFO: (10) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 31.248487ms)
    Apr 25 20:38:52.742: INFO: (10) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 32.031989ms)
    Apr 25 20:38:52.742: INFO: (10) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 31.049327ms)
    Apr 25 20:38:52.749: INFO: (10) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 38.073775ms)
    Apr 25 20:38:52.765: INFO: (11) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 15.757074ms)
    Apr 25 20:38:52.768: INFO: (11) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 17.219485ms)
    Apr 25 20:38:52.769: INFO: (11) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 18.641028ms)
    Apr 25 20:38:52.769: INFO: (11) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 18.739182ms)
    Apr 25 20:38:52.776: INFO: (11) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 25.887451ms)
    Apr 25 20:38:52.776: INFO: (11) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 25.974706ms)
    Apr 25 20:38:52.776: INFO: (11) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 25.813785ms)
    Apr 25 20:38:52.776: INFO: (11) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 25.807518ms)
    Apr 25 20:38:52.773: INFO: (11) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 23.526536ms)
    Apr 25 20:38:52.780: INFO: (11) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 29.197028ms)
    Apr 25 20:38:52.780: INFO: (11) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 29.688145ms)
    Apr 25 20:38:52.780: INFO: (11) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 29.20496ms)
    Apr 25 20:38:52.780: INFO: (11) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 30.132737ms)
    Apr 25 20:38:52.780: INFO: (11) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 29.972682ms)
    Apr 25 20:38:52.781: INFO: (11) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 30.108875ms)
    Apr 25 20:38:52.783: INFO: (11) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 33.106448ms)
    Apr 25 20:38:52.801: INFO: (12) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 17.71791ms)
    Apr 25 20:38:52.803: INFO: (12) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 19.743992ms)
    Apr 25 20:38:52.806: INFO: (12) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 21.59105ms)
    Apr 25 20:38:52.807: INFO: (12) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 23.195708ms)
    Apr 25 20:38:52.807: INFO: (12) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 23.628496ms)
    Apr 25 20:38:52.809: INFO: (12) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 24.906474ms)
    Apr 25 20:38:52.809: INFO: (12) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 25.274393ms)
    Apr 25 20:38:52.810: INFO: (12) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 25.852675ms)
    Apr 25 20:38:52.810: INFO: (12) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 26.737828ms)
    Apr 25 20:38:52.812: INFO: (12) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 28.173564ms)
    Apr 25 20:38:52.813: INFO: (12) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 28.850637ms)
    Apr 25 20:38:52.816: INFO: (12) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 31.396111ms)
    Apr 25 20:38:52.816: INFO: (12) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 31.617605ms)
    Apr 25 20:38:52.818: INFO: (12) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 33.363409ms)
    Apr 25 20:38:52.818: INFO: (12) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 33.268483ms)
    Apr 25 20:38:52.818: INFO: (12) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 34.044273ms)
    Apr 25 20:38:52.834: INFO: (13) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 15.587438ms)
    Apr 25 20:38:52.839: INFO: (13) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 17.968248ms)
    Apr 25 20:38:52.841: INFO: (13) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 20.486169ms)
    Apr 25 20:38:52.842: INFO: (13) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 22.392416ms)
    Apr 25 20:38:52.842: INFO: (13) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 22.738491ms)
    Apr 25 20:38:52.842: INFO: (13) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 21.736413ms)
    Apr 25 20:38:52.843: INFO: (13) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 23.107837ms)
    Apr 25 20:38:52.844: INFO: (13) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 24.40349ms)
    Apr 25 20:38:52.845: INFO: (13) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 25.627427ms)
    Apr 25 20:38:52.847: INFO: (13) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 28.423305ms)
    Apr 25 20:38:52.845: INFO: (13) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 25.272297ms)
    Apr 25 20:38:52.847: INFO: (13) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 26.761313ms)
    Apr 25 20:38:52.849: INFO: (13) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 29.942964ms)
    Apr 25 20:38:52.851: INFO: (13) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 31.358222ms)
    Apr 25 20:38:52.852: INFO: (13) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 32.578612ms)
    Apr 25 20:38:52.852: INFO: (13) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 32.17153ms)
    Apr 25 20:38:52.875: INFO: (14) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 21.633361ms)
    Apr 25 20:38:52.875: INFO: (14) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 21.465246ms)
    Apr 25 20:38:52.875: INFO: (14) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 21.863223ms)
    Apr 25 20:38:52.876: INFO: (14) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 22.575835ms)
    Apr 25 20:38:52.876: INFO: (14) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 22.408135ms)
    Apr 25 20:38:52.876: INFO: (14) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 23.429938ms)
    Apr 25 20:38:52.877: INFO: (14) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 24.156845ms)
    Apr 25 20:38:52.877: INFO: (14) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 24.660356ms)
    Apr 25 20:38:52.878: INFO: (14) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 24.24384ms)
    Apr 25 20:38:52.878: INFO: (14) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 24.684814ms)
    Apr 25 20:38:52.881: INFO: (14) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 28.229859ms)
    Apr 25 20:38:52.881: INFO: (14) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 27.79088ms)
    Apr 25 20:38:52.884: INFO: (14) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 31.125657ms)
    Apr 25 20:38:52.884: INFO: (14) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 30.955269ms)
    Apr 25 20:38:52.884: INFO: (14) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 31.142074ms)
    Apr 25 20:38:52.884: INFO: (14) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 30.905641ms)
    Apr 25 20:38:52.900: INFO: (15) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 15.746894ms)
    Apr 25 20:38:52.904: INFO: (15) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 18.149848ms)
    Apr 25 20:38:52.905: INFO: (15) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 19.289169ms)
    Apr 25 20:38:52.907: INFO: (15) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 21.00799ms)
    Apr 25 20:38:52.907: INFO: (15) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 21.116692ms)
    Apr 25 20:38:52.907: INFO: (15) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 22.053343ms)
    Apr 25 20:38:52.907: INFO: (15) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 23.040577ms)
    Apr 25 20:38:52.908: INFO: (15) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 23.500433ms)
    Apr 25 20:38:52.908: INFO: (15) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 23.599335ms)
    Apr 25 20:38:52.913: INFO: (15) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 26.611028ms)
    Apr 25 20:38:52.913: INFO: (15) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 27.598877ms)
    Apr 25 20:38:52.917: INFO: (15) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 31.244585ms)
    Apr 25 20:38:52.921: INFO: (15) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 35.535108ms)
    Apr 25 20:38:52.923: INFO: (15) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 37.408768ms)
    Apr 25 20:38:52.924: INFO: (15) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 37.782526ms)
    Apr 25 20:38:52.965: INFO: (15) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 80.428813ms)
    Apr 25 20:38:52.986: INFO: (16) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 19.763698ms)
    Apr 25 20:38:52.987: INFO: (16) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 20.555617ms)
    Apr 25 20:38:52.988: INFO: (16) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 20.960206ms)
    Apr 25 20:38:52.989: INFO: (16) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 22.503218ms)
    Apr 25 20:38:52.989: INFO: (16) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 22.683199ms)
    Apr 25 20:38:52.989: INFO: (16) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 22.909314ms)
    Apr 25 20:38:52.989: INFO: (16) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 22.407285ms)
    Apr 25 20:38:52.989: INFO: (16) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 23.791217ms)
    Apr 25 20:38:52.990: INFO: (16) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 23.14967ms)
    Apr 25 20:38:52.990: INFO: (16) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 23.396295ms)
    Apr 25 20:38:52.995: INFO: (16) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 27.888216ms)
    Apr 25 20:38:52.995: INFO: (16) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 28.141904ms)
    Apr 25 20:38:52.996: INFO: (16) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 29.942971ms)
    Apr 25 20:38:52.997: INFO: (16) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 31.347448ms)
    Apr 25 20:38:52.998: INFO: (16) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 31.564302ms)
    Apr 25 20:38:53.007: INFO: (16) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 40.737621ms)
    Apr 25 20:38:53.027: INFO: (17) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 18.744342ms)
    Apr 25 20:38:53.027: INFO: (17) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 18.634574ms)
    Apr 25 20:38:53.027: INFO: (17) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 18.95222ms)
    Apr 25 20:38:53.028: INFO: (17) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 19.216228ms)
    Apr 25 20:38:53.029: INFO: (17) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 20.200107ms)
    Apr 25 20:38:53.031: INFO: (17) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 22.464268ms)
    Apr 25 20:38:53.032: INFO: (17) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 23.515225ms)
    Apr 25 20:38:53.032: INFO: (17) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 24.269024ms)
    Apr 25 20:38:53.033: INFO: (17) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 24.795889ms)
    Apr 25 20:38:53.034: INFO: (17) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 25.424051ms)
    Apr 25 20:38:53.034: INFO: (17) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 25.519632ms)
    Apr 25 20:38:53.036: INFO: (17) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 27.285587ms)
    Apr 25 20:38:53.040: INFO: (17) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 30.810417ms)
    Apr 25 20:38:53.040: INFO: (17) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 31.354379ms)
    Apr 25 20:38:53.040: INFO: (17) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 31.949816ms)
    Apr 25 20:38:53.040: INFO: (17) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 32.042028ms)
    Apr 25 20:38:53.059: INFO: (18) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 17.966808ms)
    Apr 25 20:38:53.061: INFO: (18) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 19.78533ms)
    Apr 25 20:38:53.062: INFO: (18) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 20.96054ms)
    Apr 25 20:38:53.064: INFO: (18) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 21.396104ms)
    Apr 25 20:38:53.065: INFO: (18) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 22.580273ms)
    Apr 25 20:38:53.066: INFO: (18) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 23.439799ms)
    Apr 25 20:38:53.069: INFO: (18) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 28.291577ms)
    Apr 25 20:38:53.069: INFO: (18) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 27.549ms)
    Apr 25 20:38:53.073: INFO: (18) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 30.900602ms)
    Apr 25 20:38:53.078: INFO: (18) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 36.414691ms)
    Apr 25 20:38:53.080: INFO: (18) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 37.701183ms)
    Apr 25 20:38:53.080: INFO: (18) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 38.829552ms)
    Apr 25 20:38:53.086: INFO: (18) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 45.047816ms)
    Apr 25 20:38:53.087: INFO: (18) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 44.785104ms)
    Apr 25 20:38:53.087: INFO: (18) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 45.20082ms)
    Apr 25 20:38:53.087: INFO: (18) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 44.695646ms)
    Apr 25 20:38:53.103: INFO: (19) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 15.047002ms)
    Apr 25 20:38:53.112: INFO: (19) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 22.924741ms)
    Apr 25 20:38:53.112: INFO: (19) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:160/proxy/: foo (200; 23.659934ms)
    Apr 25 20:38:53.113: INFO: (19) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">test<... (200; 24.174108ms)
    Apr 25 20:38:53.113: INFO: (19) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:1080/proxy/rewriteme">... (200; 24.220273ms)
    Apr 25 20:38:53.114: INFO: (19) /api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/proxy-service-nhc2l-zqkpg/proxy/rewriteme">test</a> (200; 24.432104ms)
    Apr 25 20:38:53.116: INFO: (19) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/: <a href="/api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:443/proxy/tlsrewritem... (200; 27.210907ms)
    Apr 25 20:38:53.117: INFO: (19) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:460/proxy/: tls baz (200; 27.691354ms)
    Apr 25 20:38:53.117: INFO: (19) /api/v1/namespaces/proxy-1290/pods/http:proxy-service-nhc2l-zqkpg:162/proxy/: bar (200; 27.762145ms)
    Apr 25 20:38:53.118: INFO: (19) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname1/proxy/: tls baz (200; 29.056629ms)
    Apr 25 20:38:53.118: INFO: (19) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname1/proxy/: foo (200; 29.671875ms)
    Apr 25 20:38:53.119: INFO: (19) /api/v1/namespaces/proxy-1290/services/http:proxy-service-nhc2l:portname2/proxy/: bar (200; 30.563184ms)
    Apr 25 20:38:53.119: INFO: (19) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname1/proxy/: foo (200; 30.360624ms)
    Apr 25 20:38:53.123: INFO: (19) /api/v1/namespaces/proxy-1290/services/proxy-service-nhc2l:portname2/proxy/: bar (200; 34.826066ms)
    Apr 25 20:38:53.124: INFO: (19) /api/v1/namespaces/proxy-1290/pods/https:proxy-service-nhc2l-zqkpg:462/proxy/: tls qux (200; 34.819367ms)
    Apr 25 20:38:53.125: INFO: (19) /api/v1/namespaces/proxy-1290/services/https:proxy-service-nhc2l:tlsportname2/proxy/: tls qux (200; 35.756163ms)
    STEP: deleting ReplicationController proxy-service-nhc2l in namespace proxy-1290, will wait for the garbage collector to delete the pods 04/25/23 20:38:53.125
    Apr 25 20:38:53.237: INFO: Deleting ReplicationController proxy-service-nhc2l took: 51.665273ms
    Apr 25 20:38:53.338: INFO: Terminating ReplicationController proxy-service-nhc2l pods took: 100.713674ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Apr 25 20:38:55.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-1290" for this suite. 04/25/23 20:38:55.96
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:38:55.985
Apr 25 20:38:55.986: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename security-context-test 04/25/23 20:38:55.989
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:56.058
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:56.067
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Apr 25 20:38:56.098: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-88fedcb7-dfa4-4919-99d6-ed7d365dcb70" in namespace "security-context-test-1734" to be "Succeeded or Failed"
Apr 25 20:38:56.107: INFO: Pod "busybox-readonly-false-88fedcb7-dfa4-4919-99d6-ed7d365dcb70": Phase="Pending", Reason="", readiness=false. Elapsed: 8.770247ms
Apr 25 20:38:58.118: INFO: Pod "busybox-readonly-false-88fedcb7-dfa4-4919-99d6-ed7d365dcb70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019841666s
Apr 25 20:39:00.119: INFO: Pod "busybox-readonly-false-88fedcb7-dfa4-4919-99d6-ed7d365dcb70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020714359s
Apr 25 20:39:00.119: INFO: Pod "busybox-readonly-false-88fedcb7-dfa4-4919-99d6-ed7d365dcb70" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 25 20:39:00.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1734" for this suite. 04/25/23 20:39:00.136
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":233,"skipped":4236,"failed":0}
------------------------------
• [4.169 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:38:55.985
    Apr 25 20:38:55.986: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename security-context-test 04/25/23 20:38:55.989
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:38:56.058
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:38:56.067
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Apr 25 20:38:56.098: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-88fedcb7-dfa4-4919-99d6-ed7d365dcb70" in namespace "security-context-test-1734" to be "Succeeded or Failed"
    Apr 25 20:38:56.107: INFO: Pod "busybox-readonly-false-88fedcb7-dfa4-4919-99d6-ed7d365dcb70": Phase="Pending", Reason="", readiness=false. Elapsed: 8.770247ms
    Apr 25 20:38:58.118: INFO: Pod "busybox-readonly-false-88fedcb7-dfa4-4919-99d6-ed7d365dcb70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019841666s
    Apr 25 20:39:00.119: INFO: Pod "busybox-readonly-false-88fedcb7-dfa4-4919-99d6-ed7d365dcb70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020714359s
    Apr 25 20:39:00.119: INFO: Pod "busybox-readonly-false-88fedcb7-dfa4-4919-99d6-ed7d365dcb70" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 25 20:39:00.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-1734" for this suite. 04/25/23 20:39:00.136
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:39:00.168
Apr 25 20:39:00.169: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:39:00.172
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:00.221
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:00.241
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-f66c2ce5-ddcd-4e17-b756-d332e3ebf695 04/25/23 20:39:00.249
STEP: Creating a pod to test consume configMaps 04/25/23 20:39:00.263
Apr 25 20:39:00.299: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7" in namespace "projected-6599" to be "Succeeded or Failed"
Apr 25 20:39:00.309: INFO: Pod "pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.076016ms
Apr 25 20:39:02.320: INFO: Pod "pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021640347s
Apr 25 20:39:04.321: INFO: Pod "pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02207899s
STEP: Saw pod success 04/25/23 20:39:04.321
Apr 25 20:39:04.322: INFO: Pod "pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7" satisfied condition "Succeeded or Failed"
Apr 25 20:39:04.332: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7 container agnhost-container: <nil>
STEP: delete the pod 04/25/23 20:39:04.41
Apr 25 20:39:04.437: INFO: Waiting for pod pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7 to disappear
Apr 25 20:39:04.450: INFO: Pod pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 25 20:39:04.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6599" for this suite. 04/25/23 20:39:04.466
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":234,"skipped":4311,"failed":0}
------------------------------
• [4.317 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:39:00.168
    Apr 25 20:39:00.169: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:39:00.172
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:00.221
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:00.241
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-f66c2ce5-ddcd-4e17-b756-d332e3ebf695 04/25/23 20:39:00.249
    STEP: Creating a pod to test consume configMaps 04/25/23 20:39:00.263
    Apr 25 20:39:00.299: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7" in namespace "projected-6599" to be "Succeeded or Failed"
    Apr 25 20:39:00.309: INFO: Pod "pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.076016ms
    Apr 25 20:39:02.320: INFO: Pod "pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021640347s
    Apr 25 20:39:04.321: INFO: Pod "pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02207899s
    STEP: Saw pod success 04/25/23 20:39:04.321
    Apr 25 20:39:04.322: INFO: Pod "pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7" satisfied condition "Succeeded or Failed"
    Apr 25 20:39:04.332: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7 container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 20:39:04.41
    Apr 25 20:39:04.437: INFO: Waiting for pod pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7 to disappear
    Apr 25 20:39:04.450: INFO: Pod pod-projected-configmaps-cd7b516b-04f0-4157-9bb0-530adb63a7c7 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 25 20:39:04.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6599" for this suite. 04/25/23 20:39:04.466
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:39:04.487
Apr 25 20:39:04.487: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:39:04.489
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:04.54
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:04.549
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-9332174c-61f0-4f3a-ae03-89b327b4455b 04/25/23 20:39:04.558
STEP: Creating a pod to test consume secrets 04/25/23 20:39:04.571
Apr 25 20:39:04.599: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016" in namespace "projected-4300" to be "Succeeded or Failed"
Apr 25 20:39:04.611: INFO: Pod "pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016": Phase="Pending", Reason="", readiness=false. Elapsed: 11.939483ms
Apr 25 20:39:06.624: INFO: Pod "pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025040444s
Apr 25 20:39:08.640: INFO: Pod "pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040425523s
STEP: Saw pod success 04/25/23 20:39:08.64
Apr 25 20:39:08.641: INFO: Pod "pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016" satisfied condition "Succeeded or Failed"
Apr 25 20:39:08.651: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016 container secret-volume-test: <nil>
STEP: delete the pod 04/25/23 20:39:08.683
Apr 25 20:39:08.739: INFO: Waiting for pod pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016 to disappear
Apr 25 20:39:08.749: INFO: Pod pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 25 20:39:08.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4300" for this suite. 04/25/23 20:39:08.785
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":235,"skipped":4332,"failed":0}
------------------------------
• [4.321 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:39:04.487
    Apr 25 20:39:04.487: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:39:04.489
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:04.54
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:04.549
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-9332174c-61f0-4f3a-ae03-89b327b4455b 04/25/23 20:39:04.558
    STEP: Creating a pod to test consume secrets 04/25/23 20:39:04.571
    Apr 25 20:39:04.599: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016" in namespace "projected-4300" to be "Succeeded or Failed"
    Apr 25 20:39:04.611: INFO: Pod "pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016": Phase="Pending", Reason="", readiness=false. Elapsed: 11.939483ms
    Apr 25 20:39:06.624: INFO: Pod "pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025040444s
    Apr 25 20:39:08.640: INFO: Pod "pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040425523s
    STEP: Saw pod success 04/25/23 20:39:08.64
    Apr 25 20:39:08.641: INFO: Pod "pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016" satisfied condition "Succeeded or Failed"
    Apr 25 20:39:08.651: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016 container secret-volume-test: <nil>
    STEP: delete the pod 04/25/23 20:39:08.683
    Apr 25 20:39:08.739: INFO: Waiting for pod pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016 to disappear
    Apr 25 20:39:08.749: INFO: Pod pod-projected-secrets-71e1858d-c472-4422-bd28-3855a8c9f016 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 25 20:39:08.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4300" for this suite. 04/25/23 20:39:08.785
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:39:08.813
Apr 25 20:39:08.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:39:08.815
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:08.855
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:08.865
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-456aed29-97a3-4d84-a7f7-d49789f8fc7d 04/25/23 20:39:08.875
STEP: Creating secret with name secret-projected-all-test-volume-8c1a1fd3-b47d-4bf3-b5c9-bace945ed210 04/25/23 20:39:08.893
STEP: Creating a pod to test Check all projections for projected volume plugin 04/25/23 20:39:08.92
Apr 25 20:39:08.942: INFO: Waiting up to 5m0s for pod "projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1" in namespace "projected-3228" to be "Succeeded or Failed"
Apr 25 20:39:08.959: INFO: Pod "projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.219032ms
Apr 25 20:39:10.970: INFO: Pod "projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028176178s
Apr 25 20:39:12.972: INFO: Pod "projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030028338s
STEP: Saw pod success 04/25/23 20:39:12.972
Apr 25 20:39:12.973: INFO: Pod "projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1" satisfied condition "Succeeded or Failed"
Apr 25 20:39:12.983: INFO: Trying to get logs from node 10.10.21.190 pod projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1 container projected-all-volume-test: <nil>
STEP: delete the pod 04/25/23 20:39:13.018
Apr 25 20:39:13.045: INFO: Waiting for pod projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1 to disappear
Apr 25 20:39:13.056: INFO: Pod projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Apr 25 20:39:13.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3228" for this suite. 04/25/23 20:39:13.074
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":236,"skipped":4347,"failed":0}
------------------------------
• [4.279 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:39:08.813
    Apr 25 20:39:08.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:39:08.815
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:08.855
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:08.865
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-456aed29-97a3-4d84-a7f7-d49789f8fc7d 04/25/23 20:39:08.875
    STEP: Creating secret with name secret-projected-all-test-volume-8c1a1fd3-b47d-4bf3-b5c9-bace945ed210 04/25/23 20:39:08.893
    STEP: Creating a pod to test Check all projections for projected volume plugin 04/25/23 20:39:08.92
    Apr 25 20:39:08.942: INFO: Waiting up to 5m0s for pod "projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1" in namespace "projected-3228" to be "Succeeded or Failed"
    Apr 25 20:39:08.959: INFO: Pod "projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.219032ms
    Apr 25 20:39:10.970: INFO: Pod "projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028176178s
    Apr 25 20:39:12.972: INFO: Pod "projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030028338s
    STEP: Saw pod success 04/25/23 20:39:12.972
    Apr 25 20:39:12.973: INFO: Pod "projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1" satisfied condition "Succeeded or Failed"
    Apr 25 20:39:12.983: INFO: Trying to get logs from node 10.10.21.190 pod projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1 container projected-all-volume-test: <nil>
    STEP: delete the pod 04/25/23 20:39:13.018
    Apr 25 20:39:13.045: INFO: Waiting for pod projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1 to disappear
    Apr 25 20:39:13.056: INFO: Pod projected-volume-1500abd9-1021-48cc-803a-0fa6c1ccb7c1 no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Apr 25 20:39:13.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3228" for this suite. 04/25/23 20:39:13.074
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:39:13.094
Apr 25 20:39:13.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 20:39:13.098
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:13.159
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:13.167
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Apr 25 20:39:13.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5613 create -f -'
Apr 25 20:39:13.510: INFO: stderr: ""
Apr 25 20:39:13.510: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Apr 25 20:39:13.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5613 create -f -'
Apr 25 20:39:13.872: INFO: stderr: ""
Apr 25 20:39:13.872: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/25/23 20:39:13.872
Apr 25 20:39:14.882: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 25 20:39:14.882: INFO: Found 0 / 1
Apr 25 20:39:15.883: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 25 20:39:15.884: INFO: Found 1 / 1
Apr 25 20:39:15.884: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 25 20:39:15.894: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 25 20:39:15.894: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 25 20:39:15.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5613 describe pod agnhost-primary-c97n5'
Apr 25 20:39:16.059: INFO: stderr: ""
Apr 25 20:39:16.059: INFO: stdout: "Name:             agnhost-primary-c97n5\nNamespace:        kubectl-5613\nPriority:         0\nService Account:  default\nNode:             10.10.21.190/10.10.21.190\nStart Time:       Tue, 25 Apr 2023 20:39:13 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 591e17bcfc14af7afddfd71768d8c59df44903b2094c6cc4170539e1759e2ca3\n                  cni.projectcalico.org/podIP: 172.30.142.164/32\n                  cni.projectcalico.org/podIPs: 172.30.142.164/32\nStatus:           Running\nIP:               172.30.142.164\nIPs:\n  IP:           172.30.142.164\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://69ff41954375d3918bd7e61e8a3f15e3e402d26d1b4906fb79be6a5c03caae28\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 25 Apr 2023 20:39:14 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-xqt8x (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-xqt8x:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 600s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 600s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-5613/agnhost-primary-c97n5 to 10.10.21.190\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
Apr 25 20:39:16.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5613 describe rc agnhost-primary'
Apr 25 20:39:16.207: INFO: stderr: ""
Apr 25 20:39:16.207: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5613\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-c97n5\n"
Apr 25 20:39:16.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5613 describe service agnhost-primary'
Apr 25 20:39:16.367: INFO: stderr: ""
Apr 25 20:39:16.367: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5613\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                172.21.239.11\nIPs:               172.21.239.11\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.30.142.164:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 25 20:39:16.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5613 describe node 10.10.21.136'
Apr 25 20:39:16.621: INFO: stderr: ""
Apr 25 20:39:16.621: INFO: stdout: "Name:               10.10.21.136\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=jp-osa\n                    failure-domain.beta.kubernetes.io/zone=osa23\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=163.73.70.156\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.10.21.136\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_20_64\n                    ibm-cloud.kubernetes.io/region=jp-osa\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-ch40dmlo0r3ao1g695p0-kubee2epvgt-default-0000033e\n                    ibm-cloud.kubernetes.io/worker-pool-id=ch40dmlo0r3ao1g695p0-137dee0\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.25.9_1543\n                    ibm-cloud.kubernetes.io/zone=osa23\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.10.21.136\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    privateVLAN=2981446\n                    publicVLAN=2981452\n                    topology.kubernetes.io/region=jp-osa\n                    topology.kubernetes.io/zone=osa23\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.10.21.136/26\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.30.191.0\nCreationTimestamp:  Tue, 25 Apr 2023 17:13:58 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  10.10.21.136\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 25 Apr 2023 20:39:08 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 25 Apr 2023 17:14:48 +0000   Tue, 25 Apr 2023 17:14:48 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 25 Apr 2023 20:35:50 +0000   Tue, 25 Apr 2023 17:13:58 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 25 Apr 2023 20:35:50 +0000   Tue, 25 Apr 2023 17:13:58 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 25 Apr 2023 20:35:50 +0000   Tue, 25 Apr 2023 17:13:58 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 25 Apr 2023 20:35:50 +0000   Tue, 25 Apr 2023 17:14:29 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.10.21.136\n  ExternalIP:  163.73.70.156\n  Hostname:    10.10.21.136\nCapacity:\n  cpu:                4\n  ephemeral-storage:  102609848Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16177420Ki\n  pods:               110\nAllocatable:\n  cpu:                3910m\n  ephemeral-storage:  93913280025\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             13409548Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 4b680e8051dc417b9c5a8cbd4cb1cab8\n  System UUID:                54057120-a689-255b-cf5f-087e3794877a\n  Boot ID:                    273a1df2-bb5e-4cd9-8e03-c7c1b3db2faa\n  Kernel Version:             5.4.0-139-generic\n  OS Image:                   Ubuntu 20.04.6 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.20\n  Kubelet Version:            v1.25.9+IKS\n  Kube-Proxy Version:         v1.25.9+IKS\nProviderID:                   ibm://fee034388aa6435883a1f720010ab3a2///ch40dmlo0r3ao1g695p0/kube-ch40dmlo0r3ao1g695p0-kubee2epvgt-default-0000033e\nNon-terminated Pods:          (14 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  ibm-system                  ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-nzg9s       5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         62m\n  kube-system                 calico-node-q95vg                                          250m (6%)     0 (0%)      90Mi (0%)        0 (0%)         3h25m\n  kube-system                 calico-typha-677688fdc5-5f8fr                              250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         3h31m\n  kube-system                 coredns-6754846f95-cn7xr                                   100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     62m\n  kube-system                 coredns-6754846f95-dnk45                                   100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     3h11m\n  kube-system                 ibm-keepalived-watcher-p87jk                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         3h25m\n  kube-system                 ibm-master-proxy-static-10.10.21.136                       25m (0%)      300m (7%)   32M (0%)         512M (3%)      3h25m\n  kube-system                 ibmcloud-block-storage-driver-fm7g7                        50m (1%)      500m (12%)  100Mi (0%)       300Mi (2%)     3h25m\n  kube-system                 konnectivity-agent-mv6tj                                   10m (0%)      0 (0%)      10Mi (0%)        500Mi (3%)     3h12m\n  kube-system                 metrics-server-c785bfcff-b2n5l                             126m (3%)     266m (6%)   191Mi (1%)       536Mi (4%)     153m\n  kube-system                 public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-p575r        20m (0%)      0 (0%)      115Mi (0%)       0 (0%)         62m\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         64m\n  sonobuoy                    sonobuoy-e2e-job-38c24e91f58b4d35                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         64m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-88nhh    0 (0%)        0 (0%)      0 (0%)           0 (0%)         64m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                941m (24%)     1066m (27%)\n  memory             795154Ki (5%)  2687264Ki (20%)\n  ephemeral-storage  0 (0%)         0 (0%)\n  hugepages-1Gi      0 (0%)         0 (0%)\n  hugepages-2Mi      0 (0%)         0 (0%)\nEvents:              <none>\n"
Apr 25 20:39:16.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5613 describe namespace kubectl-5613'
Apr 25 20:39:16.781: INFO: stderr: ""
Apr 25 20:39:16.781: INFO: stdout: "Name:         kubectl-5613\nLabels:       e2e-framework=kubectl\n              e2e-run=efc57b0c-51af-4be6-a02d-33534060be11\n              kubernetes.io/metadata.name=kubectl-5613\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 20:39:16.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5613" for this suite. 04/25/23 20:39:16.799
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":237,"skipped":4347,"failed":0}
------------------------------
• [3.723 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:39:13.094
    Apr 25 20:39:13.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 20:39:13.098
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:13.159
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:13.167
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Apr 25 20:39:13.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5613 create -f -'
    Apr 25 20:39:13.510: INFO: stderr: ""
    Apr 25 20:39:13.510: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Apr 25 20:39:13.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5613 create -f -'
    Apr 25 20:39:13.872: INFO: stderr: ""
    Apr 25 20:39:13.872: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/25/23 20:39:13.872
    Apr 25 20:39:14.882: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 25 20:39:14.882: INFO: Found 0 / 1
    Apr 25 20:39:15.883: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 25 20:39:15.884: INFO: Found 1 / 1
    Apr 25 20:39:15.884: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Apr 25 20:39:15.894: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 25 20:39:15.894: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 25 20:39:15.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5613 describe pod agnhost-primary-c97n5'
    Apr 25 20:39:16.059: INFO: stderr: ""
    Apr 25 20:39:16.059: INFO: stdout: "Name:             agnhost-primary-c97n5\nNamespace:        kubectl-5613\nPriority:         0\nService Account:  default\nNode:             10.10.21.190/10.10.21.190\nStart Time:       Tue, 25 Apr 2023 20:39:13 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 591e17bcfc14af7afddfd71768d8c59df44903b2094c6cc4170539e1759e2ca3\n                  cni.projectcalico.org/podIP: 172.30.142.164/32\n                  cni.projectcalico.org/podIPs: 172.30.142.164/32\nStatus:           Running\nIP:               172.30.142.164\nIPs:\n  IP:           172.30.142.164\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://69ff41954375d3918bd7e61e8a3f15e3e402d26d1b4906fb79be6a5c03caae28\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 25 Apr 2023 20:39:14 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-xqt8x (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-xqt8x:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 600s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 600s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-5613/agnhost-primary-c97n5 to 10.10.21.190\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
    Apr 25 20:39:16.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5613 describe rc agnhost-primary'
    Apr 25 20:39:16.207: INFO: stderr: ""
    Apr 25 20:39:16.207: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5613\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-c97n5\n"
    Apr 25 20:39:16.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5613 describe service agnhost-primary'
    Apr 25 20:39:16.367: INFO: stderr: ""
    Apr 25 20:39:16.367: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5613\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                172.21.239.11\nIPs:               172.21.239.11\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.30.142.164:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Apr 25 20:39:16.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5613 describe node 10.10.21.136'
    Apr 25 20:39:16.621: INFO: stderr: ""
    Apr 25 20:39:16.621: INFO: stdout: "Name:               10.10.21.136\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=jp-osa\n                    failure-domain.beta.kubernetes.io/zone=osa23\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=163.73.70.156\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.10.21.136\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_20_64\n                    ibm-cloud.kubernetes.io/region=jp-osa\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-ch40dmlo0r3ao1g695p0-kubee2epvgt-default-0000033e\n                    ibm-cloud.kubernetes.io/worker-pool-id=ch40dmlo0r3ao1g695p0-137dee0\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.25.9_1543\n                    ibm-cloud.kubernetes.io/zone=osa23\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.10.21.136\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    privateVLAN=2981446\n                    publicVLAN=2981452\n                    topology.kubernetes.io/region=jp-osa\n                    topology.kubernetes.io/zone=osa23\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.10.21.136/26\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.30.191.0\nCreationTimestamp:  Tue, 25 Apr 2023 17:13:58 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  10.10.21.136\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 25 Apr 2023 20:39:08 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 25 Apr 2023 17:14:48 +0000   Tue, 25 Apr 2023 17:14:48 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 25 Apr 2023 20:35:50 +0000   Tue, 25 Apr 2023 17:13:58 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 25 Apr 2023 20:35:50 +0000   Tue, 25 Apr 2023 17:13:58 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 25 Apr 2023 20:35:50 +0000   Tue, 25 Apr 2023 17:13:58 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 25 Apr 2023 20:35:50 +0000   Tue, 25 Apr 2023 17:14:29 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.10.21.136\n  ExternalIP:  163.73.70.156\n  Hostname:    10.10.21.136\nCapacity:\n  cpu:                4\n  ephemeral-storage:  102609848Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16177420Ki\n  pods:               110\nAllocatable:\n  cpu:                3910m\n  ephemeral-storage:  93913280025\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             13409548Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 4b680e8051dc417b9c5a8cbd4cb1cab8\n  System UUID:                54057120-a689-255b-cf5f-087e3794877a\n  Boot ID:                    273a1df2-bb5e-4cd9-8e03-c7c1b3db2faa\n  Kernel Version:             5.4.0-139-generic\n  OS Image:                   Ubuntu 20.04.6 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.20\n  Kubelet Version:            v1.25.9+IKS\n  Kube-Proxy Version:         v1.25.9+IKS\nProviderID:                   ibm://fee034388aa6435883a1f720010ab3a2///ch40dmlo0r3ao1g695p0/kube-ch40dmlo0r3ao1g695p0-kubee2epvgt-default-0000033e\nNon-terminated Pods:          (14 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  ibm-system                  ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-nzg9s       5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         62m\n  kube-system                 calico-node-q95vg                                          250m (6%)     0 (0%)      90Mi (0%)        0 (0%)         3h25m\n  kube-system                 calico-typha-677688fdc5-5f8fr                              250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         3h31m\n  kube-system                 coredns-6754846f95-cn7xr                                   100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     62m\n  kube-system                 coredns-6754846f95-dnk45                                   100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     3h11m\n  kube-system                 ibm-keepalived-watcher-p87jk                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         3h25m\n  kube-system                 ibm-master-proxy-static-10.10.21.136                       25m (0%)      300m (7%)   32M (0%)         512M (3%)      3h25m\n  kube-system                 ibmcloud-block-storage-driver-fm7g7                        50m (1%)      500m (12%)  100Mi (0%)       300Mi (2%)     3h25m\n  kube-system                 konnectivity-agent-mv6tj                                   10m (0%)      0 (0%)      10Mi (0%)        500Mi (3%)     3h12m\n  kube-system                 metrics-server-c785bfcff-b2n5l                             126m (3%)     266m (6%)   191Mi (1%)       536Mi (4%)     153m\n  kube-system                 public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-p575r        20m (0%)      0 (0%)      115Mi (0%)       0 (0%)         62m\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         64m\n  sonobuoy                    sonobuoy-e2e-job-38c24e91f58b4d35                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         64m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-88nhh    0 (0%)        0 (0%)      0 (0%)           0 (0%)         64m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                941m (24%)     1066m (27%)\n  memory             795154Ki (5%)  2687264Ki (20%)\n  ephemeral-storage  0 (0%)         0 (0%)\n  hugepages-1Gi      0 (0%)         0 (0%)\n  hugepages-2Mi      0 (0%)         0 (0%)\nEvents:              <none>\n"
    Apr 25 20:39:16.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5613 describe namespace kubectl-5613'
    Apr 25 20:39:16.781: INFO: stderr: ""
    Apr 25 20:39:16.781: INFO: stdout: "Name:         kubectl-5613\nLabels:       e2e-framework=kubectl\n              e2e-run=efc57b0c-51af-4be6-a02d-33534060be11\n              kubernetes.io/metadata.name=kubectl-5613\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 20:39:16.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5613" for this suite. 04/25/23 20:39:16.799
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:39:16.823
Apr 25 20:39:16.824: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename replicaset 04/25/23 20:39:16.827
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:16.869
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:16.879
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Apr 25 20:39:16.929: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 25 20:39:21.941: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/25/23 20:39:21.941
STEP: Scaling up "test-rs" replicaset  04/25/23 20:39:21.942
Apr 25 20:39:21.969: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 04/25/23 20:39:21.969
W0425 20:39:21.986087      23 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 25 20:39:21.990: INFO: observed ReplicaSet test-rs in namespace replicaset-2375 with ReadyReplicas 1, AvailableReplicas 1
Apr 25 20:39:22.032: INFO: observed ReplicaSet test-rs in namespace replicaset-2375 with ReadyReplicas 1, AvailableReplicas 1
Apr 25 20:39:22.079: INFO: observed ReplicaSet test-rs in namespace replicaset-2375 with ReadyReplicas 1, AvailableReplicas 1
Apr 25 20:39:22.113: INFO: observed ReplicaSet test-rs in namespace replicaset-2375 with ReadyReplicas 1, AvailableReplicas 1
Apr 25 20:39:23.438: INFO: observed ReplicaSet test-rs in namespace replicaset-2375 with ReadyReplicas 2, AvailableReplicas 2
Apr 25 20:39:23.946: INFO: observed Replicaset test-rs in namespace replicaset-2375 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 25 20:39:23.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2375" for this suite. 04/25/23 20:39:23.963
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":238,"skipped":4374,"failed":0}
------------------------------
• [SLOW TEST] [7.159 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:39:16.823
    Apr 25 20:39:16.824: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename replicaset 04/25/23 20:39:16.827
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:16.869
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:16.879
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Apr 25 20:39:16.929: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 25 20:39:21.941: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/25/23 20:39:21.941
    STEP: Scaling up "test-rs" replicaset  04/25/23 20:39:21.942
    Apr 25 20:39:21.969: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 04/25/23 20:39:21.969
    W0425 20:39:21.986087      23 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 25 20:39:21.990: INFO: observed ReplicaSet test-rs in namespace replicaset-2375 with ReadyReplicas 1, AvailableReplicas 1
    Apr 25 20:39:22.032: INFO: observed ReplicaSet test-rs in namespace replicaset-2375 with ReadyReplicas 1, AvailableReplicas 1
    Apr 25 20:39:22.079: INFO: observed ReplicaSet test-rs in namespace replicaset-2375 with ReadyReplicas 1, AvailableReplicas 1
    Apr 25 20:39:22.113: INFO: observed ReplicaSet test-rs in namespace replicaset-2375 with ReadyReplicas 1, AvailableReplicas 1
    Apr 25 20:39:23.438: INFO: observed ReplicaSet test-rs in namespace replicaset-2375 with ReadyReplicas 2, AvailableReplicas 2
    Apr 25 20:39:23.946: INFO: observed Replicaset test-rs in namespace replicaset-2375 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 25 20:39:23.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-2375" for this suite. 04/25/23 20:39:23.963
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:39:23.993
Apr 25 20:39:23.994: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-probe 04/25/23 20:39:23.995
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:24.036
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:24.044
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Apr 25 20:39:24.071: INFO: Waiting up to 5m0s for pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced" in namespace "container-probe-7456" to be "running and ready"
Apr 25 20:39:24.082: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Pending", Reason="", readiness=false. Elapsed: 10.852343ms
Apr 25 20:39:24.082: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:39:26.092: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 2.021453198s
Apr 25 20:39:26.092: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
Apr 25 20:39:28.094: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 4.022921643s
Apr 25 20:39:28.094: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
Apr 25 20:39:30.092: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 6.020806618s
Apr 25 20:39:30.092: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
Apr 25 20:39:32.093: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 8.022673057s
Apr 25 20:39:32.094: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
Apr 25 20:39:34.094: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 10.022745937s
Apr 25 20:39:34.094: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
Apr 25 20:39:36.094: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 12.023094749s
Apr 25 20:39:36.094: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
Apr 25 20:39:38.094: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 14.022820674s
Apr 25 20:39:38.094: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
Apr 25 20:39:40.094: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 16.023333186s
Apr 25 20:39:40.094: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
Apr 25 20:39:42.093: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 18.022582849s
Apr 25 20:39:42.093: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
Apr 25 20:39:44.115: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 20.044649436s
Apr 25 20:39:44.116: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
Apr 25 20:39:46.100: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=true. Elapsed: 22.029683877s
Apr 25 20:39:46.101: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = true)
Apr 25 20:39:46.101: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced" satisfied condition "running and ready"
Apr 25 20:39:46.111: INFO: Container started at 2023-04-25 20:39:25 +0000 UTC, pod became ready at 2023-04-25 20:39:44 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 25 20:39:46.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7456" for this suite. 04/25/23 20:39:46.13
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":239,"skipped":4407,"failed":0}
------------------------------
• [SLOW TEST] [22.153 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:39:23.993
    Apr 25 20:39:23.994: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-probe 04/25/23 20:39:23.995
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:24.036
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:24.044
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Apr 25 20:39:24.071: INFO: Waiting up to 5m0s for pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced" in namespace "container-probe-7456" to be "running and ready"
    Apr 25 20:39:24.082: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Pending", Reason="", readiness=false. Elapsed: 10.852343ms
    Apr 25 20:39:24.082: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:39:26.092: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 2.021453198s
    Apr 25 20:39:26.092: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
    Apr 25 20:39:28.094: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 4.022921643s
    Apr 25 20:39:28.094: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
    Apr 25 20:39:30.092: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 6.020806618s
    Apr 25 20:39:30.092: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
    Apr 25 20:39:32.093: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 8.022673057s
    Apr 25 20:39:32.094: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
    Apr 25 20:39:34.094: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 10.022745937s
    Apr 25 20:39:34.094: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
    Apr 25 20:39:36.094: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 12.023094749s
    Apr 25 20:39:36.094: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
    Apr 25 20:39:38.094: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 14.022820674s
    Apr 25 20:39:38.094: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
    Apr 25 20:39:40.094: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 16.023333186s
    Apr 25 20:39:40.094: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
    Apr 25 20:39:42.093: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 18.022582849s
    Apr 25 20:39:42.093: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
    Apr 25 20:39:44.115: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=false. Elapsed: 20.044649436s
    Apr 25 20:39:44.116: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = false)
    Apr 25 20:39:46.100: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced": Phase="Running", Reason="", readiness=true. Elapsed: 22.029683877s
    Apr 25 20:39:46.101: INFO: The phase of Pod test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced is Running (Ready = true)
    Apr 25 20:39:46.101: INFO: Pod "test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced" satisfied condition "running and ready"
    Apr 25 20:39:46.111: INFO: Container started at 2023-04-25 20:39:25 +0000 UTC, pod became ready at 2023-04-25 20:39:44 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 25 20:39:46.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7456" for this suite. 04/25/23 20:39:46.13
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:39:46.158
Apr 25 20:39:46.158: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename sched-pred 04/25/23 20:39:46.159
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:46.231
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:46.24
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 25 20:39:46.247: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 25 20:39:46.277: INFO: Waiting for terminating namespaces to be deleted...
Apr 25 20:39:46.287: INFO: 
Logging pods the apiserver thinks is on node 10.10.21.136 before test
Apr 25 20:39:46.314: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-nzg9s from ibm-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.314: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
Apr 25 20:39:46.315: INFO: calico-node-q95vg from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.315: INFO: 	Container calico-node ready: true, restart count 0
Apr 25 20:39:46.315: INFO: calico-typha-677688fdc5-5f8fr from kube-system started at 2023-04-25 17:14:29 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.315: INFO: 	Container calico-typha ready: true, restart count 0
Apr 25 20:39:46.315: INFO: coredns-6754846f95-cn7xr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.315: INFO: 	Container coredns ready: true, restart count 0
Apr 25 20:39:46.316: INFO: coredns-6754846f95-dnk45 from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.316: INFO: 	Container coredns ready: true, restart count 0
Apr 25 20:39:46.316: INFO: ibm-keepalived-watcher-p87jk from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.316: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 25 20:39:46.316: INFO: ibm-master-proxy-static-10.10.21.136 from kube-system started at 2023-04-25 17:13:57 +0000 UTC (2 container statuses recorded)
Apr 25 20:39:46.317: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 25 20:39:46.317: INFO: 	Container pause ready: true, restart count 0
Apr 25 20:39:46.317: INFO: ibmcloud-block-storage-driver-fm7g7 from kube-system started at 2023-04-25 17:14:07 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.317: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Apr 25 20:39:46.317: INFO: konnectivity-agent-mv6tj from kube-system started at 2023-04-25 17:26:45 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.317: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 25 20:39:46.318: INFO: metrics-server-c785bfcff-b2n5l from kube-system started at 2023-04-25 18:05:55 +0000 UTC (3 container statuses recorded)
Apr 25 20:39:46.318: INFO: 	Container config-watcher ready: true, restart count 0
Apr 25 20:39:46.318: INFO: 	Container metrics-server ready: true, restart count 0
Apr 25 20:39:46.318: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr 25 20:39:46.318: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-p575r from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.318: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 25 20:39:46.318: INFO: sonobuoy from sonobuoy started at 2023-04-25 19:35:04 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.318: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 25 20:39:46.318: INFO: sonobuoy-e2e-job-38c24e91f58b4d35 from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 20:39:46.318: INFO: 	Container e2e ready: true, restart count 0
Apr 25 20:39:46.319: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 20:39:46.319: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-88nhh from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 20:39:46.319: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 20:39:46.319: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 25 20:39:46.319: INFO: 
Logging pods the apiserver thinks is on node 10.10.21.161 before test
Apr 25 20:39:46.372: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-g4ql4 from ibm-system started at 2023-04-25 17:18:17 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
Apr 25 20:39:46.372: INFO: calico-kube-controllers-5754dfd4dd-jfqrl from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 25 20:39:46.372: INFO: calico-node-mqpqg from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container calico-node ready: true, restart count 0
Apr 25 20:39:46.372: INFO: calico-typha-677688fdc5-bt4pk from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container calico-typha ready: true, restart count 0
Apr 25 20:39:46.372: INFO: coredns-6754846f95-8fzmk from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container coredns ready: true, restart count 0
Apr 25 20:39:46.372: INFO: coredns-autoscaler-669cf746f6-hnjbg from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container autoscaler ready: true, restart count 0
Apr 25 20:39:46.372: INFO: dashboard-metrics-scraper-c964d5594-wvstn from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 25 20:39:46.372: INFO: ibm-file-plugin-84d44c69b5-kz8hc from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Apr 25 20:39:46.372: INFO: ibm-keepalived-watcher-9dj6q from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 25 20:39:46.372: INFO: ibm-master-proxy-static-10.10.21.161 from kube-system started at 2023-04-25 17:13:31 +0000 UTC (2 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 25 20:39:46.372: INFO: 	Container pause ready: true, restart count 0
Apr 25 20:39:46.372: INFO: ibm-storage-watcher-65957667f-vtkpm from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Apr 25 20:39:46.372: INFO: ibmcloud-block-storage-driver-wstqs from kube-system started at 2023-04-25 17:13:40 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Apr 25 20:39:46.372: INFO: ibmcloud-block-storage-plugin-6d48895c6b-bh5sb from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Apr 25 20:39:46.372: INFO: ingress-cluster-healthcheck-6f7f6b87df-nfchz from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Apr 25 20:39:46.372: INFO: konnectivity-agent-ghrrh from kube-system started at 2023-04-25 17:26:42 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 25 20:39:46.372: INFO: kubernetes-dashboard-55c4d56798-pm8jr from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 25 20:39:46.372: INFO: metrics-server-c785bfcff-jltfr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (3 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container config-watcher ready: true, restart count 0
Apr 25 20:39:46.372: INFO: 	Container metrics-server ready: true, restart count 0
Apr 25 20:39:46.372: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr 25 20:39:46.372: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-bvz72 from kube-system started at 2023-04-25 17:18:07 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 25 20:39:46.372: INFO: snapshot-controller-c5c6dddff-2s9qq from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container snapshot-controller ready: true, restart count 0
Apr 25 20:39:46.372: INFO: snapshot-controller-c5c6dddff-55rkz from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container snapshot-controller ready: true, restart count 0
Apr 25 20:39:46.372: INFO: snapshot-controller-c5c6dddff-mxcw7 from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container snapshot-controller ready: true, restart count 0
Apr 25 20:39:46.372: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-w68zf from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 20:39:46.372: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 20:39:46.372: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 25 20:39:46.372: INFO: 
Logging pods the apiserver thinks is on node 10.10.21.190 before test
Apr 25 20:39:46.420: INFO: test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced from container-probe-7456 started at 2023-04-25 20:39:24 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.420: INFO: 	Container test-webserver ready: true, restart count 0
Apr 25 20:39:46.420: INFO: calico-node-4mqrc from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.420: INFO: 	Container calico-node ready: true, restart count 0
Apr 25 20:39:46.420: INFO: calico-typha-677688fdc5-mnnwk from kube-system started at 2023-04-25 20:31:28 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.420: INFO: 	Container calico-typha ready: true, restart count 0
Apr 25 20:39:46.420: INFO: ibm-keepalived-watcher-r8lvr from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.420: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 25 20:39:46.420: INFO: ibm-master-proxy-static-10.10.21.190 from kube-system started at 2023-04-25 17:14:39 +0000 UTC (2 container statuses recorded)
Apr 25 20:39:46.420: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 25 20:39:46.420: INFO: 	Container pause ready: true, restart count 0
Apr 25 20:39:46.420: INFO: ibmcloud-block-storage-driver-gpzl6 from kube-system started at 2023-04-25 17:14:49 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.420: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Apr 25 20:39:46.420: INFO: konnectivity-agent-hkzc4 from kube-system started at 2023-04-25 17:26:39 +0000 UTC (1 container statuses recorded)
Apr 25 20:39:46.420: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 25 20:39:46.420: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-gq2qk from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 20:39:46.420: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 20:39:46.420: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 04/25/23 20:39:46.42
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1759481400b501fc], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 04/25/23 20:39:46.56
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 25 20:39:47.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7219" for this suite. 04/25/23 20:39:47.577
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":240,"skipped":4452,"failed":0}
------------------------------
• [1.442 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:39:46.158
    Apr 25 20:39:46.158: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename sched-pred 04/25/23 20:39:46.159
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:46.231
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:46.24
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 25 20:39:46.247: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 25 20:39:46.277: INFO: Waiting for terminating namespaces to be deleted...
    Apr 25 20:39:46.287: INFO: 
    Logging pods the apiserver thinks is on node 10.10.21.136 before test
    Apr 25 20:39:46.314: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-nzg9s from ibm-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.314: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
    Apr 25 20:39:46.315: INFO: calico-node-q95vg from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.315: INFO: 	Container calico-node ready: true, restart count 0
    Apr 25 20:39:46.315: INFO: calico-typha-677688fdc5-5f8fr from kube-system started at 2023-04-25 17:14:29 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.315: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 25 20:39:46.315: INFO: coredns-6754846f95-cn7xr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.315: INFO: 	Container coredns ready: true, restart count 0
    Apr 25 20:39:46.316: INFO: coredns-6754846f95-dnk45 from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.316: INFO: 	Container coredns ready: true, restart count 0
    Apr 25 20:39:46.316: INFO: ibm-keepalived-watcher-p87jk from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.316: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Apr 25 20:39:46.316: INFO: ibm-master-proxy-static-10.10.21.136 from kube-system started at 2023-04-25 17:13:57 +0000 UTC (2 container statuses recorded)
    Apr 25 20:39:46.317: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Apr 25 20:39:46.317: INFO: 	Container pause ready: true, restart count 0
    Apr 25 20:39:46.317: INFO: ibmcloud-block-storage-driver-fm7g7 from kube-system started at 2023-04-25 17:14:07 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.317: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Apr 25 20:39:46.317: INFO: konnectivity-agent-mv6tj from kube-system started at 2023-04-25 17:26:45 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.317: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Apr 25 20:39:46.318: INFO: metrics-server-c785bfcff-b2n5l from kube-system started at 2023-04-25 18:05:55 +0000 UTC (3 container statuses recorded)
    Apr 25 20:39:46.318: INFO: 	Container config-watcher ready: true, restart count 0
    Apr 25 20:39:46.318: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 25 20:39:46.318: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Apr 25 20:39:46.318: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-p575r from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.318: INFO: 	Container nginx-ingress ready: true, restart count 0
    Apr 25 20:39:46.318: INFO: sonobuoy from sonobuoy started at 2023-04-25 19:35:04 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.318: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 25 20:39:46.318: INFO: sonobuoy-e2e-job-38c24e91f58b4d35 from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 20:39:46.318: INFO: 	Container e2e ready: true, restart count 0
    Apr 25 20:39:46.319: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 20:39:46.319: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-88nhh from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 20:39:46.319: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 20:39:46.319: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 25 20:39:46.319: INFO: 
    Logging pods the apiserver thinks is on node 10.10.21.161 before test
    Apr 25 20:39:46.372: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-g4ql4 from ibm-system started at 2023-04-25 17:18:17 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: calico-kube-controllers-5754dfd4dd-jfqrl from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: calico-node-mqpqg from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container calico-node ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: calico-typha-677688fdc5-bt4pk from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: coredns-6754846f95-8fzmk from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container coredns ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: coredns-autoscaler-669cf746f6-hnjbg from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: dashboard-metrics-scraper-c964d5594-wvstn from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: ibm-file-plugin-84d44c69b5-kz8hc from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: ibm-keepalived-watcher-9dj6q from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: ibm-master-proxy-static-10.10.21.161 from kube-system started at 2023-04-25 17:13:31 +0000 UTC (2 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: 	Container pause ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: ibm-storage-watcher-65957667f-vtkpm from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: ibmcloud-block-storage-driver-wstqs from kube-system started at 2023-04-25 17:13:40 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: ibmcloud-block-storage-plugin-6d48895c6b-bh5sb from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: ingress-cluster-healthcheck-6f7f6b87df-nfchz from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: konnectivity-agent-ghrrh from kube-system started at 2023-04-25 17:26:42 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: kubernetes-dashboard-55c4d56798-pm8jr from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: metrics-server-c785bfcff-jltfr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (3 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container config-watcher ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-bvz72 from kube-system started at 2023-04-25 17:18:07 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container nginx-ingress ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: snapshot-controller-c5c6dddff-2s9qq from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container snapshot-controller ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: snapshot-controller-c5c6dddff-55rkz from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container snapshot-controller ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: snapshot-controller-c5c6dddff-mxcw7 from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container snapshot-controller ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-w68zf from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 20:39:46.372: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 25 20:39:46.372: INFO: 
    Logging pods the apiserver thinks is on node 10.10.21.190 before test
    Apr 25 20:39:46.420: INFO: test-webserver-9a8403d9-0201-4fab-8597-aa06752d1ced from container-probe-7456 started at 2023-04-25 20:39:24 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.420: INFO: 	Container test-webserver ready: true, restart count 0
    Apr 25 20:39:46.420: INFO: calico-node-4mqrc from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.420: INFO: 	Container calico-node ready: true, restart count 0
    Apr 25 20:39:46.420: INFO: calico-typha-677688fdc5-mnnwk from kube-system started at 2023-04-25 20:31:28 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.420: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 25 20:39:46.420: INFO: ibm-keepalived-watcher-r8lvr from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.420: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Apr 25 20:39:46.420: INFO: ibm-master-proxy-static-10.10.21.190 from kube-system started at 2023-04-25 17:14:39 +0000 UTC (2 container statuses recorded)
    Apr 25 20:39:46.420: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Apr 25 20:39:46.420: INFO: 	Container pause ready: true, restart count 0
    Apr 25 20:39:46.420: INFO: ibmcloud-block-storage-driver-gpzl6 from kube-system started at 2023-04-25 17:14:49 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.420: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Apr 25 20:39:46.420: INFO: konnectivity-agent-hkzc4 from kube-system started at 2023-04-25 17:26:39 +0000 UTC (1 container statuses recorded)
    Apr 25 20:39:46.420: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Apr 25 20:39:46.420: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-gq2qk from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 20:39:46.420: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 20:39:46.420: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 04/25/23 20:39:46.42
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.1759481400b501fc], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 04/25/23 20:39:46.56
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 20:39:47.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-7219" for this suite. 04/25/23 20:39:47.577
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:39:47.603
Apr 25 20:39:47.603: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename replication-controller 04/25/23 20:39:47.609
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:47.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:47.666
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 04/25/23 20:39:47.675
Apr 25 20:39:47.695: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-5670" to be "running and ready"
Apr 25 20:39:47.707: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 11.528116ms
Apr 25 20:39:47.707: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:39:49.724: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.028427277s
Apr 25 20:39:49.724: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Apr 25 20:39:49.724: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 04/25/23 20:39:49.76
STEP: Then the orphan pod is adopted 04/25/23 20:39:49.773
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 25 20:39:50.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5670" for this suite. 04/25/23 20:39:50.82
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":241,"skipped":4464,"failed":0}
------------------------------
• [3.238 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:39:47.603
    Apr 25 20:39:47.603: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename replication-controller 04/25/23 20:39:47.609
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:47.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:47.666
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 04/25/23 20:39:47.675
    Apr 25 20:39:47.695: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-5670" to be "running and ready"
    Apr 25 20:39:47.707: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 11.528116ms
    Apr 25 20:39:47.707: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:39:49.724: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.028427277s
    Apr 25 20:39:49.724: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Apr 25 20:39:49.724: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 04/25/23 20:39:49.76
    STEP: Then the orphan pod is adopted 04/25/23 20:39:49.773
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 25 20:39:50.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-5670" for this suite. 04/25/23 20:39:50.82
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:39:50.843
Apr 25 20:39:50.843: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename pods 04/25/23 20:39:50.846
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:50.886
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:50.896
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 04/25/23 20:39:50.951
STEP: watching for Pod to be ready 04/25/23 20:39:50.973
Apr 25 20:39:50.978: INFO: observed Pod pod-test in namespace pods-2136 in phase Pending with labels: map[test-pod-static:true] & conditions []
Apr 25 20:39:50.983: INFO: observed Pod pod-test in namespace pods-2136 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC  }]
Apr 25 20:39:51.017: INFO: observed Pod pod-test in namespace pods-2136 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC  }]
Apr 25 20:39:51.779: INFO: observed Pod pod-test in namespace pods-2136 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC  }]
Apr 25 20:39:52.182: INFO: Found Pod pod-test in namespace pods-2136 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 04/25/23 20:39:52.193
STEP: getting the Pod and ensuring that it's patched 04/25/23 20:39:52.212
STEP: replacing the Pod's status Ready condition to False 04/25/23 20:39:52.224
STEP: check the Pod again to ensure its Ready conditions are False 04/25/23 20:39:52.284
STEP: deleting the Pod via a Collection with a LabelSelector 04/25/23 20:39:52.285
STEP: watching for the Pod to be deleted 04/25/23 20:39:52.344
Apr 25 20:39:52.351: INFO: observed event type MODIFIED
Apr 25 20:39:54.210: INFO: observed event type MODIFIED
Apr 25 20:39:54.448: INFO: observed event type MODIFIED
Apr 25 20:39:55.211: INFO: observed event type MODIFIED
Apr 25 20:39:55.236: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 25 20:39:55.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2136" for this suite. 04/25/23 20:39:55.314
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":242,"skipped":4466,"failed":0}
------------------------------
• [4.492 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:39:50.843
    Apr 25 20:39:50.843: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename pods 04/25/23 20:39:50.846
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:50.886
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:50.896
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 04/25/23 20:39:50.951
    STEP: watching for Pod to be ready 04/25/23 20:39:50.973
    Apr 25 20:39:50.978: INFO: observed Pod pod-test in namespace pods-2136 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Apr 25 20:39:50.983: INFO: observed Pod pod-test in namespace pods-2136 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC  }]
    Apr 25 20:39:51.017: INFO: observed Pod pod-test in namespace pods-2136 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC  }]
    Apr 25 20:39:51.779: INFO: observed Pod pod-test in namespace pods-2136 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC  }]
    Apr 25 20:39:52.182: INFO: Found Pod pod-test in namespace pods-2136 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 20:39:50 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 04/25/23 20:39:52.193
    STEP: getting the Pod and ensuring that it's patched 04/25/23 20:39:52.212
    STEP: replacing the Pod's status Ready condition to False 04/25/23 20:39:52.224
    STEP: check the Pod again to ensure its Ready conditions are False 04/25/23 20:39:52.284
    STEP: deleting the Pod via a Collection with a LabelSelector 04/25/23 20:39:52.285
    STEP: watching for the Pod to be deleted 04/25/23 20:39:52.344
    Apr 25 20:39:52.351: INFO: observed event type MODIFIED
    Apr 25 20:39:54.210: INFO: observed event type MODIFIED
    Apr 25 20:39:54.448: INFO: observed event type MODIFIED
    Apr 25 20:39:55.211: INFO: observed event type MODIFIED
    Apr 25 20:39:55.236: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 25 20:39:55.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2136" for this suite. 04/25/23 20:39:55.314
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:39:55.335
Apr 25 20:39:55.335: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir 04/25/23 20:39:55.337
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:55.376
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:55.382
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 04/25/23 20:39:55.394
Apr 25 20:39:55.425: INFO: Waiting up to 5m0s for pod "pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447" in namespace "emptydir-2333" to be "Succeeded or Failed"
Apr 25 20:39:55.441: INFO: Pod "pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447": Phase="Pending", Reason="", readiness=false. Elapsed: 11.105438ms
Apr 25 20:39:57.452: INFO: Pod "pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022076275s
Apr 25 20:39:59.453: INFO: Pod "pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023027413s
STEP: Saw pod success 04/25/23 20:39:59.453
Apr 25 20:39:59.453: INFO: Pod "pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447" satisfied condition "Succeeded or Failed"
Apr 25 20:39:59.468: INFO: Trying to get logs from node 10.10.21.190 pod pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447 container test-container: <nil>
STEP: delete the pod 04/25/23 20:39:59.503
Apr 25 20:39:59.549: INFO: Waiting for pod pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447 to disappear
Apr 25 20:39:59.559: INFO: Pod pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 25 20:39:59.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2333" for this suite. 04/25/23 20:39:59.574
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":243,"skipped":4467,"failed":0}
------------------------------
• [4.256 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:39:55.335
    Apr 25 20:39:55.335: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir 04/25/23 20:39:55.337
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:55.376
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:55.382
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 04/25/23 20:39:55.394
    Apr 25 20:39:55.425: INFO: Waiting up to 5m0s for pod "pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447" in namespace "emptydir-2333" to be "Succeeded or Failed"
    Apr 25 20:39:55.441: INFO: Pod "pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447": Phase="Pending", Reason="", readiness=false. Elapsed: 11.105438ms
    Apr 25 20:39:57.452: INFO: Pod "pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022076275s
    Apr 25 20:39:59.453: INFO: Pod "pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023027413s
    STEP: Saw pod success 04/25/23 20:39:59.453
    Apr 25 20:39:59.453: INFO: Pod "pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447" satisfied condition "Succeeded or Failed"
    Apr 25 20:39:59.468: INFO: Trying to get logs from node 10.10.21.190 pod pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447 container test-container: <nil>
    STEP: delete the pod 04/25/23 20:39:59.503
    Apr 25 20:39:59.549: INFO: Waiting for pod pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447 to disappear
    Apr 25 20:39:59.559: INFO: Pod pod-8d033ef7-1d17-4f44-9d6c-ce88e4020447 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 25 20:39:59.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2333" for this suite. 04/25/23 20:39:59.574
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:39:59.593
Apr 25 20:39:59.595: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir 04/25/23 20:39:59.598
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:59.662
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:59.67
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 04/25/23 20:39:59.678
Apr 25 20:39:59.702: INFO: Waiting up to 5m0s for pod "pod-2994a086-8449-46bc-9575-e0d561890cea" in namespace "emptydir-8025" to be "Succeeded or Failed"
Apr 25 20:39:59.714: INFO: Pod "pod-2994a086-8449-46bc-9575-e0d561890cea": Phase="Pending", Reason="", readiness=false. Elapsed: 12.232217ms
Apr 25 20:40:01.726: INFO: Pod "pod-2994a086-8449-46bc-9575-e0d561890cea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02419388s
Apr 25 20:40:03.725: INFO: Pod "pod-2994a086-8449-46bc-9575-e0d561890cea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022600901s
STEP: Saw pod success 04/25/23 20:40:03.725
Apr 25 20:40:03.725: INFO: Pod "pod-2994a086-8449-46bc-9575-e0d561890cea" satisfied condition "Succeeded or Failed"
Apr 25 20:40:03.736: INFO: Trying to get logs from node 10.10.21.190 pod pod-2994a086-8449-46bc-9575-e0d561890cea container test-container: <nil>
STEP: delete the pod 04/25/23 20:40:03.766
Apr 25 20:40:03.843: INFO: Waiting for pod pod-2994a086-8449-46bc-9575-e0d561890cea to disappear
Apr 25 20:40:03.856: INFO: Pod pod-2994a086-8449-46bc-9575-e0d561890cea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 25 20:40:03.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8025" for this suite. 04/25/23 20:40:03.872
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":244,"skipped":4467,"failed":0}
------------------------------
• [4.297 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:39:59.593
    Apr 25 20:39:59.595: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir 04/25/23 20:39:59.598
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:39:59.662
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:39:59.67
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 04/25/23 20:39:59.678
    Apr 25 20:39:59.702: INFO: Waiting up to 5m0s for pod "pod-2994a086-8449-46bc-9575-e0d561890cea" in namespace "emptydir-8025" to be "Succeeded or Failed"
    Apr 25 20:39:59.714: INFO: Pod "pod-2994a086-8449-46bc-9575-e0d561890cea": Phase="Pending", Reason="", readiness=false. Elapsed: 12.232217ms
    Apr 25 20:40:01.726: INFO: Pod "pod-2994a086-8449-46bc-9575-e0d561890cea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02419388s
    Apr 25 20:40:03.725: INFO: Pod "pod-2994a086-8449-46bc-9575-e0d561890cea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022600901s
    STEP: Saw pod success 04/25/23 20:40:03.725
    Apr 25 20:40:03.725: INFO: Pod "pod-2994a086-8449-46bc-9575-e0d561890cea" satisfied condition "Succeeded or Failed"
    Apr 25 20:40:03.736: INFO: Trying to get logs from node 10.10.21.190 pod pod-2994a086-8449-46bc-9575-e0d561890cea container test-container: <nil>
    STEP: delete the pod 04/25/23 20:40:03.766
    Apr 25 20:40:03.843: INFO: Waiting for pod pod-2994a086-8449-46bc-9575-e0d561890cea to disappear
    Apr 25 20:40:03.856: INFO: Pod pod-2994a086-8449-46bc-9575-e0d561890cea no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 25 20:40:03.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8025" for this suite. 04/25/23 20:40:03.872
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:40:03.903
Apr 25 20:40:03.903: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:40:03.905
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:40:03.961
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:40:03.969
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-5d3b9ad9-c6df-432b-b566-4e91e9aaa1bb 04/25/23 20:40:03.994
STEP: Creating the pod 04/25/23 20:40:04.006
Apr 25 20:40:04.026: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9656de28-e338-48a1-96fe-4d49c13c5b65" in namespace "projected-4070" to be "running and ready"
Apr 25 20:40:04.038: INFO: Pod "pod-projected-configmaps-9656de28-e338-48a1-96fe-4d49c13c5b65": Phase="Pending", Reason="", readiness=false. Elapsed: 12.255249ms
Apr 25 20:40:04.038: INFO: The phase of Pod pod-projected-configmaps-9656de28-e338-48a1-96fe-4d49c13c5b65 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:40:06.051: INFO: Pod "pod-projected-configmaps-9656de28-e338-48a1-96fe-4d49c13c5b65": Phase="Running", Reason="", readiness=true. Elapsed: 2.025621694s
Apr 25 20:40:06.052: INFO: The phase of Pod pod-projected-configmaps-9656de28-e338-48a1-96fe-4d49c13c5b65 is Running (Ready = true)
Apr 25 20:40:06.052: INFO: Pod "pod-projected-configmaps-9656de28-e338-48a1-96fe-4d49c13c5b65" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-5d3b9ad9-c6df-432b-b566-4e91e9aaa1bb 04/25/23 20:40:06.094
STEP: waiting to observe update in volume 04/25/23 20:40:06.107
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 25 20:40:08.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4070" for this suite. 04/25/23 20:40:08.218
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":245,"skipped":4507,"failed":0}
------------------------------
• [4.339 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:40:03.903
    Apr 25 20:40:03.903: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:40:03.905
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:40:03.961
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:40:03.969
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-5d3b9ad9-c6df-432b-b566-4e91e9aaa1bb 04/25/23 20:40:03.994
    STEP: Creating the pod 04/25/23 20:40:04.006
    Apr 25 20:40:04.026: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9656de28-e338-48a1-96fe-4d49c13c5b65" in namespace "projected-4070" to be "running and ready"
    Apr 25 20:40:04.038: INFO: Pod "pod-projected-configmaps-9656de28-e338-48a1-96fe-4d49c13c5b65": Phase="Pending", Reason="", readiness=false. Elapsed: 12.255249ms
    Apr 25 20:40:04.038: INFO: The phase of Pod pod-projected-configmaps-9656de28-e338-48a1-96fe-4d49c13c5b65 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:40:06.051: INFO: Pod "pod-projected-configmaps-9656de28-e338-48a1-96fe-4d49c13c5b65": Phase="Running", Reason="", readiness=true. Elapsed: 2.025621694s
    Apr 25 20:40:06.052: INFO: The phase of Pod pod-projected-configmaps-9656de28-e338-48a1-96fe-4d49c13c5b65 is Running (Ready = true)
    Apr 25 20:40:06.052: INFO: Pod "pod-projected-configmaps-9656de28-e338-48a1-96fe-4d49c13c5b65" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-5d3b9ad9-c6df-432b-b566-4e91e9aaa1bb 04/25/23 20:40:06.094
    STEP: waiting to observe update in volume 04/25/23 20:40:06.107
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 25 20:40:08.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4070" for this suite. 04/25/23 20:40:08.218
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:40:08.263
Apr 25 20:40:08.263: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-runtime 04/25/23 20:40:08.264
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:40:08.317
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:40:08.326
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 04/25/23 20:40:08.336
STEP: wait for the container to reach Succeeded 04/25/23 20:40:08.354
STEP: get the container status 04/25/23 20:40:12.453
STEP: the container should be terminated 04/25/23 20:40:12.462
STEP: the termination message should be set 04/25/23 20:40:12.463
Apr 25 20:40:12.463: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 04/25/23 20:40:12.463
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 25 20:40:12.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8152" for this suite. 04/25/23 20:40:12.578
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":246,"skipped":4596,"failed":0}
------------------------------
• [4.334 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:40:08.263
    Apr 25 20:40:08.263: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-runtime 04/25/23 20:40:08.264
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:40:08.317
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:40:08.326
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 04/25/23 20:40:08.336
    STEP: wait for the container to reach Succeeded 04/25/23 20:40:08.354
    STEP: get the container status 04/25/23 20:40:12.453
    STEP: the container should be terminated 04/25/23 20:40:12.462
    STEP: the termination message should be set 04/25/23 20:40:12.463
    Apr 25 20:40:12.463: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 04/25/23 20:40:12.463
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 25 20:40:12.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-8152" for this suite. 04/25/23 20:40:12.578
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:40:12.599
Apr 25 20:40:12.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir 04/25/23 20:40:12.602
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:40:12.645
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:40:12.652
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 04/25/23 20:40:12.659
Apr 25 20:40:12.705: INFO: Waiting up to 5m0s for pod "pod-b558c8e1-6317-4690-ba25-3dff6dd56560" in namespace "emptydir-8358" to be "Succeeded or Failed"
Apr 25 20:40:12.716: INFO: Pod "pod-b558c8e1-6317-4690-ba25-3dff6dd56560": Phase="Pending", Reason="", readiness=false. Elapsed: 10.897304ms
Apr 25 20:40:14.727: INFO: Pod "pod-b558c8e1-6317-4690-ba25-3dff6dd56560": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022220634s
Apr 25 20:40:16.729: INFO: Pod "pod-b558c8e1-6317-4690-ba25-3dff6dd56560": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023778537s
STEP: Saw pod success 04/25/23 20:40:16.729
Apr 25 20:40:16.729: INFO: Pod "pod-b558c8e1-6317-4690-ba25-3dff6dd56560" satisfied condition "Succeeded or Failed"
Apr 25 20:40:16.737: INFO: Trying to get logs from node 10.10.21.190 pod pod-b558c8e1-6317-4690-ba25-3dff6dd56560 container test-container: <nil>
STEP: delete the pod 04/25/23 20:40:16.777
Apr 25 20:40:16.842: INFO: Waiting for pod pod-b558c8e1-6317-4690-ba25-3dff6dd56560 to disappear
Apr 25 20:40:16.858: INFO: Pod pod-b558c8e1-6317-4690-ba25-3dff6dd56560 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 25 20:40:16.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8358" for this suite. 04/25/23 20:40:16.876
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":247,"skipped":4600,"failed":0}
------------------------------
• [4.295 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:40:12.599
    Apr 25 20:40:12.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir 04/25/23 20:40:12.602
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:40:12.645
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:40:12.652
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 04/25/23 20:40:12.659
    Apr 25 20:40:12.705: INFO: Waiting up to 5m0s for pod "pod-b558c8e1-6317-4690-ba25-3dff6dd56560" in namespace "emptydir-8358" to be "Succeeded or Failed"
    Apr 25 20:40:12.716: INFO: Pod "pod-b558c8e1-6317-4690-ba25-3dff6dd56560": Phase="Pending", Reason="", readiness=false. Elapsed: 10.897304ms
    Apr 25 20:40:14.727: INFO: Pod "pod-b558c8e1-6317-4690-ba25-3dff6dd56560": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022220634s
    Apr 25 20:40:16.729: INFO: Pod "pod-b558c8e1-6317-4690-ba25-3dff6dd56560": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023778537s
    STEP: Saw pod success 04/25/23 20:40:16.729
    Apr 25 20:40:16.729: INFO: Pod "pod-b558c8e1-6317-4690-ba25-3dff6dd56560" satisfied condition "Succeeded or Failed"
    Apr 25 20:40:16.737: INFO: Trying to get logs from node 10.10.21.190 pod pod-b558c8e1-6317-4690-ba25-3dff6dd56560 container test-container: <nil>
    STEP: delete the pod 04/25/23 20:40:16.777
    Apr 25 20:40:16.842: INFO: Waiting for pod pod-b558c8e1-6317-4690-ba25-3dff6dd56560 to disappear
    Apr 25 20:40:16.858: INFO: Pod pod-b558c8e1-6317-4690-ba25-3dff6dd56560 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 25 20:40:16.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8358" for this suite. 04/25/23 20:40:16.876
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:40:16.898
Apr 25 20:40:16.898: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename var-expansion 04/25/23 20:40:16.9
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:40:16.942
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:40:16.954
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 04/25/23 20:40:16.962
Apr 25 20:40:16.993: INFO: Waiting up to 5m0s for pod "var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124" in namespace "var-expansion-4912" to be "Succeeded or Failed"
Apr 25 20:40:17.034: INFO: Pod "var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124": Phase="Pending", Reason="", readiness=false. Elapsed: 40.894267ms
Apr 25 20:40:19.059: INFO: Pod "var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065515346s
Apr 25 20:40:21.046: INFO: Pod "var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05269834s
STEP: Saw pod success 04/25/23 20:40:21.046
Apr 25 20:40:21.047: INFO: Pod "var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124" satisfied condition "Succeeded or Failed"
Apr 25 20:40:21.059: INFO: Trying to get logs from node 10.10.21.190 pod var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124 container dapi-container: <nil>
STEP: delete the pod 04/25/23 20:40:21.098
Apr 25 20:40:21.127: INFO: Waiting for pod var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124 to disappear
Apr 25 20:40:21.138: INFO: Pod var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 25 20:40:21.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4912" for this suite. 04/25/23 20:40:21.154
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":248,"skipped":4611,"failed":0}
------------------------------
• [4.274 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:40:16.898
    Apr 25 20:40:16.898: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename var-expansion 04/25/23 20:40:16.9
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:40:16.942
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:40:16.954
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 04/25/23 20:40:16.962
    Apr 25 20:40:16.993: INFO: Waiting up to 5m0s for pod "var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124" in namespace "var-expansion-4912" to be "Succeeded or Failed"
    Apr 25 20:40:17.034: INFO: Pod "var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124": Phase="Pending", Reason="", readiness=false. Elapsed: 40.894267ms
    Apr 25 20:40:19.059: INFO: Pod "var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065515346s
    Apr 25 20:40:21.046: INFO: Pod "var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05269834s
    STEP: Saw pod success 04/25/23 20:40:21.046
    Apr 25 20:40:21.047: INFO: Pod "var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124" satisfied condition "Succeeded or Failed"
    Apr 25 20:40:21.059: INFO: Trying to get logs from node 10.10.21.190 pod var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124 container dapi-container: <nil>
    STEP: delete the pod 04/25/23 20:40:21.098
    Apr 25 20:40:21.127: INFO: Waiting for pod var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124 to disappear
    Apr 25 20:40:21.138: INFO: Pod var-expansion-489f8e06-550f-4e4f-919f-f0d2c5495124 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 25 20:40:21.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4912" for this suite. 04/25/23 20:40:21.154
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:40:21.189
Apr 25 20:40:21.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 20:40:21.191
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:40:21.245
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:40:21.255
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 04/25/23 20:40:21.265
Apr 25 20:40:21.284: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a" in namespace "downward-api-5231" to be "Succeeded or Failed"
Apr 25 20:40:21.310: INFO: Pod "downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a": Phase="Pending", Reason="", readiness=false. Elapsed: 25.130047ms
Apr 25 20:40:23.319: INFO: Pod "downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034513502s
Apr 25 20:40:25.324: INFO: Pod "downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039696477s
Apr 25 20:40:27.340: INFO: Pod "downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.055689542s
STEP: Saw pod success 04/25/23 20:40:27.341
Apr 25 20:40:27.341: INFO: Pod "downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a" satisfied condition "Succeeded or Failed"
Apr 25 20:40:27.376: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a container client-container: <nil>
STEP: delete the pod 04/25/23 20:40:27.404
Apr 25 20:40:27.461: INFO: Waiting for pod downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a to disappear
Apr 25 20:40:27.478: INFO: Pod downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 25 20:40:27.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5231" for this suite. 04/25/23 20:40:27.501
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":249,"skipped":4638,"failed":0}
------------------------------
• [SLOW TEST] [6.334 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:40:21.189
    Apr 25 20:40:21.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 20:40:21.191
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:40:21.245
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:40:21.255
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 04/25/23 20:40:21.265
    Apr 25 20:40:21.284: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a" in namespace "downward-api-5231" to be "Succeeded or Failed"
    Apr 25 20:40:21.310: INFO: Pod "downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a": Phase="Pending", Reason="", readiness=false. Elapsed: 25.130047ms
    Apr 25 20:40:23.319: INFO: Pod "downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034513502s
    Apr 25 20:40:25.324: INFO: Pod "downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039696477s
    Apr 25 20:40:27.340: INFO: Pod "downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.055689542s
    STEP: Saw pod success 04/25/23 20:40:27.341
    Apr 25 20:40:27.341: INFO: Pod "downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a" satisfied condition "Succeeded or Failed"
    Apr 25 20:40:27.376: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a container client-container: <nil>
    STEP: delete the pod 04/25/23 20:40:27.404
    Apr 25 20:40:27.461: INFO: Waiting for pod downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a to disappear
    Apr 25 20:40:27.478: INFO: Pod downwardapi-volume-8ee42946-9aa0-42fe-b864-fc77ab17ba9a no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 25 20:40:27.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5231" for this suite. 04/25/23 20:40:27.501
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:40:27.527
Apr 25 20:40:27.527: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename cronjob 04/25/23 20:40:27.53
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:40:27.57
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:40:27.579
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 04/25/23 20:40:27.588
STEP: Ensuring a job is scheduled 04/25/23 20:40:27.601
STEP: Ensuring exactly one is scheduled 04/25/23 20:41:01.614
STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/25/23 20:41:01.626
STEP: Ensuring no more jobs are scheduled 04/25/23 20:41:01.638
STEP: Removing cronjob 04/25/23 20:46:01.711
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 25 20:46:01.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5401" for this suite. 04/25/23 20:46:01.778
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":250,"skipped":4640,"failed":0}
------------------------------
• [SLOW TEST] [334.313 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:40:27.527
    Apr 25 20:40:27.527: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename cronjob 04/25/23 20:40:27.53
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:40:27.57
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:40:27.579
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 04/25/23 20:40:27.588
    STEP: Ensuring a job is scheduled 04/25/23 20:40:27.601
    STEP: Ensuring exactly one is scheduled 04/25/23 20:41:01.614
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/25/23 20:41:01.626
    STEP: Ensuring no more jobs are scheduled 04/25/23 20:41:01.638
    STEP: Removing cronjob 04/25/23 20:46:01.711
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 25 20:46:01.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5401" for this suite. 04/25/23 20:46:01.778
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:46:01.845
Apr 25 20:46:01.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename resourcequota 04/25/23 20:46:01.851
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:01.895
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:01.903
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 04/25/23 20:46:01.952
STEP: Getting a ResourceQuota 04/25/23 20:46:01.967
STEP: Listing all ResourceQuotas with LabelSelector 04/25/23 20:46:01.977
STEP: Patching the ResourceQuota 04/25/23 20:46:01.987
STEP: Deleting a Collection of ResourceQuotas 04/25/23 20:46:02.002
STEP: Verifying the deleted ResourceQuota 04/25/23 20:46:02.036
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 25 20:46:02.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1026" for this suite. 04/25/23 20:46:02.067
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":251,"skipped":4642,"failed":0}
------------------------------
• [0.267 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:46:01.845
    Apr 25 20:46:01.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename resourcequota 04/25/23 20:46:01.851
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:01.895
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:01.903
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 04/25/23 20:46:01.952
    STEP: Getting a ResourceQuota 04/25/23 20:46:01.967
    STEP: Listing all ResourceQuotas with LabelSelector 04/25/23 20:46:01.977
    STEP: Patching the ResourceQuota 04/25/23 20:46:01.987
    STEP: Deleting a Collection of ResourceQuotas 04/25/23 20:46:02.002
    STEP: Verifying the deleted ResourceQuota 04/25/23 20:46:02.036
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 25 20:46:02.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-1026" for this suite. 04/25/23 20:46:02.067
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:46:02.125
Apr 25 20:46:02.125: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir-wrapper 04/25/23 20:46:02.126
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:02.167
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:02.176
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Apr 25 20:46:02.244: INFO: Waiting up to 5m0s for pod "pod-secrets-0c44f255-87e5-4da8-bf2e-c2a5b8cf7794" in namespace "emptydir-wrapper-3620" to be "running and ready"
Apr 25 20:46:02.255: INFO: Pod "pod-secrets-0c44f255-87e5-4da8-bf2e-c2a5b8cf7794": Phase="Pending", Reason="", readiness=false. Elapsed: 10.32689ms
Apr 25 20:46:02.255: INFO: The phase of Pod pod-secrets-0c44f255-87e5-4da8-bf2e-c2a5b8cf7794 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:46:04.265: INFO: Pod "pod-secrets-0c44f255-87e5-4da8-bf2e-c2a5b8cf7794": Phase="Running", Reason="", readiness=true. Elapsed: 2.020515214s
Apr 25 20:46:04.265: INFO: The phase of Pod pod-secrets-0c44f255-87e5-4da8-bf2e-c2a5b8cf7794 is Running (Ready = true)
Apr 25 20:46:04.265: INFO: Pod "pod-secrets-0c44f255-87e5-4da8-bf2e-c2a5b8cf7794" satisfied condition "running and ready"
STEP: Cleaning up the secret 04/25/23 20:46:04.304
STEP: Cleaning up the configmap 04/25/23 20:46:04.364
STEP: Cleaning up the pod 04/25/23 20:46:04.381
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Apr 25 20:46:04.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3620" for this suite. 04/25/23 20:46:04.453
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":252,"skipped":4666,"failed":0}
------------------------------
• [2.381 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:46:02.125
    Apr 25 20:46:02.125: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir-wrapper 04/25/23 20:46:02.126
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:02.167
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:02.176
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Apr 25 20:46:02.244: INFO: Waiting up to 5m0s for pod "pod-secrets-0c44f255-87e5-4da8-bf2e-c2a5b8cf7794" in namespace "emptydir-wrapper-3620" to be "running and ready"
    Apr 25 20:46:02.255: INFO: Pod "pod-secrets-0c44f255-87e5-4da8-bf2e-c2a5b8cf7794": Phase="Pending", Reason="", readiness=false. Elapsed: 10.32689ms
    Apr 25 20:46:02.255: INFO: The phase of Pod pod-secrets-0c44f255-87e5-4da8-bf2e-c2a5b8cf7794 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:46:04.265: INFO: Pod "pod-secrets-0c44f255-87e5-4da8-bf2e-c2a5b8cf7794": Phase="Running", Reason="", readiness=true. Elapsed: 2.020515214s
    Apr 25 20:46:04.265: INFO: The phase of Pod pod-secrets-0c44f255-87e5-4da8-bf2e-c2a5b8cf7794 is Running (Ready = true)
    Apr 25 20:46:04.265: INFO: Pod "pod-secrets-0c44f255-87e5-4da8-bf2e-c2a5b8cf7794" satisfied condition "running and ready"
    STEP: Cleaning up the secret 04/25/23 20:46:04.304
    STEP: Cleaning up the configmap 04/25/23 20:46:04.364
    STEP: Cleaning up the pod 04/25/23 20:46:04.381
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Apr 25 20:46:04.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-3620" for this suite. 04/25/23 20:46:04.453
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:46:04.514
Apr 25 20:46:04.514: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename namespaces 04/25/23 20:46:04.517
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:04.563
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:04.572
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 04/25/23 20:46:04.581
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:04.638
STEP: Creating a service in the namespace 04/25/23 20:46:04.647
STEP: Deleting the namespace 04/25/23 20:46:04.686
STEP: Waiting for the namespace to be removed. 04/25/23 20:46:04.703
STEP: Recreating the namespace 04/25/23 20:46:11.714
STEP: Verifying there is no service in the namespace 04/25/23 20:46:11.76
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 25 20:46:11.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8629" for this suite. 04/25/23 20:46:11.819
STEP: Destroying namespace "nsdeletetest-7198" for this suite. 04/25/23 20:46:11.864
Apr 25 20:46:11.876: INFO: Namespace nsdeletetest-7198 was already deleted
STEP: Destroying namespace "nsdeletetest-3744" for this suite. 04/25/23 20:46:11.876
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":253,"skipped":4673,"failed":0}
------------------------------
• [SLOW TEST] [7.385 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:46:04.514
    Apr 25 20:46:04.514: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename namespaces 04/25/23 20:46:04.517
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:04.563
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:04.572
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 04/25/23 20:46:04.581
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:04.638
    STEP: Creating a service in the namespace 04/25/23 20:46:04.647
    STEP: Deleting the namespace 04/25/23 20:46:04.686
    STEP: Waiting for the namespace to be removed. 04/25/23 20:46:04.703
    STEP: Recreating the namespace 04/25/23 20:46:11.714
    STEP: Verifying there is no service in the namespace 04/25/23 20:46:11.76
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 20:46:11.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-8629" for this suite. 04/25/23 20:46:11.819
    STEP: Destroying namespace "nsdeletetest-7198" for this suite. 04/25/23 20:46:11.864
    Apr 25 20:46:11.876: INFO: Namespace nsdeletetest-7198 was already deleted
    STEP: Destroying namespace "nsdeletetest-3744" for this suite. 04/25/23 20:46:11.876
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:46:11.903
Apr 25 20:46:11.903: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename init-container 04/25/23 20:46:11.906
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:11.947
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:11.956
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 04/25/23 20:46:11.964
Apr 25 20:46:11.965: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 25 20:46:17.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9843" for this suite. 04/25/23 20:46:17.088
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":254,"skipped":4680,"failed":0}
------------------------------
• [SLOW TEST] [5.206 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:46:11.903
    Apr 25 20:46:11.903: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename init-container 04/25/23 20:46:11.906
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:11.947
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:11.956
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 04/25/23 20:46:11.964
    Apr 25 20:46:11.965: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 25 20:46:17.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-9843" for this suite. 04/25/23 20:46:17.088
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:46:17.12
Apr 25 20:46:17.121: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename secrets 04/25/23 20:46:17.124
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:17.176
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:17.185
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-006eae09-3188-4067-a2e8-0c916fc0cfa1 04/25/23 20:46:17.264
STEP: Creating a pod to test consume secrets 04/25/23 20:46:17.277
Apr 25 20:46:17.305: INFO: Waiting up to 5m0s for pod "pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46" in namespace "secrets-3344" to be "Succeeded or Failed"
Apr 25 20:46:17.315: INFO: Pod "pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46": Phase="Pending", Reason="", readiness=false. Elapsed: 9.921934ms
Apr 25 20:46:19.327: INFO: Pod "pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021902028s
Apr 25 20:46:21.355: INFO: Pod "pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050054025s
STEP: Saw pod success 04/25/23 20:46:21.355
Apr 25 20:46:21.355: INFO: Pod "pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46" satisfied condition "Succeeded or Failed"
Apr 25 20:46:21.369: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46 container secret-volume-test: <nil>
STEP: delete the pod 04/25/23 20:46:21.483
Apr 25 20:46:21.512: INFO: Waiting for pod pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46 to disappear
Apr 25 20:46:21.540: INFO: Pod pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 25 20:46:21.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3344" for this suite. 04/25/23 20:46:21.557
STEP: Destroying namespace "secret-namespace-8498" for this suite. 04/25/23 20:46:21.577
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":255,"skipped":4682,"failed":0}
------------------------------
• [4.478 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:46:17.12
    Apr 25 20:46:17.121: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename secrets 04/25/23 20:46:17.124
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:17.176
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:17.185
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-006eae09-3188-4067-a2e8-0c916fc0cfa1 04/25/23 20:46:17.264
    STEP: Creating a pod to test consume secrets 04/25/23 20:46:17.277
    Apr 25 20:46:17.305: INFO: Waiting up to 5m0s for pod "pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46" in namespace "secrets-3344" to be "Succeeded or Failed"
    Apr 25 20:46:17.315: INFO: Pod "pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46": Phase="Pending", Reason="", readiness=false. Elapsed: 9.921934ms
    Apr 25 20:46:19.327: INFO: Pod "pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021902028s
    Apr 25 20:46:21.355: INFO: Pod "pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050054025s
    STEP: Saw pod success 04/25/23 20:46:21.355
    Apr 25 20:46:21.355: INFO: Pod "pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46" satisfied condition "Succeeded or Failed"
    Apr 25 20:46:21.369: INFO: Trying to get logs from node 10.10.21.190 pod pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46 container secret-volume-test: <nil>
    STEP: delete the pod 04/25/23 20:46:21.483
    Apr 25 20:46:21.512: INFO: Waiting for pod pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46 to disappear
    Apr 25 20:46:21.540: INFO: Pod pod-secrets-a9eb30af-82dd-4e16-8d8b-0e2aea5dba46 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 25 20:46:21.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3344" for this suite. 04/25/23 20:46:21.557
    STEP: Destroying namespace "secret-namespace-8498" for this suite. 04/25/23 20:46:21.577
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:46:21.6
Apr 25 20:46:21.601: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename dns 04/25/23 20:46:21.605
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:21.671
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:21.679
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 04/25/23 20:46:21.688
Apr 25 20:46:21.722: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-3191  56a71971-889b-40a1-bbc2-a88c800f34e6 40137 0 2023-04-25 20:46:21 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-04-25 20:46:21 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k2hxj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k2hxj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 25 20:46:21.723: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-3191" to be "running and ready"
Apr 25 20:46:21.761: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 38.610517ms
Apr 25 20:46:21.761: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:46:23.772: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.049865536s
Apr 25 20:46:23.773: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Apr 25 20:46:23.773: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 04/25/23 20:46:23.773
Apr 25 20:46:23.773: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-3191 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:46:23.774: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:46:23.776: INFO: ExecWithOptions: Clientset creation
Apr 25 20:46:23.777: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-3191/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 04/25/23 20:46:24.029
Apr 25 20:46:24.029: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-3191 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:46:24.029: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:46:24.032: INFO: ExecWithOptions: Clientset creation
Apr 25 20:46:24.032: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-3191/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 25 20:46:24.317: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 25 20:46:24.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3191" for this suite. 04/25/23 20:46:24.388
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":256,"skipped":4689,"failed":0}
------------------------------
• [2.805 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:46:21.6
    Apr 25 20:46:21.601: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename dns 04/25/23 20:46:21.605
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:21.671
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:21.679
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 04/25/23 20:46:21.688
    Apr 25 20:46:21.722: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-3191  56a71971-889b-40a1-bbc2-a88c800f34e6 40137 0 2023-04-25 20:46:21 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-04-25 20:46:21 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k2hxj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k2hxj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 25 20:46:21.723: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-3191" to be "running and ready"
    Apr 25 20:46:21.761: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 38.610517ms
    Apr 25 20:46:21.761: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:46:23.772: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.049865536s
    Apr 25 20:46:23.773: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Apr 25 20:46:23.773: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 04/25/23 20:46:23.773
    Apr 25 20:46:23.773: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-3191 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:46:23.774: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:46:23.776: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:46:23.777: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-3191/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 04/25/23 20:46:24.029
    Apr 25 20:46:24.029: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-3191 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:46:24.029: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:46:24.032: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:46:24.032: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-3191/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 25 20:46:24.317: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 25 20:46:24.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3191" for this suite. 04/25/23 20:46:24.388
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:46:24.407
Apr 25 20:46:24.407: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename deployment 04/25/23 20:46:24.41
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:24.452
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:24.46
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 04/25/23 20:46:24.482
STEP: waiting for Deployment to be created 04/25/23 20:46:24.528
STEP: waiting for all Replicas to be Ready 04/25/23 20:46:24.531
Apr 25 20:46:24.534: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 25 20:46:24.534: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 25 20:46:24.562: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 25 20:46:24.562: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 25 20:46:24.584: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 25 20:46:24.585: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 25 20:46:24.708: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 25 20:46:24.708: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 25 20:46:25.912: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr 25 20:46:25.912: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr 25 20:46:26.175: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 04/25/23 20:46:26.175
W0425 20:46:26.190639      23 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 25 20:46:26.195: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 04/25/23 20:46:26.196
Apr 25 20:46:26.202: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
Apr 25 20:46:26.202: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
Apr 25 20:46:26.202: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
Apr 25 20:46:26.203: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
Apr 25 20:46:26.203: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
Apr 25 20:46:26.203: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
Apr 25 20:46:26.204: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
Apr 25 20:46:26.204: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
Apr 25 20:46:26.204: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
Apr 25 20:46:26.204: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
Apr 25 20:46:26.205: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
Apr 25 20:46:26.206: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
Apr 25 20:46:26.206: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
Apr 25 20:46:26.206: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
Apr 25 20:46:26.219: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
Apr 25 20:46:26.219: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
Apr 25 20:46:26.262: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
Apr 25 20:46:26.263: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
Apr 25 20:46:26.317: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
Apr 25 20:46:26.317: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
Apr 25 20:46:28.252: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
Apr 25 20:46:28.252: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
Apr 25 20:46:28.324: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
STEP: listing Deployments 04/25/23 20:46:28.324
Apr 25 20:46:28.379: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 04/25/23 20:46:28.379
Apr 25 20:46:28.415: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 04/25/23 20:46:28.415
Apr 25 20:46:28.501: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 25 20:46:28.502: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 25 20:46:28.510: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 25 20:46:28.537: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 25 20:46:28.576: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 25 20:46:28.642: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 25 20:46:30.259: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 25 20:46:30.304: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 25 20:46:30.317: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 25 20:46:30.355: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 25 20:46:30.388: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 25 20:46:32.076: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 04/25/23 20:46:32.124
STEP: fetching the DeploymentStatus 04/25/23 20:46:32.142
Apr 25 20:46:32.163: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
Apr 25 20:46:32.164: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
Apr 25 20:46:32.165: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
Apr 25 20:46:32.165: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
Apr 25 20:46:32.166: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
Apr 25 20:46:32.167: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
Apr 25 20:46:32.167: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
Apr 25 20:46:32.168: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
Apr 25 20:46:32.168: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
Apr 25 20:46:32.169: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
Apr 25 20:46:32.169: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
Apr 25 20:46:32.170: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 3
STEP: deleting the Deployment 04/25/23 20:46:32.17
Apr 25 20:46:32.243: INFO: observed event type MODIFIED
Apr 25 20:46:32.243: INFO: observed event type MODIFIED
Apr 25 20:46:32.243: INFO: observed event type MODIFIED
Apr 25 20:46:32.243: INFO: observed event type MODIFIED
Apr 25 20:46:32.243: INFO: observed event type MODIFIED
Apr 25 20:46:32.243: INFO: observed event type MODIFIED
Apr 25 20:46:32.244: INFO: observed event type MODIFIED
Apr 25 20:46:32.244: INFO: observed event type MODIFIED
Apr 25 20:46:32.244: INFO: observed event type MODIFIED
Apr 25 20:46:32.245: INFO: observed event type MODIFIED
Apr 25 20:46:32.245: INFO: observed event type MODIFIED
Apr 25 20:46:32.246: INFO: observed event type MODIFIED
Apr 25 20:46:32.247: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 25 20:46:32.258: INFO: Log out all the ReplicaSets if there is no deployment created
Apr 25 20:46:32.273: INFO: ReplicaSet "test-deployment-54cc775c4b":
&ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-7731  ce21c654-c51f-4d8d-a4e7-7138016e5a14 40367 4 2023-04-25 20:46:26 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment bb4591b0-7ec4-400b-80d6-16a4a0582795 0xc0043368b7 0xc0043368b8}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:46:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bb4591b0-7ec4-400b-80d6-16a4a0582795\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:46:32 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004336940 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Apr 25 20:46:32.285: INFO: pod: "test-deployment-54cc775c4b-5tm8h":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-5tm8h test-deployment-54cc775c4b- deployment-7731  765295b5-bbed-4979-9ab6-f743114e4203 40363 0 2023-04-25 20:46:26 +0000 UTC 2023-04-25 20:46:33 +0000 UTC 0xc004336d98 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:8687bc1c8bf28983c1e168d8a06692b2730f609236573299ab374d6ffdb44145 cni.projectcalico.org/podIP:172.30.142.169/32 cni.projectcalico.org/podIPs:172.30.142.169/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b ce21c654-c51f-4d8d-a4e7-7138016e5a14 0xc004336dc7 0xc004336dc8}] [] [{kube-controller-manager Update v1 2023-04-25 20:46:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce21c654-c51f-4d8d-a4e7-7138016e5a14\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:46:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:46:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.169\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zmqcb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zmqcb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.169,StartTime:2023-04-25 20:46:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:46:27 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://02f8d3b5ec15f1405b7f3f15580289495981e5042b1021ff804c5781da7febae,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.169,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 25 20:46:32.286: INFO: pod: "test-deployment-54cc775c4b-l5xbj":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-l5xbj test-deployment-54cc775c4b- deployment-7731  23959fa5-620c-483c-a42c-259a0a4a7b01 40370 0 2023-04-25 20:46:28 +0000 UTC 2023-04-25 20:46:31 +0000 UTC 0xc004336fb0 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:cae37cf46b457fcdb64522af4e6e7f4a9c7ffecc085d40e2cafc119e75ee2763 cni.projectcalico.org/podIP: cni.projectcalico.org/podIPs:] [{apps/v1 ReplicaSet test-deployment-54cc775c4b ce21c654-c51f-4d8d-a4e7-7138016e5a14 0xc004336fe7 0xc004336fe8}] [] [{kube-controller-manager Update v1 2023-04-25 20:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce21c654-c51f-4d8d-a4e7-7138016e5a14\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:46:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.226.110\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status} {calico Update v1 2023-04-25 20:46:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fwhsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fwhsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:172.30.226.110,StartTime:2023-04-25 20:46:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:46:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://a221e5ef801041bcb4d644b22409092ce38a5a0695c34814a5155ed4014e45ed,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.226.110,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 25 20:46:32.287: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
&ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-7731  615fc875-ede0-4496-ae48-57454a889f0e 40359 2 2023-04-25 20:46:28 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment bb4591b0-7ec4-400b-80d6-16a4a0582795 0xc0043369a7 0xc0043369a8}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:46:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bb4591b0-7ec4-400b-80d6-16a4a0582795\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:46:31 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004336a30 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Apr 25 20:46:32.299: INFO: pod: "test-deployment-7c7d8d58c8-dbpfm":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-dbpfm test-deployment-7c7d8d58c8- deployment-7731  85219aee-99f7-4cbe-a993-bb08cce12be6 40321 0 2023-04-25 20:46:28 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:7594f11dd3e2fb504e59fc8d4401bb78546382cc484e42015a7fabd13cc01a43 cni.projectcalico.org/podIP:172.30.142.172/32 cni.projectcalico.org/podIPs:172.30.142.172/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 615fc875-ede0-4496-ae48-57454a889f0e 0xc003976427 0xc003976428}] [] [{kube-controller-manager Update v1 2023-04-25 20:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"615fc875-ede0-4496-ae48-57454a889f0e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:46:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:46:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.172\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9s75d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9s75d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.172,StartTime:2023-04-25 20:46:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:46:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b191375f8020b3a00cba3d121cb2cd44b51a71e1029ce770c0608eaf96b779aa,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.172,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 25 20:46:32.300: INFO: pod: "test-deployment-7c7d8d58c8-p6pcw":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-p6pcw test-deployment-7c7d8d58c8- deployment-7731  17c6eb21-b72f-4189-b45f-e6bead6c1c19 40357 0 2023-04-25 20:46:30 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:6162fceed387a240977a020f20a743b4e86e11fd66c8edfc8532480bedd0b78c cni.projectcalico.org/podIP:172.30.226.112/32 cni.projectcalico.org/podIPs:172.30.226.112/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 615fc875-ede0-4496-ae48-57454a889f0e 0xc003976637 0xc003976638}] [] [{kube-controller-manager Update v1 2023-04-25 20:46:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"615fc875-ede0-4496-ae48-57454a889f0e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:46:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:46:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.226.112\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-b4hnb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-b4hnb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:172.30.226.112,StartTime:2023-04-25 20:46:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:46:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://096439354ddf45dbfdc65c2d026035e432fee8bafd21e14d46fcc9c3755f4062,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.226.112,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 25 20:46:32.301: INFO: ReplicaSet "test-deployment-8594bb6fdd":
&ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-7731  d703cd4c-88ad-4ef2-8055-7a2e99b9bea1 40264 3 2023-04-25 20:46:24 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment bb4591b0-7ec4-400b-80d6-16a4a0582795 0xc004336a97 0xc004336a98}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bb4591b0-7ec4-400b-80d6-16a4a0582795\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:46:28 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004336b20 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 25 20:46:32.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7731" for this suite. 04/25/23 20:46:32.362
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":257,"skipped":4699,"failed":0}
------------------------------
• [SLOW TEST] [7.999 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:46:24.407
    Apr 25 20:46:24.407: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename deployment 04/25/23 20:46:24.41
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:24.452
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:24.46
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 04/25/23 20:46:24.482
    STEP: waiting for Deployment to be created 04/25/23 20:46:24.528
    STEP: waiting for all Replicas to be Ready 04/25/23 20:46:24.531
    Apr 25 20:46:24.534: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 25 20:46:24.534: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 25 20:46:24.562: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 25 20:46:24.562: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 25 20:46:24.584: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 25 20:46:24.585: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 25 20:46:24.708: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 25 20:46:24.708: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 25 20:46:25.912: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Apr 25 20:46:25.912: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Apr 25 20:46:26.175: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 04/25/23 20:46:26.175
    W0425 20:46:26.190639      23 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 25 20:46:26.195: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 04/25/23 20:46:26.196
    Apr 25 20:46:26.202: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
    Apr 25 20:46:26.202: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
    Apr 25 20:46:26.202: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
    Apr 25 20:46:26.203: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
    Apr 25 20:46:26.203: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
    Apr 25 20:46:26.203: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
    Apr 25 20:46:26.204: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
    Apr 25 20:46:26.204: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 0
    Apr 25 20:46:26.204: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
    Apr 25 20:46:26.204: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
    Apr 25 20:46:26.205: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
    Apr 25 20:46:26.206: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
    Apr 25 20:46:26.206: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
    Apr 25 20:46:26.206: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
    Apr 25 20:46:26.219: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
    Apr 25 20:46:26.219: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
    Apr 25 20:46:26.262: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
    Apr 25 20:46:26.263: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
    Apr 25 20:46:26.317: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
    Apr 25 20:46:26.317: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
    Apr 25 20:46:28.252: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
    Apr 25 20:46:28.252: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
    Apr 25 20:46:28.324: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
    STEP: listing Deployments 04/25/23 20:46:28.324
    Apr 25 20:46:28.379: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 04/25/23 20:46:28.379
    Apr 25 20:46:28.415: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 04/25/23 20:46:28.415
    Apr 25 20:46:28.501: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 25 20:46:28.502: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 25 20:46:28.510: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 25 20:46:28.537: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 25 20:46:28.576: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 25 20:46:28.642: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 25 20:46:30.259: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 25 20:46:30.304: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 25 20:46:30.317: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 25 20:46:30.355: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 25 20:46:30.388: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 25 20:46:32.076: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 04/25/23 20:46:32.124
    STEP: fetching the DeploymentStatus 04/25/23 20:46:32.142
    Apr 25 20:46:32.163: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
    Apr 25 20:46:32.164: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
    Apr 25 20:46:32.165: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
    Apr 25 20:46:32.165: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
    Apr 25 20:46:32.166: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
    Apr 25 20:46:32.167: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 1
    Apr 25 20:46:32.167: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
    Apr 25 20:46:32.168: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
    Apr 25 20:46:32.168: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
    Apr 25 20:46:32.169: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
    Apr 25 20:46:32.169: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 2
    Apr 25 20:46:32.170: INFO: observed Deployment test-deployment in namespace deployment-7731 with ReadyReplicas 3
    STEP: deleting the Deployment 04/25/23 20:46:32.17
    Apr 25 20:46:32.243: INFO: observed event type MODIFIED
    Apr 25 20:46:32.243: INFO: observed event type MODIFIED
    Apr 25 20:46:32.243: INFO: observed event type MODIFIED
    Apr 25 20:46:32.243: INFO: observed event type MODIFIED
    Apr 25 20:46:32.243: INFO: observed event type MODIFIED
    Apr 25 20:46:32.243: INFO: observed event type MODIFIED
    Apr 25 20:46:32.244: INFO: observed event type MODIFIED
    Apr 25 20:46:32.244: INFO: observed event type MODIFIED
    Apr 25 20:46:32.244: INFO: observed event type MODIFIED
    Apr 25 20:46:32.245: INFO: observed event type MODIFIED
    Apr 25 20:46:32.245: INFO: observed event type MODIFIED
    Apr 25 20:46:32.246: INFO: observed event type MODIFIED
    Apr 25 20:46:32.247: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 25 20:46:32.258: INFO: Log out all the ReplicaSets if there is no deployment created
    Apr 25 20:46:32.273: INFO: ReplicaSet "test-deployment-54cc775c4b":
    &ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-7731  ce21c654-c51f-4d8d-a4e7-7138016e5a14 40367 4 2023-04-25 20:46:26 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment bb4591b0-7ec4-400b-80d6-16a4a0582795 0xc0043368b7 0xc0043368b8}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:46:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bb4591b0-7ec4-400b-80d6-16a4a0582795\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:46:32 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004336940 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Apr 25 20:46:32.285: INFO: pod: "test-deployment-54cc775c4b-5tm8h":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-5tm8h test-deployment-54cc775c4b- deployment-7731  765295b5-bbed-4979-9ab6-f743114e4203 40363 0 2023-04-25 20:46:26 +0000 UTC 2023-04-25 20:46:33 +0000 UTC 0xc004336d98 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:8687bc1c8bf28983c1e168d8a06692b2730f609236573299ab374d6ffdb44145 cni.projectcalico.org/podIP:172.30.142.169/32 cni.projectcalico.org/podIPs:172.30.142.169/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b ce21c654-c51f-4d8d-a4e7-7138016e5a14 0xc004336dc7 0xc004336dc8}] [] [{kube-controller-manager Update v1 2023-04-25 20:46:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce21c654-c51f-4d8d-a4e7-7138016e5a14\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:46:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:46:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.169\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zmqcb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zmqcb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.169,StartTime:2023-04-25 20:46:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:46:27 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://02f8d3b5ec15f1405b7f3f15580289495981e5042b1021ff804c5781da7febae,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.169,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 25 20:46:32.286: INFO: pod: "test-deployment-54cc775c4b-l5xbj":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-l5xbj test-deployment-54cc775c4b- deployment-7731  23959fa5-620c-483c-a42c-259a0a4a7b01 40370 0 2023-04-25 20:46:28 +0000 UTC 2023-04-25 20:46:31 +0000 UTC 0xc004336fb0 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:cae37cf46b457fcdb64522af4e6e7f4a9c7ffecc085d40e2cafc119e75ee2763 cni.projectcalico.org/podIP: cni.projectcalico.org/podIPs:] [{apps/v1 ReplicaSet test-deployment-54cc775c4b ce21c654-c51f-4d8d-a4e7-7138016e5a14 0xc004336fe7 0xc004336fe8}] [] [{kube-controller-manager Update v1 2023-04-25 20:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce21c654-c51f-4d8d-a4e7-7138016e5a14\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-25 20:46:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.226.110\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status} {calico Update v1 2023-04-25 20:46:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fwhsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fwhsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:172.30.226.110,StartTime:2023-04-25 20:46:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:46:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://a221e5ef801041bcb4d644b22409092ce38a5a0695c34814a5155ed4014e45ed,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.226.110,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 25 20:46:32.287: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
    &ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-7731  615fc875-ede0-4496-ae48-57454a889f0e 40359 2 2023-04-25 20:46:28 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment bb4591b0-7ec4-400b-80d6-16a4a0582795 0xc0043369a7 0xc0043369a8}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:46:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bb4591b0-7ec4-400b-80d6-16a4a0582795\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:46:31 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004336a30 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

    Apr 25 20:46:32.299: INFO: pod: "test-deployment-7c7d8d58c8-dbpfm":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-dbpfm test-deployment-7c7d8d58c8- deployment-7731  85219aee-99f7-4cbe-a993-bb08cce12be6 40321 0 2023-04-25 20:46:28 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:7594f11dd3e2fb504e59fc8d4401bb78546382cc484e42015a7fabd13cc01a43 cni.projectcalico.org/podIP:172.30.142.172/32 cni.projectcalico.org/podIPs:172.30.142.172/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 615fc875-ede0-4496-ae48-57454a889f0e 0xc003976427 0xc003976428}] [] [{kube-controller-manager Update v1 2023-04-25 20:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"615fc875-ede0-4496-ae48-57454a889f0e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:46:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:46:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.142.172\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9s75d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9s75d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.190,PodIP:172.30.142.172,StartTime:2023-04-25 20:46:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:46:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b191375f8020b3a00cba3d121cb2cd44b51a71e1029ce770c0608eaf96b779aa,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.142.172,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 25 20:46:32.300: INFO: pod: "test-deployment-7c7d8d58c8-p6pcw":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-p6pcw test-deployment-7c7d8d58c8- deployment-7731  17c6eb21-b72f-4189-b45f-e6bead6c1c19 40357 0 2023-04-25 20:46:30 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:6162fceed387a240977a020f20a743b4e86e11fd66c8edfc8532480bedd0b78c cni.projectcalico.org/podIP:172.30.226.112/32 cni.projectcalico.org/podIPs:172.30.226.112/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 615fc875-ede0-4496-ae48-57454a889f0e 0xc003976637 0xc003976638}] [] [{kube-controller-manager Update v1 2023-04-25 20:46:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"615fc875-ede0-4496-ae48-57454a889f0e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-25 20:46:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-25 20:46:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.226.112\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-b4hnb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-b4hnb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.21.161,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-25 20:46:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.21.161,PodIP:172.30.226.112,StartTime:2023-04-25 20:46:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-25 20:46:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://096439354ddf45dbfdc65c2d026035e432fee8bafd21e14d46fcc9c3755f4062,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.226.112,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 25 20:46:32.301: INFO: ReplicaSet "test-deployment-8594bb6fdd":
    &ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-7731  d703cd4c-88ad-4ef2-8055-7a2e99b9bea1 40264 3 2023-04-25 20:46:24 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment bb4591b0-7ec4-400b-80d6-16a4a0582795 0xc004336a97 0xc004336a98}] [] [{kube-controller-manager Update apps/v1 2023-04-25 20:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bb4591b0-7ec4-400b-80d6-16a4a0582795\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-25 20:46:28 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004336b20 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 25 20:46:32.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7731" for this suite. 04/25/23 20:46:32.362
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:46:32.417
Apr 25 20:46:32.418: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename events 04/25/23 20:46:32.42
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:32.525
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:32.534
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 04/25/23 20:46:32.545
STEP: listing events in all namespaces 04/25/23 20:46:32.601
STEP: listing events in test namespace 04/25/23 20:46:32.614
STEP: listing events with field selection filtering on source 04/25/23 20:46:32.653
STEP: listing events with field selection filtering on reportingController 04/25/23 20:46:32.665
STEP: getting the test event 04/25/23 20:46:32.676
STEP: patching the test event 04/25/23 20:46:32.687
STEP: getting the test event 04/25/23 20:46:32.715
STEP: updating the test event 04/25/23 20:46:32.725
STEP: getting the test event 04/25/23 20:46:32.743
STEP: deleting the test event 04/25/23 20:46:32.757
STEP: listing events in all namespaces 04/25/23 20:46:32.806
STEP: listing events in test namespace 04/25/23 20:46:32.819
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Apr 25 20:46:32.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5333" for this suite. 04/25/23 20:46:32.869
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":258,"skipped":4708,"failed":0}
------------------------------
• [0.473 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:46:32.417
    Apr 25 20:46:32.418: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename events 04/25/23 20:46:32.42
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:32.525
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:32.534
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 04/25/23 20:46:32.545
    STEP: listing events in all namespaces 04/25/23 20:46:32.601
    STEP: listing events in test namespace 04/25/23 20:46:32.614
    STEP: listing events with field selection filtering on source 04/25/23 20:46:32.653
    STEP: listing events with field selection filtering on reportingController 04/25/23 20:46:32.665
    STEP: getting the test event 04/25/23 20:46:32.676
    STEP: patching the test event 04/25/23 20:46:32.687
    STEP: getting the test event 04/25/23 20:46:32.715
    STEP: updating the test event 04/25/23 20:46:32.725
    STEP: getting the test event 04/25/23 20:46:32.743
    STEP: deleting the test event 04/25/23 20:46:32.757
    STEP: listing events in all namespaces 04/25/23 20:46:32.806
    STEP: listing events in test namespace 04/25/23 20:46:32.819
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Apr 25 20:46:32.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-5333" for this suite. 04/25/23 20:46:32.869
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:46:32.896
Apr 25 20:46:32.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename sched-preemption 04/25/23 20:46:32.9
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:32.964
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:32.974
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 25 20:46:33.070: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 25 20:47:33.163: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 04/25/23 20:47:33.175
Apr 25 20:47:33.226: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr 25 20:47:33.239: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr 25 20:47:33.277: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr 25 20:47:33.294: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Apr 25 20:47:33.332: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Apr 25 20:47:33.346: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 04/25/23 20:47:33.346
Apr 25 20:47:33.347: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-828" to be "running"
Apr 25 20:47:33.368: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 20.170299ms
Apr 25 20:47:35.392: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044545398s
Apr 25 20:47:37.389: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041866027s
Apr 25 20:47:39.379: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.031846812s
Apr 25 20:47:39.379: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Apr 25 20:47:39.379: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-828" to be "running"
Apr 25 20:47:39.391: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.255601ms
Apr 25 20:47:39.391: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 25 20:47:39.391: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-828" to be "running"
Apr 25 20:47:39.401: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.581104ms
Apr 25 20:47:39.401: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 25 20:47:39.401: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-828" to be "running"
Apr 25 20:47:39.411: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.737642ms
Apr 25 20:47:39.411: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 25 20:47:39.411: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-828" to be "running"
Apr 25 20:47:39.421: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.161101ms
Apr 25 20:47:39.421: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 25 20:47:39.421: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-828" to be "running"
Apr 25 20:47:39.433: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.487177ms
Apr 25 20:47:39.433: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 04/25/23 20:47:39.433
Apr 25 20:47:39.458: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Apr 25 20:47:39.470: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.7247ms
Apr 25 20:47:41.482: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023635421s
Apr 25 20:47:43.485: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026925223s
Apr 25 20:47:45.481: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.023153994s
Apr 25 20:47:45.481: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 25 20:47:45.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-828" for this suite. 04/25/23 20:47:45.638
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":259,"skipped":4717,"failed":0}
------------------------------
• [SLOW TEST] [72.893 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:46:32.896
    Apr 25 20:46:32.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename sched-preemption 04/25/23 20:46:32.9
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:46:32.964
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:46:32.974
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 25 20:46:33.070: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 25 20:47:33.163: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 04/25/23 20:47:33.175
    Apr 25 20:47:33.226: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Apr 25 20:47:33.239: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Apr 25 20:47:33.277: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Apr 25 20:47:33.294: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Apr 25 20:47:33.332: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Apr 25 20:47:33.346: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 04/25/23 20:47:33.346
    Apr 25 20:47:33.347: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-828" to be "running"
    Apr 25 20:47:33.368: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 20.170299ms
    Apr 25 20:47:35.392: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044545398s
    Apr 25 20:47:37.389: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041866027s
    Apr 25 20:47:39.379: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.031846812s
    Apr 25 20:47:39.379: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Apr 25 20:47:39.379: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-828" to be "running"
    Apr 25 20:47:39.391: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.255601ms
    Apr 25 20:47:39.391: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 25 20:47:39.391: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-828" to be "running"
    Apr 25 20:47:39.401: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.581104ms
    Apr 25 20:47:39.401: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 25 20:47:39.401: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-828" to be "running"
    Apr 25 20:47:39.411: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.737642ms
    Apr 25 20:47:39.411: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 25 20:47:39.411: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-828" to be "running"
    Apr 25 20:47:39.421: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.161101ms
    Apr 25 20:47:39.421: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 25 20:47:39.421: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-828" to be "running"
    Apr 25 20:47:39.433: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.487177ms
    Apr 25 20:47:39.433: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 04/25/23 20:47:39.433
    Apr 25 20:47:39.458: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Apr 25 20:47:39.470: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.7247ms
    Apr 25 20:47:41.482: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023635421s
    Apr 25 20:47:43.485: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026925223s
    Apr 25 20:47:45.481: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.023153994s
    Apr 25 20:47:45.481: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 20:47:45.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-828" for this suite. 04/25/23 20:47:45.638
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:47:45.794
Apr 25 20:47:45.794: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename resourcequota 04/25/23 20:47:45.795
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:47:45.838
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:47:45.846
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 04/25/23 20:47:45.853
STEP: Creating a ResourceQuota 04/25/23 20:47:50.887
STEP: Ensuring resource quota status is calculated 04/25/23 20:47:50.904
STEP: Creating a Service 04/25/23 20:47:52.918
STEP: Creating a NodePort Service 04/25/23 20:47:52.954
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 04/25/23 20:47:53.008
STEP: Ensuring resource quota status captures service creation 04/25/23 20:47:53.189
STEP: Deleting Services 04/25/23 20:47:55.202
STEP: Ensuring resource quota status released usage 04/25/23 20:47:55.326
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 25 20:47:57.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4992" for this suite. 04/25/23 20:47:57.358
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":260,"skipped":4752,"failed":0}
------------------------------
• [SLOW TEST] [11.583 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:47:45.794
    Apr 25 20:47:45.794: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename resourcequota 04/25/23 20:47:45.795
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:47:45.838
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:47:45.846
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 04/25/23 20:47:45.853
    STEP: Creating a ResourceQuota 04/25/23 20:47:50.887
    STEP: Ensuring resource quota status is calculated 04/25/23 20:47:50.904
    STEP: Creating a Service 04/25/23 20:47:52.918
    STEP: Creating a NodePort Service 04/25/23 20:47:52.954
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 04/25/23 20:47:53.008
    STEP: Ensuring resource quota status captures service creation 04/25/23 20:47:53.189
    STEP: Deleting Services 04/25/23 20:47:55.202
    STEP: Ensuring resource quota status released usage 04/25/23 20:47:55.326
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 25 20:47:57.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4992" for this suite. 04/25/23 20:47:57.358
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:47:57.378
Apr 25 20:47:57.378: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename subpath 04/25/23 20:47:57.381
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:47:57.428
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:47:57.438
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/25/23 20:47:57.449
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-xfzc 04/25/23 20:47:57.474
STEP: Creating a pod to test atomic-volume-subpath 04/25/23 20:47:57.475
Apr 25 20:47:57.497: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-xfzc" in namespace "subpath-599" to be "Succeeded or Failed"
Apr 25 20:47:57.508: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.663222ms
Apr 25 20:47:59.519: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021391994s
Apr 25 20:48:01.532: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 4.035218888s
Apr 25 20:48:03.518: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 6.021223871s
Apr 25 20:48:05.519: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 8.022307681s
Apr 25 20:48:07.520: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 10.023064889s
Apr 25 20:48:09.520: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 12.023079807s
Apr 25 20:48:11.519: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 14.021684768s
Apr 25 20:48:13.520: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 16.022576514s
Apr 25 20:48:15.520: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 18.022845932s
Apr 25 20:48:17.520: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 20.023281104s
Apr 25 20:48:19.522: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 22.025144544s
Apr 25 20:48:21.523: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=false. Elapsed: 24.025445255s
Apr 25 20:48:23.519: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.021399673s
STEP: Saw pod success 04/25/23 20:48:23.519
Apr 25 20:48:23.520: INFO: Pod "pod-subpath-test-secret-xfzc" satisfied condition "Succeeded or Failed"
Apr 25 20:48:23.530: INFO: Trying to get logs from node 10.10.21.190 pod pod-subpath-test-secret-xfzc container test-container-subpath-secret-xfzc: <nil>
STEP: delete the pod 04/25/23 20:48:23.608
Apr 25 20:48:23.635: INFO: Waiting for pod pod-subpath-test-secret-xfzc to disappear
Apr 25 20:48:23.672: INFO: Pod pod-subpath-test-secret-xfzc no longer exists
STEP: Deleting pod pod-subpath-test-secret-xfzc 04/25/23 20:48:23.672
Apr 25 20:48:23.672: INFO: Deleting pod "pod-subpath-test-secret-xfzc" in namespace "subpath-599"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 25 20:48:23.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-599" for this suite. 04/25/23 20:48:23.7
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":261,"skipped":4754,"failed":0}
------------------------------
• [SLOW TEST] [26.339 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:47:57.378
    Apr 25 20:47:57.378: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename subpath 04/25/23 20:47:57.381
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:47:57.428
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:47:57.438
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/25/23 20:47:57.449
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-xfzc 04/25/23 20:47:57.474
    STEP: Creating a pod to test atomic-volume-subpath 04/25/23 20:47:57.475
    Apr 25 20:47:57.497: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-xfzc" in namespace "subpath-599" to be "Succeeded or Failed"
    Apr 25 20:47:57.508: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.663222ms
    Apr 25 20:47:59.519: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021391994s
    Apr 25 20:48:01.532: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 4.035218888s
    Apr 25 20:48:03.518: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 6.021223871s
    Apr 25 20:48:05.519: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 8.022307681s
    Apr 25 20:48:07.520: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 10.023064889s
    Apr 25 20:48:09.520: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 12.023079807s
    Apr 25 20:48:11.519: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 14.021684768s
    Apr 25 20:48:13.520: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 16.022576514s
    Apr 25 20:48:15.520: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 18.022845932s
    Apr 25 20:48:17.520: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 20.023281104s
    Apr 25 20:48:19.522: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=true. Elapsed: 22.025144544s
    Apr 25 20:48:21.523: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Running", Reason="", readiness=false. Elapsed: 24.025445255s
    Apr 25 20:48:23.519: INFO: Pod "pod-subpath-test-secret-xfzc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.021399673s
    STEP: Saw pod success 04/25/23 20:48:23.519
    Apr 25 20:48:23.520: INFO: Pod "pod-subpath-test-secret-xfzc" satisfied condition "Succeeded or Failed"
    Apr 25 20:48:23.530: INFO: Trying to get logs from node 10.10.21.190 pod pod-subpath-test-secret-xfzc container test-container-subpath-secret-xfzc: <nil>
    STEP: delete the pod 04/25/23 20:48:23.608
    Apr 25 20:48:23.635: INFO: Waiting for pod pod-subpath-test-secret-xfzc to disappear
    Apr 25 20:48:23.672: INFO: Pod pod-subpath-test-secret-xfzc no longer exists
    STEP: Deleting pod pod-subpath-test-secret-xfzc 04/25/23 20:48:23.672
    Apr 25 20:48:23.672: INFO: Deleting pod "pod-subpath-test-secret-xfzc" in namespace "subpath-599"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 25 20:48:23.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-599" for this suite. 04/25/23 20:48:23.7
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:48:23.724
Apr 25 20:48:23.724: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:48:23.73
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:48:23.784
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:48:23.793
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 04/25/23 20:48:23.801
Apr 25 20:48:23.821: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023" in namespace "projected-4252" to be "Succeeded or Failed"
Apr 25 20:48:23.832: INFO: Pod "downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023": Phase="Pending", Reason="", readiness=false. Elapsed: 10.749173ms
Apr 25 20:48:25.845: INFO: Pod "downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023687121s
Apr 25 20:48:27.846: INFO: Pod "downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024188587s
STEP: Saw pod success 04/25/23 20:48:27.846
Apr 25 20:48:27.847: INFO: Pod "downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023" satisfied condition "Succeeded or Failed"
Apr 25 20:48:27.887: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023 container client-container: <nil>
STEP: delete the pod 04/25/23 20:48:27.918
Apr 25 20:48:27.948: INFO: Waiting for pod downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023 to disappear
Apr 25 20:48:27.958: INFO: Pod downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 25 20:48:27.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4252" for this suite. 04/25/23 20:48:27.974
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":262,"skipped":4754,"failed":0}
------------------------------
• [4.273 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:48:23.724
    Apr 25 20:48:23.724: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:48:23.73
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:48:23.784
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:48:23.793
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 04/25/23 20:48:23.801
    Apr 25 20:48:23.821: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023" in namespace "projected-4252" to be "Succeeded or Failed"
    Apr 25 20:48:23.832: INFO: Pod "downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023": Phase="Pending", Reason="", readiness=false. Elapsed: 10.749173ms
    Apr 25 20:48:25.845: INFO: Pod "downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023687121s
    Apr 25 20:48:27.846: INFO: Pod "downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024188587s
    STEP: Saw pod success 04/25/23 20:48:27.846
    Apr 25 20:48:27.847: INFO: Pod "downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023" satisfied condition "Succeeded or Failed"
    Apr 25 20:48:27.887: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023 container client-container: <nil>
    STEP: delete the pod 04/25/23 20:48:27.918
    Apr 25 20:48:27.948: INFO: Waiting for pod downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023 to disappear
    Apr 25 20:48:27.958: INFO: Pod downwardapi-volume-e0d3cc04-5b9b-4bf7-9561-06e4a21f1023 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 25 20:48:27.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4252" for this suite. 04/25/23 20:48:27.974
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:48:28.001
Apr 25 20:48:28.002: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename pod-network-test 04/25/23 20:48:28.006
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:48:28.079
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:48:28.089
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-7126 04/25/23 20:48:28.098
STEP: creating a selector 04/25/23 20:48:28.099
STEP: Creating the service pods in kubernetes 04/25/23 20:48:28.1
Apr 25 20:48:28.101: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 25 20:48:28.290: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7126" to be "running and ready"
Apr 25 20:48:28.302: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.118908ms
Apr 25 20:48:28.303: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:48:30.323: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.032633211s
Apr 25 20:48:30.323: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 20:48:32.315: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.024480575s
Apr 25 20:48:32.315: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 20:48:34.314: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.023958731s
Apr 25 20:48:34.314: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 20:48:36.334: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.043590242s
Apr 25 20:48:36.334: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 20:48:38.328: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.038077381s
Apr 25 20:48:38.328: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 20:48:40.334: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.04363408s
Apr 25 20:48:40.334: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 20:48:42.315: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.024403623s
Apr 25 20:48:42.315: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 20:48:44.316: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.025279753s
Apr 25 20:48:44.316: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 20:48:46.315: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.024958083s
Apr 25 20:48:46.315: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 20:48:48.316: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.025420369s
Apr 25 20:48:48.316: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 20:48:50.315: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.024831806s
Apr 25 20:48:50.315: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 25 20:48:50.315: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 25 20:48:50.350: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7126" to be "running and ready"
Apr 25 20:48:50.362: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 12.264518ms
Apr 25 20:48:50.362: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 25 20:48:50.362: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 25 20:48:50.390: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-7126" to be "running and ready"
Apr 25 20:48:50.405: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 14.721146ms
Apr 25 20:48:50.405: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 25 20:48:50.405: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/25/23 20:48:50.415
Apr 25 20:48:50.439: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7126" to be "running"
Apr 25 20:48:50.477: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 37.390377ms
Apr 25 20:48:52.488: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.048899405s
Apr 25 20:48:52.488: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 25 20:48:52.498: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 25 20:48:52.499: INFO: Breadth first check of 172.30.191.32 on host 10.10.21.136...
Apr 25 20:48:52.511: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.142.176:9080/dial?request=hostname&protocol=udp&host=172.30.191.32&port=8081&tries=1'] Namespace:pod-network-test-7126 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:48:52.511: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:48:52.513: INFO: ExecWithOptions: Clientset creation
Apr 25 20:48:52.513: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-7126/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.142.176%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.191.32%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 25 20:48:52.767: INFO: Waiting for responses: map[]
Apr 25 20:48:52.768: INFO: reached 172.30.191.32 after 0/1 tries
Apr 25 20:48:52.768: INFO: Breadth first check of 172.30.226.113 on host 10.10.21.161...
Apr 25 20:48:52.794: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.142.176:9080/dial?request=hostname&protocol=udp&host=172.30.226.113&port=8081&tries=1'] Namespace:pod-network-test-7126 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:48:52.795: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:48:52.798: INFO: ExecWithOptions: Clientset creation
Apr 25 20:48:52.798: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-7126/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.142.176%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.226.113%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 25 20:48:53.024: INFO: Waiting for responses: map[]
Apr 25 20:48:53.025: INFO: reached 172.30.226.113 after 0/1 tries
Apr 25 20:48:53.025: INFO: Breadth first check of 172.30.142.191 on host 10.10.21.190...
Apr 25 20:48:53.052: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.142.176:9080/dial?request=hostname&protocol=udp&host=172.30.142.191&port=8081&tries=1'] Namespace:pod-network-test-7126 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 20:48:53.053: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 20:48:53.055: INFO: ExecWithOptions: Clientset creation
Apr 25 20:48:53.055: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-7126/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.142.176%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.142.191%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 25 20:48:53.326: INFO: Waiting for responses: map[]
Apr 25 20:48:53.326: INFO: reached 172.30.142.191 after 0/1 tries
Apr 25 20:48:53.326: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 25 20:48:53.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7126" for this suite. 04/25/23 20:48:53.344
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":263,"skipped":4759,"failed":0}
------------------------------
• [SLOW TEST] [25.389 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:48:28.001
    Apr 25 20:48:28.002: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename pod-network-test 04/25/23 20:48:28.006
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:48:28.079
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:48:28.089
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-7126 04/25/23 20:48:28.098
    STEP: creating a selector 04/25/23 20:48:28.099
    STEP: Creating the service pods in kubernetes 04/25/23 20:48:28.1
    Apr 25 20:48:28.101: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 25 20:48:28.290: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7126" to be "running and ready"
    Apr 25 20:48:28.302: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.118908ms
    Apr 25 20:48:28.303: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:48:30.323: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.032633211s
    Apr 25 20:48:30.323: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 20:48:32.315: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.024480575s
    Apr 25 20:48:32.315: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 20:48:34.314: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.023958731s
    Apr 25 20:48:34.314: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 20:48:36.334: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.043590242s
    Apr 25 20:48:36.334: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 20:48:38.328: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.038077381s
    Apr 25 20:48:38.328: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 20:48:40.334: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.04363408s
    Apr 25 20:48:40.334: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 20:48:42.315: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.024403623s
    Apr 25 20:48:42.315: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 20:48:44.316: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.025279753s
    Apr 25 20:48:44.316: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 20:48:46.315: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.024958083s
    Apr 25 20:48:46.315: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 20:48:48.316: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.025420369s
    Apr 25 20:48:48.316: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 20:48:50.315: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.024831806s
    Apr 25 20:48:50.315: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 25 20:48:50.315: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 25 20:48:50.350: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7126" to be "running and ready"
    Apr 25 20:48:50.362: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 12.264518ms
    Apr 25 20:48:50.362: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 25 20:48:50.362: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 25 20:48:50.390: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-7126" to be "running and ready"
    Apr 25 20:48:50.405: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 14.721146ms
    Apr 25 20:48:50.405: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 25 20:48:50.405: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/25/23 20:48:50.415
    Apr 25 20:48:50.439: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7126" to be "running"
    Apr 25 20:48:50.477: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 37.390377ms
    Apr 25 20:48:52.488: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.048899405s
    Apr 25 20:48:52.488: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 25 20:48:52.498: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 25 20:48:52.499: INFO: Breadth first check of 172.30.191.32 on host 10.10.21.136...
    Apr 25 20:48:52.511: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.142.176:9080/dial?request=hostname&protocol=udp&host=172.30.191.32&port=8081&tries=1'] Namespace:pod-network-test-7126 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:48:52.511: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:48:52.513: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:48:52.513: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-7126/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.142.176%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.191.32%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 25 20:48:52.767: INFO: Waiting for responses: map[]
    Apr 25 20:48:52.768: INFO: reached 172.30.191.32 after 0/1 tries
    Apr 25 20:48:52.768: INFO: Breadth first check of 172.30.226.113 on host 10.10.21.161...
    Apr 25 20:48:52.794: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.142.176:9080/dial?request=hostname&protocol=udp&host=172.30.226.113&port=8081&tries=1'] Namespace:pod-network-test-7126 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:48:52.795: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:48:52.798: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:48:52.798: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-7126/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.142.176%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.226.113%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 25 20:48:53.024: INFO: Waiting for responses: map[]
    Apr 25 20:48:53.025: INFO: reached 172.30.226.113 after 0/1 tries
    Apr 25 20:48:53.025: INFO: Breadth first check of 172.30.142.191 on host 10.10.21.190...
    Apr 25 20:48:53.052: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.142.176:9080/dial?request=hostname&protocol=udp&host=172.30.142.191&port=8081&tries=1'] Namespace:pod-network-test-7126 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 20:48:53.053: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 20:48:53.055: INFO: ExecWithOptions: Clientset creation
    Apr 25 20:48:53.055: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-7126/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.142.176%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.142.191%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 25 20:48:53.326: INFO: Waiting for responses: map[]
    Apr 25 20:48:53.326: INFO: reached 172.30.142.191 after 0/1 tries
    Apr 25 20:48:53.326: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 25 20:48:53.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-7126" for this suite. 04/25/23 20:48:53.344
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:48:53.392
Apr 25 20:48:53.393: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename podtemplate 04/25/23 20:48:53.396
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:48:53.441
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:48:53.45
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 04/25/23 20:48:53.459
STEP: Replace a pod template 04/25/23 20:48:53.471
Apr 25 20:48:53.512: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Apr 25 20:48:53.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-141" for this suite. 04/25/23 20:48:53.543
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":264,"skipped":4761,"failed":0}
------------------------------
• [0.197 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:48:53.392
    Apr 25 20:48:53.393: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename podtemplate 04/25/23 20:48:53.396
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:48:53.441
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:48:53.45
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 04/25/23 20:48:53.459
    STEP: Replace a pod template 04/25/23 20:48:53.471
    Apr 25 20:48:53.512: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Apr 25 20:48:53.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-141" for this suite. 04/25/23 20:48:53.543
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:48:53.6
Apr 25 20:48:53.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename disruption 04/25/23 20:48:53.602
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:48:53.646
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:48:53.653
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 04/25/23 20:48:53.676
STEP: Waiting for the pdb to be processed 04/25/23 20:48:53.688
STEP: updating the pdb 04/25/23 20:48:55.709
STEP: Waiting for the pdb to be processed 04/25/23 20:48:55.741
STEP: patching the pdb 04/25/23 20:48:57.765
STEP: Waiting for the pdb to be processed 04/25/23 20:48:57.819
STEP: Waiting for the pdb to be deleted 04/25/23 20:48:57.899
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 25 20:48:57.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1714" for this suite. 04/25/23 20:48:57.943
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":265,"skipped":4794,"failed":0}
------------------------------
• [4.373 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:48:53.6
    Apr 25 20:48:53.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename disruption 04/25/23 20:48:53.602
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:48:53.646
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:48:53.653
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 04/25/23 20:48:53.676
    STEP: Waiting for the pdb to be processed 04/25/23 20:48:53.688
    STEP: updating the pdb 04/25/23 20:48:55.709
    STEP: Waiting for the pdb to be processed 04/25/23 20:48:55.741
    STEP: patching the pdb 04/25/23 20:48:57.765
    STEP: Waiting for the pdb to be processed 04/25/23 20:48:57.819
    STEP: Waiting for the pdb to be deleted 04/25/23 20:48:57.899
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 25 20:48:57.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-1714" for this suite. 04/25/23 20:48:57.943
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:48:57.984
Apr 25 20:48:57.984: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename watch 04/25/23 20:48:57.985
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:48:58.035
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:48:58.049
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 04/25/23 20:48:58.064
STEP: creating a watch on configmaps with label B 04/25/23 20:48:58.071
STEP: creating a watch on configmaps with label A or B 04/25/23 20:48:58.078
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 04/25/23 20:48:58.084
Apr 25 20:48:58.097: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40976 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 25 20:48:58.098: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40976 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 04/25/23 20:48:58.098
Apr 25 20:48:58.125: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40977 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 25 20:48:58.125: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40977 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 04/25/23 20:48:58.126
Apr 25 20:48:58.153: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40978 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 25 20:48:58.154: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40978 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 04/25/23 20:48:58.154
Apr 25 20:48:58.179: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40979 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 25 20:48:58.180: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40979 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 04/25/23 20:48:58.18
Apr 25 20:48:58.200: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8043  49b0cfcc-44a5-43c4-956f-b8129f9b7ded 40980 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 25 20:48:58.201: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8043  49b0cfcc-44a5-43c4-956f-b8129f9b7ded 40980 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 04/25/23 20:49:08.202
Apr 25 20:49:08.221: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8043  49b0cfcc-44a5-43c4-956f-b8129f9b7ded 41056 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 25 20:49:08.221: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8043  49b0cfcc-44a5-43c4-956f-b8129f9b7ded 41056 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 25 20:49:18.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8043" for this suite. 04/25/23 20:49:18.246
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":266,"skipped":4809,"failed":0}
------------------------------
• [SLOW TEST] [20.323 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:48:57.984
    Apr 25 20:48:57.984: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename watch 04/25/23 20:48:57.985
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:48:58.035
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:48:58.049
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 04/25/23 20:48:58.064
    STEP: creating a watch on configmaps with label B 04/25/23 20:48:58.071
    STEP: creating a watch on configmaps with label A or B 04/25/23 20:48:58.078
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 04/25/23 20:48:58.084
    Apr 25 20:48:58.097: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40976 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 25 20:48:58.098: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40976 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 04/25/23 20:48:58.098
    Apr 25 20:48:58.125: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40977 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 25 20:48:58.125: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40977 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 04/25/23 20:48:58.126
    Apr 25 20:48:58.153: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40978 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 25 20:48:58.154: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40978 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 04/25/23 20:48:58.154
    Apr 25 20:48:58.179: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40979 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 25 20:48:58.180: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8043  52fc33a1-bdb1-491f-9a0e-68e1cc6144dc 40979 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 04/25/23 20:48:58.18
    Apr 25 20:48:58.200: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8043  49b0cfcc-44a5-43c4-956f-b8129f9b7ded 40980 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 25 20:48:58.201: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8043  49b0cfcc-44a5-43c4-956f-b8129f9b7ded 40980 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 04/25/23 20:49:08.202
    Apr 25 20:49:08.221: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8043  49b0cfcc-44a5-43c4-956f-b8129f9b7ded 41056 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 25 20:49:08.221: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8043  49b0cfcc-44a5-43c4-956f-b8129f9b7ded 41056 0 2023-04-25 20:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-25 20:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 25 20:49:18.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-8043" for this suite. 04/25/23 20:49:18.246
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:49:18.316
Apr 25 20:49:18.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir 04/25/23 20:49:18.317
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:49:18.386
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:49:18.403
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 04/25/23 20:49:18.442
Apr 25 20:49:18.477: INFO: Waiting up to 5m0s for pod "pod-873ad9ea-008f-4f97-a98f-edd638316a5d" in namespace "emptydir-6236" to be "Succeeded or Failed"
Apr 25 20:49:18.492: INFO: Pod "pod-873ad9ea-008f-4f97-a98f-edd638316a5d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.455494ms
Apr 25 20:49:20.506: INFO: Pod "pod-873ad9ea-008f-4f97-a98f-edd638316a5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029279682s
Apr 25 20:49:22.507: INFO: Pod "pod-873ad9ea-008f-4f97-a98f-edd638316a5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030012934s
STEP: Saw pod success 04/25/23 20:49:22.507
Apr 25 20:49:22.508: INFO: Pod "pod-873ad9ea-008f-4f97-a98f-edd638316a5d" satisfied condition "Succeeded or Failed"
Apr 25 20:49:22.523: INFO: Trying to get logs from node 10.10.21.190 pod pod-873ad9ea-008f-4f97-a98f-edd638316a5d container test-container: <nil>
STEP: delete the pod 04/25/23 20:49:22.61
Apr 25 20:49:22.666: INFO: Waiting for pod pod-873ad9ea-008f-4f97-a98f-edd638316a5d to disappear
Apr 25 20:49:22.684: INFO: Pod pod-873ad9ea-008f-4f97-a98f-edd638316a5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 25 20:49:22.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6236" for this suite. 04/25/23 20:49:22.704
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":267,"skipped":4835,"failed":0}
------------------------------
• [4.440 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:49:18.316
    Apr 25 20:49:18.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir 04/25/23 20:49:18.317
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:49:18.386
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:49:18.403
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 04/25/23 20:49:18.442
    Apr 25 20:49:18.477: INFO: Waiting up to 5m0s for pod "pod-873ad9ea-008f-4f97-a98f-edd638316a5d" in namespace "emptydir-6236" to be "Succeeded or Failed"
    Apr 25 20:49:18.492: INFO: Pod "pod-873ad9ea-008f-4f97-a98f-edd638316a5d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.455494ms
    Apr 25 20:49:20.506: INFO: Pod "pod-873ad9ea-008f-4f97-a98f-edd638316a5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029279682s
    Apr 25 20:49:22.507: INFO: Pod "pod-873ad9ea-008f-4f97-a98f-edd638316a5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030012934s
    STEP: Saw pod success 04/25/23 20:49:22.507
    Apr 25 20:49:22.508: INFO: Pod "pod-873ad9ea-008f-4f97-a98f-edd638316a5d" satisfied condition "Succeeded or Failed"
    Apr 25 20:49:22.523: INFO: Trying to get logs from node 10.10.21.190 pod pod-873ad9ea-008f-4f97-a98f-edd638316a5d container test-container: <nil>
    STEP: delete the pod 04/25/23 20:49:22.61
    Apr 25 20:49:22.666: INFO: Waiting for pod pod-873ad9ea-008f-4f97-a98f-edd638316a5d to disappear
    Apr 25 20:49:22.684: INFO: Pod pod-873ad9ea-008f-4f97-a98f-edd638316a5d no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 25 20:49:22.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6236" for this suite. 04/25/23 20:49:22.704
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:49:22.766
Apr 25 20:49:22.766: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-lifecycle-hook 04/25/23 20:49:22.768
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:49:22.824
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:49:22.837
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/25/23 20:49:22.909
Apr 25 20:49:22.941: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7152" to be "running and ready"
Apr 25 20:49:22.956: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 14.643509ms
Apr 25 20:49:22.956: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:49:24.972: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031021301s
Apr 25 20:49:24.972: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:49:26.973: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.03161938s
Apr 25 20:49:26.973: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 25 20:49:26.973: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 04/25/23 20:49:26.987
Apr 25 20:49:27.005: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-7152" to be "running and ready"
Apr 25 20:49:27.023: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 18.308154ms
Apr 25 20:49:27.024: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:49:29.040: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034784542s
Apr 25 20:49:29.040: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 25 20:49:31.040: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.034684207s
Apr 25 20:49:31.040: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Apr 25 20:49:31.040: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 04/25/23 20:49:31.055
Apr 25 20:49:31.081: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 25 20:49:31.096: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 25 20:49:33.097: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 25 20:49:33.118: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 04/25/23 20:49:33.118
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 25 20:49:33.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7152" for this suite. 04/25/23 20:49:33.306
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":268,"skipped":4850,"failed":0}
------------------------------
• [SLOW TEST] [10.579 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:49:22.766
    Apr 25 20:49:22.766: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/25/23 20:49:22.768
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:49:22.824
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:49:22.837
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/25/23 20:49:22.909
    Apr 25 20:49:22.941: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7152" to be "running and ready"
    Apr 25 20:49:22.956: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 14.643509ms
    Apr 25 20:49:22.956: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:49:24.972: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031021301s
    Apr 25 20:49:24.972: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:49:26.973: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.03161938s
    Apr 25 20:49:26.973: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 25 20:49:26.973: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 04/25/23 20:49:26.987
    Apr 25 20:49:27.005: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-7152" to be "running and ready"
    Apr 25 20:49:27.023: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 18.308154ms
    Apr 25 20:49:27.024: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:49:29.040: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034784542s
    Apr 25 20:49:29.040: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 20:49:31.040: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.034684207s
    Apr 25 20:49:31.040: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Apr 25 20:49:31.040: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 04/25/23 20:49:31.055
    Apr 25 20:49:31.081: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 25 20:49:31.096: INFO: Pod pod-with-prestop-exec-hook still exists
    Apr 25 20:49:33.097: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 25 20:49:33.118: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 04/25/23 20:49:33.118
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 25 20:49:33.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-7152" for this suite. 04/25/23 20:49:33.306
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:49:33.356
Apr 25 20:49:33.356: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename dns 04/25/23 20:49:33.357
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:49:33.397
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:49:33.413
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 04/25/23 20:49:33.427
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7917.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7917.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 177.27.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.27.177_udp@PTR;check="$$(dig +tcp +noall +answer +search 177.27.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.27.177_tcp@PTR;sleep 1; done
 04/25/23 20:49:33.541
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7917.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7917.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 177.27.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.27.177_udp@PTR;check="$$(dig +tcp +noall +answer +search 177.27.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.27.177_tcp@PTR;sleep 1; done
 04/25/23 20:49:33.541
STEP: creating a pod to probe DNS 04/25/23 20:49:33.542
STEP: submitting the pod to kubernetes 04/25/23 20:49:33.542
Apr 25 20:49:33.572: INFO: Waiting up to 15m0s for pod "dns-test-403f5eb0-280e-4286-a83a-27da49c159b9" in namespace "dns-7917" to be "running"
Apr 25 20:49:33.589: INFO: Pod "dns-test-403f5eb0-280e-4286-a83a-27da49c159b9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.819819ms
Apr 25 20:49:35.605: INFO: Pod "dns-test-403f5eb0-280e-4286-a83a-27da49c159b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.032725875s
Apr 25 20:49:35.606: INFO: Pod "dns-test-403f5eb0-280e-4286-a83a-27da49c159b9" satisfied condition "running"
STEP: retrieving the pod 04/25/23 20:49:35.606
STEP: looking for the results for each expected name from probers 04/25/23 20:49:35.622
Apr 25 20:49:35.689: INFO: Unable to read wheezy_udp@dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
Apr 25 20:49:35.709: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
Apr 25 20:49:35.730: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
Apr 25 20:49:35.773: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
Apr 25 20:49:35.913: INFO: Unable to read jessie_udp@dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
Apr 25 20:49:35.932: INFO: Unable to read jessie_tcp@dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
Apr 25 20:49:35.954: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
Apr 25 20:49:36.001: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
Apr 25 20:49:36.103: INFO: Lookups using dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9 failed for: [wheezy_udp@dns-test-service.dns-7917.svc.cluster.local wheezy_tcp@dns-test-service.dns-7917.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local jessie_udp@dns-test-service.dns-7917.svc.cluster.local jessie_tcp@dns-test-service.dns-7917.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local]

Apr 25 20:49:41.325: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
Apr 25 20:49:41.499: INFO: Lookups using dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9 failed for: [jessie_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local]

Apr 25 20:49:46.486: INFO: DNS probes using dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9 succeeded

STEP: deleting the pod 04/25/23 20:49:46.486
STEP: deleting the test service 04/25/23 20:49:46.531
STEP: deleting the test headless service 04/25/23 20:49:46.644
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 25 20:49:46.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7917" for this suite. 04/25/23 20:49:46.691
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":269,"skipped":4867,"failed":0}
------------------------------
• [SLOW TEST] [13.360 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:49:33.356
    Apr 25 20:49:33.356: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename dns 04/25/23 20:49:33.357
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:49:33.397
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:49:33.413
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 04/25/23 20:49:33.427
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7917.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7917.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 177.27.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.27.177_udp@PTR;check="$$(dig +tcp +noall +answer +search 177.27.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.27.177_tcp@PTR;sleep 1; done
     04/25/23 20:49:33.541
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7917.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7917.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 177.27.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.27.177_udp@PTR;check="$$(dig +tcp +noall +answer +search 177.27.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.27.177_tcp@PTR;sleep 1; done
     04/25/23 20:49:33.541
    STEP: creating a pod to probe DNS 04/25/23 20:49:33.542
    STEP: submitting the pod to kubernetes 04/25/23 20:49:33.542
    Apr 25 20:49:33.572: INFO: Waiting up to 15m0s for pod "dns-test-403f5eb0-280e-4286-a83a-27da49c159b9" in namespace "dns-7917" to be "running"
    Apr 25 20:49:33.589: INFO: Pod "dns-test-403f5eb0-280e-4286-a83a-27da49c159b9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.819819ms
    Apr 25 20:49:35.605: INFO: Pod "dns-test-403f5eb0-280e-4286-a83a-27da49c159b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.032725875s
    Apr 25 20:49:35.606: INFO: Pod "dns-test-403f5eb0-280e-4286-a83a-27da49c159b9" satisfied condition "running"
    STEP: retrieving the pod 04/25/23 20:49:35.606
    STEP: looking for the results for each expected name from probers 04/25/23 20:49:35.622
    Apr 25 20:49:35.689: INFO: Unable to read wheezy_udp@dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
    Apr 25 20:49:35.709: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
    Apr 25 20:49:35.730: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
    Apr 25 20:49:35.773: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
    Apr 25 20:49:35.913: INFO: Unable to read jessie_udp@dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
    Apr 25 20:49:35.932: INFO: Unable to read jessie_tcp@dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
    Apr 25 20:49:35.954: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
    Apr 25 20:49:36.001: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
    Apr 25 20:49:36.103: INFO: Lookups using dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9 failed for: [wheezy_udp@dns-test-service.dns-7917.svc.cluster.local wheezy_tcp@dns-test-service.dns-7917.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local jessie_udp@dns-test-service.dns-7917.svc.cluster.local jessie_tcp@dns-test-service.dns-7917.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local]

    Apr 25 20:49:41.325: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local from pod dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9: the server could not find the requested resource (get pods dns-test-403f5eb0-280e-4286-a83a-27da49c159b9)
    Apr 25 20:49:41.499: INFO: Lookups using dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9 failed for: [jessie_udp@_http._tcp.dns-test-service.dns-7917.svc.cluster.local]

    Apr 25 20:49:46.486: INFO: DNS probes using dns-7917/dns-test-403f5eb0-280e-4286-a83a-27da49c159b9 succeeded

    STEP: deleting the pod 04/25/23 20:49:46.486
    STEP: deleting the test service 04/25/23 20:49:46.531
    STEP: deleting the test headless service 04/25/23 20:49:46.644
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 25 20:49:46.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7917" for this suite. 04/25/23 20:49:46.691
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:49:46.724
Apr 25 20:49:46.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 20:49:46.726
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:49:46.766
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:49:46.784
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 20:49:46.839
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:49:47.177
STEP: Deploying the webhook pod 04/25/23 20:49:47.222
STEP: Wait for the deployment to be ready 04/25/23 20:49:47.263
Apr 25 20:49:47.291: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/25/23 20:49:49.344
STEP: Verifying the service has paired with the endpoint 04/25/23 20:49:49.429
Apr 25 20:49:50.430: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Apr 25 20:49:50.444: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Registering the custom resource webhook via the AdmissionRegistration API 04/25/23 20:49:50.995
STEP: Creating a custom resource that should be denied by the webhook 04/25/23 20:49:51.082
STEP: Creating a custom resource whose deletion would be denied by the webhook 04/25/23 20:49:53.194
STEP: Updating the custom resource with disallowed data should be denied 04/25/23 20:49:53.233
STEP: Deleting the custom resource should be denied 04/25/23 20:49:53.272
STEP: Remove the offending key and value from the custom resource data 04/25/23 20:49:53.338
STEP: Deleting the updated custom resource should be successful 04/25/23 20:49:53.381
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 20:49:54.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6753" for this suite. 04/25/23 20:49:54.034
STEP: Destroying namespace "webhook-6753-markers" for this suite. 04/25/23 20:49:54.079
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":270,"skipped":4881,"failed":0}
------------------------------
• [SLOW TEST] [7.499 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:49:46.724
    Apr 25 20:49:46.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 20:49:46.726
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:49:46.766
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:49:46.784
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 20:49:46.839
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 20:49:47.177
    STEP: Deploying the webhook pod 04/25/23 20:49:47.222
    STEP: Wait for the deployment to be ready 04/25/23 20:49:47.263
    Apr 25 20:49:47.291: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/25/23 20:49:49.344
    STEP: Verifying the service has paired with the endpoint 04/25/23 20:49:49.429
    Apr 25 20:49:50.430: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Apr 25 20:49:50.444: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 04/25/23 20:49:50.995
    STEP: Creating a custom resource that should be denied by the webhook 04/25/23 20:49:51.082
    STEP: Creating a custom resource whose deletion would be denied by the webhook 04/25/23 20:49:53.194
    STEP: Updating the custom resource with disallowed data should be denied 04/25/23 20:49:53.233
    STEP: Deleting the custom resource should be denied 04/25/23 20:49:53.272
    STEP: Remove the offending key and value from the custom resource data 04/25/23 20:49:53.338
    STEP: Deleting the updated custom resource should be successful 04/25/23 20:49:53.381
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 20:49:54.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6753" for this suite. 04/25/23 20:49:54.034
    STEP: Destroying namespace "webhook-6753-markers" for this suite. 04/25/23 20:49:54.079
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:49:54.232
Apr 25 20:49:54.233: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename cronjob 04/25/23 20:49:54.234
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:49:54.277
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:49:54.292
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 04/25/23 20:49:54.307
STEP: Ensuring a job is scheduled 04/25/23 20:49:54.329
STEP: Ensuring exactly one is scheduled 04/25/23 20:50:00.348
STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/25/23 20:50:00.362
STEP: Ensuring the job is replaced with a new one 04/25/23 20:50:00.374
STEP: Removing cronjob 04/25/23 20:51:00.388
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 25 20:51:00.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5933" for this suite. 04/25/23 20:51:00.428
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":271,"skipped":4919,"failed":0}
------------------------------
• [SLOW TEST] [66.219 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:49:54.232
    Apr 25 20:49:54.233: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename cronjob 04/25/23 20:49:54.234
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:49:54.277
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:49:54.292
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 04/25/23 20:49:54.307
    STEP: Ensuring a job is scheduled 04/25/23 20:49:54.329
    STEP: Ensuring exactly one is scheduled 04/25/23 20:50:00.348
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/25/23 20:50:00.362
    STEP: Ensuring the job is replaced with a new one 04/25/23 20:50:00.374
    STEP: Removing cronjob 04/25/23 20:51:00.388
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 25 20:51:00.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5933" for this suite. 04/25/23 20:51:00.428
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:51:00.452
Apr 25 20:51:00.453: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename var-expansion 04/25/23 20:51:00.456
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:51:00.498
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:51:00.512
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Apr 25 20:51:00.554: INFO: Waiting up to 2m0s for pod "var-expansion-cf685898-784f-4cb1-83d3-cd913bd92f3c" in namespace "var-expansion-960" to be "container 0 failed with reason CreateContainerConfigError"
Apr 25 20:51:00.568: INFO: Pod "var-expansion-cf685898-784f-4cb1-83d3-cd913bd92f3c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.365077ms
Apr 25 20:51:02.591: INFO: Pod "var-expansion-cf685898-784f-4cb1-83d3-cd913bd92f3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036850381s
Apr 25 20:51:02.592: INFO: Pod "var-expansion-cf685898-784f-4cb1-83d3-cd913bd92f3c" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Apr 25 20:51:02.592: INFO: Deleting pod "var-expansion-cf685898-784f-4cb1-83d3-cd913bd92f3c" in namespace "var-expansion-960"
Apr 25 20:51:02.617: INFO: Wait up to 5m0s for pod "var-expansion-cf685898-784f-4cb1-83d3-cd913bd92f3c" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 25 20:51:06.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-960" for this suite. 04/25/23 20:51:06.686
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":272,"skipped":4927,"failed":0}
------------------------------
• [SLOW TEST] [6.258 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:51:00.452
    Apr 25 20:51:00.453: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename var-expansion 04/25/23 20:51:00.456
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:51:00.498
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:51:00.512
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Apr 25 20:51:00.554: INFO: Waiting up to 2m0s for pod "var-expansion-cf685898-784f-4cb1-83d3-cd913bd92f3c" in namespace "var-expansion-960" to be "container 0 failed with reason CreateContainerConfigError"
    Apr 25 20:51:00.568: INFO: Pod "var-expansion-cf685898-784f-4cb1-83d3-cd913bd92f3c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.365077ms
    Apr 25 20:51:02.591: INFO: Pod "var-expansion-cf685898-784f-4cb1-83d3-cd913bd92f3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036850381s
    Apr 25 20:51:02.592: INFO: Pod "var-expansion-cf685898-784f-4cb1-83d3-cd913bd92f3c" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Apr 25 20:51:02.592: INFO: Deleting pod "var-expansion-cf685898-784f-4cb1-83d3-cd913bd92f3c" in namespace "var-expansion-960"
    Apr 25 20:51:02.617: INFO: Wait up to 5m0s for pod "var-expansion-cf685898-784f-4cb1-83d3-cd913bd92f3c" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 25 20:51:06.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-960" for this suite. 04/25/23 20:51:06.686
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:51:06.712
Apr 25 20:51:06.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename discovery 04/25/23 20:51:06.716
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:51:06.755
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:51:06.768
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 04/25/23 20:51:06.788
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Apr 25 20:51:07.326: INFO: Checking APIGroup: apiregistration.k8s.io
Apr 25 20:51:07.332: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Apr 25 20:51:07.332: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Apr 25 20:51:07.332: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Apr 25 20:51:07.332: INFO: Checking APIGroup: apps
Apr 25 20:51:07.337: INFO: PreferredVersion.GroupVersion: apps/v1
Apr 25 20:51:07.337: INFO: Versions found [{apps/v1 v1}]
Apr 25 20:51:07.337: INFO: apps/v1 matches apps/v1
Apr 25 20:51:07.337: INFO: Checking APIGroup: events.k8s.io
Apr 25 20:51:07.343: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Apr 25 20:51:07.344: INFO: Versions found [{events.k8s.io/v1 v1}]
Apr 25 20:51:07.344: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Apr 25 20:51:07.345: INFO: Checking APIGroup: authentication.k8s.io
Apr 25 20:51:07.350: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Apr 25 20:51:07.351: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Apr 25 20:51:07.351: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Apr 25 20:51:07.351: INFO: Checking APIGroup: authorization.k8s.io
Apr 25 20:51:07.357: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Apr 25 20:51:07.357: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Apr 25 20:51:07.358: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Apr 25 20:51:07.358: INFO: Checking APIGroup: autoscaling
Apr 25 20:51:07.364: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Apr 25 20:51:07.364: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Apr 25 20:51:07.365: INFO: autoscaling/v2 matches autoscaling/v2
Apr 25 20:51:07.365: INFO: Checking APIGroup: batch
Apr 25 20:51:07.371: INFO: PreferredVersion.GroupVersion: batch/v1
Apr 25 20:51:07.371: INFO: Versions found [{batch/v1 v1}]
Apr 25 20:51:07.371: INFO: batch/v1 matches batch/v1
Apr 25 20:51:07.371: INFO: Checking APIGroup: certificates.k8s.io
Apr 25 20:51:07.376: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Apr 25 20:51:07.377: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Apr 25 20:51:07.377: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Apr 25 20:51:07.377: INFO: Checking APIGroup: networking.k8s.io
Apr 25 20:51:07.383: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Apr 25 20:51:07.383: INFO: Versions found [{networking.k8s.io/v1 v1}]
Apr 25 20:51:07.383: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Apr 25 20:51:07.383: INFO: Checking APIGroup: policy
Apr 25 20:51:07.389: INFO: PreferredVersion.GroupVersion: policy/v1
Apr 25 20:51:07.389: INFO: Versions found [{policy/v1 v1}]
Apr 25 20:51:07.389: INFO: policy/v1 matches policy/v1
Apr 25 20:51:07.389: INFO: Checking APIGroup: rbac.authorization.k8s.io
Apr 25 20:51:07.396: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Apr 25 20:51:07.396: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Apr 25 20:51:07.396: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Apr 25 20:51:07.396: INFO: Checking APIGroup: storage.k8s.io
Apr 25 20:51:07.402: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Apr 25 20:51:07.402: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Apr 25 20:51:07.402: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Apr 25 20:51:07.402: INFO: Checking APIGroup: admissionregistration.k8s.io
Apr 25 20:51:07.408: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Apr 25 20:51:07.408: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Apr 25 20:51:07.408: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Apr 25 20:51:07.408: INFO: Checking APIGroup: apiextensions.k8s.io
Apr 25 20:51:07.414: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Apr 25 20:51:07.414: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Apr 25 20:51:07.415: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Apr 25 20:51:07.415: INFO: Checking APIGroup: scheduling.k8s.io
Apr 25 20:51:07.421: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Apr 25 20:51:07.421: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Apr 25 20:51:07.421: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Apr 25 20:51:07.422: INFO: Checking APIGroup: coordination.k8s.io
Apr 25 20:51:07.427: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Apr 25 20:51:07.427: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Apr 25 20:51:07.427: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Apr 25 20:51:07.427: INFO: Checking APIGroup: node.k8s.io
Apr 25 20:51:07.433: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Apr 25 20:51:07.433: INFO: Versions found [{node.k8s.io/v1 v1}]
Apr 25 20:51:07.433: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Apr 25 20:51:07.434: INFO: Checking APIGroup: discovery.k8s.io
Apr 25 20:51:07.438: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Apr 25 20:51:07.438: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Apr 25 20:51:07.438: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Apr 25 20:51:07.438: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Apr 25 20:51:07.445: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Apr 25 20:51:07.445: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Apr 25 20:51:07.445: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Apr 25 20:51:07.445: INFO: Checking APIGroup: crd.projectcalico.org
Apr 25 20:51:07.451: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Apr 25 20:51:07.451: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Apr 25 20:51:07.451: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
Apr 25 20:51:07.451: INFO: Checking APIGroup: snapshot.storage.k8s.io
Apr 25 20:51:07.456: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
Apr 25 20:51:07.456: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1}]
Apr 25 20:51:07.456: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
Apr 25 20:51:07.456: INFO: Checking APIGroup: ibm.com
Apr 25 20:51:07.463: INFO: PreferredVersion.GroupVersion: ibm.com/v1alpha1
Apr 25 20:51:07.463: INFO: Versions found [{ibm.com/v1alpha1 v1alpha1}]
Apr 25 20:51:07.463: INFO: ibm.com/v1alpha1 matches ibm.com/v1alpha1
Apr 25 20:51:07.463: INFO: Checking APIGroup: metrics.k8s.io
Apr 25 20:51:07.471: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Apr 25 20:51:07.471: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Apr 25 20:51:07.471: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Apr 25 20:51:07.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-7001" for this suite. 04/25/23 20:51:07.487
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":273,"skipped":4929,"failed":0}
------------------------------
• [0.802 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:51:06.712
    Apr 25 20:51:06.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename discovery 04/25/23 20:51:06.716
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:51:06.755
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:51:06.768
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 04/25/23 20:51:06.788
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Apr 25 20:51:07.326: INFO: Checking APIGroup: apiregistration.k8s.io
    Apr 25 20:51:07.332: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Apr 25 20:51:07.332: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Apr 25 20:51:07.332: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Apr 25 20:51:07.332: INFO: Checking APIGroup: apps
    Apr 25 20:51:07.337: INFO: PreferredVersion.GroupVersion: apps/v1
    Apr 25 20:51:07.337: INFO: Versions found [{apps/v1 v1}]
    Apr 25 20:51:07.337: INFO: apps/v1 matches apps/v1
    Apr 25 20:51:07.337: INFO: Checking APIGroup: events.k8s.io
    Apr 25 20:51:07.343: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Apr 25 20:51:07.344: INFO: Versions found [{events.k8s.io/v1 v1}]
    Apr 25 20:51:07.344: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Apr 25 20:51:07.345: INFO: Checking APIGroup: authentication.k8s.io
    Apr 25 20:51:07.350: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Apr 25 20:51:07.351: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Apr 25 20:51:07.351: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Apr 25 20:51:07.351: INFO: Checking APIGroup: authorization.k8s.io
    Apr 25 20:51:07.357: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Apr 25 20:51:07.357: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Apr 25 20:51:07.358: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Apr 25 20:51:07.358: INFO: Checking APIGroup: autoscaling
    Apr 25 20:51:07.364: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Apr 25 20:51:07.364: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Apr 25 20:51:07.365: INFO: autoscaling/v2 matches autoscaling/v2
    Apr 25 20:51:07.365: INFO: Checking APIGroup: batch
    Apr 25 20:51:07.371: INFO: PreferredVersion.GroupVersion: batch/v1
    Apr 25 20:51:07.371: INFO: Versions found [{batch/v1 v1}]
    Apr 25 20:51:07.371: INFO: batch/v1 matches batch/v1
    Apr 25 20:51:07.371: INFO: Checking APIGroup: certificates.k8s.io
    Apr 25 20:51:07.376: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Apr 25 20:51:07.377: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Apr 25 20:51:07.377: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Apr 25 20:51:07.377: INFO: Checking APIGroup: networking.k8s.io
    Apr 25 20:51:07.383: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Apr 25 20:51:07.383: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Apr 25 20:51:07.383: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Apr 25 20:51:07.383: INFO: Checking APIGroup: policy
    Apr 25 20:51:07.389: INFO: PreferredVersion.GroupVersion: policy/v1
    Apr 25 20:51:07.389: INFO: Versions found [{policy/v1 v1}]
    Apr 25 20:51:07.389: INFO: policy/v1 matches policy/v1
    Apr 25 20:51:07.389: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Apr 25 20:51:07.396: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Apr 25 20:51:07.396: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Apr 25 20:51:07.396: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Apr 25 20:51:07.396: INFO: Checking APIGroup: storage.k8s.io
    Apr 25 20:51:07.402: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Apr 25 20:51:07.402: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Apr 25 20:51:07.402: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Apr 25 20:51:07.402: INFO: Checking APIGroup: admissionregistration.k8s.io
    Apr 25 20:51:07.408: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Apr 25 20:51:07.408: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Apr 25 20:51:07.408: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Apr 25 20:51:07.408: INFO: Checking APIGroup: apiextensions.k8s.io
    Apr 25 20:51:07.414: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Apr 25 20:51:07.414: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Apr 25 20:51:07.415: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Apr 25 20:51:07.415: INFO: Checking APIGroup: scheduling.k8s.io
    Apr 25 20:51:07.421: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Apr 25 20:51:07.421: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Apr 25 20:51:07.421: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Apr 25 20:51:07.422: INFO: Checking APIGroup: coordination.k8s.io
    Apr 25 20:51:07.427: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Apr 25 20:51:07.427: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Apr 25 20:51:07.427: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Apr 25 20:51:07.427: INFO: Checking APIGroup: node.k8s.io
    Apr 25 20:51:07.433: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Apr 25 20:51:07.433: INFO: Versions found [{node.k8s.io/v1 v1}]
    Apr 25 20:51:07.433: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Apr 25 20:51:07.434: INFO: Checking APIGroup: discovery.k8s.io
    Apr 25 20:51:07.438: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Apr 25 20:51:07.438: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Apr 25 20:51:07.438: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Apr 25 20:51:07.438: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Apr 25 20:51:07.445: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Apr 25 20:51:07.445: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Apr 25 20:51:07.445: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Apr 25 20:51:07.445: INFO: Checking APIGroup: crd.projectcalico.org
    Apr 25 20:51:07.451: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
    Apr 25 20:51:07.451: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
    Apr 25 20:51:07.451: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
    Apr 25 20:51:07.451: INFO: Checking APIGroup: snapshot.storage.k8s.io
    Apr 25 20:51:07.456: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
    Apr 25 20:51:07.456: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1}]
    Apr 25 20:51:07.456: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
    Apr 25 20:51:07.456: INFO: Checking APIGroup: ibm.com
    Apr 25 20:51:07.463: INFO: PreferredVersion.GroupVersion: ibm.com/v1alpha1
    Apr 25 20:51:07.463: INFO: Versions found [{ibm.com/v1alpha1 v1alpha1}]
    Apr 25 20:51:07.463: INFO: ibm.com/v1alpha1 matches ibm.com/v1alpha1
    Apr 25 20:51:07.463: INFO: Checking APIGroup: metrics.k8s.io
    Apr 25 20:51:07.471: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Apr 25 20:51:07.471: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Apr 25 20:51:07.471: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Apr 25 20:51:07.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-7001" for this suite. 04/25/23 20:51:07.487
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:51:07.52
Apr 25 20:51:07.521: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 20:51:07.523
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:51:07.562
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:51:07.577
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 04/25/23 20:51:07.592
Apr 25 20:51:07.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 create -f -'
Apr 25 20:51:08.539: INFO: stderr: ""
Apr 25 20:51:08.539: INFO: stdout: "pod/pause created\n"
Apr 25 20:51:08.539: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 25 20:51:08.539: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-789" to be "running and ready"
Apr 25 20:51:08.554: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 14.573246ms
Apr 25 20:51:08.554: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '10.10.21.190' to be 'Running' but was 'Pending'
Apr 25 20:51:10.570: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030700648s
Apr 25 20:51:10.570: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '10.10.21.190' to be 'Running' but was 'Pending'
Apr 25 20:51:12.569: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.03013765s
Apr 25 20:51:12.570: INFO: Pod "pause" satisfied condition "running and ready"
Apr 25 20:51:12.570: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 04/25/23 20:51:12.57
Apr 25 20:51:12.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 label pods pause testing-label=testing-label-value'
Apr 25 20:51:12.728: INFO: stderr: ""
Apr 25 20:51:12.728: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 04/25/23 20:51:12.728
Apr 25 20:51:12.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 get pod pause -L testing-label'
Apr 25 20:51:12.866: INFO: stderr: ""
Apr 25 20:51:12.866: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod 04/25/23 20:51:12.866
Apr 25 20:51:12.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 label pods pause testing-label-'
Apr 25 20:51:13.039: INFO: stderr: ""
Apr 25 20:51:13.039: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 04/25/23 20:51:13.039
Apr 25 20:51:13.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 get pod pause -L testing-label'
Apr 25 20:51:13.163: INFO: stderr: ""
Apr 25 20:51:13.163: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 04/25/23 20:51:13.163
Apr 25 20:51:13.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 delete --grace-period=0 --force -f -'
Apr 25 20:51:13.308: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 20:51:13.308: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 25 20:51:13.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 get rc,svc -l name=pause --no-headers'
Apr 25 20:51:13.453: INFO: stderr: "No resources found in kubectl-789 namespace.\n"
Apr 25 20:51:13.454: INFO: stdout: ""
Apr 25 20:51:13.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 25 20:51:13.582: INFO: stderr: ""
Apr 25 20:51:13.582: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 20:51:13.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-789" for this suite. 04/25/23 20:51:13.602
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":274,"skipped":4958,"failed":0}
------------------------------
• [SLOW TEST] [6.110 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:51:07.52
    Apr 25 20:51:07.521: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 20:51:07.523
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:51:07.562
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:51:07.577
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 04/25/23 20:51:07.592
    Apr 25 20:51:07.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 create -f -'
    Apr 25 20:51:08.539: INFO: stderr: ""
    Apr 25 20:51:08.539: INFO: stdout: "pod/pause created\n"
    Apr 25 20:51:08.539: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Apr 25 20:51:08.539: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-789" to be "running and ready"
    Apr 25 20:51:08.554: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 14.573246ms
    Apr 25 20:51:08.554: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '10.10.21.190' to be 'Running' but was 'Pending'
    Apr 25 20:51:10.570: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030700648s
    Apr 25 20:51:10.570: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '10.10.21.190' to be 'Running' but was 'Pending'
    Apr 25 20:51:12.569: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.03013765s
    Apr 25 20:51:12.570: INFO: Pod "pause" satisfied condition "running and ready"
    Apr 25 20:51:12.570: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 04/25/23 20:51:12.57
    Apr 25 20:51:12.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 label pods pause testing-label=testing-label-value'
    Apr 25 20:51:12.728: INFO: stderr: ""
    Apr 25 20:51:12.728: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 04/25/23 20:51:12.728
    Apr 25 20:51:12.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 get pod pause -L testing-label'
    Apr 25 20:51:12.866: INFO: stderr: ""
    Apr 25 20:51:12.866: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 04/25/23 20:51:12.866
    Apr 25 20:51:12.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 label pods pause testing-label-'
    Apr 25 20:51:13.039: INFO: stderr: ""
    Apr 25 20:51:13.039: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 04/25/23 20:51:13.039
    Apr 25 20:51:13.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 get pod pause -L testing-label'
    Apr 25 20:51:13.163: INFO: stderr: ""
    Apr 25 20:51:13.163: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 04/25/23 20:51:13.163
    Apr 25 20:51:13.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 delete --grace-period=0 --force -f -'
    Apr 25 20:51:13.308: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 25 20:51:13.308: INFO: stdout: "pod \"pause\" force deleted\n"
    Apr 25 20:51:13.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 get rc,svc -l name=pause --no-headers'
    Apr 25 20:51:13.453: INFO: stderr: "No resources found in kubectl-789 namespace.\n"
    Apr 25 20:51:13.454: INFO: stdout: ""
    Apr 25 20:51:13.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-789 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 25 20:51:13.582: INFO: stderr: ""
    Apr 25 20:51:13.582: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 20:51:13.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-789" for this suite. 04/25/23 20:51:13.602
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:51:13.636
Apr 25 20:51:13.636: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename daemonsets 04/25/23 20:51:13.641
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:51:13.676
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:51:13.688
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Apr 25 20:51:13.770: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 04/25/23 20:51:13.789
Apr 25 20:51:13.873: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 20:51:13.873: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:51:14.906: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 20:51:14.906: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 20:51:15.907: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 25 20:51:15.907: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 04/25/23 20:51:15.968
STEP: Check that daemon pods images are updated. 04/25/23 20:51:16.003
Apr 25 20:51:16.018: INFO: Wrong image for pod: daemon-set-5gtjs. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 25 20:51:16.018: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 25 20:51:16.018: INFO: Wrong image for pod: daemon-set-qb5mp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 25 20:51:17.053: INFO: Wrong image for pod: daemon-set-5gtjs. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 25 20:51:17.054: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 25 20:51:18.055: INFO: Wrong image for pod: daemon-set-5gtjs. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 25 20:51:18.055: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 25 20:51:19.049: INFO: Wrong image for pod: daemon-set-5gtjs. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 25 20:51:19.049: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 25 20:51:19.049: INFO: Pod daemon-set-w7wtq is not available
Apr 25 20:51:20.052: INFO: Wrong image for pod: daemon-set-5gtjs. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 25 20:51:20.052: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 25 20:51:20.052: INFO: Pod daemon-set-w7wtq is not available
Apr 25 20:51:21.052: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 25 20:51:22.054: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 25 20:51:22.054: INFO: Pod daemon-set-mmttx is not available
Apr 25 20:51:23.052: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 25 20:51:23.053: INFO: Pod daemon-set-mmttx is not available
Apr 25 20:51:25.051: INFO: Pod daemon-set-zm6lr is not available
STEP: Check that daemon pods are still running on every node of the cluster. 04/25/23 20:51:25.067
Apr 25 20:51:25.095: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 25 20:51:25.096: INFO: Node 10.10.21.190 is running 0 daemon pod, expected 1
Apr 25 20:51:26.131: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 25 20:51:26.131: INFO: Node 10.10.21.190 is running 0 daemon pod, expected 1
Apr 25 20:51:27.132: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 25 20:51:27.132: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/25/23 20:51:27.218
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1211, will wait for the garbage collector to delete the pods 04/25/23 20:51:27.218
Apr 25 20:51:27.314: INFO: Deleting DaemonSet.extensions daemon-set took: 30.594936ms
Apr 25 20:51:27.415: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.855084ms
Apr 25 20:51:29.830: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 20:51:29.830: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 25 20:51:29.845: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"41703"},"items":null}

Apr 25 20:51:29.859: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"41703"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 25 20:51:29.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1211" for this suite. 04/25/23 20:51:29.924
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":275,"skipped":4980,"failed":0}
------------------------------
• [SLOW TEST] [16.310 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:51:13.636
    Apr 25 20:51:13.636: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename daemonsets 04/25/23 20:51:13.641
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:51:13.676
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:51:13.688
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Apr 25 20:51:13.770: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 04/25/23 20:51:13.789
    Apr 25 20:51:13.873: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 20:51:13.873: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:51:14.906: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 20:51:14.906: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 20:51:15.907: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 25 20:51:15.907: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 04/25/23 20:51:15.968
    STEP: Check that daemon pods images are updated. 04/25/23 20:51:16.003
    Apr 25 20:51:16.018: INFO: Wrong image for pod: daemon-set-5gtjs. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 25 20:51:16.018: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 25 20:51:16.018: INFO: Wrong image for pod: daemon-set-qb5mp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 25 20:51:17.053: INFO: Wrong image for pod: daemon-set-5gtjs. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 25 20:51:17.054: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 25 20:51:18.055: INFO: Wrong image for pod: daemon-set-5gtjs. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 25 20:51:18.055: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 25 20:51:19.049: INFO: Wrong image for pod: daemon-set-5gtjs. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 25 20:51:19.049: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 25 20:51:19.049: INFO: Pod daemon-set-w7wtq is not available
    Apr 25 20:51:20.052: INFO: Wrong image for pod: daemon-set-5gtjs. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 25 20:51:20.052: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 25 20:51:20.052: INFO: Pod daemon-set-w7wtq is not available
    Apr 25 20:51:21.052: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 25 20:51:22.054: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 25 20:51:22.054: INFO: Pod daemon-set-mmttx is not available
    Apr 25 20:51:23.052: INFO: Wrong image for pod: daemon-set-7bdgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 25 20:51:23.053: INFO: Pod daemon-set-mmttx is not available
    Apr 25 20:51:25.051: INFO: Pod daemon-set-zm6lr is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 04/25/23 20:51:25.067
    Apr 25 20:51:25.095: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 25 20:51:25.096: INFO: Node 10.10.21.190 is running 0 daemon pod, expected 1
    Apr 25 20:51:26.131: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 25 20:51:26.131: INFO: Node 10.10.21.190 is running 0 daemon pod, expected 1
    Apr 25 20:51:27.132: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 25 20:51:27.132: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/25/23 20:51:27.218
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1211, will wait for the garbage collector to delete the pods 04/25/23 20:51:27.218
    Apr 25 20:51:27.314: INFO: Deleting DaemonSet.extensions daemon-set took: 30.594936ms
    Apr 25 20:51:27.415: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.855084ms
    Apr 25 20:51:29.830: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 20:51:29.830: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 25 20:51:29.845: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"41703"},"items":null}

    Apr 25 20:51:29.859: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"41703"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 20:51:29.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-1211" for this suite. 04/25/23 20:51:29.924
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:51:29.963
Apr 25 20:51:29.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:51:29.965
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:51:30.008
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:51:30.024
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-5a98eef5-db91-47ee-a380-c19a3fa63c24 04/25/23 20:51:30.038
STEP: Creating a pod to test consume configMaps 04/25/23 20:51:30.054
Apr 25 20:51:30.085: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf" in namespace "projected-9909" to be "Succeeded or Failed"
Apr 25 20:51:30.101: INFO: Pod "pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf": Phase="Pending", Reason="", readiness=false. Elapsed: 15.869257ms
Apr 25 20:51:32.117: INFO: Pod "pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031303732s
Apr 25 20:51:34.117: INFO: Pod "pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031844601s
STEP: Saw pod success 04/25/23 20:51:34.117
Apr 25 20:51:34.118: INFO: Pod "pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf" satisfied condition "Succeeded or Failed"
Apr 25 20:51:34.132: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf container agnhost-container: <nil>
STEP: delete the pod 04/25/23 20:51:34.236
Apr 25 20:51:34.290: INFO: Waiting for pod pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf to disappear
Apr 25 20:51:34.304: INFO: Pod pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 25 20:51:34.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9909" for this suite. 04/25/23 20:51:34.323
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":276,"skipped":5032,"failed":0}
------------------------------
• [4.396 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:51:29.963
    Apr 25 20:51:29.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:51:29.965
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:51:30.008
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:51:30.024
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-5a98eef5-db91-47ee-a380-c19a3fa63c24 04/25/23 20:51:30.038
    STEP: Creating a pod to test consume configMaps 04/25/23 20:51:30.054
    Apr 25 20:51:30.085: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf" in namespace "projected-9909" to be "Succeeded or Failed"
    Apr 25 20:51:30.101: INFO: Pod "pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf": Phase="Pending", Reason="", readiness=false. Elapsed: 15.869257ms
    Apr 25 20:51:32.117: INFO: Pod "pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031303732s
    Apr 25 20:51:34.117: INFO: Pod "pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031844601s
    STEP: Saw pod success 04/25/23 20:51:34.117
    Apr 25 20:51:34.118: INFO: Pod "pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf" satisfied condition "Succeeded or Failed"
    Apr 25 20:51:34.132: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 20:51:34.236
    Apr 25 20:51:34.290: INFO: Waiting for pod pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf to disappear
    Apr 25 20:51:34.304: INFO: Pod pod-projected-configmaps-ed688dfd-3d20-414c-9fba-043549280faf no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 25 20:51:34.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9909" for this suite. 04/25/23 20:51:34.323
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:51:34.366
Apr 25 20:51:34.366: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename aggregator 04/25/23 20:51:34.367
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:51:34.468
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:51:34.485
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Apr 25 20:51:34.504: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 04/25/23 20:51:34.506
Apr 25 20:51:35.138: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr 25 20:51:37.281: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:51:39.294: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:51:41.294: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:51:43.295: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:51:45.294: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:51:47.295: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:51:49.295: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:51:51.294: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:51:53.297: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:51:55.293: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:51:57.322: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:51:59.294: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 20:52:01.587: INFO: Waited 274.196192ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 04/25/23 20:52:01.866
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 04/25/23 20:52:01.881
STEP: List APIServices 04/25/23 20:52:01.908
Apr 25 20:52:01.948: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Apr 25 20:52:02.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1586" for this suite. 04/25/23 20:52:02.811
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":277,"skipped":5079,"failed":0}
------------------------------
• [SLOW TEST] [28.467 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:51:34.366
    Apr 25 20:51:34.366: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename aggregator 04/25/23 20:51:34.367
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:51:34.468
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:51:34.485
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Apr 25 20:51:34.504: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 04/25/23 20:51:34.506
    Apr 25 20:51:35.138: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Apr 25 20:51:37.281: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:51:39.294: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:51:41.294: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:51:43.295: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:51:45.294: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:51:47.295: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:51:49.295: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:51:51.294: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:51:53.297: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:51:55.293: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:51:57.322: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:51:59.294: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 20, 51, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 25 20:52:01.587: INFO: Waited 274.196192ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 04/25/23 20:52:01.866
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 04/25/23 20:52:01.881
    STEP: List APIServices 04/25/23 20:52:01.908
    Apr 25 20:52:01.948: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Apr 25 20:52:02.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-1586" for this suite. 04/25/23 20:52:02.811
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:52:02.843
Apr 25 20:52:02.843: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename svcaccounts 04/25/23 20:52:02.846
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:52:02.893
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:52:02.906
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Apr 25 20:52:02.988: INFO: created pod pod-service-account-defaultsa
Apr 25 20:52:02.988: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 25 20:52:03.007: INFO: created pod pod-service-account-mountsa
Apr 25 20:52:03.007: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 25 20:52:03.024: INFO: created pod pod-service-account-nomountsa
Apr 25 20:52:03.024: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 25 20:52:03.064: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 25 20:52:03.064: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 25 20:52:03.092: INFO: created pod pod-service-account-mountsa-mountspec
Apr 25 20:52:03.092: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 25 20:52:03.109: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 25 20:52:03.109: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 25 20:52:03.128: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 25 20:52:03.128: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 25 20:52:03.150: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 25 20:52:03.150: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 25 20:52:03.176: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 25 20:52:03.176: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 25 20:52:03.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9083" for this suite. 04/25/23 20:52:03.191
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":278,"skipped":5109,"failed":0}
------------------------------
• [0.375 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:52:02.843
    Apr 25 20:52:02.843: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename svcaccounts 04/25/23 20:52:02.846
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:52:02.893
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:52:02.906
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Apr 25 20:52:02.988: INFO: created pod pod-service-account-defaultsa
    Apr 25 20:52:02.988: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Apr 25 20:52:03.007: INFO: created pod pod-service-account-mountsa
    Apr 25 20:52:03.007: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Apr 25 20:52:03.024: INFO: created pod pod-service-account-nomountsa
    Apr 25 20:52:03.024: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Apr 25 20:52:03.064: INFO: created pod pod-service-account-defaultsa-mountspec
    Apr 25 20:52:03.064: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Apr 25 20:52:03.092: INFO: created pod pod-service-account-mountsa-mountspec
    Apr 25 20:52:03.092: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Apr 25 20:52:03.109: INFO: created pod pod-service-account-nomountsa-mountspec
    Apr 25 20:52:03.109: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Apr 25 20:52:03.128: INFO: created pod pod-service-account-defaultsa-nomountspec
    Apr 25 20:52:03.128: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Apr 25 20:52:03.150: INFO: created pod pod-service-account-mountsa-nomountspec
    Apr 25 20:52:03.150: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Apr 25 20:52:03.176: INFO: created pod pod-service-account-nomountsa-nomountspec
    Apr 25 20:52:03.176: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 25 20:52:03.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9083" for this suite. 04/25/23 20:52:03.191
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:52:03.223
Apr 25 20:52:03.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 20:52:03.226
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:52:03.272
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:52:03.287
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8631 04/25/23 20:52:03.335
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/25/23 20:52:03.404
STEP: creating service externalsvc in namespace services-8631 04/25/23 20:52:03.405
STEP: creating replication controller externalsvc in namespace services-8631 04/25/23 20:52:03.441
I0425 20:52:03.464438      23 runners.go:193] Created replication controller with name: externalsvc, namespace: services-8631, replica count: 2
I0425 20:52:06.515714      23 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 04/25/23 20:52:06.527
Apr 25 20:52:06.641: INFO: Creating new exec pod
Apr 25 20:52:06.663: INFO: Waiting up to 5m0s for pod "execpod9npns" in namespace "services-8631" to be "running"
Apr 25 20:52:06.682: INFO: Pod "execpod9npns": Phase="Pending", Reason="", readiness=false. Elapsed: 17.979596ms
Apr 25 20:52:08.705: INFO: Pod "execpod9npns": Phase="Running", Reason="", readiness=true. Elapsed: 2.041432254s
Apr 25 20:52:08.706: INFO: Pod "execpod9npns" satisfied condition "running"
Apr 25 20:52:08.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-8631 exec execpod9npns -- /bin/sh -x -c nslookup clusterip-service.services-8631.svc.cluster.local'
Apr 25 20:52:09.149: INFO: stderr: "+ nslookup clusterip-service.services-8631.svc.cluster.local\n"
Apr 25 20:52:09.149: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nclusterip-service.services-8631.svc.cluster.local\tcanonical name = externalsvc.services-8631.svc.cluster.local.\nName:\texternalsvc.services-8631.svc.cluster.local\nAddress: 172.21.153.190\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8631, will wait for the garbage collector to delete the pods 04/25/23 20:52:09.149
Apr 25 20:52:09.290: INFO: Deleting ReplicationController externalsvc took: 76.619819ms
Apr 25 20:52:09.490: INFO: Terminating ReplicationController externalsvc pods took: 200.626131ms
Apr 25 20:52:12.255: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 20:52:12.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8631" for this suite. 04/25/23 20:52:12.306
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":279,"skipped":5109,"failed":0}
------------------------------
• [SLOW TEST] [9.111 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:52:03.223
    Apr 25 20:52:03.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 20:52:03.226
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:52:03.272
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:52:03.287
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8631 04/25/23 20:52:03.335
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/25/23 20:52:03.404
    STEP: creating service externalsvc in namespace services-8631 04/25/23 20:52:03.405
    STEP: creating replication controller externalsvc in namespace services-8631 04/25/23 20:52:03.441
    I0425 20:52:03.464438      23 runners.go:193] Created replication controller with name: externalsvc, namespace: services-8631, replica count: 2
    I0425 20:52:06.515714      23 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 04/25/23 20:52:06.527
    Apr 25 20:52:06.641: INFO: Creating new exec pod
    Apr 25 20:52:06.663: INFO: Waiting up to 5m0s for pod "execpod9npns" in namespace "services-8631" to be "running"
    Apr 25 20:52:06.682: INFO: Pod "execpod9npns": Phase="Pending", Reason="", readiness=false. Elapsed: 17.979596ms
    Apr 25 20:52:08.705: INFO: Pod "execpod9npns": Phase="Running", Reason="", readiness=true. Elapsed: 2.041432254s
    Apr 25 20:52:08.706: INFO: Pod "execpod9npns" satisfied condition "running"
    Apr 25 20:52:08.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-8631 exec execpod9npns -- /bin/sh -x -c nslookup clusterip-service.services-8631.svc.cluster.local'
    Apr 25 20:52:09.149: INFO: stderr: "+ nslookup clusterip-service.services-8631.svc.cluster.local\n"
    Apr 25 20:52:09.149: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nclusterip-service.services-8631.svc.cluster.local\tcanonical name = externalsvc.services-8631.svc.cluster.local.\nName:\texternalsvc.services-8631.svc.cluster.local\nAddress: 172.21.153.190\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-8631, will wait for the garbage collector to delete the pods 04/25/23 20:52:09.149
    Apr 25 20:52:09.290: INFO: Deleting ReplicationController externalsvc took: 76.619819ms
    Apr 25 20:52:09.490: INFO: Terminating ReplicationController externalsvc pods took: 200.626131ms
    Apr 25 20:52:12.255: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 20:52:12.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8631" for this suite. 04/25/23 20:52:12.306
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:52:12.342
Apr 25 20:52:12.342: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename resourcequota 04/25/23 20:52:12.343
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:52:12.385
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:52:12.398
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 04/25/23 20:52:12.412
STEP: Ensuring ResourceQuota status is calculated 04/25/23 20:52:12.43
STEP: Creating a ResourceQuota with not best effort scope 04/25/23 20:52:14.443
STEP: Ensuring ResourceQuota status is calculated 04/25/23 20:52:14.456
STEP: Creating a best-effort pod 04/25/23 20:52:16.47
STEP: Ensuring resource quota with best effort scope captures the pod usage 04/25/23 20:52:16.508
STEP: Ensuring resource quota with not best effort ignored the pod usage 04/25/23 20:52:18.521
STEP: Deleting the pod 04/25/23 20:52:20.536
STEP: Ensuring resource quota status released the pod usage 04/25/23 20:52:20.627
STEP: Creating a not best-effort pod 04/25/23 20:52:22.639
STEP: Ensuring resource quota with not best effort scope captures the pod usage 04/25/23 20:52:22.707
STEP: Ensuring resource quota with best effort scope ignored the pod usage 04/25/23 20:52:24.721
STEP: Deleting the pod 04/25/23 20:52:26.734
STEP: Ensuring resource quota status released the pod usage 04/25/23 20:52:26.77
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 25 20:52:28.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2881" for this suite. 04/25/23 20:52:28.802
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":280,"skipped":5168,"failed":0}
------------------------------
• [SLOW TEST] [16.494 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:52:12.342
    Apr 25 20:52:12.342: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename resourcequota 04/25/23 20:52:12.343
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:52:12.385
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:52:12.398
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 04/25/23 20:52:12.412
    STEP: Ensuring ResourceQuota status is calculated 04/25/23 20:52:12.43
    STEP: Creating a ResourceQuota with not best effort scope 04/25/23 20:52:14.443
    STEP: Ensuring ResourceQuota status is calculated 04/25/23 20:52:14.456
    STEP: Creating a best-effort pod 04/25/23 20:52:16.47
    STEP: Ensuring resource quota with best effort scope captures the pod usage 04/25/23 20:52:16.508
    STEP: Ensuring resource quota with not best effort ignored the pod usage 04/25/23 20:52:18.521
    STEP: Deleting the pod 04/25/23 20:52:20.536
    STEP: Ensuring resource quota status released the pod usage 04/25/23 20:52:20.627
    STEP: Creating a not best-effort pod 04/25/23 20:52:22.639
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 04/25/23 20:52:22.707
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 04/25/23 20:52:24.721
    STEP: Deleting the pod 04/25/23 20:52:26.734
    STEP: Ensuring resource quota status released the pod usage 04/25/23 20:52:26.77
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 25 20:52:28.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2881" for this suite. 04/25/23 20:52:28.802
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:52:28.837
Apr 25 20:52:28.837: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:52:28.84
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:52:28.92
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:52:28.934
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 04/25/23 20:52:28.949
Apr 25 20:52:29.010: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486" in namespace "projected-5536" to be "Succeeded or Failed"
Apr 25 20:52:29.024: INFO: Pod "downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486": Phase="Pending", Reason="", readiness=false. Elapsed: 13.115487ms
Apr 25 20:52:31.041: INFO: Pod "downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030664445s
Apr 25 20:52:33.070: INFO: Pod "downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486": Phase="Pending", Reason="", readiness=false. Elapsed: 4.059265723s
Apr 25 20:52:35.044: INFO: Pod "downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033749882s
STEP: Saw pod success 04/25/23 20:52:35.044
Apr 25 20:52:35.045: INFO: Pod "downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486" satisfied condition "Succeeded or Failed"
Apr 25 20:52:35.061: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486 container client-container: <nil>
STEP: delete the pod 04/25/23 20:52:35.088
Apr 25 20:52:35.151: INFO: Waiting for pod downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486 to disappear
Apr 25 20:52:35.165: INFO: Pod downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 25 20:52:35.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5536" for this suite. 04/25/23 20:52:35.186
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":281,"skipped":5168,"failed":0}
------------------------------
• [SLOW TEST] [6.372 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:52:28.837
    Apr 25 20:52:28.837: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:52:28.84
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:52:28.92
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:52:28.934
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 04/25/23 20:52:28.949
    Apr 25 20:52:29.010: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486" in namespace "projected-5536" to be "Succeeded or Failed"
    Apr 25 20:52:29.024: INFO: Pod "downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486": Phase="Pending", Reason="", readiness=false. Elapsed: 13.115487ms
    Apr 25 20:52:31.041: INFO: Pod "downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030664445s
    Apr 25 20:52:33.070: INFO: Pod "downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486": Phase="Pending", Reason="", readiness=false. Elapsed: 4.059265723s
    Apr 25 20:52:35.044: INFO: Pod "downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033749882s
    STEP: Saw pod success 04/25/23 20:52:35.044
    Apr 25 20:52:35.045: INFO: Pod "downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486" satisfied condition "Succeeded or Failed"
    Apr 25 20:52:35.061: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486 container client-container: <nil>
    STEP: delete the pod 04/25/23 20:52:35.088
    Apr 25 20:52:35.151: INFO: Waiting for pod downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486 to disappear
    Apr 25 20:52:35.165: INFO: Pod downwardapi-volume-ffc702a1-04b8-4143-a72c-8231b1b7c486 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 25 20:52:35.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5536" for this suite. 04/25/23 20:52:35.186
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:52:35.214
Apr 25 20:52:35.215: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 20:52:35.217
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:52:35.255
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:52:35.269
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 20:52:35.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7537" for this suite. 04/25/23 20:52:35.306
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":282,"skipped":5182,"failed":0}
------------------------------
• [0.118 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:52:35.214
    Apr 25 20:52:35.215: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 20:52:35.217
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:52:35.255
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:52:35.269
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 20:52:35.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7537" for this suite. 04/25/23 20:52:35.306
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:52:35.334
Apr 25 20:52:35.334: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename statefulset 04/25/23 20:52:35.336
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:52:35.405
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:52:35.419
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4568 04/25/23 20:52:35.428
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-4568 04/25/23 20:52:35.468
Apr 25 20:52:35.497: INFO: Found 0 stateful pods, waiting for 1
Apr 25 20:52:45.513: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 04/25/23 20:52:45.538
STEP: Getting /status 04/25/23 20:52:45.564
Apr 25 20:52:45.580: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 04/25/23 20:52:45.58
Apr 25 20:52:45.614: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 04/25/23 20:52:45.616
Apr 25 20:52:45.627: INFO: Observed &StatefulSet event: ADDED
Apr 25 20:52:45.627: INFO: Found Statefulset ss in namespace statefulset-4568 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 25 20:52:45.627: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 04/25/23 20:52:45.627
Apr 25 20:52:45.628: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 25 20:52:45.645: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 04/25/23 20:52:45.645
Apr 25 20:52:45.653: INFO: Observed &StatefulSet event: ADDED
Apr 25 20:52:45.653: INFO: Observed Statefulset ss in namespace statefulset-4568 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 25 20:52:45.653: INFO: Observed &StatefulSet event: MODIFIED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 25 20:52:45.653: INFO: Deleting all statefulset in ns statefulset-4568
Apr 25 20:52:45.663: INFO: Scaling statefulset ss to 0
Apr 25 20:52:55.736: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 20:52:55.748: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 25 20:52:55.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4568" for this suite. 04/25/23 20:52:55.828
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":283,"skipped":5213,"failed":0}
------------------------------
• [SLOW TEST] [20.519 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:52:35.334
    Apr 25 20:52:35.334: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename statefulset 04/25/23 20:52:35.336
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:52:35.405
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:52:35.419
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4568 04/25/23 20:52:35.428
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-4568 04/25/23 20:52:35.468
    Apr 25 20:52:35.497: INFO: Found 0 stateful pods, waiting for 1
    Apr 25 20:52:45.513: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 04/25/23 20:52:45.538
    STEP: Getting /status 04/25/23 20:52:45.564
    Apr 25 20:52:45.580: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 04/25/23 20:52:45.58
    Apr 25 20:52:45.614: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 04/25/23 20:52:45.616
    Apr 25 20:52:45.627: INFO: Observed &StatefulSet event: ADDED
    Apr 25 20:52:45.627: INFO: Found Statefulset ss in namespace statefulset-4568 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 25 20:52:45.627: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 04/25/23 20:52:45.627
    Apr 25 20:52:45.628: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 25 20:52:45.645: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 04/25/23 20:52:45.645
    Apr 25 20:52:45.653: INFO: Observed &StatefulSet event: ADDED
    Apr 25 20:52:45.653: INFO: Observed Statefulset ss in namespace statefulset-4568 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 25 20:52:45.653: INFO: Observed &StatefulSet event: MODIFIED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 25 20:52:45.653: INFO: Deleting all statefulset in ns statefulset-4568
    Apr 25 20:52:45.663: INFO: Scaling statefulset ss to 0
    Apr 25 20:52:55.736: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 25 20:52:55.748: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 25 20:52:55.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4568" for this suite. 04/25/23 20:52:55.828
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:52:55.856
Apr 25 20:52:55.857: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-probe 04/25/23 20:52:55.861
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:52:55.911
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:52:55.927
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b in namespace container-probe-2595 04/25/23 20:52:55.942
Apr 25 20:52:55.975: INFO: Waiting up to 5m0s for pod "liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b" in namespace "container-probe-2595" to be "not pending"
Apr 25 20:52:55.998: INFO: Pod "liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b": Phase="Pending", Reason="", readiness=false. Elapsed: 22.607753ms
Apr 25 20:52:58.015: INFO: Pod "liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b": Phase="Running", Reason="", readiness=true. Elapsed: 2.040199889s
Apr 25 20:52:58.015: INFO: Pod "liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b" satisfied condition "not pending"
Apr 25 20:52:58.015: INFO: Started pod liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b in namespace container-probe-2595
STEP: checking the pod's current state and verifying that restartCount is present 04/25/23 20:52:58.015
Apr 25 20:52:58.050: INFO: Initial restart count of pod liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b is 0
Apr 25 20:53:18.235: INFO: Restart count of pod container-probe-2595/liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b is now 1 (20.184274654s elapsed)
Apr 25 20:53:38.401: INFO: Restart count of pod container-probe-2595/liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b is now 2 (40.350851959s elapsed)
Apr 25 20:53:58.570: INFO: Restart count of pod container-probe-2595/liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b is now 3 (1m0.519348262s elapsed)
Apr 25 20:54:16.730: INFO: Restart count of pod container-probe-2595/liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b is now 4 (1m18.680011561s elapsed)
Apr 25 20:55:29.396: INFO: Restart count of pod container-probe-2595/liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b is now 5 (2m31.345386274s elapsed)
STEP: deleting the pod 04/25/23 20:55:29.396
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 25 20:55:29.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2595" for this suite. 04/25/23 20:55:29.489
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":284,"skipped":5214,"failed":0}
------------------------------
• [SLOW TEST] [153.658 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:52:55.856
    Apr 25 20:52:55.857: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-probe 04/25/23 20:52:55.861
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:52:55.911
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:52:55.927
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b in namespace container-probe-2595 04/25/23 20:52:55.942
    Apr 25 20:52:55.975: INFO: Waiting up to 5m0s for pod "liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b" in namespace "container-probe-2595" to be "not pending"
    Apr 25 20:52:55.998: INFO: Pod "liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b": Phase="Pending", Reason="", readiness=false. Elapsed: 22.607753ms
    Apr 25 20:52:58.015: INFO: Pod "liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b": Phase="Running", Reason="", readiness=true. Elapsed: 2.040199889s
    Apr 25 20:52:58.015: INFO: Pod "liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b" satisfied condition "not pending"
    Apr 25 20:52:58.015: INFO: Started pod liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b in namespace container-probe-2595
    STEP: checking the pod's current state and verifying that restartCount is present 04/25/23 20:52:58.015
    Apr 25 20:52:58.050: INFO: Initial restart count of pod liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b is 0
    Apr 25 20:53:18.235: INFO: Restart count of pod container-probe-2595/liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b is now 1 (20.184274654s elapsed)
    Apr 25 20:53:38.401: INFO: Restart count of pod container-probe-2595/liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b is now 2 (40.350851959s elapsed)
    Apr 25 20:53:58.570: INFO: Restart count of pod container-probe-2595/liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b is now 3 (1m0.519348262s elapsed)
    Apr 25 20:54:16.730: INFO: Restart count of pod container-probe-2595/liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b is now 4 (1m18.680011561s elapsed)
    Apr 25 20:55:29.396: INFO: Restart count of pod container-probe-2595/liveness-33db2229-c8c0-41b6-9a87-bb94fb9a4c8b is now 5 (2m31.345386274s elapsed)
    STEP: deleting the pod 04/25/23 20:55:29.396
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 25 20:55:29.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2595" for this suite. 04/25/23 20:55:29.489
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:55:29.528
Apr 25 20:55:29.528: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 20:55:29.53
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:55:29.587
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:55:29.602
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 04/25/23 20:55:29.616
Apr 25 20:55:29.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 create -f -'
Apr 25 20:55:30.676: INFO: stderr: ""
Apr 25 20:55:30.676: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/25/23 20:55:30.676
Apr 25 20:55:30.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 25 20:55:30.801: INFO: stderr: ""
Apr 25 20:55:30.802: INFO: stdout: "update-demo-nautilus-5n9b8 update-demo-nautilus-zg9zb "
Apr 25 20:55:30.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-5n9b8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 25 20:55:30.925: INFO: stderr: ""
Apr 25 20:55:30.925: INFO: stdout: ""
Apr 25 20:55:30.925: INFO: update-demo-nautilus-5n9b8 is created but not running
Apr 25 20:55:35.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 25 20:55:36.055: INFO: stderr: ""
Apr 25 20:55:36.055: INFO: stdout: "update-demo-nautilus-5n9b8 update-demo-nautilus-zg9zb "
Apr 25 20:55:36.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-5n9b8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 25 20:55:36.187: INFO: stderr: ""
Apr 25 20:55:36.187: INFO: stdout: "true"
Apr 25 20:55:36.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-5n9b8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 25 20:55:36.316: INFO: stderr: ""
Apr 25 20:55:36.316: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 25 20:55:36.316: INFO: validating pod update-demo-nautilus-5n9b8
Apr 25 20:55:36.372: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 20:55:36.372: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 20:55:36.372: INFO: update-demo-nautilus-5n9b8 is verified up and running
Apr 25 20:55:36.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-zg9zb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 25 20:55:36.487: INFO: stderr: ""
Apr 25 20:55:36.487: INFO: stdout: "true"
Apr 25 20:55:36.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-zg9zb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 25 20:55:36.621: INFO: stderr: ""
Apr 25 20:55:36.621: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 25 20:55:36.621: INFO: validating pod update-demo-nautilus-zg9zb
Apr 25 20:55:36.681: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 20:55:36.681: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 20:55:36.681: INFO: update-demo-nautilus-zg9zb is verified up and running
STEP: scaling down the replication controller 04/25/23 20:55:36.681
Apr 25 20:55:36.686: INFO: scanned /root for discovery docs: <nil>
Apr 25 20:55:36.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Apr 25 20:55:37.873: INFO: stderr: ""
Apr 25 20:55:37.873: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/25/23 20:55:37.873
Apr 25 20:55:37.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 25 20:55:38.006: INFO: stderr: ""
Apr 25 20:55:38.006: INFO: stdout: "update-demo-nautilus-5n9b8 update-demo-nautilus-zg9zb "
STEP: Replicas for name=update-demo: expected=1 actual=2 04/25/23 20:55:38.006
Apr 25 20:55:43.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 25 20:55:43.153: INFO: stderr: ""
Apr 25 20:55:43.153: INFO: stdout: "update-demo-nautilus-5n9b8 "
Apr 25 20:55:43.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-5n9b8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 25 20:55:43.278: INFO: stderr: ""
Apr 25 20:55:43.278: INFO: stdout: "true"
Apr 25 20:55:43.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-5n9b8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 25 20:55:43.372: INFO: stderr: ""
Apr 25 20:55:43.372: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 25 20:55:43.372: INFO: validating pod update-demo-nautilus-5n9b8
Apr 25 20:55:43.406: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 20:55:43.406: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 20:55:43.406: INFO: update-demo-nautilus-5n9b8 is verified up and running
STEP: scaling up the replication controller 04/25/23 20:55:43.406
Apr 25 20:55:43.408: INFO: scanned /root for discovery docs: <nil>
Apr 25 20:55:43.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Apr 25 20:55:44.601: INFO: stderr: ""
Apr 25 20:55:44.601: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/25/23 20:55:44.601
Apr 25 20:55:44.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 25 20:55:44.730: INFO: stderr: ""
Apr 25 20:55:44.730: INFO: stdout: "update-demo-nautilus-5n9b8 update-demo-nautilus-n8b54 "
Apr 25 20:55:44.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-5n9b8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 25 20:55:44.847: INFO: stderr: ""
Apr 25 20:55:44.847: INFO: stdout: "true"
Apr 25 20:55:44.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-5n9b8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 25 20:55:44.987: INFO: stderr: ""
Apr 25 20:55:44.987: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 25 20:55:44.987: INFO: validating pod update-demo-nautilus-5n9b8
Apr 25 20:55:45.044: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 20:55:45.044: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 20:55:45.044: INFO: update-demo-nautilus-5n9b8 is verified up and running
Apr 25 20:55:45.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-n8b54 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 25 20:55:45.170: INFO: stderr: ""
Apr 25 20:55:45.170: INFO: stdout: "true"
Apr 25 20:55:45.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-n8b54 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 25 20:55:45.286: INFO: stderr: ""
Apr 25 20:55:45.286: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 25 20:55:45.286: INFO: validating pod update-demo-nautilus-n8b54
Apr 25 20:55:45.350: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 20:55:45.350: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 20:55:45.351: INFO: update-demo-nautilus-n8b54 is verified up and running
STEP: using delete to clean up resources 04/25/23 20:55:45.351
Apr 25 20:55:45.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 delete --grace-period=0 --force -f -'
Apr 25 20:55:45.511: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 20:55:45.511: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 25 20:55:45.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get rc,svc -l name=update-demo --no-headers'
Apr 25 20:55:45.645: INFO: stderr: "No resources found in kubectl-3649 namespace.\n"
Apr 25 20:55:45.645: INFO: stdout: ""
Apr 25 20:55:45.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 25 20:55:45.792: INFO: stderr: ""
Apr 25 20:55:45.792: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 20:55:45.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3649" for this suite. 04/25/23 20:55:45.812
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":285,"skipped":5277,"failed":0}
------------------------------
• [SLOW TEST] [16.308 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:55:29.528
    Apr 25 20:55:29.528: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 20:55:29.53
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:55:29.587
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:55:29.602
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 04/25/23 20:55:29.616
    Apr 25 20:55:29.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 create -f -'
    Apr 25 20:55:30.676: INFO: stderr: ""
    Apr 25 20:55:30.676: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/25/23 20:55:30.676
    Apr 25 20:55:30.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 25 20:55:30.801: INFO: stderr: ""
    Apr 25 20:55:30.802: INFO: stdout: "update-demo-nautilus-5n9b8 update-demo-nautilus-zg9zb "
    Apr 25 20:55:30.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-5n9b8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 25 20:55:30.925: INFO: stderr: ""
    Apr 25 20:55:30.925: INFO: stdout: ""
    Apr 25 20:55:30.925: INFO: update-demo-nautilus-5n9b8 is created but not running
    Apr 25 20:55:35.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 25 20:55:36.055: INFO: stderr: ""
    Apr 25 20:55:36.055: INFO: stdout: "update-demo-nautilus-5n9b8 update-demo-nautilus-zg9zb "
    Apr 25 20:55:36.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-5n9b8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 25 20:55:36.187: INFO: stderr: ""
    Apr 25 20:55:36.187: INFO: stdout: "true"
    Apr 25 20:55:36.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-5n9b8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 25 20:55:36.316: INFO: stderr: ""
    Apr 25 20:55:36.316: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 25 20:55:36.316: INFO: validating pod update-demo-nautilus-5n9b8
    Apr 25 20:55:36.372: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 25 20:55:36.372: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 25 20:55:36.372: INFO: update-demo-nautilus-5n9b8 is verified up and running
    Apr 25 20:55:36.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-zg9zb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 25 20:55:36.487: INFO: stderr: ""
    Apr 25 20:55:36.487: INFO: stdout: "true"
    Apr 25 20:55:36.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-zg9zb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 25 20:55:36.621: INFO: stderr: ""
    Apr 25 20:55:36.621: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 25 20:55:36.621: INFO: validating pod update-demo-nautilus-zg9zb
    Apr 25 20:55:36.681: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 25 20:55:36.681: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 25 20:55:36.681: INFO: update-demo-nautilus-zg9zb is verified up and running
    STEP: scaling down the replication controller 04/25/23 20:55:36.681
    Apr 25 20:55:36.686: INFO: scanned /root for discovery docs: <nil>
    Apr 25 20:55:36.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Apr 25 20:55:37.873: INFO: stderr: ""
    Apr 25 20:55:37.873: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/25/23 20:55:37.873
    Apr 25 20:55:37.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 25 20:55:38.006: INFO: stderr: ""
    Apr 25 20:55:38.006: INFO: stdout: "update-demo-nautilus-5n9b8 update-demo-nautilus-zg9zb "
    STEP: Replicas for name=update-demo: expected=1 actual=2 04/25/23 20:55:38.006
    Apr 25 20:55:43.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 25 20:55:43.153: INFO: stderr: ""
    Apr 25 20:55:43.153: INFO: stdout: "update-demo-nautilus-5n9b8 "
    Apr 25 20:55:43.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-5n9b8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 25 20:55:43.278: INFO: stderr: ""
    Apr 25 20:55:43.278: INFO: stdout: "true"
    Apr 25 20:55:43.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-5n9b8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 25 20:55:43.372: INFO: stderr: ""
    Apr 25 20:55:43.372: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 25 20:55:43.372: INFO: validating pod update-demo-nautilus-5n9b8
    Apr 25 20:55:43.406: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 25 20:55:43.406: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 25 20:55:43.406: INFO: update-demo-nautilus-5n9b8 is verified up and running
    STEP: scaling up the replication controller 04/25/23 20:55:43.406
    Apr 25 20:55:43.408: INFO: scanned /root for discovery docs: <nil>
    Apr 25 20:55:43.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Apr 25 20:55:44.601: INFO: stderr: ""
    Apr 25 20:55:44.601: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/25/23 20:55:44.601
    Apr 25 20:55:44.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 25 20:55:44.730: INFO: stderr: ""
    Apr 25 20:55:44.730: INFO: stdout: "update-demo-nautilus-5n9b8 update-demo-nautilus-n8b54 "
    Apr 25 20:55:44.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-5n9b8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 25 20:55:44.847: INFO: stderr: ""
    Apr 25 20:55:44.847: INFO: stdout: "true"
    Apr 25 20:55:44.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-5n9b8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 25 20:55:44.987: INFO: stderr: ""
    Apr 25 20:55:44.987: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 25 20:55:44.987: INFO: validating pod update-demo-nautilus-5n9b8
    Apr 25 20:55:45.044: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 25 20:55:45.044: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 25 20:55:45.044: INFO: update-demo-nautilus-5n9b8 is verified up and running
    Apr 25 20:55:45.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-n8b54 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 25 20:55:45.170: INFO: stderr: ""
    Apr 25 20:55:45.170: INFO: stdout: "true"
    Apr 25 20:55:45.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods update-demo-nautilus-n8b54 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 25 20:55:45.286: INFO: stderr: ""
    Apr 25 20:55:45.286: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 25 20:55:45.286: INFO: validating pod update-demo-nautilus-n8b54
    Apr 25 20:55:45.350: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 25 20:55:45.350: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 25 20:55:45.351: INFO: update-demo-nautilus-n8b54 is verified up and running
    STEP: using delete to clean up resources 04/25/23 20:55:45.351
    Apr 25 20:55:45.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 delete --grace-period=0 --force -f -'
    Apr 25 20:55:45.511: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 25 20:55:45.511: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Apr 25 20:55:45.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get rc,svc -l name=update-demo --no-headers'
    Apr 25 20:55:45.645: INFO: stderr: "No resources found in kubectl-3649 namespace.\n"
    Apr 25 20:55:45.645: INFO: stdout: ""
    Apr 25 20:55:45.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3649 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 25 20:55:45.792: INFO: stderr: ""
    Apr 25 20:55:45.792: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 20:55:45.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3649" for this suite. 04/25/23 20:55:45.812
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:55:45.852
Apr 25 20:55:45.852: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 20:55:45.854
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:55:45.894
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:55:45.908
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-ce019a4f-9652-4dcd-b057-46c8b780332c 04/25/23 20:55:45.922
STEP: Creating a pod to test consume secrets 04/25/23 20:55:45.941
Apr 25 20:55:45.995: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0" in namespace "projected-371" to be "Succeeded or Failed"
Apr 25 20:55:46.010: INFO: Pod "pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.469115ms
Apr 25 20:55:48.027: INFO: Pod "pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031831435s
Apr 25 20:55:50.030: INFO: Pod "pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03438904s
Apr 25 20:55:52.033: INFO: Pod "pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037869756s
STEP: Saw pod success 04/25/23 20:55:52.033
Apr 25 20:55:52.033: INFO: Pod "pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0" satisfied condition "Succeeded or Failed"
Apr 25 20:55:52.048: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/25/23 20:55:52.156
Apr 25 20:55:52.203: INFO: Waiting for pod pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0 to disappear
Apr 25 20:55:52.217: INFO: Pod pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 25 20:55:52.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-371" for this suite. 04/25/23 20:55:52.237
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":286,"skipped":5316,"failed":0}
------------------------------
• [SLOW TEST] [6.415 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:55:45.852
    Apr 25 20:55:45.852: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 20:55:45.854
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:55:45.894
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:55:45.908
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-ce019a4f-9652-4dcd-b057-46c8b780332c 04/25/23 20:55:45.922
    STEP: Creating a pod to test consume secrets 04/25/23 20:55:45.941
    Apr 25 20:55:45.995: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0" in namespace "projected-371" to be "Succeeded or Failed"
    Apr 25 20:55:46.010: INFO: Pod "pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.469115ms
    Apr 25 20:55:48.027: INFO: Pod "pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031831435s
    Apr 25 20:55:50.030: INFO: Pod "pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03438904s
    Apr 25 20:55:52.033: INFO: Pod "pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037869756s
    STEP: Saw pod success 04/25/23 20:55:52.033
    Apr 25 20:55:52.033: INFO: Pod "pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0" satisfied condition "Succeeded or Failed"
    Apr 25 20:55:52.048: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/25/23 20:55:52.156
    Apr 25 20:55:52.203: INFO: Waiting for pod pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0 to disappear
    Apr 25 20:55:52.217: INFO: Pod pod-projected-secrets-aef1f9fe-bee5-4b86-90c1-27180ef2d6c0 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 25 20:55:52.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-371" for this suite. 04/25/23 20:55:52.237
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:55:52.274
Apr 25 20:55:52.276: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename endpointslice 04/25/23 20:55:52.278
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:55:52.321
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:55:52.339
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 25 20:55:52.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5535" for this suite. 04/25/23 20:55:52.528
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":287,"skipped":5325,"failed":0}
------------------------------
• [0.288 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:55:52.274
    Apr 25 20:55:52.276: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename endpointslice 04/25/23 20:55:52.278
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:55:52.321
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:55:52.339
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 25 20:55:52.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-5535" for this suite. 04/25/23 20:55:52.528
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:55:52.571
Apr 25 20:55:52.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 20:55:52.573
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:55:52.614
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:55:52.658
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 04/25/23 20:55:52.671
Apr 25 20:55:52.738: INFO: Waiting up to 5m0s for pod "downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0" in namespace "downward-api-9277" to be "Succeeded or Failed"
Apr 25 20:55:52.756: INFO: Pod "downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0": Phase="Pending", Reason="", readiness=false. Elapsed: 17.742912ms
Apr 25 20:55:54.772: INFO: Pod "downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033563516s
Apr 25 20:55:56.771: INFO: Pod "downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032906369s
Apr 25 20:55:58.774: INFO: Pod "downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036083613s
STEP: Saw pod success 04/25/23 20:55:58.775
Apr 25 20:55:58.775: INFO: Pod "downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0" satisfied condition "Succeeded or Failed"
Apr 25 20:55:58.789: INFO: Trying to get logs from node 10.10.21.190 pod downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0 container dapi-container: <nil>
STEP: delete the pod 04/25/23 20:55:58.839
Apr 25 20:55:58.888: INFO: Waiting for pod downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0 to disappear
Apr 25 20:55:58.905: INFO: Pod downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 25 20:55:58.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9277" for this suite. 04/25/23 20:55:58.923
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":288,"skipped":5340,"failed":0}
------------------------------
• [SLOW TEST] [6.377 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:55:52.571
    Apr 25 20:55:52.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 20:55:52.573
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:55:52.614
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:55:52.658
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 04/25/23 20:55:52.671
    Apr 25 20:55:52.738: INFO: Waiting up to 5m0s for pod "downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0" in namespace "downward-api-9277" to be "Succeeded or Failed"
    Apr 25 20:55:52.756: INFO: Pod "downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0": Phase="Pending", Reason="", readiness=false. Elapsed: 17.742912ms
    Apr 25 20:55:54.772: INFO: Pod "downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033563516s
    Apr 25 20:55:56.771: INFO: Pod "downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032906369s
    Apr 25 20:55:58.774: INFO: Pod "downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036083613s
    STEP: Saw pod success 04/25/23 20:55:58.775
    Apr 25 20:55:58.775: INFO: Pod "downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0" satisfied condition "Succeeded or Failed"
    Apr 25 20:55:58.789: INFO: Trying to get logs from node 10.10.21.190 pod downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0 container dapi-container: <nil>
    STEP: delete the pod 04/25/23 20:55:58.839
    Apr 25 20:55:58.888: INFO: Waiting for pod downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0 to disappear
    Apr 25 20:55:58.905: INFO: Pod downward-api-50ef1a5c-23ca-4963-846c-f9740d983bc0 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 25 20:55:58.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9277" for this suite. 04/25/23 20:55:58.923
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 20:55:58.963
Apr 25 20:55:58.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename cronjob 04/25/23 20:55:58.964
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:55:59.042
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:55:59.056
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 04/25/23 20:55:59.07
STEP: Ensuring no jobs are scheduled 04/25/23 20:55:59.09
STEP: Ensuring no job exists by listing jobs explicitly 04/25/23 21:00:59.121
STEP: Removing cronjob 04/25/23 21:00:59.132
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 25 21:00:59.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5655" for this suite. 04/25/23 21:00:59.178
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":289,"skipped":5356,"failed":0}
------------------------------
• [SLOW TEST] [300.240 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 20:55:58.963
    Apr 25 20:55:58.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename cronjob 04/25/23 20:55:58.964
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 20:55:59.042
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 20:55:59.056
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 04/25/23 20:55:59.07
    STEP: Ensuring no jobs are scheduled 04/25/23 20:55:59.09
    STEP: Ensuring no job exists by listing jobs explicitly 04/25/23 21:00:59.121
    STEP: Removing cronjob 04/25/23 21:00:59.132
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 25 21:00:59.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5655" for this suite. 04/25/23 21:00:59.178
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:00:59.208
Apr 25 21:00:59.208: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename downward-api 04/25/23 21:00:59.21
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:00:59.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:00:59.278
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 04/25/23 21:00:59.29
Apr 25 21:00:59.332: INFO: Waiting up to 5m0s for pod "downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9" in namespace "downward-api-1108" to be "Succeeded or Failed"
Apr 25 21:00:59.349: INFO: Pod "downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.894349ms
Apr 25 21:01:01.365: INFO: Pod "downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032765385s
Apr 25 21:01:03.364: INFO: Pod "downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031896207s
Apr 25 21:01:05.366: INFO: Pod "downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033759677s
STEP: Saw pod success 04/25/23 21:01:05.366
Apr 25 21:01:05.366: INFO: Pod "downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9" satisfied condition "Succeeded or Failed"
Apr 25 21:01:05.381: INFO: Trying to get logs from node 10.10.21.190 pod downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9 container dapi-container: <nil>
STEP: delete the pod 04/25/23 21:01:05.48
Apr 25 21:01:05.528: INFO: Waiting for pod downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9 to disappear
Apr 25 21:01:05.544: INFO: Pod downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 25 21:01:05.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1108" for this suite. 04/25/23 21:01:05.563
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":290,"skipped":5374,"failed":0}
------------------------------
• [SLOW TEST] [6.377 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:00:59.208
    Apr 25 21:00:59.208: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename downward-api 04/25/23 21:00:59.21
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:00:59.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:00:59.278
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 04/25/23 21:00:59.29
    Apr 25 21:00:59.332: INFO: Waiting up to 5m0s for pod "downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9" in namespace "downward-api-1108" to be "Succeeded or Failed"
    Apr 25 21:00:59.349: INFO: Pod "downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.894349ms
    Apr 25 21:01:01.365: INFO: Pod "downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032765385s
    Apr 25 21:01:03.364: INFO: Pod "downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031896207s
    Apr 25 21:01:05.366: INFO: Pod "downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033759677s
    STEP: Saw pod success 04/25/23 21:01:05.366
    Apr 25 21:01:05.366: INFO: Pod "downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9" satisfied condition "Succeeded or Failed"
    Apr 25 21:01:05.381: INFO: Trying to get logs from node 10.10.21.190 pod downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9 container dapi-container: <nil>
    STEP: delete the pod 04/25/23 21:01:05.48
    Apr 25 21:01:05.528: INFO: Waiting for pod downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9 to disappear
    Apr 25 21:01:05.544: INFO: Pod downward-api-fa06810b-dc07-4c88-9759-5697743ca9b9 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 25 21:01:05.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1108" for this suite. 04/25/23 21:01:05.563
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:01:05.586
Apr 25 21:01:05.586: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename job 04/25/23 21:01:05.591
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:01:05.647
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:01:05.669
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 04/25/23 21:01:05.687
STEP: Patching the Job 04/25/23 21:01:05.7
STEP: Watching for Job to be patched 04/25/23 21:01:05.739
Apr 25 21:01:05.747: INFO: Event ADDED observed for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92] and annotations: map[batch.kubernetes.io/job-tracking:]
Apr 25 21:01:05.747: INFO: Event MODIFIED observed for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92] and annotations: map[batch.kubernetes.io/job-tracking:]
Apr 25 21:01:05.747: INFO: Event MODIFIED found for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 04/25/23 21:01:05.747
STEP: Watching for Job to be updated 04/25/23 21:01:05.779
Apr 25 21:01:05.786: INFO: Event MODIFIED found for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 25 21:01:05.786: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 04/25/23 21:01:05.787
Apr 25 21:01:05.799: INFO: Job: e2e-k4b92 as labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched]
STEP: Waiting for job to complete 04/25/23 21:01:05.799
STEP: Delete a job collection with a labelselector 04/25/23 21:01:15.819
STEP: Watching for Job to be deleted 04/25/23 21:01:15.839
Apr 25 21:01:15.848: INFO: Event MODIFIED observed for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 25 21:01:15.849: INFO: Event MODIFIED observed for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 25 21:01:15.849: INFO: Event MODIFIED observed for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 25 21:01:15.850: INFO: Event MODIFIED observed for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 25 21:01:15.851: INFO: Event MODIFIED observed for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 25 21:01:15.851: INFO: Event DELETED found for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 04/25/23 21:01:15.852
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 25 21:01:15.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9196" for this suite. 04/25/23 21:01:15.881
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":291,"skipped":5376,"failed":0}
------------------------------
• [SLOW TEST] [10.329 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:01:05.586
    Apr 25 21:01:05.586: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename job 04/25/23 21:01:05.591
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:01:05.647
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:01:05.669
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 04/25/23 21:01:05.687
    STEP: Patching the Job 04/25/23 21:01:05.7
    STEP: Watching for Job to be patched 04/25/23 21:01:05.739
    Apr 25 21:01:05.747: INFO: Event ADDED observed for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92] and annotations: map[batch.kubernetes.io/job-tracking:]
    Apr 25 21:01:05.747: INFO: Event MODIFIED observed for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92] and annotations: map[batch.kubernetes.io/job-tracking:]
    Apr 25 21:01:05.747: INFO: Event MODIFIED found for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 04/25/23 21:01:05.747
    STEP: Watching for Job to be updated 04/25/23 21:01:05.779
    Apr 25 21:01:05.786: INFO: Event MODIFIED found for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 25 21:01:05.786: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 04/25/23 21:01:05.787
    Apr 25 21:01:05.799: INFO: Job: e2e-k4b92 as labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched]
    STEP: Waiting for job to complete 04/25/23 21:01:05.799
    STEP: Delete a job collection with a labelselector 04/25/23 21:01:15.819
    STEP: Watching for Job to be deleted 04/25/23 21:01:15.839
    Apr 25 21:01:15.848: INFO: Event MODIFIED observed for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 25 21:01:15.849: INFO: Event MODIFIED observed for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 25 21:01:15.849: INFO: Event MODIFIED observed for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 25 21:01:15.850: INFO: Event MODIFIED observed for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 25 21:01:15.851: INFO: Event MODIFIED observed for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 25 21:01:15.851: INFO: Event DELETED found for Job e2e-k4b92 in namespace job-9196 with labels: map[e2e-job-label:e2e-k4b92 e2e-k4b92:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 04/25/23 21:01:15.852
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 25 21:01:15.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9196" for this suite. 04/25/23 21:01:15.881
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:01:15.923
Apr 25 21:01:15.923: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename configmap 04/25/23 21:01:15.925
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:01:15.97
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:01:15.984
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 04/25/23 21:01:15.999
STEP: fetching the ConfigMap 04/25/23 21:01:16.014
STEP: patching the ConfigMap 04/25/23 21:01:16.024
STEP: listing all ConfigMaps in all namespaces with a label selector 04/25/23 21:01:16.043
STEP: deleting the ConfigMap by collection with a label selector 04/25/23 21:01:16.056
STEP: listing all ConfigMaps in test namespace 04/25/23 21:01:16.078
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 25 21:01:16.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5135" for this suite. 04/25/23 21:01:16.108
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":292,"skipped":5385,"failed":0}
------------------------------
• [0.209 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:01:15.923
    Apr 25 21:01:15.923: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename configmap 04/25/23 21:01:15.925
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:01:15.97
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:01:15.984
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 04/25/23 21:01:15.999
    STEP: fetching the ConfigMap 04/25/23 21:01:16.014
    STEP: patching the ConfigMap 04/25/23 21:01:16.024
    STEP: listing all ConfigMaps in all namespaces with a label selector 04/25/23 21:01:16.043
    STEP: deleting the ConfigMap by collection with a label selector 04/25/23 21:01:16.056
    STEP: listing all ConfigMaps in test namespace 04/25/23 21:01:16.078
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 25 21:01:16.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5135" for this suite. 04/25/23 21:01:16.108
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:01:16.139
Apr 25 21:01:16.139: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename init-container 04/25/23 21:01:16.142
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:01:16.183
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:01:16.196
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 04/25/23 21:01:16.209
Apr 25 21:01:16.210: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 25 21:01:21.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8681" for this suite. 04/25/23 21:01:21.727
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":293,"skipped":5396,"failed":0}
------------------------------
• [SLOW TEST] [5.616 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:01:16.139
    Apr 25 21:01:16.139: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename init-container 04/25/23 21:01:16.142
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:01:16.183
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:01:16.196
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 04/25/23 21:01:16.209
    Apr 25 21:01:16.210: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 25 21:01:21.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-8681" for this suite. 04/25/23 21:01:21.727
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:01:21.759
Apr 25 21:01:21.759: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename subpath 04/25/23 21:01:21.762
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:01:21.802
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:01:21.813
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/25/23 21:01:21.825
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-2jbg 04/25/23 21:01:21.857
STEP: Creating a pod to test atomic-volume-subpath 04/25/23 21:01:21.857
Apr 25 21:01:21.894: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-2jbg" in namespace "subpath-2906" to be "Succeeded or Failed"
Apr 25 21:01:21.912: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Pending", Reason="", readiness=false. Elapsed: 18.069828ms
Apr 25 21:01:23.929: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 2.034335236s
Apr 25 21:01:25.929: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 4.035267852s
Apr 25 21:01:27.926: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 6.03204857s
Apr 25 21:01:29.935: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 8.040687749s
Apr 25 21:01:31.937: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 10.042492112s
Apr 25 21:01:33.941: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 12.046567348s
Apr 25 21:01:35.929: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 14.034905775s
Apr 25 21:01:37.928: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 16.033900515s
Apr 25 21:01:39.931: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 18.037126625s
Apr 25 21:01:41.979: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 20.084430379s
Apr 25 21:01:43.928: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=false. Elapsed: 22.033809246s
Apr 25 21:01:45.952: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.057625448s
STEP: Saw pod success 04/25/23 21:01:45.952
Apr 25 21:01:45.953: INFO: Pod "pod-subpath-test-downwardapi-2jbg" satisfied condition "Succeeded or Failed"
Apr 25 21:01:45.969: INFO: Trying to get logs from node 10.10.21.190 pod pod-subpath-test-downwardapi-2jbg container test-container-subpath-downwardapi-2jbg: <nil>
STEP: delete the pod 04/25/23 21:01:46.005
Apr 25 21:01:46.049: INFO: Waiting for pod pod-subpath-test-downwardapi-2jbg to disappear
Apr 25 21:01:46.085: INFO: Pod pod-subpath-test-downwardapi-2jbg no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-2jbg 04/25/23 21:01:46.085
Apr 25 21:01:46.086: INFO: Deleting pod "pod-subpath-test-downwardapi-2jbg" in namespace "subpath-2906"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 25 21:01:46.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2906" for this suite. 04/25/23 21:01:46.115
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":294,"skipped":5412,"failed":0}
------------------------------
• [SLOW TEST] [24.402 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:01:21.759
    Apr 25 21:01:21.759: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename subpath 04/25/23 21:01:21.762
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:01:21.802
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:01:21.813
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/25/23 21:01:21.825
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-2jbg 04/25/23 21:01:21.857
    STEP: Creating a pod to test atomic-volume-subpath 04/25/23 21:01:21.857
    Apr 25 21:01:21.894: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-2jbg" in namespace "subpath-2906" to be "Succeeded or Failed"
    Apr 25 21:01:21.912: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Pending", Reason="", readiness=false. Elapsed: 18.069828ms
    Apr 25 21:01:23.929: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 2.034335236s
    Apr 25 21:01:25.929: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 4.035267852s
    Apr 25 21:01:27.926: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 6.03204857s
    Apr 25 21:01:29.935: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 8.040687749s
    Apr 25 21:01:31.937: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 10.042492112s
    Apr 25 21:01:33.941: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 12.046567348s
    Apr 25 21:01:35.929: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 14.034905775s
    Apr 25 21:01:37.928: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 16.033900515s
    Apr 25 21:01:39.931: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 18.037126625s
    Apr 25 21:01:41.979: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=true. Elapsed: 20.084430379s
    Apr 25 21:01:43.928: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Running", Reason="", readiness=false. Elapsed: 22.033809246s
    Apr 25 21:01:45.952: INFO: Pod "pod-subpath-test-downwardapi-2jbg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.057625448s
    STEP: Saw pod success 04/25/23 21:01:45.952
    Apr 25 21:01:45.953: INFO: Pod "pod-subpath-test-downwardapi-2jbg" satisfied condition "Succeeded or Failed"
    Apr 25 21:01:45.969: INFO: Trying to get logs from node 10.10.21.190 pod pod-subpath-test-downwardapi-2jbg container test-container-subpath-downwardapi-2jbg: <nil>
    STEP: delete the pod 04/25/23 21:01:46.005
    Apr 25 21:01:46.049: INFO: Waiting for pod pod-subpath-test-downwardapi-2jbg to disappear
    Apr 25 21:01:46.085: INFO: Pod pod-subpath-test-downwardapi-2jbg no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-2jbg 04/25/23 21:01:46.085
    Apr 25 21:01:46.086: INFO: Deleting pod "pod-subpath-test-downwardapi-2jbg" in namespace "subpath-2906"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 25 21:01:46.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-2906" for this suite. 04/25/23 21:01:46.115
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:01:46.172
Apr 25 21:01:46.172: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename namespaces 04/25/23 21:01:46.173
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:01:46.224
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:01:46.237
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 04/25/23 21:01:46.254
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:01:46.366
STEP: Creating a pod in the namespace 04/25/23 21:01:46.38
STEP: Waiting for the pod to have running status 04/25/23 21:01:46.41
Apr 25 21:01:46.410: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-3176" to be "running"
Apr 25 21:01:46.429: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 19.260464ms
Apr 25 21:01:48.446: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.036096044s
Apr 25 21:01:48.446: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 04/25/23 21:01:48.446
STEP: Waiting for the namespace to be removed. 04/25/23 21:01:48.523
STEP: Recreating the namespace 04/25/23 21:02:00.536
STEP: Verifying there are no pods in the namespace 04/25/23 21:02:00.581
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 25 21:02:00.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1556" for this suite. 04/25/23 21:02:00.658
STEP: Destroying namespace "nsdeletetest-3176" for this suite. 04/25/23 21:02:00.69
Apr 25 21:02:00.702: INFO: Namespace nsdeletetest-3176 was already deleted
STEP: Destroying namespace "nsdeletetest-5374" for this suite. 04/25/23 21:02:00.703
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":295,"skipped":5428,"failed":0}
------------------------------
• [SLOW TEST] [14.556 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:01:46.172
    Apr 25 21:01:46.172: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename namespaces 04/25/23 21:01:46.173
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:01:46.224
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:01:46.237
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 04/25/23 21:01:46.254
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:01:46.366
    STEP: Creating a pod in the namespace 04/25/23 21:01:46.38
    STEP: Waiting for the pod to have running status 04/25/23 21:01:46.41
    Apr 25 21:01:46.410: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-3176" to be "running"
    Apr 25 21:01:46.429: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 19.260464ms
    Apr 25 21:01:48.446: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.036096044s
    Apr 25 21:01:48.446: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 04/25/23 21:01:48.446
    STEP: Waiting for the namespace to be removed. 04/25/23 21:01:48.523
    STEP: Recreating the namespace 04/25/23 21:02:00.536
    STEP: Verifying there are no pods in the namespace 04/25/23 21:02:00.581
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 21:02:00.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-1556" for this suite. 04/25/23 21:02:00.658
    STEP: Destroying namespace "nsdeletetest-3176" for this suite. 04/25/23 21:02:00.69
    Apr 25 21:02:00.702: INFO: Namespace nsdeletetest-3176 was already deleted
    STEP: Destroying namespace "nsdeletetest-5374" for this suite. 04/25/23 21:02:00.703
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:02:00.741
Apr 25 21:02:00.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename statefulset 04/25/23 21:02:00.743
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:02:00.825
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:02:00.838
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3667 04/25/23 21:02:00.849
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 04/25/23 21:02:00.869
STEP: Creating stateful set ss in namespace statefulset-3667 04/25/23 21:02:00.883
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3667 04/25/23 21:02:00.897
Apr 25 21:02:00.929: INFO: Found 0 stateful pods, waiting for 1
Apr 25 21:02:10.970: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 04/25/23 21:02:10.971
Apr 25 21:02:10.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 25 21:02:11.377: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 25 21:02:11.377: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 25 21:02:11.377: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 25 21:02:11.392: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 25 21:02:21.410: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 21:02:21.410: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 21:02:21.475: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999994725s
Apr 25 21:02:22.516: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.971294974s
Apr 25 21:02:23.554: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.931216862s
Apr 25 21:02:24.569: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.892825335s
Apr 25 21:02:25.595: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.877821903s
Apr 25 21:02:26.614: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.852522062s
Apr 25 21:02:27.652: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.833111023s
Apr 25 21:02:28.666: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.795457964s
Apr 25 21:02:29.685: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.780910739s
Apr 25 21:02:30.707: INFO: Verifying statefulset ss doesn't scale past 1 for another 762.464847ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3667 04/25/23 21:02:31.707
Apr 25 21:02:31.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 25 21:02:32.103: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 25 21:02:32.103: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 25 21:02:32.103: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 25 21:02:32.117: INFO: Found 1 stateful pods, waiting for 3
Apr 25 21:02:42.154: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 21:02:42.154: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 21:02:42.154: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 04/25/23 21:02:42.154
STEP: Scale down will halt with unhealthy stateful pod 04/25/23 21:02:42.155
Apr 25 21:02:42.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 25 21:02:42.569: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 25 21:02:42.569: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 25 21:02:42.569: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 25 21:02:42.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 25 21:02:42.938: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 25 21:02:42.938: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 25 21:02:42.938: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 25 21:02:42.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 25 21:02:43.323: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 25 21:02:43.323: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 25 21:02:43.323: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 25 21:02:43.323: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 21:02:43.332: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Apr 25 21:02:53.358: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 21:02:53.359: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 21:02:53.359: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 21:02:53.423: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999994856s
Apr 25 21:02:54.460: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.959454039s
Apr 25 21:02:55.477: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.922852736s
Apr 25 21:02:56.511: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.906093232s
Apr 25 21:02:57.526: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.872317657s
Apr 25 21:02:58.540: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.857876582s
Apr 25 21:02:59.565: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.84254863s
Apr 25 21:03:00.583: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.817715348s
Apr 25 21:03:01.618: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.800451779s
Apr 25 21:03:02.632: INFO: Verifying statefulset ss doesn't scale past 3 for another 765.530753ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3667 04/25/23 21:03:03.632
Apr 25 21:03:03.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 25 21:03:04.007: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 25 21:03:04.007: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 25 21:03:04.007: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 25 21:03:04.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 25 21:03:04.343: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 25 21:03:04.343: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 25 21:03:04.343: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 25 21:03:04.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 25 21:03:04.713: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 25 21:03:04.713: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 25 21:03:04.713: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 25 21:03:04.713: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 04/25/23 21:03:14.767
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 25 21:03:14.769: INFO: Deleting all statefulset in ns statefulset-3667
Apr 25 21:03:14.780: INFO: Scaling statefulset ss to 0
Apr 25 21:03:14.816: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 21:03:14.825: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 25 21:03:14.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3667" for this suite. 04/25/23 21:03:14.881
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":296,"skipped":5436,"failed":0}
------------------------------
• [SLOW TEST] [74.171 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:02:00.741
    Apr 25 21:02:00.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename statefulset 04/25/23 21:02:00.743
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:02:00.825
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:02:00.838
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3667 04/25/23 21:02:00.849
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 04/25/23 21:02:00.869
    STEP: Creating stateful set ss in namespace statefulset-3667 04/25/23 21:02:00.883
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3667 04/25/23 21:02:00.897
    Apr 25 21:02:00.929: INFO: Found 0 stateful pods, waiting for 1
    Apr 25 21:02:10.970: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 04/25/23 21:02:10.971
    Apr 25 21:02:10.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 25 21:02:11.377: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 25 21:02:11.377: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 25 21:02:11.377: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 25 21:02:11.392: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Apr 25 21:02:21.410: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 25 21:02:21.410: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 25 21:02:21.475: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999994725s
    Apr 25 21:02:22.516: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.971294974s
    Apr 25 21:02:23.554: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.931216862s
    Apr 25 21:02:24.569: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.892825335s
    Apr 25 21:02:25.595: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.877821903s
    Apr 25 21:02:26.614: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.852522062s
    Apr 25 21:02:27.652: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.833111023s
    Apr 25 21:02:28.666: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.795457964s
    Apr 25 21:02:29.685: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.780910739s
    Apr 25 21:02:30.707: INFO: Verifying statefulset ss doesn't scale past 1 for another 762.464847ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3667 04/25/23 21:02:31.707
    Apr 25 21:02:31.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 25 21:02:32.103: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 25 21:02:32.103: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 25 21:02:32.103: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 25 21:02:32.117: INFO: Found 1 stateful pods, waiting for 3
    Apr 25 21:02:42.154: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 25 21:02:42.154: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 25 21:02:42.154: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 04/25/23 21:02:42.154
    STEP: Scale down will halt with unhealthy stateful pod 04/25/23 21:02:42.155
    Apr 25 21:02:42.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 25 21:02:42.569: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 25 21:02:42.569: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 25 21:02:42.569: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 25 21:02:42.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 25 21:02:42.938: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 25 21:02:42.938: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 25 21:02:42.938: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 25 21:02:42.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 25 21:02:43.323: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 25 21:02:43.323: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 25 21:02:43.323: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 25 21:02:43.323: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 25 21:02:43.332: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Apr 25 21:02:53.358: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 25 21:02:53.359: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Apr 25 21:02:53.359: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Apr 25 21:02:53.423: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999994856s
    Apr 25 21:02:54.460: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.959454039s
    Apr 25 21:02:55.477: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.922852736s
    Apr 25 21:02:56.511: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.906093232s
    Apr 25 21:02:57.526: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.872317657s
    Apr 25 21:02:58.540: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.857876582s
    Apr 25 21:02:59.565: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.84254863s
    Apr 25 21:03:00.583: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.817715348s
    Apr 25 21:03:01.618: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.800451779s
    Apr 25 21:03:02.632: INFO: Verifying statefulset ss doesn't scale past 3 for another 765.530753ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3667 04/25/23 21:03:03.632
    Apr 25 21:03:03.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 25 21:03:04.007: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 25 21:03:04.007: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 25 21:03:04.007: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 25 21:03:04.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 25 21:03:04.343: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 25 21:03:04.343: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 25 21:03:04.343: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 25 21:03:04.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-3667 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 25 21:03:04.713: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 25 21:03:04.713: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 25 21:03:04.713: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 25 21:03:04.713: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 04/25/23 21:03:14.767
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 25 21:03:14.769: INFO: Deleting all statefulset in ns statefulset-3667
    Apr 25 21:03:14.780: INFO: Scaling statefulset ss to 0
    Apr 25 21:03:14.816: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 25 21:03:14.825: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 25 21:03:14.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3667" for this suite. 04/25/23 21:03:14.881
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:03:14.915
Apr 25 21:03:14.916: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 21:03:14.92
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:03:14.961
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:03:14.972
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 04/25/23 21:03:14.982
Apr 25 21:03:14.984: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: mark a version not serverd 04/25/23 21:03:22.798
STEP: check the unserved version gets removed 04/25/23 21:03:22.86
STEP: check the other version is not changed 04/25/23 21:03:26.714
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 21:03:33.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9042" for this suite. 04/25/23 21:03:33.305
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":297,"skipped":5441,"failed":0}
------------------------------
• [SLOW TEST] [18.417 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:03:14.915
    Apr 25 21:03:14.916: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 21:03:14.92
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:03:14.961
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:03:14.972
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 04/25/23 21:03:14.982
    Apr 25 21:03:14.984: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: mark a version not serverd 04/25/23 21:03:22.798
    STEP: check the unserved version gets removed 04/25/23 21:03:22.86
    STEP: check the other version is not changed 04/25/23 21:03:26.714
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 21:03:33.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9042" for this suite. 04/25/23 21:03:33.305
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:03:33.334
Apr 25 21:03:33.334: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename configmap 04/25/23 21:03:33.338
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:03:33.381
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:03:33.393
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-0097cae5-6552-4886-be27-954a88bc31f7 04/25/23 21:03:33.426
STEP: Creating the pod 04/25/23 21:03:33.441
Apr 25 21:03:33.470: INFO: Waiting up to 5m0s for pod "pod-configmaps-f0bff6da-d540-41e4-ad31-cb254f1e39cc" in namespace "configmap-3908" to be "running"
Apr 25 21:03:33.483: INFO: Pod "pod-configmaps-f0bff6da-d540-41e4-ad31-cb254f1e39cc": Phase="Pending", Reason="", readiness=false. Elapsed: 13.538551ms
Apr 25 21:03:35.499: INFO: Pod "pod-configmaps-f0bff6da-d540-41e4-ad31-cb254f1e39cc": Phase="Running", Reason="", readiness=false. Elapsed: 2.029451063s
Apr 25 21:03:35.499: INFO: Pod "pod-configmaps-f0bff6da-d540-41e4-ad31-cb254f1e39cc" satisfied condition "running"
STEP: Waiting for pod with text data 04/25/23 21:03:35.499
STEP: Waiting for pod with binary data 04/25/23 21:03:35.62
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 25 21:03:35.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3908" for this suite. 04/25/23 21:03:35.678
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":298,"skipped":5446,"failed":0}
------------------------------
• [2.369 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:03:33.334
    Apr 25 21:03:33.334: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename configmap 04/25/23 21:03:33.338
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:03:33.381
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:03:33.393
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-0097cae5-6552-4886-be27-954a88bc31f7 04/25/23 21:03:33.426
    STEP: Creating the pod 04/25/23 21:03:33.441
    Apr 25 21:03:33.470: INFO: Waiting up to 5m0s for pod "pod-configmaps-f0bff6da-d540-41e4-ad31-cb254f1e39cc" in namespace "configmap-3908" to be "running"
    Apr 25 21:03:33.483: INFO: Pod "pod-configmaps-f0bff6da-d540-41e4-ad31-cb254f1e39cc": Phase="Pending", Reason="", readiness=false. Elapsed: 13.538551ms
    Apr 25 21:03:35.499: INFO: Pod "pod-configmaps-f0bff6da-d540-41e4-ad31-cb254f1e39cc": Phase="Running", Reason="", readiness=false. Elapsed: 2.029451063s
    Apr 25 21:03:35.499: INFO: Pod "pod-configmaps-f0bff6da-d540-41e4-ad31-cb254f1e39cc" satisfied condition "running"
    STEP: Waiting for pod with text data 04/25/23 21:03:35.499
    STEP: Waiting for pod with binary data 04/25/23 21:03:35.62
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 25 21:03:35.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3908" for this suite. 04/25/23 21:03:35.678
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:03:35.705
Apr 25 21:03:35.705: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename sched-preemption 04/25/23 21:03:35.709
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:03:35.755
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:03:35.773
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 25 21:03:35.854: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 25 21:04:35.983: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:04:36.002
Apr 25 21:04:36.002: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename sched-preemption-path 04/25/23 21:04:36.005
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:04:36.102
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:04:36.114
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 04/25/23 21:04:36.127
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/25/23 21:04:36.128
Apr 25 21:04:36.159: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-8058" to be "running"
Apr 25 21:04:36.198: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 38.956652ms
Apr 25 21:04:38.214: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.05555399s
Apr 25 21:04:38.215: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/25/23 21:04:38.228
Apr 25 21:04:38.264: INFO: found a healthy node: 10.10.21.190
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Apr 25 21:04:56.612: INFO: pods created so far: [1 1 1]
Apr 25 21:04:56.612: INFO: length of pods created so far: 3
Apr 25 21:04:58.648: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Apr 25 21:05:05.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-8058" for this suite. 04/25/23 21:05:05.668
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 25 21:05:05.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-887" for this suite. 04/25/23 21:05:05.958
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":299,"skipped":5447,"failed":0}
------------------------------
• [SLOW TEST] [90.460 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:03:35.705
    Apr 25 21:03:35.705: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename sched-preemption 04/25/23 21:03:35.709
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:03:35.755
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:03:35.773
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 25 21:03:35.854: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 25 21:04:35.983: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:04:36.002
    Apr 25 21:04:36.002: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename sched-preemption-path 04/25/23 21:04:36.005
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:04:36.102
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:04:36.114
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 04/25/23 21:04:36.127
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/25/23 21:04:36.128
    Apr 25 21:04:36.159: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-8058" to be "running"
    Apr 25 21:04:36.198: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 38.956652ms
    Apr 25 21:04:38.214: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.05555399s
    Apr 25 21:04:38.215: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/25/23 21:04:38.228
    Apr 25 21:04:38.264: INFO: found a healthy node: 10.10.21.190
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Apr 25 21:04:56.612: INFO: pods created so far: [1 1 1]
    Apr 25 21:04:56.612: INFO: length of pods created so far: 3
    Apr 25 21:04:58.648: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Apr 25 21:05:05.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-8058" for this suite. 04/25/23 21:05:05.668
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 21:05:05.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-887" for this suite. 04/25/23 21:05:05.958
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:05:06.175
Apr 25 21:05:06.175: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 21:05:06.176
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:05:06.23
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:05:06.242
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 04/25/23 21:05:06.256
Apr 25 21:05:06.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Apr 25 21:05:06.413: INFO: stderr: ""
Apr 25 21:05:06.413: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 04/25/23 21:05:06.413
Apr 25 21:05:06.413: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Apr 25 21:05:06.413: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-5942" to be "running and ready, or succeeded"
Apr 25 21:05:06.437: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 23.238915ms
Apr 25 21:05:06.437: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '10.10.21.190' to be 'Running' but was 'Pending'
Apr 25 21:05:08.458: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.044195099s
Apr 25 21:05:08.458: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Apr 25 21:05:08.458: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 04/25/23 21:05:08.458
Apr 25 21:05:08.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 logs logs-generator logs-generator'
Apr 25 21:05:08.659: INFO: stderr: ""
Apr 25 21:05:08.659: INFO: stdout: "I0425 21:05:07.618275       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/dqpr 478\nI0425 21:05:07.818654       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/7784 591\nI0425 21:05:08.019132       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/zr5p 348\nI0425 21:05:08.218580       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/rdqt 330\nI0425 21:05:08.419815       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/664 383\nI0425 21:05:08.619409       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/xmq7 272\n"
STEP: limiting log lines 04/25/23 21:05:08.659
Apr 25 21:05:08.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 logs logs-generator logs-generator --tail=1'
Apr 25 21:05:08.882: INFO: stderr: ""
Apr 25 21:05:08.882: INFO: stdout: "I0425 21:05:08.818975       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/fw6v 452\n"
Apr 25 21:05:08.882: INFO: got output "I0425 21:05:08.818975       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/fw6v 452\n"
STEP: limiting log bytes 04/25/23 21:05:08.882
Apr 25 21:05:08.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 logs logs-generator logs-generator --limit-bytes=1'
Apr 25 21:05:09.116: INFO: stderr: ""
Apr 25 21:05:09.116: INFO: stdout: "I"
Apr 25 21:05:09.116: INFO: got output "I"
STEP: exposing timestamps 04/25/23 21:05:09.116
Apr 25 21:05:09.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 logs logs-generator logs-generator --tail=1 --timestamps'
Apr 25 21:05:09.274: INFO: stderr: ""
Apr 25 21:05:09.274: INFO: stdout: "2023-04-25T21:05:09.219470939Z I0425 21:05:09.219077       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/kdp6 204\n"
Apr 25 21:05:09.274: INFO: got output "2023-04-25T21:05:09.219470939Z I0425 21:05:09.219077       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/kdp6 204\n"
STEP: restricting to a time range 04/25/23 21:05:09.274
Apr 25 21:05:11.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 logs logs-generator logs-generator --since=1s'
Apr 25 21:05:11.977: INFO: stderr: ""
Apr 25 21:05:11.977: INFO: stdout: "I0425 21:05:11.018784       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/5476 327\nI0425 21:05:11.219409       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/hxpf 305\nI0425 21:05:11.419199       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/2xw 477\nI0425 21:05:11.618640       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/n25 530\nI0425 21:05:11.819364       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/876 496\n"
Apr 25 21:05:11.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 logs logs-generator logs-generator --since=24h'
Apr 25 21:05:12.146: INFO: stderr: ""
Apr 25 21:05:12.147: INFO: stdout: "I0425 21:05:07.618275       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/dqpr 478\nI0425 21:05:07.818654       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/7784 591\nI0425 21:05:08.019132       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/zr5p 348\nI0425 21:05:08.218580       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/rdqt 330\nI0425 21:05:08.419815       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/664 383\nI0425 21:05:08.619409       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/xmq7 272\nI0425 21:05:08.818975       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/fw6v 452\nI0425 21:05:09.018403       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/2lh 389\nI0425 21:05:09.219077       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/kdp6 204\nI0425 21:05:09.418540       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/4x8r 239\nI0425 21:05:09.619002       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/cg4 290\nI0425 21:05:09.819474       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/s8fx 259\nI0425 21:05:10.019095       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/26t2 595\nI0425 21:05:10.219033       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/lds 322\nI0425 21:05:10.418648       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/h8r7 352\nI0425 21:05:10.618663       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/pss4 481\nI0425 21:05:10.819245       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/67kj 229\nI0425 21:05:11.018784       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/5476 327\nI0425 21:05:11.219409       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/hxpf 305\nI0425 21:05:11.419199       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/2xw 477\nI0425 21:05:11.618640       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/n25 530\nI0425 21:05:11.819364       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/876 496\nI0425 21:05:12.018769       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/7wz 350\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Apr 25 21:05:12.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 delete pod logs-generator'
Apr 25 21:05:13.950: INFO: stderr: ""
Apr 25 21:05:13.950: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 21:05:13.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5942" for this suite. 04/25/23 21:05:13.969
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":300,"skipped":5468,"failed":0}
------------------------------
• [SLOW TEST] [7.820 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:05:06.175
    Apr 25 21:05:06.175: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 21:05:06.176
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:05:06.23
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:05:06.242
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 04/25/23 21:05:06.256
    Apr 25 21:05:06.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Apr 25 21:05:06.413: INFO: stderr: ""
    Apr 25 21:05:06.413: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 04/25/23 21:05:06.413
    Apr 25 21:05:06.413: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Apr 25 21:05:06.413: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-5942" to be "running and ready, or succeeded"
    Apr 25 21:05:06.437: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 23.238915ms
    Apr 25 21:05:06.437: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '10.10.21.190' to be 'Running' but was 'Pending'
    Apr 25 21:05:08.458: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.044195099s
    Apr 25 21:05:08.458: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Apr 25 21:05:08.458: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 04/25/23 21:05:08.458
    Apr 25 21:05:08.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 logs logs-generator logs-generator'
    Apr 25 21:05:08.659: INFO: stderr: ""
    Apr 25 21:05:08.659: INFO: stdout: "I0425 21:05:07.618275       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/dqpr 478\nI0425 21:05:07.818654       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/7784 591\nI0425 21:05:08.019132       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/zr5p 348\nI0425 21:05:08.218580       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/rdqt 330\nI0425 21:05:08.419815       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/664 383\nI0425 21:05:08.619409       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/xmq7 272\n"
    STEP: limiting log lines 04/25/23 21:05:08.659
    Apr 25 21:05:08.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 logs logs-generator logs-generator --tail=1'
    Apr 25 21:05:08.882: INFO: stderr: ""
    Apr 25 21:05:08.882: INFO: stdout: "I0425 21:05:08.818975       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/fw6v 452\n"
    Apr 25 21:05:08.882: INFO: got output "I0425 21:05:08.818975       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/fw6v 452\n"
    STEP: limiting log bytes 04/25/23 21:05:08.882
    Apr 25 21:05:08.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 logs logs-generator logs-generator --limit-bytes=1'
    Apr 25 21:05:09.116: INFO: stderr: ""
    Apr 25 21:05:09.116: INFO: stdout: "I"
    Apr 25 21:05:09.116: INFO: got output "I"
    STEP: exposing timestamps 04/25/23 21:05:09.116
    Apr 25 21:05:09.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 logs logs-generator logs-generator --tail=1 --timestamps'
    Apr 25 21:05:09.274: INFO: stderr: ""
    Apr 25 21:05:09.274: INFO: stdout: "2023-04-25T21:05:09.219470939Z I0425 21:05:09.219077       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/kdp6 204\n"
    Apr 25 21:05:09.274: INFO: got output "2023-04-25T21:05:09.219470939Z I0425 21:05:09.219077       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/kdp6 204\n"
    STEP: restricting to a time range 04/25/23 21:05:09.274
    Apr 25 21:05:11.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 logs logs-generator logs-generator --since=1s'
    Apr 25 21:05:11.977: INFO: stderr: ""
    Apr 25 21:05:11.977: INFO: stdout: "I0425 21:05:11.018784       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/5476 327\nI0425 21:05:11.219409       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/hxpf 305\nI0425 21:05:11.419199       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/2xw 477\nI0425 21:05:11.618640       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/n25 530\nI0425 21:05:11.819364       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/876 496\n"
    Apr 25 21:05:11.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 logs logs-generator logs-generator --since=24h'
    Apr 25 21:05:12.146: INFO: stderr: ""
    Apr 25 21:05:12.147: INFO: stdout: "I0425 21:05:07.618275       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/dqpr 478\nI0425 21:05:07.818654       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/7784 591\nI0425 21:05:08.019132       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/zr5p 348\nI0425 21:05:08.218580       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/rdqt 330\nI0425 21:05:08.419815       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/664 383\nI0425 21:05:08.619409       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/xmq7 272\nI0425 21:05:08.818975       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/fw6v 452\nI0425 21:05:09.018403       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/2lh 389\nI0425 21:05:09.219077       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/kdp6 204\nI0425 21:05:09.418540       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/4x8r 239\nI0425 21:05:09.619002       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/cg4 290\nI0425 21:05:09.819474       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/s8fx 259\nI0425 21:05:10.019095       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/26t2 595\nI0425 21:05:10.219033       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/lds 322\nI0425 21:05:10.418648       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/h8r7 352\nI0425 21:05:10.618663       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/pss4 481\nI0425 21:05:10.819245       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/67kj 229\nI0425 21:05:11.018784       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/5476 327\nI0425 21:05:11.219409       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/hxpf 305\nI0425 21:05:11.419199       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/2xw 477\nI0425 21:05:11.618640       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/n25 530\nI0425 21:05:11.819364       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/876 496\nI0425 21:05:12.018769       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/7wz 350\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Apr 25 21:05:12.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-5942 delete pod logs-generator'
    Apr 25 21:05:13.950: INFO: stderr: ""
    Apr 25 21:05:13.950: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 21:05:13.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5942" for this suite. 04/25/23 21:05:13.969
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:05:13.997
Apr 25 21:05:13.998: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename statefulset 04/25/23 21:05:14.001
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:05:14.043
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:05:14.056
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3061 04/25/23 21:05:14.07
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 04/25/23 21:05:14.087
Apr 25 21:05:14.141: INFO: Found 0 stateful pods, waiting for 3
Apr 25 21:05:24.156: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 21:05:24.156: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 21:05:24.156: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/25/23 21:05:24.199
Apr 25 21:05:24.235: INFO: Updating stateful set ss2
STEP: Creating a new revision 04/25/23 21:05:24.236
STEP: Not applying an update when the partition is greater than the number of replicas 04/25/23 21:05:34.291
STEP: Performing a canary update 04/25/23 21:05:34.291
Apr 25 21:05:34.328: INFO: Updating stateful set ss2
Apr 25 21:05:34.388: INFO: Waiting for Pod statefulset-3061/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 04/25/23 21:05:44.417
Apr 25 21:05:44.626: INFO: Found 2 stateful pods, waiting for 3
Apr 25 21:05:54.644: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 21:05:54.644: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 21:05:54.644: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 04/25/23 21:05:54.672
Apr 25 21:05:54.710: INFO: Updating stateful set ss2
Apr 25 21:05:54.738: INFO: Waiting for Pod statefulset-3061/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Apr 25 21:06:04.808: INFO: Updating stateful set ss2
Apr 25 21:06:04.858: INFO: Waiting for StatefulSet statefulset-3061/ss2 to complete update
Apr 25 21:06:04.858: INFO: Waiting for Pod statefulset-3061/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 25 21:06:14.885: INFO: Deleting all statefulset in ns statefulset-3061
Apr 25 21:06:14.897: INFO: Scaling statefulset ss2 to 0
Apr 25 21:06:24.986: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 21:06:24.997: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 25 21:06:25.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3061" for this suite. 04/25/23 21:06:25.068
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":301,"skipped":5473,"failed":0}
------------------------------
• [SLOW TEST] [71.095 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:05:13.997
    Apr 25 21:05:13.998: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename statefulset 04/25/23 21:05:14.001
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:05:14.043
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:05:14.056
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3061 04/25/23 21:05:14.07
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 04/25/23 21:05:14.087
    Apr 25 21:05:14.141: INFO: Found 0 stateful pods, waiting for 3
    Apr 25 21:05:24.156: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 25 21:05:24.156: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 25 21:05:24.156: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/25/23 21:05:24.199
    Apr 25 21:05:24.235: INFO: Updating stateful set ss2
    STEP: Creating a new revision 04/25/23 21:05:24.236
    STEP: Not applying an update when the partition is greater than the number of replicas 04/25/23 21:05:34.291
    STEP: Performing a canary update 04/25/23 21:05:34.291
    Apr 25 21:05:34.328: INFO: Updating stateful set ss2
    Apr 25 21:05:34.388: INFO: Waiting for Pod statefulset-3061/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 04/25/23 21:05:44.417
    Apr 25 21:05:44.626: INFO: Found 2 stateful pods, waiting for 3
    Apr 25 21:05:54.644: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 25 21:05:54.644: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 25 21:05:54.644: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 04/25/23 21:05:54.672
    Apr 25 21:05:54.710: INFO: Updating stateful set ss2
    Apr 25 21:05:54.738: INFO: Waiting for Pod statefulset-3061/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Apr 25 21:06:04.808: INFO: Updating stateful set ss2
    Apr 25 21:06:04.858: INFO: Waiting for StatefulSet statefulset-3061/ss2 to complete update
    Apr 25 21:06:04.858: INFO: Waiting for Pod statefulset-3061/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 25 21:06:14.885: INFO: Deleting all statefulset in ns statefulset-3061
    Apr 25 21:06:14.897: INFO: Scaling statefulset ss2 to 0
    Apr 25 21:06:24.986: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 25 21:06:24.997: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 25 21:06:25.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3061" for this suite. 04/25/23 21:06:25.068
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3620
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:06:25.103
Apr 25 21:06:25.103: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 21:06:25.105
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:25.15
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:25.163
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3620
STEP: creating a collection of services 04/25/23 21:06:25.176
Apr 25 21:06:25.177: INFO: Creating e2e-svc-a-l24m8
Apr 25 21:06:25.215: INFO: Creating e2e-svc-b-qw5b5
Apr 25 21:06:25.245: INFO: Creating e2e-svc-c-kckbs
STEP: deleting service collection 04/25/23 21:06:25.286
Apr 25 21:06:25.361: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 21:06:25.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3934" for this suite. 04/25/23 21:06:25.379
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":302,"skipped":5487,"failed":0}
------------------------------
• [0.303 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3620

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:06:25.103
    Apr 25 21:06:25.103: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 21:06:25.105
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:25.15
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:25.163
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3620
    STEP: creating a collection of services 04/25/23 21:06:25.176
    Apr 25 21:06:25.177: INFO: Creating e2e-svc-a-l24m8
    Apr 25 21:06:25.215: INFO: Creating e2e-svc-b-qw5b5
    Apr 25 21:06:25.245: INFO: Creating e2e-svc-c-kckbs
    STEP: deleting service collection 04/25/23 21:06:25.286
    Apr 25 21:06:25.361: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 21:06:25.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3934" for this suite. 04/25/23 21:06:25.379
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:06:25.41
Apr 25 21:06:25.410: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir 04/25/23 21:06:25.412
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:25.45
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:25.46
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 04/25/23 21:06:25.473
Apr 25 21:06:25.504: INFO: Waiting up to 5m0s for pod "pod-952c1f9d-abaf-496d-a098-6903b82053ef" in namespace "emptydir-3346" to be "Succeeded or Failed"
Apr 25 21:06:25.518: INFO: Pod "pod-952c1f9d-abaf-496d-a098-6903b82053ef": Phase="Pending", Reason="", readiness=false. Elapsed: 14.333703ms
Apr 25 21:06:27.532: INFO: Pod "pod-952c1f9d-abaf-496d-a098-6903b82053ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028138831s
Apr 25 21:06:29.553: INFO: Pod "pod-952c1f9d-abaf-496d-a098-6903b82053ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048915985s
STEP: Saw pod success 04/25/23 21:06:29.553
Apr 25 21:06:29.554: INFO: Pod "pod-952c1f9d-abaf-496d-a098-6903b82053ef" satisfied condition "Succeeded or Failed"
Apr 25 21:06:29.568: INFO: Trying to get logs from node 10.10.21.190 pod pod-952c1f9d-abaf-496d-a098-6903b82053ef container test-container: <nil>
STEP: delete the pod 04/25/23 21:06:29.634
Apr 25 21:06:29.674: INFO: Waiting for pod pod-952c1f9d-abaf-496d-a098-6903b82053ef to disappear
Apr 25 21:06:29.687: INFO: Pod pod-952c1f9d-abaf-496d-a098-6903b82053ef no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 25 21:06:29.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3346" for this suite. 04/25/23 21:06:29.704
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":303,"skipped":5505,"failed":0}
------------------------------
• [4.319 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:06:25.41
    Apr 25 21:06:25.410: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir 04/25/23 21:06:25.412
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:25.45
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:25.46
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 04/25/23 21:06:25.473
    Apr 25 21:06:25.504: INFO: Waiting up to 5m0s for pod "pod-952c1f9d-abaf-496d-a098-6903b82053ef" in namespace "emptydir-3346" to be "Succeeded or Failed"
    Apr 25 21:06:25.518: INFO: Pod "pod-952c1f9d-abaf-496d-a098-6903b82053ef": Phase="Pending", Reason="", readiness=false. Elapsed: 14.333703ms
    Apr 25 21:06:27.532: INFO: Pod "pod-952c1f9d-abaf-496d-a098-6903b82053ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028138831s
    Apr 25 21:06:29.553: INFO: Pod "pod-952c1f9d-abaf-496d-a098-6903b82053ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048915985s
    STEP: Saw pod success 04/25/23 21:06:29.553
    Apr 25 21:06:29.554: INFO: Pod "pod-952c1f9d-abaf-496d-a098-6903b82053ef" satisfied condition "Succeeded or Failed"
    Apr 25 21:06:29.568: INFO: Trying to get logs from node 10.10.21.190 pod pod-952c1f9d-abaf-496d-a098-6903b82053ef container test-container: <nil>
    STEP: delete the pod 04/25/23 21:06:29.634
    Apr 25 21:06:29.674: INFO: Waiting for pod pod-952c1f9d-abaf-496d-a098-6903b82053ef to disappear
    Apr 25 21:06:29.687: INFO: Pod pod-952c1f9d-abaf-496d-a098-6903b82053ef no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 25 21:06:29.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3346" for this suite. 04/25/23 21:06:29.704
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:06:29.732
Apr 25 21:06:29.733: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 21:06:29.736
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:29.776
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:29.788
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 21:06:29.849
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 21:06:30.124
STEP: Deploying the webhook pod 04/25/23 21:06:30.143
STEP: Wait for the deployment to be ready 04/25/23 21:06:30.173
Apr 25 21:06:30.217: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 25 21:06:32.263: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 21, 6, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 21, 6, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 21, 6, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 21, 6, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/25/23 21:06:34.275
STEP: Verifying the service has paired with the endpoint 04/25/23 21:06:34.308
Apr 25 21:06:35.312: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 04/25/23 21:06:35.323
STEP: create a namespace for the webhook 04/25/23 21:06:35.41
STEP: create a configmap should be unconditionally rejected by the webhook 04/25/23 21:06:35.435
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 21:06:35.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9296" for this suite. 04/25/23 21:06:35.547
STEP: Destroying namespace "webhook-9296-markers" for this suite. 04/25/23 21:06:35.611
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":304,"skipped":5520,"failed":0}
------------------------------
• [SLOW TEST] [6.062 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:06:29.732
    Apr 25 21:06:29.733: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 21:06:29.736
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:29.776
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:29.788
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 21:06:29.849
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 21:06:30.124
    STEP: Deploying the webhook pod 04/25/23 21:06:30.143
    STEP: Wait for the deployment to be ready 04/25/23 21:06:30.173
    Apr 25 21:06:30.217: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 25 21:06:32.263: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 25, 21, 6, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 21, 6, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 25, 21, 6, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 25, 21, 6, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/25/23 21:06:34.275
    STEP: Verifying the service has paired with the endpoint 04/25/23 21:06:34.308
    Apr 25 21:06:35.312: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 04/25/23 21:06:35.323
    STEP: create a namespace for the webhook 04/25/23 21:06:35.41
    STEP: create a configmap should be unconditionally rejected by the webhook 04/25/23 21:06:35.435
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 21:06:35.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9296" for this suite. 04/25/23 21:06:35.547
    STEP: Destroying namespace "webhook-9296-markers" for this suite. 04/25/23 21:06:35.611
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:06:35.799
Apr 25 21:06:35.799: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename emptydir 04/25/23 21:06:35.8
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:35.843
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:35.855
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 04/25/23 21:06:35.868
Apr 25 21:06:35.898: INFO: Waiting up to 5m0s for pod "pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c" in namespace "emptydir-5193" to be "Succeeded or Failed"
Apr 25 21:06:35.930: INFO: Pod "pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c": Phase="Pending", Reason="", readiness=false. Elapsed: 31.644126ms
Apr 25 21:06:37.948: INFO: Pod "pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049727887s
Apr 25 21:06:39.946: INFO: Pod "pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047645724s
STEP: Saw pod success 04/25/23 21:06:39.946
Apr 25 21:06:39.946: INFO: Pod "pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c" satisfied condition "Succeeded or Failed"
Apr 25 21:06:39.960: INFO: Trying to get logs from node 10.10.21.190 pod pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c container test-container: <nil>
STEP: delete the pod 04/25/23 21:06:39.994
Apr 25 21:06:40.062: INFO: Waiting for pod pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c to disappear
Apr 25 21:06:40.075: INFO: Pod pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 25 21:06:40.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5193" for this suite. 04/25/23 21:06:40.091
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":305,"skipped":5521,"failed":0}
------------------------------
• [4.317 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:06:35.799
    Apr 25 21:06:35.799: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename emptydir 04/25/23 21:06:35.8
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:35.843
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:35.855
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 04/25/23 21:06:35.868
    Apr 25 21:06:35.898: INFO: Waiting up to 5m0s for pod "pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c" in namespace "emptydir-5193" to be "Succeeded or Failed"
    Apr 25 21:06:35.930: INFO: Pod "pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c": Phase="Pending", Reason="", readiness=false. Elapsed: 31.644126ms
    Apr 25 21:06:37.948: INFO: Pod "pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049727887s
    Apr 25 21:06:39.946: INFO: Pod "pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047645724s
    STEP: Saw pod success 04/25/23 21:06:39.946
    Apr 25 21:06:39.946: INFO: Pod "pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c" satisfied condition "Succeeded or Failed"
    Apr 25 21:06:39.960: INFO: Trying to get logs from node 10.10.21.190 pod pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c container test-container: <nil>
    STEP: delete the pod 04/25/23 21:06:39.994
    Apr 25 21:06:40.062: INFO: Waiting for pod pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c to disappear
    Apr 25 21:06:40.075: INFO: Pod pod-d7b7d2de-30cc-48f4-9f0c-adc81acdfb2c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 25 21:06:40.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5193" for this suite. 04/25/23 21:06:40.091
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:06:40.12
Apr 25 21:06:40.121: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename replicaset 04/25/23 21:06:40.123
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:40.185
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:40.199
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 04/25/23 21:06:40.208
Apr 25 21:06:40.238: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 25 21:06:45.254: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/25/23 21:06:45.254
STEP: getting scale subresource 04/25/23 21:06:45.255
STEP: updating a scale subresource 04/25/23 21:06:45.271
STEP: verifying the replicaset Spec.Replicas was modified 04/25/23 21:06:45.287
STEP: Patch a scale subresource 04/25/23 21:06:45.3
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 25 21:06:45.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5795" for this suite. 04/25/23 21:06:45.405
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":306,"skipped":5534,"failed":0}
------------------------------
• [SLOW TEST] [5.324 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:06:40.12
    Apr 25 21:06:40.121: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename replicaset 04/25/23 21:06:40.123
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:40.185
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:40.199
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 04/25/23 21:06:40.208
    Apr 25 21:06:40.238: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 25 21:06:45.254: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/25/23 21:06:45.254
    STEP: getting scale subresource 04/25/23 21:06:45.255
    STEP: updating a scale subresource 04/25/23 21:06:45.271
    STEP: verifying the replicaset Spec.Replicas was modified 04/25/23 21:06:45.287
    STEP: Patch a scale subresource 04/25/23 21:06:45.3
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 25 21:06:45.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-5795" for this suite. 04/25/23 21:06:45.405
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:06:45.462
Apr 25 21:06:45.463: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename configmap 04/25/23 21:06:45.464
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:45.506
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:45.517
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-6759/configmap-test-2b094df4-c68e-400c-ae07-fe9ad59442e9 04/25/23 21:06:45.531
STEP: Creating a pod to test consume configMaps 04/25/23 21:06:45.542
Apr 25 21:06:45.570: INFO: Waiting up to 5m0s for pod "pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4" in namespace "configmap-6759" to be "Succeeded or Failed"
Apr 25 21:06:45.584: INFO: Pod "pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.111596ms
Apr 25 21:06:47.600: INFO: Pod "pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02969196s
Apr 25 21:06:49.600: INFO: Pod "pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029937159s
STEP: Saw pod success 04/25/23 21:06:49.6
Apr 25 21:06:49.601: INFO: Pod "pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4" satisfied condition "Succeeded or Failed"
Apr 25 21:06:49.617: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4 container env-test: <nil>
STEP: delete the pod 04/25/23 21:06:49.655
Apr 25 21:06:49.696: INFO: Waiting for pod pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4 to disappear
Apr 25 21:06:49.711: INFO: Pod pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 25 21:06:49.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6759" for this suite. 04/25/23 21:06:49.729
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":307,"skipped":5584,"failed":0}
------------------------------
• [4.295 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:06:45.462
    Apr 25 21:06:45.463: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename configmap 04/25/23 21:06:45.464
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:45.506
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:45.517
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-6759/configmap-test-2b094df4-c68e-400c-ae07-fe9ad59442e9 04/25/23 21:06:45.531
    STEP: Creating a pod to test consume configMaps 04/25/23 21:06:45.542
    Apr 25 21:06:45.570: INFO: Waiting up to 5m0s for pod "pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4" in namespace "configmap-6759" to be "Succeeded or Failed"
    Apr 25 21:06:45.584: INFO: Pod "pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.111596ms
    Apr 25 21:06:47.600: INFO: Pod "pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02969196s
    Apr 25 21:06:49.600: INFO: Pod "pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029937159s
    STEP: Saw pod success 04/25/23 21:06:49.6
    Apr 25 21:06:49.601: INFO: Pod "pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4" satisfied condition "Succeeded or Failed"
    Apr 25 21:06:49.617: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4 container env-test: <nil>
    STEP: delete the pod 04/25/23 21:06:49.655
    Apr 25 21:06:49.696: INFO: Waiting for pod pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4 to disappear
    Apr 25 21:06:49.711: INFO: Pod pod-configmaps-42452abf-bb23-498b-84b2-84ad15a641d4 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 25 21:06:49.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6759" for this suite. 04/25/23 21:06:49.729
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:06:49.764
Apr 25 21:06:49.764: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename configmap 04/25/23 21:06:49.766
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:49.828
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:49.841
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-620c6fd7-a285-4e16-8bd6-1793a58301fb 04/25/23 21:06:49.854
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 25 21:06:49.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6579" for this suite. 04/25/23 21:06:49.879
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":308,"skipped":5598,"failed":0}
------------------------------
• [0.141 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:06:49.764
    Apr 25 21:06:49.764: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename configmap 04/25/23 21:06:49.766
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:49.828
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:49.841
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-620c6fd7-a285-4e16-8bd6-1793a58301fb 04/25/23 21:06:49.854
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 25 21:06:49.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6579" for this suite. 04/25/23 21:06:49.879
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:06:49.92
Apr 25 21:06:49.920: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename daemonsets 04/25/23 21:06:49.921
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:49.965
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:49.978
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Apr 25 21:06:50.069: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 04/25/23 21:06:50.091
Apr 25 21:06:50.109: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 21:06:50.110: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 04/25/23 21:06:50.11
Apr 25 21:06:50.182: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 21:06:50.182: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 21:06:51.196: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 21:06:51.196: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 21:06:52.198: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 25 21:06:52.198: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 04/25/23 21:06:52.223
Apr 25 21:06:52.279: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 25 21:06:52.279: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Apr 25 21:06:53.294: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 21:06:53.294: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 04/25/23 21:06:53.294
Apr 25 21:06:53.335: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 21:06:53.335: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 21:06:54.357: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 21:06:54.357: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 21:06:55.368: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 21:06:55.368: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 21:06:56.351: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 21:06:56.351: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 21:06:57.353: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 25 21:06:57.353: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/25/23 21:06:57.383
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4984, will wait for the garbage collector to delete the pods 04/25/23 21:06:57.383
Apr 25 21:06:57.472: INFO: Deleting DaemonSet.extensions daemon-set took: 22.542197ms
Apr 25 21:06:57.573: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.36881ms
Apr 25 21:06:59.988: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 21:06:59.988: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 25 21:07:00.002: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"44915"},"items":null}

Apr 25 21:07:00.019: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"44915"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 25 21:07:00.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4984" for this suite. 04/25/23 21:07:00.125
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":309,"skipped":5621,"failed":0}
------------------------------
• [SLOW TEST] [10.234 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:06:49.92
    Apr 25 21:06:49.920: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename daemonsets 04/25/23 21:06:49.921
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:06:49.965
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:06:49.978
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Apr 25 21:06:50.069: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 04/25/23 21:06:50.091
    Apr 25 21:06:50.109: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 21:06:50.110: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 04/25/23 21:06:50.11
    Apr 25 21:06:50.182: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 21:06:50.182: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 21:06:51.196: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 21:06:51.196: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 21:06:52.198: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 25 21:06:52.198: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 04/25/23 21:06:52.223
    Apr 25 21:06:52.279: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 25 21:06:52.279: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Apr 25 21:06:53.294: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 21:06:53.294: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 04/25/23 21:06:53.294
    Apr 25 21:06:53.335: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 21:06:53.335: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 21:06:54.357: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 21:06:54.357: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 21:06:55.368: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 21:06:55.368: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 21:06:56.351: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 21:06:56.351: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 21:06:57.353: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 25 21:06:57.353: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/25/23 21:06:57.383
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4984, will wait for the garbage collector to delete the pods 04/25/23 21:06:57.383
    Apr 25 21:06:57.472: INFO: Deleting DaemonSet.extensions daemon-set took: 22.542197ms
    Apr 25 21:06:57.573: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.36881ms
    Apr 25 21:06:59.988: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 21:06:59.988: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 25 21:07:00.002: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"44915"},"items":null}

    Apr 25 21:07:00.019: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"44915"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 21:07:00.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4984" for this suite. 04/25/23 21:07:00.125
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:07:00.16
Apr 25 21:07:00.161: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename disruption 04/25/23 21:07:00.161
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:07:00.204
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:07:00.216
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:07:00.228
Apr 25 21:07:00.228: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename disruption-2 04/25/23 21:07:00.233
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:07:00.298
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:07:00.307
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 04/25/23 21:07:00.336
STEP: Waiting for the pdb to be processed 04/25/23 21:07:02.398
STEP: Waiting for the pdb to be processed 04/25/23 21:07:02.457
STEP: listing a collection of PDBs across all namespaces 04/25/23 21:07:04.488
STEP: listing a collection of PDBs in namespace disruption-6401 04/25/23 21:07:04.505
STEP: deleting a collection of PDBs 04/25/23 21:07:04.519
STEP: Waiting for the PDB collection to be deleted 04/25/23 21:07:04.582
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Apr 25 21:07:04.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-9925" for this suite. 04/25/23 21:07:04.613
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 25 21:07:04.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6401" for this suite. 04/25/23 21:07:04.658
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":310,"skipped":5720,"failed":0}
------------------------------
• [4.529 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:07:00.16
    Apr 25 21:07:00.161: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename disruption 04/25/23 21:07:00.161
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:07:00.204
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:07:00.216
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:07:00.228
    Apr 25 21:07:00.228: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename disruption-2 04/25/23 21:07:00.233
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:07:00.298
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:07:00.307
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 04/25/23 21:07:00.336
    STEP: Waiting for the pdb to be processed 04/25/23 21:07:02.398
    STEP: Waiting for the pdb to be processed 04/25/23 21:07:02.457
    STEP: listing a collection of PDBs across all namespaces 04/25/23 21:07:04.488
    STEP: listing a collection of PDBs in namespace disruption-6401 04/25/23 21:07:04.505
    STEP: deleting a collection of PDBs 04/25/23 21:07:04.519
    STEP: Waiting for the PDB collection to be deleted 04/25/23 21:07:04.582
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Apr 25 21:07:04.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-9925" for this suite. 04/25/23 21:07:04.613
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 25 21:07:04.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-6401" for this suite. 04/25/23 21:07:04.658
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:07:04.694
Apr 25 21:07:04.694: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 21:07:04.696
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:07:04.737
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:07:04.747
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-c66d85c3-233d-43eb-80cf-e2a1c0a2be24 04/25/23 21:07:04.759
STEP: Creating a pod to test consume secrets 04/25/23 21:07:04.776
Apr 25 21:07:04.815: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7" in namespace "projected-4694" to be "Succeeded or Failed"
Apr 25 21:07:04.830: INFO: Pod "pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7": Phase="Pending", Reason="", readiness=false. Elapsed: 15.153441ms
Apr 25 21:07:06.846: INFO: Pod "pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030830149s
Apr 25 21:07:08.846: INFO: Pod "pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030855161s
STEP: Saw pod success 04/25/23 21:07:08.846
Apr 25 21:07:08.846: INFO: Pod "pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7" satisfied condition "Succeeded or Failed"
Apr 25 21:07:08.864: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/25/23 21:07:08.901
Apr 25 21:07:08.940: INFO: Waiting for pod pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7 to disappear
Apr 25 21:07:08.953: INFO: Pod pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 25 21:07:08.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4694" for this suite. 04/25/23 21:07:08.972
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":311,"skipped":5749,"failed":0}
------------------------------
• [4.303 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:07:04.694
    Apr 25 21:07:04.694: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 21:07:04.696
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:07:04.737
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:07:04.747
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-c66d85c3-233d-43eb-80cf-e2a1c0a2be24 04/25/23 21:07:04.759
    STEP: Creating a pod to test consume secrets 04/25/23 21:07:04.776
    Apr 25 21:07:04.815: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7" in namespace "projected-4694" to be "Succeeded or Failed"
    Apr 25 21:07:04.830: INFO: Pod "pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7": Phase="Pending", Reason="", readiness=false. Elapsed: 15.153441ms
    Apr 25 21:07:06.846: INFO: Pod "pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030830149s
    Apr 25 21:07:08.846: INFO: Pod "pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030855161s
    STEP: Saw pod success 04/25/23 21:07:08.846
    Apr 25 21:07:08.846: INFO: Pod "pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7" satisfied condition "Succeeded or Failed"
    Apr 25 21:07:08.864: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/25/23 21:07:08.901
    Apr 25 21:07:08.940: INFO: Waiting for pod pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7 to disappear
    Apr 25 21:07:08.953: INFO: Pod pod-projected-secrets-392c3191-e745-4dcd-81d1-9183b50eb3c7 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 25 21:07:08.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4694" for this suite. 04/25/23 21:07:08.972
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:07:09.005
Apr 25 21:07:09.006: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 21:07:09.008
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:07:09.052
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:07:09.063
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 04/25/23 21:07:09.076
Apr 25 21:07:09.108: INFO: Waiting up to 5m0s for pod "downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911" in namespace "projected-818" to be "Succeeded or Failed"
Apr 25 21:07:09.122: INFO: Pod "downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911": Phase="Pending", Reason="", readiness=false. Elapsed: 12.829197ms
Apr 25 21:07:11.139: INFO: Pod "downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030240694s
Apr 25 21:07:13.137: INFO: Pod "downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027816933s
STEP: Saw pod success 04/25/23 21:07:13.137
Apr 25 21:07:13.138: INFO: Pod "downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911" satisfied condition "Succeeded or Failed"
Apr 25 21:07:13.154: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911 container client-container: <nil>
STEP: delete the pod 04/25/23 21:07:13.184
Apr 25 21:07:13.227: INFO: Waiting for pod downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911 to disappear
Apr 25 21:07:13.241: INFO: Pod downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 25 21:07:13.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-818" for this suite. 04/25/23 21:07:13.262
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":312,"skipped":5758,"failed":0}
------------------------------
• [4.281 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:07:09.005
    Apr 25 21:07:09.006: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 21:07:09.008
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:07:09.052
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:07:09.063
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 04/25/23 21:07:09.076
    Apr 25 21:07:09.108: INFO: Waiting up to 5m0s for pod "downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911" in namespace "projected-818" to be "Succeeded or Failed"
    Apr 25 21:07:09.122: INFO: Pod "downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911": Phase="Pending", Reason="", readiness=false. Elapsed: 12.829197ms
    Apr 25 21:07:11.139: INFO: Pod "downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030240694s
    Apr 25 21:07:13.137: INFO: Pod "downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027816933s
    STEP: Saw pod success 04/25/23 21:07:13.137
    Apr 25 21:07:13.138: INFO: Pod "downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911" satisfied condition "Succeeded or Failed"
    Apr 25 21:07:13.154: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911 container client-container: <nil>
    STEP: delete the pod 04/25/23 21:07:13.184
    Apr 25 21:07:13.227: INFO: Waiting for pod downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911 to disappear
    Apr 25 21:07:13.241: INFO: Pod downwardapi-volume-41777e4c-77bc-434b-b8e2-ec485cc86911 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 25 21:07:13.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-818" for this suite. 04/25/23 21:07:13.262
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:07:13.293
Apr 25 21:07:13.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename job 04/25/23 21:07:13.296
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:07:13.337
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:07:13.346
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 04/25/23 21:07:13.357
STEP: Ensuring job reaches completions 04/25/23 21:07:13.371
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 25 21:07:25.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5231" for this suite. 04/25/23 21:07:25.41
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":313,"skipped":5792,"failed":0}
------------------------------
• [SLOW TEST] [12.143 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:07:13.293
    Apr 25 21:07:13.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename job 04/25/23 21:07:13.296
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:07:13.337
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:07:13.346
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 04/25/23 21:07:13.357
    STEP: Ensuring job reaches completions 04/25/23 21:07:13.371
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 25 21:07:25.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-5231" for this suite. 04/25/23 21:07:25.41
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:07:25.441
Apr 25 21:07:25.441: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename pod-network-test 04/25/23 21:07:25.445
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:07:25.486
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:07:25.498
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-6936 04/25/23 21:07:25.511
STEP: creating a selector 04/25/23 21:07:25.511
STEP: Creating the service pods in kubernetes 04/25/23 21:07:25.511
Apr 25 21:07:25.512: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 25 21:07:25.639: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6936" to be "running and ready"
Apr 25 21:07:25.658: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.851932ms
Apr 25 21:07:25.658: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 21:07:27.674: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.03510332s
Apr 25 21:07:27.674: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:07:29.673: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.033633583s
Apr 25 21:07:29.673: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:07:31.672: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.032836901s
Apr 25 21:07:31.672: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:07:33.675: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.035376244s
Apr 25 21:07:33.675: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:07:35.673: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.034085374s
Apr 25 21:07:35.673: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:07:37.672: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.032997754s
Apr 25 21:07:37.672: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:07:39.674: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.034766385s
Apr 25 21:07:39.674: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:07:41.679: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.039978066s
Apr 25 21:07:41.679: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:07:43.679: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.039624291s
Apr 25 21:07:43.679: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:07:45.674: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.034932569s
Apr 25 21:07:45.674: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:07:47.673: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.034120201s
Apr 25 21:07:47.674: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 25 21:07:47.674: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 25 21:07:47.687: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6936" to be "running and ready"
Apr 25 21:07:47.701: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 14.267355ms
Apr 25 21:07:47.701: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 25 21:07:47.702: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 25 21:07:47.716: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6936" to be "running and ready"
Apr 25 21:07:47.730: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 13.742436ms
Apr 25 21:07:47.730: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 25 21:07:47.730: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/25/23 21:07:47.743
Apr 25 21:07:47.784: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6936" to be "running"
Apr 25 21:07:47.820: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 36.633649ms
Apr 25 21:07:49.836: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.052148365s
Apr 25 21:07:49.836: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 25 21:07:49.850: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-6936" to be "running"
Apr 25 21:07:49.863: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 13.065456ms
Apr 25 21:07:49.863: INFO: Pod "host-test-container-pod" satisfied condition "running"
Apr 25 21:07:49.880: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 25 21:07:49.880: INFO: Going to poll 172.30.191.11 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Apr 25 21:07:49.892: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.191.11:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6936 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 21:07:49.892: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 21:07:49.893: INFO: ExecWithOptions: Clientset creation
Apr 25 21:07:49.894: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6936/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.191.11%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 25 21:07:50.139: INFO: Found all 1 expected endpoints: [netserver-0]
Apr 25 21:07:50.139: INFO: Going to poll 172.30.226.84 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Apr 25 21:07:50.153: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.226.84:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6936 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 21:07:50.153: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 21:07:50.155: INFO: ExecWithOptions: Clientset creation
Apr 25 21:07:50.155: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6936/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.226.84%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 25 21:07:50.398: INFO: Found all 1 expected endpoints: [netserver-1]
Apr 25 21:07:50.398: INFO: Going to poll 172.30.142.146 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Apr 25 21:07:50.421: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.142.146:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6936 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 21:07:50.421: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 21:07:50.423: INFO: ExecWithOptions: Clientset creation
Apr 25 21:07:50.423: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6936/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.142.146%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 25 21:07:50.665: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 25 21:07:50.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6936" for this suite. 04/25/23 21:07:50.685
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":314,"skipped":5793,"failed":0}
------------------------------
• [SLOW TEST] [25.268 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:07:25.441
    Apr 25 21:07:25.441: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename pod-network-test 04/25/23 21:07:25.445
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:07:25.486
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:07:25.498
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-6936 04/25/23 21:07:25.511
    STEP: creating a selector 04/25/23 21:07:25.511
    STEP: Creating the service pods in kubernetes 04/25/23 21:07:25.511
    Apr 25 21:07:25.512: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 25 21:07:25.639: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6936" to be "running and ready"
    Apr 25 21:07:25.658: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.851932ms
    Apr 25 21:07:25.658: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 21:07:27.674: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.03510332s
    Apr 25 21:07:27.674: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:07:29.673: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.033633583s
    Apr 25 21:07:29.673: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:07:31.672: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.032836901s
    Apr 25 21:07:31.672: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:07:33.675: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.035376244s
    Apr 25 21:07:33.675: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:07:35.673: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.034085374s
    Apr 25 21:07:35.673: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:07:37.672: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.032997754s
    Apr 25 21:07:37.672: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:07:39.674: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.034766385s
    Apr 25 21:07:39.674: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:07:41.679: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.039978066s
    Apr 25 21:07:41.679: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:07:43.679: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.039624291s
    Apr 25 21:07:43.679: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:07:45.674: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.034932569s
    Apr 25 21:07:45.674: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:07:47.673: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.034120201s
    Apr 25 21:07:47.674: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 25 21:07:47.674: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 25 21:07:47.687: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6936" to be "running and ready"
    Apr 25 21:07:47.701: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 14.267355ms
    Apr 25 21:07:47.701: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 25 21:07:47.702: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 25 21:07:47.716: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6936" to be "running and ready"
    Apr 25 21:07:47.730: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 13.742436ms
    Apr 25 21:07:47.730: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 25 21:07:47.730: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/25/23 21:07:47.743
    Apr 25 21:07:47.784: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6936" to be "running"
    Apr 25 21:07:47.820: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 36.633649ms
    Apr 25 21:07:49.836: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.052148365s
    Apr 25 21:07:49.836: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 25 21:07:49.850: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-6936" to be "running"
    Apr 25 21:07:49.863: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 13.065456ms
    Apr 25 21:07:49.863: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Apr 25 21:07:49.880: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 25 21:07:49.880: INFO: Going to poll 172.30.191.11 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Apr 25 21:07:49.892: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.191.11:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6936 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 21:07:49.892: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 21:07:49.893: INFO: ExecWithOptions: Clientset creation
    Apr 25 21:07:49.894: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6936/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.191.11%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 25 21:07:50.139: INFO: Found all 1 expected endpoints: [netserver-0]
    Apr 25 21:07:50.139: INFO: Going to poll 172.30.226.84 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Apr 25 21:07:50.153: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.226.84:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6936 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 21:07:50.153: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 21:07:50.155: INFO: ExecWithOptions: Clientset creation
    Apr 25 21:07:50.155: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6936/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.226.84%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 25 21:07:50.398: INFO: Found all 1 expected endpoints: [netserver-1]
    Apr 25 21:07:50.398: INFO: Going to poll 172.30.142.146 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Apr 25 21:07:50.421: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.142.146:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6936 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 21:07:50.421: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 21:07:50.423: INFO: ExecWithOptions: Clientset creation
    Apr 25 21:07:50.423: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6936/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.142.146%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 25 21:07:50.665: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 25 21:07:50.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-6936" for this suite. 04/25/23 21:07:50.685
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:07:50.719
Apr 25 21:07:50.719: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename statefulset 04/25/23 21:07:50.722
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:07:50.814
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:07:50.828
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2506 04/25/23 21:07:50.843
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 04/25/23 21:07:50.862
Apr 25 21:07:50.891: INFO: Found 0 stateful pods, waiting for 3
Apr 25 21:08:00.910: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 21:08:00.911: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 21:08:00.911: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 21:08:00.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-2506 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 25 21:08:01.318: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 25 21:08:01.318: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 25 21:08:01.319: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/25/23 21:08:11.39
Apr 25 21:08:11.433: INFO: Updating stateful set ss2
STEP: Creating a new revision 04/25/23 21:08:11.433
STEP: Updating Pods in reverse ordinal order 04/25/23 21:08:21.489
Apr 25 21:08:21.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-2506 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 25 21:08:21.922: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 25 21:08:21.922: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 25 21:08:21.922: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 25 21:08:32.018: INFO: Waiting for StatefulSet statefulset-2506/ss2 to complete update
STEP: Rolling back to a previous revision 04/25/23 21:08:42.049
Apr 25 21:08:42.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-2506 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 25 21:08:42.420: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 25 21:08:42.420: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 25 21:08:42.420: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 25 21:08:52.522: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 04/25/23 21:09:02.592
Apr 25 21:09:02.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-2506 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 25 21:09:03.025: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 25 21:09:03.025: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 25 21:09:03.025: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 25 21:09:13.118: INFO: Waiting for StatefulSet statefulset-2506/ss2 to complete update
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 25 21:09:23.166: INFO: Deleting all statefulset in ns statefulset-2506
Apr 25 21:09:23.177: INFO: Scaling statefulset ss2 to 0
Apr 25 21:09:33.234: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 21:09:33.246: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 25 21:09:33.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2506" for this suite. 04/25/23 21:09:33.316
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":315,"skipped":5819,"failed":0}
------------------------------
• [SLOW TEST] [102.628 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:07:50.719
    Apr 25 21:07:50.719: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename statefulset 04/25/23 21:07:50.722
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:07:50.814
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:07:50.828
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2506 04/25/23 21:07:50.843
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 04/25/23 21:07:50.862
    Apr 25 21:07:50.891: INFO: Found 0 stateful pods, waiting for 3
    Apr 25 21:08:00.910: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 25 21:08:00.911: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 25 21:08:00.911: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Apr 25 21:08:00.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-2506 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 25 21:08:01.318: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 25 21:08:01.318: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 25 21:08:01.319: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/25/23 21:08:11.39
    Apr 25 21:08:11.433: INFO: Updating stateful set ss2
    STEP: Creating a new revision 04/25/23 21:08:11.433
    STEP: Updating Pods in reverse ordinal order 04/25/23 21:08:21.489
    Apr 25 21:08:21.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-2506 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 25 21:08:21.922: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 25 21:08:21.922: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 25 21:08:21.922: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 25 21:08:32.018: INFO: Waiting for StatefulSet statefulset-2506/ss2 to complete update
    STEP: Rolling back to a previous revision 04/25/23 21:08:42.049
    Apr 25 21:08:42.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-2506 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 25 21:08:42.420: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 25 21:08:42.420: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 25 21:08:42.420: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 25 21:08:52.522: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 04/25/23 21:09:02.592
    Apr 25 21:09:02.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=statefulset-2506 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 25 21:09:03.025: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 25 21:09:03.025: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 25 21:09:03.025: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 25 21:09:13.118: INFO: Waiting for StatefulSet statefulset-2506/ss2 to complete update
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 25 21:09:23.166: INFO: Deleting all statefulset in ns statefulset-2506
    Apr 25 21:09:23.177: INFO: Scaling statefulset ss2 to 0
    Apr 25 21:09:33.234: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 25 21:09:33.246: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 25 21:09:33.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2506" for this suite. 04/25/23 21:09:33.316
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:09:33.359
Apr 25 21:09:33.360: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename endpointslice 04/25/23 21:09:33.362
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:09:33.396
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:09:33.407
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Apr 25 21:09:33.454: INFO: Endpoints addresses: [172.20.0.1] , ports: [2040]
Apr 25 21:09:33.454: INFO: EndpointSlices addresses: [172.20.0.1] , ports: [2040]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 25 21:09:33.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-6492" for this suite. 04/25/23 21:09:33.471
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":316,"skipped":5843,"failed":0}
------------------------------
• [0.137 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:09:33.359
    Apr 25 21:09:33.360: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename endpointslice 04/25/23 21:09:33.362
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:09:33.396
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:09:33.407
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Apr 25 21:09:33.454: INFO: Endpoints addresses: [172.20.0.1] , ports: [2040]
    Apr 25 21:09:33.454: INFO: EndpointSlices addresses: [172.20.0.1] , ports: [2040]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 25 21:09:33.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-6492" for this suite. 04/25/23 21:09:33.471
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:09:33.517
Apr 25 21:09:33.517: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename replicaset 04/25/23 21:09:33.519
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:09:33.56
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:09:33.572
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Apr 25 21:09:33.583: INFO: Creating ReplicaSet my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00
Apr 25 21:09:33.618: INFO: Pod name my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00: Found 0 pods out of 1
Apr 25 21:09:38.632: INFO: Pod name my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00: Found 1 pods out of 1
Apr 25 21:09:38.632: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00" is running
Apr 25 21:09:38.633: INFO: Waiting up to 5m0s for pod "my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00-x6gng" in namespace "replicaset-9332" to be "running"
Apr 25 21:09:38.646: INFO: Pod "my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00-x6gng": Phase="Running", Reason="", readiness=true. Elapsed: 13.437604ms
Apr 25 21:09:38.646: INFO: Pod "my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00-x6gng" satisfied condition "running"
Apr 25 21:09:38.647: INFO: Pod "my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00-x6gng" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:09:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:09:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:09:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:09:33 +0000 UTC Reason: Message:}])
Apr 25 21:09:38.647: INFO: Trying to dial the pod
Apr 25 21:09:43.776: INFO: Controller my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00: Got expected result from replica 1 [my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00-x6gng]: "my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00-x6gng", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 25 21:09:43.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9332" for this suite. 04/25/23 21:09:43.794
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":317,"skipped":5861,"failed":0}
------------------------------
• [SLOW TEST] [10.301 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:09:33.517
    Apr 25 21:09:33.517: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename replicaset 04/25/23 21:09:33.519
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:09:33.56
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:09:33.572
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Apr 25 21:09:33.583: INFO: Creating ReplicaSet my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00
    Apr 25 21:09:33.618: INFO: Pod name my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00: Found 0 pods out of 1
    Apr 25 21:09:38.632: INFO: Pod name my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00: Found 1 pods out of 1
    Apr 25 21:09:38.632: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00" is running
    Apr 25 21:09:38.633: INFO: Waiting up to 5m0s for pod "my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00-x6gng" in namespace "replicaset-9332" to be "running"
    Apr 25 21:09:38.646: INFO: Pod "my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00-x6gng": Phase="Running", Reason="", readiness=true. Elapsed: 13.437604ms
    Apr 25 21:09:38.646: INFO: Pod "my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00-x6gng" satisfied condition "running"
    Apr 25 21:09:38.647: INFO: Pod "my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00-x6gng" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:09:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:09:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:09:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:09:33 +0000 UTC Reason: Message:}])
    Apr 25 21:09:38.647: INFO: Trying to dial the pod
    Apr 25 21:09:43.776: INFO: Controller my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00: Got expected result from replica 1 [my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00-x6gng]: "my-hostname-basic-5a2fb738-b7d6-4752-b329-93afb3b07b00-x6gng", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 25 21:09:43.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9332" for this suite. 04/25/23 21:09:43.794
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:09:43.825
Apr 25 21:09:43.825: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename watch 04/25/23 21:09:43.828
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:09:43.866
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:09:43.88
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 04/25/23 21:09:43.894
STEP: creating a new configmap 04/25/23 21:09:43.899
STEP: modifying the configmap once 04/25/23 21:09:43.914
STEP: closing the watch once it receives two notifications 04/25/23 21:09:43.938
Apr 25 21:09:43.938: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2511  6b97918c-58fb-4f35-9bf7-4355e5bd9076 45927 0 2023-04-25 21:09:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-25 21:09:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 25 21:09:43.939: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2511  6b97918c-58fb-4f35-9bf7-4355e5bd9076 45928 0 2023-04-25 21:09:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-25 21:09:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 04/25/23 21:09:43.94
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 04/25/23 21:09:43.964
STEP: deleting the configmap 04/25/23 21:09:43.971
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 04/25/23 21:09:43.986
Apr 25 21:09:43.987: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2511  6b97918c-58fb-4f35-9bf7-4355e5bd9076 45929 0 2023-04-25 21:09:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-25 21:09:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 25 21:09:43.987: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2511  6b97918c-58fb-4f35-9bf7-4355e5bd9076 45930 0 2023-04-25 21:09:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-25 21:09:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 25 21:09:43.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2511" for this suite. 04/25/23 21:09:44.005
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":318,"skipped":5901,"failed":0}
------------------------------
• [0.236 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:09:43.825
    Apr 25 21:09:43.825: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename watch 04/25/23 21:09:43.828
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:09:43.866
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:09:43.88
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 04/25/23 21:09:43.894
    STEP: creating a new configmap 04/25/23 21:09:43.899
    STEP: modifying the configmap once 04/25/23 21:09:43.914
    STEP: closing the watch once it receives two notifications 04/25/23 21:09:43.938
    Apr 25 21:09:43.938: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2511  6b97918c-58fb-4f35-9bf7-4355e5bd9076 45927 0 2023-04-25 21:09:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-25 21:09:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 25 21:09:43.939: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2511  6b97918c-58fb-4f35-9bf7-4355e5bd9076 45928 0 2023-04-25 21:09:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-25 21:09:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 04/25/23 21:09:43.94
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 04/25/23 21:09:43.964
    STEP: deleting the configmap 04/25/23 21:09:43.971
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 04/25/23 21:09:43.986
    Apr 25 21:09:43.987: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2511  6b97918c-58fb-4f35-9bf7-4355e5bd9076 45929 0 2023-04-25 21:09:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-25 21:09:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 25 21:09:43.987: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2511  6b97918c-58fb-4f35-9bf7-4355e5bd9076 45930 0 2023-04-25 21:09:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-25 21:09:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 25 21:09:43.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2511" for this suite. 04/25/23 21:09:44.005
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:09:44.071
Apr 25 21:09:44.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 21:09:44.073
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:09:44.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:09:44.131
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 21:09:44.207
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 21:09:44.664
STEP: Deploying the webhook pod 04/25/23 21:09:44.683
STEP: Wait for the deployment to be ready 04/25/23 21:09:44.72
Apr 25 21:09:44.792: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/25/23 21:09:46.829
STEP: Verifying the service has paired with the endpoint 04/25/23 21:09:46.865
Apr 25 21:09:47.867: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Apr 25 21:09:47.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4810-crds.webhook.example.com via the AdmissionRegistration API 04/25/23 21:09:48.413
STEP: Creating a custom resource that should be mutated by the webhook 04/25/23 21:09:48.502
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 21:09:51.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5809" for this suite. 04/25/23 21:09:51.229
STEP: Destroying namespace "webhook-5809-markers" for this suite. 04/25/23 21:09:51.254
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":319,"skipped":5971,"failed":0}
------------------------------
• [SLOW TEST] [7.368 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:09:44.071
    Apr 25 21:09:44.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 21:09:44.073
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:09:44.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:09:44.131
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 21:09:44.207
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 21:09:44.664
    STEP: Deploying the webhook pod 04/25/23 21:09:44.683
    STEP: Wait for the deployment to be ready 04/25/23 21:09:44.72
    Apr 25 21:09:44.792: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/25/23 21:09:46.829
    STEP: Verifying the service has paired with the endpoint 04/25/23 21:09:46.865
    Apr 25 21:09:47.867: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Apr 25 21:09:47.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4810-crds.webhook.example.com via the AdmissionRegistration API 04/25/23 21:09:48.413
    STEP: Creating a custom resource that should be mutated by the webhook 04/25/23 21:09:48.502
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 21:09:51.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5809" for this suite. 04/25/23 21:09:51.229
    STEP: Destroying namespace "webhook-5809-markers" for this suite. 04/25/23 21:09:51.254
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:09:51.443
Apr 25 21:09:51.444: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename pods 04/25/23 21:09:51.447
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:09:51.534
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:09:51.544
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 04/25/23 21:09:51.557
Apr 25 21:09:51.612: INFO: created test-pod-1
Apr 25 21:09:51.630: INFO: created test-pod-2
Apr 25 21:09:51.653: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 04/25/23 21:09:51.653
Apr 25 21:09:51.654: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-7825' to be running and ready
Apr 25 21:09:51.696: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 25 21:09:51.697: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 25 21:09:51.697: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 25 21:09:51.697: INFO: 0 / 3 pods in namespace 'pods-7825' are running and ready (0 seconds elapsed)
Apr 25 21:09:51.698: INFO: expected 0 pod replicas in namespace 'pods-7825', 0 are Running and Ready.
Apr 25 21:09:51.698: INFO: POD         NODE          PHASE    GRACE  CONDITIONS
Apr 25 21:09:51.698: INFO: test-pod-1  10.10.21.190  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 21:09:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 21:09:51 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 21:09:51 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 21:09:51 +0000 UTC  }]
Apr 25 21:09:51.699: INFO: test-pod-2  10.10.21.190  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 21:09:51 +0000 UTC  }]
Apr 25 21:09:51.699: INFO: test-pod-3  10.10.21.190  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 21:09:51 +0000 UTC  }]
Apr 25 21:09:51.699: INFO: 
Apr 25 21:09:53.740: INFO: 3 / 3 pods in namespace 'pods-7825' are running and ready (2 seconds elapsed)
Apr 25 21:09:53.740: INFO: expected 0 pod replicas in namespace 'pods-7825', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 04/25/23 21:09:53.809
Apr 25 21:09:53.824: INFO: Pod quantity 3 is different from expected quantity 0
Apr 25 21:09:54.839: INFO: Pod quantity 3 is different from expected quantity 0
Apr 25 21:09:55.839: INFO: Pod quantity 3 is different from expected quantity 0
Apr 25 21:09:56.839: INFO: Pod quantity 2 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 25 21:09:57.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7825" for this suite. 04/25/23 21:09:57.854
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":320,"skipped":5992,"failed":0}
------------------------------
• [SLOW TEST] [6.434 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:09:51.443
    Apr 25 21:09:51.444: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename pods 04/25/23 21:09:51.447
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:09:51.534
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:09:51.544
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 04/25/23 21:09:51.557
    Apr 25 21:09:51.612: INFO: created test-pod-1
    Apr 25 21:09:51.630: INFO: created test-pod-2
    Apr 25 21:09:51.653: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 04/25/23 21:09:51.653
    Apr 25 21:09:51.654: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-7825' to be running and ready
    Apr 25 21:09:51.696: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 25 21:09:51.697: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 25 21:09:51.697: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 25 21:09:51.697: INFO: 0 / 3 pods in namespace 'pods-7825' are running and ready (0 seconds elapsed)
    Apr 25 21:09:51.698: INFO: expected 0 pod replicas in namespace 'pods-7825', 0 are Running and Ready.
    Apr 25 21:09:51.698: INFO: POD         NODE          PHASE    GRACE  CONDITIONS
    Apr 25 21:09:51.698: INFO: test-pod-1  10.10.21.190  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 21:09:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 21:09:51 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-25 21:09:51 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 21:09:51 +0000 UTC  }]
    Apr 25 21:09:51.699: INFO: test-pod-2  10.10.21.190  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 21:09:51 +0000 UTC  }]
    Apr 25 21:09:51.699: INFO: test-pod-3  10.10.21.190  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-25 21:09:51 +0000 UTC  }]
    Apr 25 21:09:51.699: INFO: 
    Apr 25 21:09:53.740: INFO: 3 / 3 pods in namespace 'pods-7825' are running and ready (2 seconds elapsed)
    Apr 25 21:09:53.740: INFO: expected 0 pod replicas in namespace 'pods-7825', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 04/25/23 21:09:53.809
    Apr 25 21:09:53.824: INFO: Pod quantity 3 is different from expected quantity 0
    Apr 25 21:09:54.839: INFO: Pod quantity 3 is different from expected quantity 0
    Apr 25 21:09:55.839: INFO: Pod quantity 3 is different from expected quantity 0
    Apr 25 21:09:56.839: INFO: Pod quantity 2 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 25 21:09:57.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7825" for this suite. 04/25/23 21:09:57.854
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:09:57.881
Apr 25 21:09:57.882: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename svcaccounts 04/25/23 21:09:57.883
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:09:57.936
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:09:57.948
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Apr 25 21:09:57.973: INFO: Got root ca configmap in namespace "svcaccounts-2910"
Apr 25 21:09:58.021: INFO: Deleted root ca configmap in namespace "svcaccounts-2910"
STEP: waiting for a new root ca configmap created 04/25/23 21:09:58.522
Apr 25 21:09:58.534: INFO: Recreated root ca configmap in namespace "svcaccounts-2910"
Apr 25 21:09:58.548: INFO: Updated root ca configmap in namespace "svcaccounts-2910"
STEP: waiting for the root ca configmap reconciled 04/25/23 21:09:59.049
Apr 25 21:09:59.061: INFO: Reconciled root ca configmap in namespace "svcaccounts-2910"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 25 21:09:59.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2910" for this suite. 04/25/23 21:09:59.078
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":321,"skipped":6015,"failed":0}
------------------------------
• [1.220 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:09:57.881
    Apr 25 21:09:57.882: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename svcaccounts 04/25/23 21:09:57.883
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:09:57.936
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:09:57.948
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Apr 25 21:09:57.973: INFO: Got root ca configmap in namespace "svcaccounts-2910"
    Apr 25 21:09:58.021: INFO: Deleted root ca configmap in namespace "svcaccounts-2910"
    STEP: waiting for a new root ca configmap created 04/25/23 21:09:58.522
    Apr 25 21:09:58.534: INFO: Recreated root ca configmap in namespace "svcaccounts-2910"
    Apr 25 21:09:58.548: INFO: Updated root ca configmap in namespace "svcaccounts-2910"
    STEP: waiting for the root ca configmap reconciled 04/25/23 21:09:59.049
    Apr 25 21:09:59.061: INFO: Reconciled root ca configmap in namespace "svcaccounts-2910"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 25 21:09:59.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2910" for this suite. 04/25/23 21:09:59.078
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:09:59.126
Apr 25 21:09:59.126: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename pod-network-test 04/25/23 21:09:59.127
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:09:59.167
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:09:59.18
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-8824 04/25/23 21:09:59.191
STEP: creating a selector 04/25/23 21:09:59.192
STEP: Creating the service pods in kubernetes 04/25/23 21:09:59.192
Apr 25 21:09:59.193: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 25 21:09:59.310: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-8824" to be "running and ready"
Apr 25 21:09:59.346: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 35.379055ms
Apr 25 21:09:59.346: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 21:10:01.362: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.051248269s
Apr 25 21:10:01.362: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:10:03.386: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.075733791s
Apr 25 21:10:03.386: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:10:05.365: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.054933344s
Apr 25 21:10:05.366: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:10:07.363: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.052286676s
Apr 25 21:10:07.363: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:10:09.361: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.050696415s
Apr 25 21:10:09.361: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:10:11.361: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.050234081s
Apr 25 21:10:11.362: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:10:13.360: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.050043831s
Apr 25 21:10:13.361: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:10:15.359: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.048941678s
Apr 25 21:10:15.359: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:10:17.361: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.050164214s
Apr 25 21:10:17.361: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:10:19.360: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.049784944s
Apr 25 21:10:19.360: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 25 21:10:21.360: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.049723052s
Apr 25 21:10:21.360: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 25 21:10:21.360: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 25 21:10:21.375: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-8824" to be "running and ready"
Apr 25 21:10:21.389: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 13.707342ms
Apr 25 21:10:21.389: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 25 21:10:21.389: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 25 21:10:21.428: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-8824" to be "running and ready"
Apr 25 21:10:21.443: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 14.0792ms
Apr 25 21:10:21.443: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 25 21:10:21.443: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/25/23 21:10:21.456
Apr 25 21:10:21.512: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-8824" to be "running"
Apr 25 21:10:21.526: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.994218ms
Apr 25 21:10:23.555: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.042315956s
Apr 25 21:10:23.555: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 25 21:10:23.567: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-8824" to be "running"
Apr 25 21:10:23.581: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 13.825889ms
Apr 25 21:10:23.581: INFO: Pod "host-test-container-pod" satisfied condition "running"
Apr 25 21:10:23.594: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 25 21:10:23.594: INFO: Going to poll 172.30.191.2 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Apr 25 21:10:23.607: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.191.2 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8824 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 21:10:23.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 21:10:23.609: INFO: ExecWithOptions: Clientset creation
Apr 25 21:10:23.610: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-8824/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.191.2+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 25 21:10:24.866: INFO: Found all 1 expected endpoints: [netserver-0]
Apr 25 21:10:24.866: INFO: Going to poll 172.30.226.96 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Apr 25 21:10:24.890: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.226.96 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8824 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 21:10:24.890: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 21:10:24.891: INFO: ExecWithOptions: Clientset creation
Apr 25 21:10:24.892: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-8824/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.226.96+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 25 21:10:26.117: INFO: Found all 1 expected endpoints: [netserver-1]
Apr 25 21:10:26.117: INFO: Going to poll 172.30.142.176 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Apr 25 21:10:26.137: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.142.176 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8824 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 25 21:10:26.138: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
Apr 25 21:10:26.140: INFO: ExecWithOptions: Clientset creation
Apr 25 21:10:26.140: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-8824/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.142.176+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 25 21:10:27.362: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 25 21:10:27.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8824" for this suite. 04/25/23 21:10:27.38
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":322,"skipped":6088,"failed":0}
------------------------------
• [SLOW TEST] [28.279 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:09:59.126
    Apr 25 21:09:59.126: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename pod-network-test 04/25/23 21:09:59.127
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:09:59.167
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:09:59.18
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-8824 04/25/23 21:09:59.191
    STEP: creating a selector 04/25/23 21:09:59.192
    STEP: Creating the service pods in kubernetes 04/25/23 21:09:59.192
    Apr 25 21:09:59.193: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 25 21:09:59.310: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-8824" to be "running and ready"
    Apr 25 21:09:59.346: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 35.379055ms
    Apr 25 21:09:59.346: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 21:10:01.362: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.051248269s
    Apr 25 21:10:01.362: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:10:03.386: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.075733791s
    Apr 25 21:10:03.386: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:10:05.365: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.054933344s
    Apr 25 21:10:05.366: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:10:07.363: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.052286676s
    Apr 25 21:10:07.363: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:10:09.361: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.050696415s
    Apr 25 21:10:09.361: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:10:11.361: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.050234081s
    Apr 25 21:10:11.362: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:10:13.360: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.050043831s
    Apr 25 21:10:13.361: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:10:15.359: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.048941678s
    Apr 25 21:10:15.359: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:10:17.361: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.050164214s
    Apr 25 21:10:17.361: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:10:19.360: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.049784944s
    Apr 25 21:10:19.360: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 25 21:10:21.360: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.049723052s
    Apr 25 21:10:21.360: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 25 21:10:21.360: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 25 21:10:21.375: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-8824" to be "running and ready"
    Apr 25 21:10:21.389: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 13.707342ms
    Apr 25 21:10:21.389: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 25 21:10:21.389: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 25 21:10:21.428: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-8824" to be "running and ready"
    Apr 25 21:10:21.443: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 14.0792ms
    Apr 25 21:10:21.443: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 25 21:10:21.443: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/25/23 21:10:21.456
    Apr 25 21:10:21.512: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-8824" to be "running"
    Apr 25 21:10:21.526: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.994218ms
    Apr 25 21:10:23.555: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.042315956s
    Apr 25 21:10:23.555: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 25 21:10:23.567: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-8824" to be "running"
    Apr 25 21:10:23.581: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 13.825889ms
    Apr 25 21:10:23.581: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Apr 25 21:10:23.594: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 25 21:10:23.594: INFO: Going to poll 172.30.191.2 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Apr 25 21:10:23.607: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.191.2 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8824 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 21:10:23.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 21:10:23.609: INFO: ExecWithOptions: Clientset creation
    Apr 25 21:10:23.610: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-8824/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.191.2+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 25 21:10:24.866: INFO: Found all 1 expected endpoints: [netserver-0]
    Apr 25 21:10:24.866: INFO: Going to poll 172.30.226.96 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Apr 25 21:10:24.890: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.226.96 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8824 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 21:10:24.890: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 21:10:24.891: INFO: ExecWithOptions: Clientset creation
    Apr 25 21:10:24.892: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-8824/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.226.96+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 25 21:10:26.117: INFO: Found all 1 expected endpoints: [netserver-1]
    Apr 25 21:10:26.117: INFO: Going to poll 172.30.142.176 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Apr 25 21:10:26.137: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.142.176 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8824 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 25 21:10:26.138: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    Apr 25 21:10:26.140: INFO: ExecWithOptions: Clientset creation
    Apr 25 21:10:26.140: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-8824/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.142.176+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 25 21:10:27.362: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 25 21:10:27.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-8824" for this suite. 04/25/23 21:10:27.38
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:10:27.412
Apr 25 21:10:27.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 21:10:27.416
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:10:27.464
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:10:27.48
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 21:10:27.544
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 21:10:27.947
STEP: Deploying the webhook pod 04/25/23 21:10:27.968
STEP: Wait for the deployment to be ready 04/25/23 21:10:28.001
Apr 25 21:10:28.027: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/25/23 21:10:30.064
STEP: Verifying the service has paired with the endpoint 04/25/23 21:10:30.097
Apr 25 21:10:31.098: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 04/25/23 21:10:31.112
STEP: create a pod that should be denied by the webhook 04/25/23 21:10:31.216
STEP: create a pod that causes the webhook to hang 04/25/23 21:10:31.298
STEP: create a configmap that should be denied by the webhook 04/25/23 21:10:41.324
STEP: create a configmap that should be admitted by the webhook 04/25/23 21:10:41.393
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 04/25/23 21:10:41.492
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 04/25/23 21:10:41.523
STEP: create a namespace that bypass the webhook 04/25/23 21:10:41.547
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 04/25/23 21:10:41.576
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 21:10:41.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8372" for this suite. 04/25/23 21:10:41.723
STEP: Destroying namespace "webhook-8372-markers" for this suite. 04/25/23 21:10:41.777
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":323,"skipped":6091,"failed":0}
------------------------------
• [SLOW TEST] [14.541 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:10:27.412
    Apr 25 21:10:27.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 21:10:27.416
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:10:27.464
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:10:27.48
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 21:10:27.544
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 21:10:27.947
    STEP: Deploying the webhook pod 04/25/23 21:10:27.968
    STEP: Wait for the deployment to be ready 04/25/23 21:10:28.001
    Apr 25 21:10:28.027: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/25/23 21:10:30.064
    STEP: Verifying the service has paired with the endpoint 04/25/23 21:10:30.097
    Apr 25 21:10:31.098: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 04/25/23 21:10:31.112
    STEP: create a pod that should be denied by the webhook 04/25/23 21:10:31.216
    STEP: create a pod that causes the webhook to hang 04/25/23 21:10:31.298
    STEP: create a configmap that should be denied by the webhook 04/25/23 21:10:41.324
    STEP: create a configmap that should be admitted by the webhook 04/25/23 21:10:41.393
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 04/25/23 21:10:41.492
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 04/25/23 21:10:41.523
    STEP: create a namespace that bypass the webhook 04/25/23 21:10:41.547
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 04/25/23 21:10:41.576
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 21:10:41.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8372" for this suite. 04/25/23 21:10:41.723
    STEP: Destroying namespace "webhook-8372-markers" for this suite. 04/25/23 21:10:41.777
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:10:41.957
Apr 25 21:10:41.958: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename custom-resource-definition 04/25/23 21:10:41.959
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:10:42.005
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:10:42.014
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Apr 25 21:10:42.025: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 21:10:48.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5539" for this suite. 04/25/23 21:10:48.342
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":324,"skipped":6106,"failed":0}
------------------------------
• [SLOW TEST] [6.407 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:10:41.957
    Apr 25 21:10:41.958: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename custom-resource-definition 04/25/23 21:10:41.959
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:10:42.005
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:10:42.014
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Apr 25 21:10:42.025: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 21:10:48.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-5539" for this suite. 04/25/23 21:10:48.342
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:10:48.372
Apr 25 21:10:48.372: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename daemonsets 04/25/23 21:10:48.374
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:10:48.42
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:10:48.433
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Apr 25 21:10:48.530: INFO: Create a RollingUpdate DaemonSet
Apr 25 21:10:48.559: INFO: Check that daemon pods launch on every node of the cluster
Apr 25 21:10:48.588: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 21:10:48.588: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 21:10:49.616: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 21:10:49.616: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
Apr 25 21:10:50.627: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 25 21:10:50.627: INFO: Node 10.10.21.190 is running 0 daemon pod, expected 1
Apr 25 21:10:51.623: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 25 21:10:51.623: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Apr 25 21:10:51.624: INFO: Update the DaemonSet to trigger a rollout
Apr 25 21:10:51.676: INFO: Updating DaemonSet daemon-set
Apr 25 21:10:54.742: INFO: Roll back the DaemonSet before rollout is complete
Apr 25 21:10:54.773: INFO: Updating DaemonSet daemon-set
Apr 25 21:10:54.773: INFO: Make sure DaemonSet rollback is complete
Apr 25 21:10:54.789: INFO: Wrong image for pod: daemon-set-v7xld. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Apr 25 21:10:54.789: INFO: Pod daemon-set-v7xld is not available
Apr 25 21:11:02.822: INFO: Pod daemon-set-cdncf is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/25/23 21:11:02.869
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4343, will wait for the garbage collector to delete the pods 04/25/23 21:11:02.87
Apr 25 21:11:02.958: INFO: Deleting DaemonSet.extensions daemon-set took: 22.163285ms
Apr 25 21:11:03.058: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.596433ms
Apr 25 21:11:05.278: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 25 21:11:05.278: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 25 21:11:05.290: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"46582"},"items":null}

Apr 25 21:11:05.302: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"46582"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 25 21:11:05.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4343" for this suite. 04/25/23 21:11:05.406
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":325,"skipped":6179,"failed":0}
------------------------------
• [SLOW TEST] [17.068 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:10:48.372
    Apr 25 21:10:48.372: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename daemonsets 04/25/23 21:10:48.374
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:10:48.42
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:10:48.433
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Apr 25 21:10:48.530: INFO: Create a RollingUpdate DaemonSet
    Apr 25 21:10:48.559: INFO: Check that daemon pods launch on every node of the cluster
    Apr 25 21:10:48.588: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 21:10:48.588: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 21:10:49.616: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 21:10:49.616: INFO: Node 10.10.21.136 is running 0 daemon pod, expected 1
    Apr 25 21:10:50.627: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 25 21:10:50.627: INFO: Node 10.10.21.190 is running 0 daemon pod, expected 1
    Apr 25 21:10:51.623: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 25 21:10:51.623: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Apr 25 21:10:51.624: INFO: Update the DaemonSet to trigger a rollout
    Apr 25 21:10:51.676: INFO: Updating DaemonSet daemon-set
    Apr 25 21:10:54.742: INFO: Roll back the DaemonSet before rollout is complete
    Apr 25 21:10:54.773: INFO: Updating DaemonSet daemon-set
    Apr 25 21:10:54.773: INFO: Make sure DaemonSet rollback is complete
    Apr 25 21:10:54.789: INFO: Wrong image for pod: daemon-set-v7xld. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Apr 25 21:10:54.789: INFO: Pod daemon-set-v7xld is not available
    Apr 25 21:11:02.822: INFO: Pod daemon-set-cdncf is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/25/23 21:11:02.869
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4343, will wait for the garbage collector to delete the pods 04/25/23 21:11:02.87
    Apr 25 21:11:02.958: INFO: Deleting DaemonSet.extensions daemon-set took: 22.163285ms
    Apr 25 21:11:03.058: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.596433ms
    Apr 25 21:11:05.278: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 25 21:11:05.278: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 25 21:11:05.290: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"46582"},"items":null}

    Apr 25 21:11:05.302: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"46582"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 21:11:05.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4343" for this suite. 04/25/23 21:11:05.406
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:11:05.442
Apr 25 21:11:05.443: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename security-context-test 04/25/23 21:11:05.443
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:11:05.486
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:11:05.496
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Apr 25 21:11:05.561: INFO: Waiting up to 5m0s for pod "busybox-user-65534-077dce27-6752-43a3-be02-ddb0a386918f" in namespace "security-context-test-7151" to be "Succeeded or Failed"
Apr 25 21:11:05.575: INFO: Pod "busybox-user-65534-077dce27-6752-43a3-be02-ddb0a386918f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.592318ms
Apr 25 21:11:07.598: INFO: Pod "busybox-user-65534-077dce27-6752-43a3-be02-ddb0a386918f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036757125s
Apr 25 21:11:09.592: INFO: Pod "busybox-user-65534-077dce27-6752-43a3-be02-ddb0a386918f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030307504s
Apr 25 21:11:09.592: INFO: Pod "busybox-user-65534-077dce27-6752-43a3-be02-ddb0a386918f" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 25 21:11:09.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7151" for this suite. 04/25/23 21:11:09.614
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":326,"skipped":6196,"failed":0}
------------------------------
• [4.199 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:11:05.442
    Apr 25 21:11:05.443: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename security-context-test 04/25/23 21:11:05.443
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:11:05.486
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:11:05.496
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Apr 25 21:11:05.561: INFO: Waiting up to 5m0s for pod "busybox-user-65534-077dce27-6752-43a3-be02-ddb0a386918f" in namespace "security-context-test-7151" to be "Succeeded or Failed"
    Apr 25 21:11:05.575: INFO: Pod "busybox-user-65534-077dce27-6752-43a3-be02-ddb0a386918f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.592318ms
    Apr 25 21:11:07.598: INFO: Pod "busybox-user-65534-077dce27-6752-43a3-be02-ddb0a386918f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036757125s
    Apr 25 21:11:09.592: INFO: Pod "busybox-user-65534-077dce27-6752-43a3-be02-ddb0a386918f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030307504s
    Apr 25 21:11:09.592: INFO: Pod "busybox-user-65534-077dce27-6752-43a3-be02-ddb0a386918f" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 25 21:11:09.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-7151" for this suite. 04/25/23 21:11:09.614
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:11:09.652
Apr 25 21:11:09.652: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename statefulset 04/25/23 21:11:09.653
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:11:09.695
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:11:09.707
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6749 04/25/23 21:11:09.721
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-6749 04/25/23 21:11:09.739
Apr 25 21:11:09.783: INFO: Found 0 stateful pods, waiting for 1
Apr 25 21:11:19.803: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 04/25/23 21:11:19.831
STEP: updating a scale subresource 04/25/23 21:11:19.843
STEP: verifying the statefulset Spec.Replicas was modified 04/25/23 21:11:19.859
STEP: Patch a scale subresource 04/25/23 21:11:19.868
STEP: verifying the statefulset Spec.Replicas was modified 04/25/23 21:11:19.898
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 25 21:11:19.908: INFO: Deleting all statefulset in ns statefulset-6749
Apr 25 21:11:19.919: INFO: Scaling statefulset ss to 0
Apr 25 21:11:30.008: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 21:11:30.019: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 25 21:11:30.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6749" for this suite. 04/25/23 21:11:30.082
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":327,"skipped":6228,"failed":0}
------------------------------
• [SLOW TEST] [20.460 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:11:09.652
    Apr 25 21:11:09.652: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename statefulset 04/25/23 21:11:09.653
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:11:09.695
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:11:09.707
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6749 04/25/23 21:11:09.721
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-6749 04/25/23 21:11:09.739
    Apr 25 21:11:09.783: INFO: Found 0 stateful pods, waiting for 1
    Apr 25 21:11:19.803: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 04/25/23 21:11:19.831
    STEP: updating a scale subresource 04/25/23 21:11:19.843
    STEP: verifying the statefulset Spec.Replicas was modified 04/25/23 21:11:19.859
    STEP: Patch a scale subresource 04/25/23 21:11:19.868
    STEP: verifying the statefulset Spec.Replicas was modified 04/25/23 21:11:19.898
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 25 21:11:19.908: INFO: Deleting all statefulset in ns statefulset-6749
    Apr 25 21:11:19.919: INFO: Scaling statefulset ss to 0
    Apr 25 21:11:30.008: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 25 21:11:30.019: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 25 21:11:30.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6749" for this suite. 04/25/23 21:11:30.082
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:11:30.119
Apr 25 21:11:30.123: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 21:11:30.126
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:11:30.165
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:11:30.177
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 04/25/23 21:11:30.191
Apr 25 21:11:30.317: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e" in namespace "projected-4854" to be "Succeeded or Failed"
Apr 25 21:11:30.334: INFO: Pod "downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.26718ms
Apr 25 21:11:32.353: INFO: Pod "downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034991149s
Apr 25 21:11:34.349: INFO: Pod "downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030420693s
STEP: Saw pod success 04/25/23 21:11:34.349
Apr 25 21:11:34.349: INFO: Pod "downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e" satisfied condition "Succeeded or Failed"
Apr 25 21:11:34.363: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e container client-container: <nil>
STEP: delete the pod 04/25/23 21:11:34.459
Apr 25 21:11:34.503: INFO: Waiting for pod downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e to disappear
Apr 25 21:11:34.515: INFO: Pod downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 25 21:11:34.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4854" for this suite. 04/25/23 21:11:34.534
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":328,"skipped":6249,"failed":0}
------------------------------
• [4.444 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:11:30.119
    Apr 25 21:11:30.123: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 21:11:30.126
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:11:30.165
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:11:30.177
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 04/25/23 21:11:30.191
    Apr 25 21:11:30.317: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e" in namespace "projected-4854" to be "Succeeded or Failed"
    Apr 25 21:11:30.334: INFO: Pod "downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.26718ms
    Apr 25 21:11:32.353: INFO: Pod "downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034991149s
    Apr 25 21:11:34.349: INFO: Pod "downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030420693s
    STEP: Saw pod success 04/25/23 21:11:34.349
    Apr 25 21:11:34.349: INFO: Pod "downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e" satisfied condition "Succeeded or Failed"
    Apr 25 21:11:34.363: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e container client-container: <nil>
    STEP: delete the pod 04/25/23 21:11:34.459
    Apr 25 21:11:34.503: INFO: Waiting for pod downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e to disappear
    Apr 25 21:11:34.515: INFO: Pod downwardapi-volume-a0f23f86-0693-4956-b8a7-6de804a34d9e no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 25 21:11:34.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4854" for this suite. 04/25/23 21:11:34.534
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:11:34.568
Apr 25 21:11:34.568: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename proxy 04/25/23 21:11:34.572
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:11:34.611
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:11:34.622
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Apr 25 21:11:34.635: INFO: Creating pod...
Apr 25 21:11:34.665: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-1066" to be "running"
Apr 25 21:11:34.679: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 13.906818ms
Apr 25 21:11:36.694: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.029408346s
Apr 25 21:11:36.694: INFO: Pod "agnhost" satisfied condition "running"
Apr 25 21:11:36.694: INFO: Creating service...
Apr 25 21:11:36.728: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/pods/agnhost/proxy/some/path/with/DELETE
Apr 25 21:11:36.811: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 25 21:11:36.811: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/pods/agnhost/proxy/some/path/with/GET
Apr 25 21:11:36.828: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr 25 21:11:36.828: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/pods/agnhost/proxy/some/path/with/HEAD
Apr 25 21:11:36.849: INFO: http.Client request:HEAD | StatusCode:200
Apr 25 21:11:36.849: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/pods/agnhost/proxy/some/path/with/OPTIONS
Apr 25 21:11:36.867: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 25 21:11:36.867: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/pods/agnhost/proxy/some/path/with/PATCH
Apr 25 21:11:36.885: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 25 21:11:36.885: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/pods/agnhost/proxy/some/path/with/POST
Apr 25 21:11:36.902: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 25 21:11:36.902: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/pods/agnhost/proxy/some/path/with/PUT
Apr 25 21:11:36.920: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 25 21:11:36.920: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/services/test-service/proxy/some/path/with/DELETE
Apr 25 21:11:36.949: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 25 21:11:36.949: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/services/test-service/proxy/some/path/with/GET
Apr 25 21:11:36.972: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr 25 21:11:36.972: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/services/test-service/proxy/some/path/with/HEAD
Apr 25 21:11:36.996: INFO: http.Client request:HEAD | StatusCode:200
Apr 25 21:11:36.996: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/services/test-service/proxy/some/path/with/OPTIONS
Apr 25 21:11:37.018: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 25 21:11:37.019: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/services/test-service/proxy/some/path/with/PATCH
Apr 25 21:11:37.041: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 25 21:11:37.041: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/services/test-service/proxy/some/path/with/POST
Apr 25 21:11:37.068: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 25 21:11:37.068: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/services/test-service/proxy/some/path/with/PUT
Apr 25 21:11:37.089: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Apr 25 21:11:37.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1066" for this suite. 04/25/23 21:11:37.106
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":329,"skipped":6254,"failed":0}
------------------------------
• [2.571 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:11:34.568
    Apr 25 21:11:34.568: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename proxy 04/25/23 21:11:34.572
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:11:34.611
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:11:34.622
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Apr 25 21:11:34.635: INFO: Creating pod...
    Apr 25 21:11:34.665: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-1066" to be "running"
    Apr 25 21:11:34.679: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 13.906818ms
    Apr 25 21:11:36.694: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.029408346s
    Apr 25 21:11:36.694: INFO: Pod "agnhost" satisfied condition "running"
    Apr 25 21:11:36.694: INFO: Creating service...
    Apr 25 21:11:36.728: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/pods/agnhost/proxy/some/path/with/DELETE
    Apr 25 21:11:36.811: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 25 21:11:36.811: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/pods/agnhost/proxy/some/path/with/GET
    Apr 25 21:11:36.828: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Apr 25 21:11:36.828: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/pods/agnhost/proxy/some/path/with/HEAD
    Apr 25 21:11:36.849: INFO: http.Client request:HEAD | StatusCode:200
    Apr 25 21:11:36.849: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/pods/agnhost/proxy/some/path/with/OPTIONS
    Apr 25 21:11:36.867: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 25 21:11:36.867: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/pods/agnhost/proxy/some/path/with/PATCH
    Apr 25 21:11:36.885: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 25 21:11:36.885: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/pods/agnhost/proxy/some/path/with/POST
    Apr 25 21:11:36.902: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 25 21:11:36.902: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/pods/agnhost/proxy/some/path/with/PUT
    Apr 25 21:11:36.920: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 25 21:11:36.920: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/services/test-service/proxy/some/path/with/DELETE
    Apr 25 21:11:36.949: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 25 21:11:36.949: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/services/test-service/proxy/some/path/with/GET
    Apr 25 21:11:36.972: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Apr 25 21:11:36.972: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/services/test-service/proxy/some/path/with/HEAD
    Apr 25 21:11:36.996: INFO: http.Client request:HEAD | StatusCode:200
    Apr 25 21:11:36.996: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/services/test-service/proxy/some/path/with/OPTIONS
    Apr 25 21:11:37.018: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 25 21:11:37.019: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/services/test-service/proxy/some/path/with/PATCH
    Apr 25 21:11:37.041: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 25 21:11:37.041: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/services/test-service/proxy/some/path/with/POST
    Apr 25 21:11:37.068: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 25 21:11:37.068: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-1066/services/test-service/proxy/some/path/with/PUT
    Apr 25 21:11:37.089: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Apr 25 21:11:37.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-1066" for this suite. 04/25/23 21:11:37.106
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:11:37.145
Apr 25 21:11:37.146: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename configmap 04/25/23 21:11:37.148
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:11:37.187
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:11:37.2
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-c45f4ff1-f0c2-4e88-b029-d3627483dcee 04/25/23 21:11:37.213
STEP: Creating a pod to test consume configMaps 04/25/23 21:11:37.228
Apr 25 21:11:37.263: INFO: Waiting up to 5m0s for pod "pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83" in namespace "configmap-3623" to be "Succeeded or Failed"
Apr 25 21:11:37.278: INFO: Pod "pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83": Phase="Pending", Reason="", readiness=false. Elapsed: 15.232798ms
Apr 25 21:11:39.296: INFO: Pod "pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032633238s
Apr 25 21:11:41.292: INFO: Pod "pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028704082s
Apr 25 21:11:43.295: INFO: Pod "pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032534013s
STEP: Saw pod success 04/25/23 21:11:43.296
Apr 25 21:11:43.297: INFO: Pod "pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83" satisfied condition "Succeeded or Failed"
Apr 25 21:11:43.312: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83 container agnhost-container: <nil>
STEP: delete the pod 04/25/23 21:11:43.336
Apr 25 21:11:43.378: INFO: Waiting for pod pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83 to disappear
Apr 25 21:11:43.392: INFO: Pod pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 25 21:11:43.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3623" for this suite. 04/25/23 21:11:43.411
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":330,"skipped":6262,"failed":0}
------------------------------
• [SLOW TEST] [6.325 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:11:37.145
    Apr 25 21:11:37.146: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename configmap 04/25/23 21:11:37.148
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:11:37.187
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:11:37.2
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-c45f4ff1-f0c2-4e88-b029-d3627483dcee 04/25/23 21:11:37.213
    STEP: Creating a pod to test consume configMaps 04/25/23 21:11:37.228
    Apr 25 21:11:37.263: INFO: Waiting up to 5m0s for pod "pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83" in namespace "configmap-3623" to be "Succeeded or Failed"
    Apr 25 21:11:37.278: INFO: Pod "pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83": Phase="Pending", Reason="", readiness=false. Elapsed: 15.232798ms
    Apr 25 21:11:39.296: INFO: Pod "pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032633238s
    Apr 25 21:11:41.292: INFO: Pod "pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028704082s
    Apr 25 21:11:43.295: INFO: Pod "pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032534013s
    STEP: Saw pod success 04/25/23 21:11:43.296
    Apr 25 21:11:43.297: INFO: Pod "pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83" satisfied condition "Succeeded or Failed"
    Apr 25 21:11:43.312: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83 container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 21:11:43.336
    Apr 25 21:11:43.378: INFO: Waiting for pod pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83 to disappear
    Apr 25 21:11:43.392: INFO: Pod pod-configmaps-45973cdf-2b32-4a0e-adef-74f5c3d38e83 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 25 21:11:43.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3623" for this suite. 04/25/23 21:11:43.411
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:11:43.474
Apr 25 21:11:43.475: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 21:11:43.478
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:11:43.527
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:11:43.54
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-4383 04/25/23 21:11:43.555
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/25/23 21:11:43.6
STEP: creating service externalsvc in namespace services-4383 04/25/23 21:11:43.601
STEP: creating replication controller externalsvc in namespace services-4383 04/25/23 21:11:43.655
I0425 21:11:43.674114      23 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4383, replica count: 2
I0425 21:11:46.725421      23 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 04/25/23 21:11:46.738
Apr 25 21:11:46.802: INFO: Creating new exec pod
Apr 25 21:11:46.825: INFO: Waiting up to 5m0s for pod "execpod6556v" in namespace "services-4383" to be "running"
Apr 25 21:11:46.853: INFO: Pod "execpod6556v": Phase="Pending", Reason="", readiness=false. Elapsed: 28.200272ms
Apr 25 21:11:48.871: INFO: Pod "execpod6556v": Phase="Running", Reason="", readiness=true. Elapsed: 2.045589441s
Apr 25 21:11:48.871: INFO: Pod "execpod6556v" satisfied condition "running"
Apr 25 21:11:48.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-4383 exec execpod6556v -- /bin/sh -x -c nslookup nodeport-service.services-4383.svc.cluster.local'
Apr 25 21:11:49.239: INFO: stderr: "+ nslookup nodeport-service.services-4383.svc.cluster.local\n"
Apr 25 21:11:49.239: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nnodeport-service.services-4383.svc.cluster.local\tcanonical name = externalsvc.services-4383.svc.cluster.local.\nName:\texternalsvc.services-4383.svc.cluster.local\nAddress: 172.21.185.59\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4383, will wait for the garbage collector to delete the pods 04/25/23 21:11:49.239
Apr 25 21:11:49.317: INFO: Deleting ReplicationController externalsvc took: 17.196651ms
Apr 25 21:11:49.418: INFO: Terminating ReplicationController externalsvc pods took: 101.308213ms
Apr 25 21:11:52.074: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 21:11:52.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4383" for this suite. 04/25/23 21:11:52.135
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":331,"skipped":6266,"failed":0}
------------------------------
• [SLOW TEST] [8.687 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:11:43.474
    Apr 25 21:11:43.475: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 21:11:43.478
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:11:43.527
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:11:43.54
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-4383 04/25/23 21:11:43.555
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/25/23 21:11:43.6
    STEP: creating service externalsvc in namespace services-4383 04/25/23 21:11:43.601
    STEP: creating replication controller externalsvc in namespace services-4383 04/25/23 21:11:43.655
    I0425 21:11:43.674114      23 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4383, replica count: 2
    I0425 21:11:46.725421      23 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 04/25/23 21:11:46.738
    Apr 25 21:11:46.802: INFO: Creating new exec pod
    Apr 25 21:11:46.825: INFO: Waiting up to 5m0s for pod "execpod6556v" in namespace "services-4383" to be "running"
    Apr 25 21:11:46.853: INFO: Pod "execpod6556v": Phase="Pending", Reason="", readiness=false. Elapsed: 28.200272ms
    Apr 25 21:11:48.871: INFO: Pod "execpod6556v": Phase="Running", Reason="", readiness=true. Elapsed: 2.045589441s
    Apr 25 21:11:48.871: INFO: Pod "execpod6556v" satisfied condition "running"
    Apr 25 21:11:48.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-4383 exec execpod6556v -- /bin/sh -x -c nslookup nodeport-service.services-4383.svc.cluster.local'
    Apr 25 21:11:49.239: INFO: stderr: "+ nslookup nodeport-service.services-4383.svc.cluster.local\n"
    Apr 25 21:11:49.239: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nnodeport-service.services-4383.svc.cluster.local\tcanonical name = externalsvc.services-4383.svc.cluster.local.\nName:\texternalsvc.services-4383.svc.cluster.local\nAddress: 172.21.185.59\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-4383, will wait for the garbage collector to delete the pods 04/25/23 21:11:49.239
    Apr 25 21:11:49.317: INFO: Deleting ReplicationController externalsvc took: 17.196651ms
    Apr 25 21:11:49.418: INFO: Terminating ReplicationController externalsvc pods took: 101.308213ms
    Apr 25 21:11:52.074: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 21:11:52.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4383" for this suite. 04/25/23 21:11:52.135
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:11:52.166
Apr 25 21:11:52.167: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 21:11:52.169
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:11:52.224
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:11:52.236
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 04/25/23 21:11:52.249
Apr 25 21:11:52.252: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: rename a version 04/25/23 21:12:01.147
STEP: check the new version name is served 04/25/23 21:12:01.187
STEP: check the old version name is removed 04/25/23 21:12:04.69
STEP: check the other version is not changed 04/25/23 21:12:06.442
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 21:12:12.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1939" for this suite. 04/25/23 21:12:12.783
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":332,"skipped":6273,"failed":0}
------------------------------
• [SLOW TEST] [20.635 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:11:52.166
    Apr 25 21:11:52.167: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename crd-publish-openapi 04/25/23 21:11:52.169
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:11:52.224
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:11:52.236
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 04/25/23 21:11:52.249
    Apr 25 21:11:52.252: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: rename a version 04/25/23 21:12:01.147
    STEP: check the new version name is served 04/25/23 21:12:01.187
    STEP: check the old version name is removed 04/25/23 21:12:04.69
    STEP: check the other version is not changed 04/25/23 21:12:06.442
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 21:12:12.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1939" for this suite. 04/25/23 21:12:12.783
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:12:12.811
Apr 25 21:12:12.811: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename statefulset 04/25/23 21:12:12.812
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:12:12.871
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:12:12.878
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7267 04/25/23 21:12:12.891
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Apr 25 21:12:12.951: INFO: Found 0 stateful pods, waiting for 1
Apr 25 21:12:22.964: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 04/25/23 21:12:22.985
W0425 21:12:23.008740      23 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 25 21:12:23.027: INFO: Found 1 stateful pods, waiting for 2
Apr 25 21:12:33.039: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 21:12:33.039: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 04/25/23 21:12:33.061
STEP: Delete all of the StatefulSets 04/25/23 21:12:33.071
STEP: Verify that StatefulSets have been deleted 04/25/23 21:12:33.094
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 25 21:12:33.103: INFO: Deleting all statefulset in ns statefulset-7267
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 25 21:12:33.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7267" for this suite. 04/25/23 21:12:33.144
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":333,"skipped":6292,"failed":0}
------------------------------
• [SLOW TEST] [20.351 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:12:12.811
    Apr 25 21:12:12.811: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename statefulset 04/25/23 21:12:12.812
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:12:12.871
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:12:12.878
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-7267 04/25/23 21:12:12.891
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Apr 25 21:12:12.951: INFO: Found 0 stateful pods, waiting for 1
    Apr 25 21:12:22.964: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 04/25/23 21:12:22.985
    W0425 21:12:23.008740      23 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 25 21:12:23.027: INFO: Found 1 stateful pods, waiting for 2
    Apr 25 21:12:33.039: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 25 21:12:33.039: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 04/25/23 21:12:33.061
    STEP: Delete all of the StatefulSets 04/25/23 21:12:33.071
    STEP: Verify that StatefulSets have been deleted 04/25/23 21:12:33.094
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 25 21:12:33.103: INFO: Deleting all statefulset in ns statefulset-7267
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 25 21:12:33.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-7267" for this suite. 04/25/23 21:12:33.144
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:12:33.166
Apr 25 21:12:33.169: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 21:12:33.171
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:12:33.226
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:12:33.233
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 04/25/23 21:12:33.24
Apr 25 21:12:33.263: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9600842-5393-4684-84ad-d413320701da" in namespace "projected-1203" to be "Succeeded or Failed"
Apr 25 21:12:33.274: INFO: Pod "downwardapi-volume-d9600842-5393-4684-84ad-d413320701da": Phase="Pending", Reason="", readiness=false. Elapsed: 10.298047ms
Apr 25 21:12:35.285: INFO: Pod "downwardapi-volume-d9600842-5393-4684-84ad-d413320701da": Phase="Running", Reason="", readiness=true. Elapsed: 2.021687484s
Apr 25 21:12:37.286: INFO: Pod "downwardapi-volume-d9600842-5393-4684-84ad-d413320701da": Phase="Running", Reason="", readiness=false. Elapsed: 4.022870752s
Apr 25 21:12:39.286: INFO: Pod "downwardapi-volume-d9600842-5393-4684-84ad-d413320701da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022749079s
STEP: Saw pod success 04/25/23 21:12:39.286
Apr 25 21:12:39.287: INFO: Pod "downwardapi-volume-d9600842-5393-4684-84ad-d413320701da" satisfied condition "Succeeded or Failed"
Apr 25 21:12:39.298: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-d9600842-5393-4684-84ad-d413320701da container client-container: <nil>
STEP: delete the pod 04/25/23 21:12:39.372
Apr 25 21:12:39.402: INFO: Waiting for pod downwardapi-volume-d9600842-5393-4684-84ad-d413320701da to disappear
Apr 25 21:12:39.412: INFO: Pod downwardapi-volume-d9600842-5393-4684-84ad-d413320701da no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 25 21:12:39.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1203" for this suite. 04/25/23 21:12:39.43
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":334,"skipped":6319,"failed":0}
------------------------------
• [SLOW TEST] [6.282 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:12:33.166
    Apr 25 21:12:33.169: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 21:12:33.171
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:12:33.226
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:12:33.233
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 04/25/23 21:12:33.24
    Apr 25 21:12:33.263: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9600842-5393-4684-84ad-d413320701da" in namespace "projected-1203" to be "Succeeded or Failed"
    Apr 25 21:12:33.274: INFO: Pod "downwardapi-volume-d9600842-5393-4684-84ad-d413320701da": Phase="Pending", Reason="", readiness=false. Elapsed: 10.298047ms
    Apr 25 21:12:35.285: INFO: Pod "downwardapi-volume-d9600842-5393-4684-84ad-d413320701da": Phase="Running", Reason="", readiness=true. Elapsed: 2.021687484s
    Apr 25 21:12:37.286: INFO: Pod "downwardapi-volume-d9600842-5393-4684-84ad-d413320701da": Phase="Running", Reason="", readiness=false. Elapsed: 4.022870752s
    Apr 25 21:12:39.286: INFO: Pod "downwardapi-volume-d9600842-5393-4684-84ad-d413320701da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022749079s
    STEP: Saw pod success 04/25/23 21:12:39.286
    Apr 25 21:12:39.287: INFO: Pod "downwardapi-volume-d9600842-5393-4684-84ad-d413320701da" satisfied condition "Succeeded or Failed"
    Apr 25 21:12:39.298: INFO: Trying to get logs from node 10.10.21.190 pod downwardapi-volume-d9600842-5393-4684-84ad-d413320701da container client-container: <nil>
    STEP: delete the pod 04/25/23 21:12:39.372
    Apr 25 21:12:39.402: INFO: Waiting for pod downwardapi-volume-d9600842-5393-4684-84ad-d413320701da to disappear
    Apr 25 21:12:39.412: INFO: Pod downwardapi-volume-d9600842-5393-4684-84ad-d413320701da no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 25 21:12:39.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1203" for this suite. 04/25/23 21:12:39.43
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:12:39.456
Apr 25 21:12:39.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 21:12:39.46
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:12:39.506
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:12:39.514
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Apr 25 21:12:39.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-4812 version'
Apr 25 21:12:39.631: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Apr 25 21:12:39.631: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9\", GitCommit:\"a1a87a0a2bcd605820920c6b0e618a8ab7d117d4\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:16:51Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9+IKS\", GitCommit:\"d2e4c0d700f981da8974506c93d92503b83c6889\", GitTreeState:\"clean\", BuildDate:\"2023-04-13T04:38:24Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 21:12:39.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4812" for this suite. 04/25/23 21:12:39.645
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":335,"skipped":6328,"failed":0}
------------------------------
• [0.206 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:12:39.456
    Apr 25 21:12:39.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 21:12:39.46
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:12:39.506
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:12:39.514
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Apr 25 21:12:39.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-4812 version'
    Apr 25 21:12:39.631: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Apr 25 21:12:39.631: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9\", GitCommit:\"a1a87a0a2bcd605820920c6b0e618a8ab7d117d4\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:16:51Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9+IKS\", GitCommit:\"d2e4c0d700f981da8974506c93d92503b83c6889\", GitTreeState:\"clean\", BuildDate:\"2023-04-13T04:38:24Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 21:12:39.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4812" for this suite. 04/25/23 21:12:39.645
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:12:39.666
Apr 25 21:12:39.666: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 21:12:39.669
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:12:39.714
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:12:39.721
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-3ffe7454-29cc-4fe4-abe2-44c7369dc06d 04/25/23 21:12:39.734
STEP: Creating a pod to test consume configMaps 04/25/23 21:12:39.755
Apr 25 21:12:39.792: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d" in namespace "projected-1436" to be "Succeeded or Failed"
Apr 25 21:12:39.810: INFO: Pod "pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.088201ms
Apr 25 21:12:41.823: INFO: Pod "pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03110217s
Apr 25 21:12:43.823: INFO: Pod "pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03059505s
STEP: Saw pod success 04/25/23 21:12:43.823
Apr 25 21:12:43.823: INFO: Pod "pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d" satisfied condition "Succeeded or Failed"
Apr 25 21:12:43.834: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d container agnhost-container: <nil>
STEP: delete the pod 04/25/23 21:12:43.861
Apr 25 21:12:43.896: INFO: Waiting for pod pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d to disappear
Apr 25 21:12:43.907: INFO: Pod pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 25 21:12:43.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1436" for this suite. 04/25/23 21:12:43.925
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":336,"skipped":6334,"failed":0}
------------------------------
• [4.276 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:12:39.666
    Apr 25 21:12:39.666: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 21:12:39.669
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:12:39.714
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:12:39.721
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-3ffe7454-29cc-4fe4-abe2-44c7369dc06d 04/25/23 21:12:39.734
    STEP: Creating a pod to test consume configMaps 04/25/23 21:12:39.755
    Apr 25 21:12:39.792: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d" in namespace "projected-1436" to be "Succeeded or Failed"
    Apr 25 21:12:39.810: INFO: Pod "pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.088201ms
    Apr 25 21:12:41.823: INFO: Pod "pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03110217s
    Apr 25 21:12:43.823: INFO: Pod "pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03059505s
    STEP: Saw pod success 04/25/23 21:12:43.823
    Apr 25 21:12:43.823: INFO: Pod "pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d" satisfied condition "Succeeded or Failed"
    Apr 25 21:12:43.834: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d container agnhost-container: <nil>
    STEP: delete the pod 04/25/23 21:12:43.861
    Apr 25 21:12:43.896: INFO: Waiting for pod pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d to disappear
    Apr 25 21:12:43.907: INFO: Pod pod-projected-configmaps-12c0a5d2-4acc-472a-937e-be9d2a78833d no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 25 21:12:43.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1436" for this suite. 04/25/23 21:12:43.925
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:12:43.948
Apr 25 21:12:43.950: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename replicaset 04/25/23 21:12:43.953
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:12:44.011
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:12:44.024
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 04/25/23 21:12:44.036
Apr 25 21:12:44.056: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-4197" to be "running and ready"
Apr 25 21:12:44.067: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 11.386945ms
Apr 25 21:12:44.068: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Apr 25 21:12:46.081: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.025000767s
Apr 25 21:12:46.081: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Apr 25 21:12:46.081: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 04/25/23 21:12:46.093
STEP: Then the orphan pod is adopted 04/25/23 21:12:46.114
STEP: When the matched label of one of its pods change 04/25/23 21:12:47.139
Apr 25 21:12:47.152: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 04/25/23 21:12:47.179
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 25 21:12:48.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4197" for this suite. 04/25/23 21:12:48.223
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":337,"skipped":6345,"failed":0}
------------------------------
• [4.293 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:12:43.948
    Apr 25 21:12:43.950: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename replicaset 04/25/23 21:12:43.953
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:12:44.011
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:12:44.024
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 04/25/23 21:12:44.036
    Apr 25 21:12:44.056: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-4197" to be "running and ready"
    Apr 25 21:12:44.067: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 11.386945ms
    Apr 25 21:12:44.068: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 21:12:46.081: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.025000767s
    Apr 25 21:12:46.081: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Apr 25 21:12:46.081: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 04/25/23 21:12:46.093
    STEP: Then the orphan pod is adopted 04/25/23 21:12:46.114
    STEP: When the matched label of one of its pods change 04/25/23 21:12:47.139
    Apr 25 21:12:47.152: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 04/25/23 21:12:47.179
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 25 21:12:48.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4197" for this suite. 04/25/23 21:12:48.223
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:12:48.255
Apr 25 21:12:48.256: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename secrets 04/25/23 21:12:48.257
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:12:48.303
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:12:48.315
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-3372/secret-test-09fc622e-7c91-4fc1-9d3a-de635371b72e 04/25/23 21:12:48.327
STEP: Creating a pod to test consume secrets 04/25/23 21:12:48.343
Apr 25 21:12:48.364: INFO: Waiting up to 5m0s for pod "pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937" in namespace "secrets-3372" to be "Succeeded or Failed"
Apr 25 21:12:48.377: INFO: Pod "pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937": Phase="Pending", Reason="", readiness=false. Elapsed: 13.208799ms
Apr 25 21:12:50.390: INFO: Pod "pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025927071s
Apr 25 21:12:52.391: INFO: Pod "pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027456232s
STEP: Saw pod success 04/25/23 21:12:52.391
Apr 25 21:12:52.392: INFO: Pod "pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937" satisfied condition "Succeeded or Failed"
Apr 25 21:12:52.405: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937 container env-test: <nil>
STEP: delete the pod 04/25/23 21:12:52.496
Apr 25 21:12:52.525: INFO: Waiting for pod pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937 to disappear
Apr 25 21:12:52.536: INFO: Pod pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 25 21:12:52.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3372" for this suite. 04/25/23 21:12:52.555
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":338,"skipped":6369,"failed":0}
------------------------------
• [4.329 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:12:48.255
    Apr 25 21:12:48.256: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename secrets 04/25/23 21:12:48.257
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:12:48.303
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:12:48.315
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-3372/secret-test-09fc622e-7c91-4fc1-9d3a-de635371b72e 04/25/23 21:12:48.327
    STEP: Creating a pod to test consume secrets 04/25/23 21:12:48.343
    Apr 25 21:12:48.364: INFO: Waiting up to 5m0s for pod "pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937" in namespace "secrets-3372" to be "Succeeded or Failed"
    Apr 25 21:12:48.377: INFO: Pod "pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937": Phase="Pending", Reason="", readiness=false. Elapsed: 13.208799ms
    Apr 25 21:12:50.390: INFO: Pod "pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025927071s
    Apr 25 21:12:52.391: INFO: Pod "pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027456232s
    STEP: Saw pod success 04/25/23 21:12:52.391
    Apr 25 21:12:52.392: INFO: Pod "pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937" satisfied condition "Succeeded or Failed"
    Apr 25 21:12:52.405: INFO: Trying to get logs from node 10.10.21.190 pod pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937 container env-test: <nil>
    STEP: delete the pod 04/25/23 21:12:52.496
    Apr 25 21:12:52.525: INFO: Waiting for pod pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937 to disappear
    Apr 25 21:12:52.536: INFO: Pod pod-configmaps-ee5d435b-0e58-473e-8536-f33dded5c937 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 25 21:12:52.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3372" for this suite. 04/25/23 21:12:52.555
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:12:52.588
Apr 25 21:12:52.588: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-lifecycle-hook 04/25/23 21:12:52.591
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:12:52.676
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:12:52.69
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/25/23 21:12:52.72
Apr 25 21:12:52.741: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-6971" to be "running and ready"
Apr 25 21:12:52.754: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 12.826764ms
Apr 25 21:12:52.754: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 25 21:12:54.766: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025331693s
Apr 25 21:12:54.766: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 25 21:12:56.767: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.025656969s
Apr 25 21:12:56.767: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 25 21:12:56.767: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 04/25/23 21:12:56.78
Apr 25 21:12:56.795: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-6971" to be "running and ready"
Apr 25 21:12:56.807: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 11.951265ms
Apr 25 21:12:56.807: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 25 21:12:58.820: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024684819s
Apr 25 21:12:58.820: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 25 21:13:00.820: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.024242263s
Apr 25 21:13:00.820: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Apr 25 21:13:00.820: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 04/25/23 21:13:00.831
STEP: delete the pod with lifecycle hook 04/25/23 21:13:00.865
Apr 25 21:13:00.886: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 25 21:13:00.899: INFO: Pod pod-with-poststart-http-hook still exists
Apr 25 21:13:02.899: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 25 21:13:02.917: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 25 21:13:02.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6971" for this suite. 04/25/23 21:13:02.939
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":339,"skipped":6373,"failed":0}
------------------------------
• [SLOW TEST] [10.372 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:12:52.588
    Apr 25 21:12:52.588: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/25/23 21:12:52.591
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:12:52.676
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:12:52.69
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/25/23 21:12:52.72
    Apr 25 21:12:52.741: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-6971" to be "running and ready"
    Apr 25 21:12:52.754: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 12.826764ms
    Apr 25 21:12:52.754: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 21:12:54.766: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025331693s
    Apr 25 21:12:54.766: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 21:12:56.767: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.025656969s
    Apr 25 21:12:56.767: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 25 21:12:56.767: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 04/25/23 21:12:56.78
    Apr 25 21:12:56.795: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-6971" to be "running and ready"
    Apr 25 21:12:56.807: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 11.951265ms
    Apr 25 21:12:56.807: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 21:12:58.820: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024684819s
    Apr 25 21:12:58.820: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 21:13:00.820: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.024242263s
    Apr 25 21:13:00.820: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Apr 25 21:13:00.820: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 04/25/23 21:13:00.831
    STEP: delete the pod with lifecycle hook 04/25/23 21:13:00.865
    Apr 25 21:13:00.886: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Apr 25 21:13:00.899: INFO: Pod pod-with-poststart-http-hook still exists
    Apr 25 21:13:02.899: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Apr 25 21:13:02.917: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 25 21:13:02.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-6971" for this suite. 04/25/23 21:13:02.939
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:13:02.981
Apr 25 21:13:02.982: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename pods 04/25/23 21:13:02.983
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:03.034
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:03.046
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 04/25/23 21:13:03.061
STEP: setting up watch 04/25/23 21:13:03.063
STEP: submitting the pod to kubernetes 04/25/23 21:13:03.18
STEP: verifying the pod is in kubernetes 04/25/23 21:13:03.203
STEP: verifying pod creation was observed 04/25/23 21:13:03.216
Apr 25 21:13:03.216: INFO: Waiting up to 5m0s for pod "pod-submit-remove-cc0abded-9998-48eb-97d6-82ca13c0823f" in namespace "pods-7965" to be "running"
Apr 25 21:13:03.234: INFO: Pod "pod-submit-remove-cc0abded-9998-48eb-97d6-82ca13c0823f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.154607ms
Apr 25 21:13:05.248: INFO: Pod "pod-submit-remove-cc0abded-9998-48eb-97d6-82ca13c0823f": Phase="Running", Reason="", readiness=true. Elapsed: 2.032142739s
Apr 25 21:13:05.249: INFO: Pod "pod-submit-remove-cc0abded-9998-48eb-97d6-82ca13c0823f" satisfied condition "running"
STEP: deleting the pod gracefully 04/25/23 21:13:05.261
STEP: verifying pod deletion was observed 04/25/23 21:13:05.28
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 25 21:13:07.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7965" for this suite. 04/25/23 21:13:08.006
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":340,"skipped":6394,"failed":0}
------------------------------
• [SLOW TEST] [5.044 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:13:02.981
    Apr 25 21:13:02.982: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename pods 04/25/23 21:13:02.983
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:03.034
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:03.046
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 04/25/23 21:13:03.061
    STEP: setting up watch 04/25/23 21:13:03.063
    STEP: submitting the pod to kubernetes 04/25/23 21:13:03.18
    STEP: verifying the pod is in kubernetes 04/25/23 21:13:03.203
    STEP: verifying pod creation was observed 04/25/23 21:13:03.216
    Apr 25 21:13:03.216: INFO: Waiting up to 5m0s for pod "pod-submit-remove-cc0abded-9998-48eb-97d6-82ca13c0823f" in namespace "pods-7965" to be "running"
    Apr 25 21:13:03.234: INFO: Pod "pod-submit-remove-cc0abded-9998-48eb-97d6-82ca13c0823f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.154607ms
    Apr 25 21:13:05.248: INFO: Pod "pod-submit-remove-cc0abded-9998-48eb-97d6-82ca13c0823f": Phase="Running", Reason="", readiness=true. Elapsed: 2.032142739s
    Apr 25 21:13:05.249: INFO: Pod "pod-submit-remove-cc0abded-9998-48eb-97d6-82ca13c0823f" satisfied condition "running"
    STEP: deleting the pod gracefully 04/25/23 21:13:05.261
    STEP: verifying pod deletion was observed 04/25/23 21:13:05.28
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 25 21:13:07.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7965" for this suite. 04/25/23 21:13:08.006
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:13:08.028
Apr 25 21:13:08.028: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename custom-resource-definition 04/25/23 21:13:08.032
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:08.082
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:08.091
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 04/25/23 21:13:08.101
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 04/25/23 21:13:08.107
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 04/25/23 21:13:08.107
STEP: fetching the /apis/apiextensions.k8s.io discovery document 04/25/23 21:13:08.108
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 04/25/23 21:13:08.113
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 04/25/23 21:13:08.113
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 04/25/23 21:13:08.119
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 21:13:08.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1291" for this suite. 04/25/23 21:13:08.137
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":341,"skipped":6406,"failed":0}
------------------------------
• [0.129 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:13:08.028
    Apr 25 21:13:08.028: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename custom-resource-definition 04/25/23 21:13:08.032
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:08.082
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:08.091
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 04/25/23 21:13:08.101
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 04/25/23 21:13:08.107
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 04/25/23 21:13:08.107
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 04/25/23 21:13:08.108
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 04/25/23 21:13:08.113
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 04/25/23 21:13:08.113
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 04/25/23 21:13:08.119
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 21:13:08.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1291" for this suite. 04/25/23 21:13:08.137
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:13:08.163
Apr 25 21:13:08.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 21:13:08.167
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:08.208
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:08.218
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 04/25/23 21:13:08.229
Apr 25 21:13:08.229: INFO: namespace kubectl-3640
Apr 25 21:13:08.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3640 create -f -'
Apr 25 21:13:08.977: INFO: stderr: ""
Apr 25 21:13:08.977: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/25/23 21:13:08.977
Apr 25 21:13:09.990: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 25 21:13:09.990: INFO: Found 0 / 1
Apr 25 21:13:10.989: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 25 21:13:10.989: INFO: Found 1 / 1
Apr 25 21:13:10.989: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 25 21:13:11.001: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 25 21:13:11.001: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 25 21:13:11.001: INFO: wait on agnhost-primary startup in kubectl-3640 
Apr 25 21:13:11.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3640 logs agnhost-primary-lr2rm agnhost-primary'
Apr 25 21:13:11.162: INFO: stderr: ""
Apr 25 21:13:11.162: INFO: stdout: "Paused\n"
STEP: exposing RC 04/25/23 21:13:11.162
Apr 25 21:13:11.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3640 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Apr 25 21:13:11.353: INFO: stderr: ""
Apr 25 21:13:11.353: INFO: stdout: "service/rm2 exposed\n"
Apr 25 21:13:11.405: INFO: Service rm2 in namespace kubectl-3640 found.
STEP: exposing service 04/25/23 21:13:13.445
Apr 25 21:13:13.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3640 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Apr 25 21:13:13.621: INFO: stderr: ""
Apr 25 21:13:13.622: INFO: stdout: "service/rm3 exposed\n"
Apr 25 21:13:13.636: INFO: Service rm3 in namespace kubectl-3640 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 21:13:15.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3640" for this suite. 04/25/23 21:13:15.721
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":342,"skipped":6419,"failed":0}
------------------------------
• [SLOW TEST] [7.586 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:13:08.163
    Apr 25 21:13:08.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 21:13:08.167
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:08.208
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:08.218
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 04/25/23 21:13:08.229
    Apr 25 21:13:08.229: INFO: namespace kubectl-3640
    Apr 25 21:13:08.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3640 create -f -'
    Apr 25 21:13:08.977: INFO: stderr: ""
    Apr 25 21:13:08.977: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/25/23 21:13:08.977
    Apr 25 21:13:09.990: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 25 21:13:09.990: INFO: Found 0 / 1
    Apr 25 21:13:10.989: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 25 21:13:10.989: INFO: Found 1 / 1
    Apr 25 21:13:10.989: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Apr 25 21:13:11.001: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 25 21:13:11.001: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 25 21:13:11.001: INFO: wait on agnhost-primary startup in kubectl-3640 
    Apr 25 21:13:11.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3640 logs agnhost-primary-lr2rm agnhost-primary'
    Apr 25 21:13:11.162: INFO: stderr: ""
    Apr 25 21:13:11.162: INFO: stdout: "Paused\n"
    STEP: exposing RC 04/25/23 21:13:11.162
    Apr 25 21:13:11.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3640 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Apr 25 21:13:11.353: INFO: stderr: ""
    Apr 25 21:13:11.353: INFO: stdout: "service/rm2 exposed\n"
    Apr 25 21:13:11.405: INFO: Service rm2 in namespace kubectl-3640 found.
    STEP: exposing service 04/25/23 21:13:13.445
    Apr 25 21:13:13.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3640 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Apr 25 21:13:13.621: INFO: stderr: ""
    Apr 25 21:13:13.622: INFO: stdout: "service/rm3 exposed\n"
    Apr 25 21:13:13.636: INFO: Service rm3 in namespace kubectl-3640 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 21:13:15.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3640" for this suite. 04/25/23 21:13:15.721
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3210
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:13:15.77
Apr 25 21:13:15.771: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 21:13:15.773
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:15.814
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:15.825
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3210
STEP: creating an Endpoint 04/25/23 21:13:15.859
STEP: waiting for available Endpoint 04/25/23 21:13:15.928
STEP: listing all Endpoints 04/25/23 21:13:15.934
STEP: updating the Endpoint 04/25/23 21:13:15.966
STEP: fetching the Endpoint 04/25/23 21:13:16.013
STEP: patching the Endpoint 04/25/23 21:13:16.026
STEP: fetching the Endpoint 04/25/23 21:13:16.048
STEP: deleting the Endpoint by Collection 04/25/23 21:13:16.061
STEP: waiting for Endpoint deletion 04/25/23 21:13:16.094
STEP: fetching the Endpoint 04/25/23 21:13:16.1
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 21:13:16.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7631" for this suite. 04/25/23 21:13:16.131
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":343,"skipped":6465,"failed":0}
------------------------------
• [0.379 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3210

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:13:15.77
    Apr 25 21:13:15.771: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 21:13:15.773
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:15.814
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:15.825
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3210
    STEP: creating an Endpoint 04/25/23 21:13:15.859
    STEP: waiting for available Endpoint 04/25/23 21:13:15.928
    STEP: listing all Endpoints 04/25/23 21:13:15.934
    STEP: updating the Endpoint 04/25/23 21:13:15.966
    STEP: fetching the Endpoint 04/25/23 21:13:16.013
    STEP: patching the Endpoint 04/25/23 21:13:16.026
    STEP: fetching the Endpoint 04/25/23 21:13:16.048
    STEP: deleting the Endpoint by Collection 04/25/23 21:13:16.061
    STEP: waiting for Endpoint deletion 04/25/23 21:13:16.094
    STEP: fetching the Endpoint 04/25/23 21:13:16.1
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 21:13:16.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7631" for this suite. 04/25/23 21:13:16.131
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:13:16.151
Apr 25 21:13:16.152: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename container-runtime 04/25/23 21:13:16.155
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:16.198
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:16.209
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 04/25/23 21:13:16.242
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 04/25/23 21:13:35.505
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 04/25/23 21:13:35.517
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 04/25/23 21:13:35.541
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 04/25/23 21:13:35.541
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 04/25/23 21:13:35.603
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 04/25/23 21:13:38.656
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 04/25/23 21:13:40.694
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 04/25/23 21:13:40.718
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 04/25/23 21:13:40.718
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 04/25/23 21:13:40.768
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 04/25/23 21:13:41.792
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 04/25/23 21:13:44.843
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 04/25/23 21:13:44.867
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 04/25/23 21:13:44.867
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 25 21:13:44.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1570" for this suite. 04/25/23 21:13:44.963
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":344,"skipped":6474,"failed":0}
------------------------------
• [SLOW TEST] [28.859 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:13:16.151
    Apr 25 21:13:16.152: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename container-runtime 04/25/23 21:13:16.155
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:16.198
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:16.209
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 04/25/23 21:13:16.242
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 04/25/23 21:13:35.505
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 04/25/23 21:13:35.517
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 04/25/23 21:13:35.541
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 04/25/23 21:13:35.541
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 04/25/23 21:13:35.603
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 04/25/23 21:13:38.656
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 04/25/23 21:13:40.694
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 04/25/23 21:13:40.718
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 04/25/23 21:13:40.718
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 04/25/23 21:13:40.768
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 04/25/23 21:13:41.792
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 04/25/23 21:13:44.843
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 04/25/23 21:13:44.867
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 04/25/23 21:13:44.867
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 25 21:13:44.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-1570" for this suite. 04/25/23 21:13:44.963
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:13:45.014
Apr 25 21:13:45.014: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename pods 04/25/23 21:13:45.016
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:45.098
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:45.111
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 04/25/23 21:13:45.123
Apr 25 21:13:45.173: INFO: Waiting up to 5m0s for pod "pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf" in namespace "pods-6910" to be "running and ready"
Apr 25 21:13:45.191: INFO: Pod "pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf": Phase="Pending", Reason="", readiness=false. Elapsed: 17.367811ms
Apr 25 21:13:45.191: INFO: The phase of Pod pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf is Pending, waiting for it to be Running (with Ready = true)
Apr 25 21:13:47.204: INFO: Pod "pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030219591s
Apr 25 21:13:47.204: INFO: The phase of Pod pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf is Pending, waiting for it to be Running (with Ready = true)
Apr 25 21:13:49.202: INFO: Pod "pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf": Phase="Running", Reason="", readiness=true. Elapsed: 4.028545509s
Apr 25 21:13:49.202: INFO: The phase of Pod pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf is Running (Ready = true)
Apr 25 21:13:49.202: INFO: Pod "pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf" satisfied condition "running and ready"
Apr 25 21:13:49.223: INFO: Pod pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf has hostIP: 10.10.21.190
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 25 21:13:49.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6910" for this suite. 04/25/23 21:13:49.242
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":345,"skipped":6487,"failed":0}
------------------------------
• [4.245 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:13:45.014
    Apr 25 21:13:45.014: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename pods 04/25/23 21:13:45.016
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:45.098
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:45.111
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 04/25/23 21:13:45.123
    Apr 25 21:13:45.173: INFO: Waiting up to 5m0s for pod "pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf" in namespace "pods-6910" to be "running and ready"
    Apr 25 21:13:45.191: INFO: Pod "pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf": Phase="Pending", Reason="", readiness=false. Elapsed: 17.367811ms
    Apr 25 21:13:45.191: INFO: The phase of Pod pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 21:13:47.204: INFO: Pod "pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030219591s
    Apr 25 21:13:47.204: INFO: The phase of Pod pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 21:13:49.202: INFO: Pod "pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf": Phase="Running", Reason="", readiness=true. Elapsed: 4.028545509s
    Apr 25 21:13:49.202: INFO: The phase of Pod pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf is Running (Ready = true)
    Apr 25 21:13:49.202: INFO: Pod "pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf" satisfied condition "running and ready"
    Apr 25 21:13:49.223: INFO: Pod pod-hostip-d4691419-0bd8-4690-8226-30ed7dab13cf has hostIP: 10.10.21.190
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 25 21:13:49.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6910" for this suite. 04/25/23 21:13:49.242
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:13:49.269
Apr 25 21:13:49.270: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename custom-resource-definition 04/25/23 21:13:49.272
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:49.318
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:49.329
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Apr 25 21:13:49.342: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 21:13:49.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6372" for this suite. 04/25/23 21:13:49.998
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":346,"skipped":6511,"failed":0}
------------------------------
• [0.747 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:13:49.269
    Apr 25 21:13:49.270: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename custom-resource-definition 04/25/23 21:13:49.272
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:49.318
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:49.329
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Apr 25 21:13:49.342: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 21:13:49.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-6372" for this suite. 04/25/23 21:13:49.998
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:13:50.022
Apr 25 21:13:50.023: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 21:13:50.025
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:50.102
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:50.113
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 04/25/23 21:13:50.126
Apr 25 21:13:50.127: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3247 proxy --unix-socket=/tmp/kubectl-proxy-unix966123421/test'
STEP: retrieving proxy /api/ output 04/25/23 21:13:50.206
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 21:13:50.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3247" for this suite. 04/25/23 21:13:50.238
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":347,"skipped":6523,"failed":0}
------------------------------
• [0.250 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:13:50.022
    Apr 25 21:13:50.023: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 21:13:50.025
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:50.102
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:50.113
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 04/25/23 21:13:50.126
    Apr 25 21:13:50.127: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-3247 proxy --unix-socket=/tmp/kubectl-proxy-unix966123421/test'
    STEP: retrieving proxy /api/ output 04/25/23 21:13:50.206
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 21:13:50.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3247" for this suite. 04/25/23 21:13:50.238
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:13:50.285
Apr 25 21:13:50.285: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename conformance-tests 04/25/23 21:13:50.286
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:50.343
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:50.353
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 04/25/23 21:13:50.364
Apr 25 21:13:50.364: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Apr 25 21:13:50.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-1779" for this suite. 04/25/23 21:13:50.41
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":348,"skipped":6557,"failed":0}
------------------------------
• [0.142 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:13:50.285
    Apr 25 21:13:50.285: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename conformance-tests 04/25/23 21:13:50.286
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:50.343
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:50.353
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 04/25/23 21:13:50.364
    Apr 25 21:13:50.364: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Apr 25 21:13:50.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-1779" for this suite. 04/25/23 21:13:50.41
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:13:50.433
Apr 25 21:13:50.433: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename kubectl 04/25/23 21:13:50.435
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:50.475
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:50.487
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 04/25/23 21:13:50.5
Apr 25 21:13:50.502: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-1406 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 04/25/23 21:13:50.588
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 25 21:13:50.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1406" for this suite. 04/25/23 21:13:50.622
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":349,"skipped":6570,"failed":0}
------------------------------
• [0.208 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:13:50.433
    Apr 25 21:13:50.433: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename kubectl 04/25/23 21:13:50.435
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:50.475
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:50.487
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 04/25/23 21:13:50.5
    Apr 25 21:13:50.502: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=kubectl-1406 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 04/25/23 21:13:50.588
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 25 21:13:50.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1406" for this suite. 04/25/23 21:13:50.622
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:13:50.642
Apr 25 21:13:50.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename pods 04/25/23 21:13:50.646
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:50.698
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:50.709
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 04/25/23 21:13:50.721
STEP: submitting the pod to kubernetes 04/25/23 21:13:50.722
Apr 25 21:13:50.742: INFO: Waiting up to 5m0s for pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f" in namespace "pods-69" to be "running and ready"
Apr 25 21:13:50.758: INFO: Pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.298324ms
Apr 25 21:13:50.759: INFO: The phase of Pod pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f is Pending, waiting for it to be Running (with Ready = true)
Apr 25 21:13:52.770: INFO: Pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f": Phase="Running", Reason="", readiness=true. Elapsed: 2.028206474s
Apr 25 21:13:52.771: INFO: The phase of Pod pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f is Running (Ready = true)
Apr 25 21:13:52.772: INFO: Pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 04/25/23 21:13:52.785
STEP: updating the pod 04/25/23 21:13:52.799
Apr 25 21:13:53.336: INFO: Successfully updated pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f"
Apr 25 21:13:53.336: INFO: Waiting up to 5m0s for pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f" in namespace "pods-69" to be "running"
Apr 25 21:13:53.347: INFO: Pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f": Phase="Running", Reason="", readiness=true. Elapsed: 10.607294ms
Apr 25 21:13:53.347: INFO: Pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 04/25/23 21:13:53.347
Apr 25 21:13:53.358: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 25 21:13:53.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-69" for this suite. 04/25/23 21:13:53.383
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":350,"skipped":6571,"failed":0}
------------------------------
• [2.759 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:13:50.642
    Apr 25 21:13:50.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename pods 04/25/23 21:13:50.646
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:50.698
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:50.709
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 04/25/23 21:13:50.721
    STEP: submitting the pod to kubernetes 04/25/23 21:13:50.722
    Apr 25 21:13:50.742: INFO: Waiting up to 5m0s for pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f" in namespace "pods-69" to be "running and ready"
    Apr 25 21:13:50.758: INFO: Pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.298324ms
    Apr 25 21:13:50.759: INFO: The phase of Pod pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 21:13:52.770: INFO: Pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f": Phase="Running", Reason="", readiness=true. Elapsed: 2.028206474s
    Apr 25 21:13:52.771: INFO: The phase of Pod pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f is Running (Ready = true)
    Apr 25 21:13:52.772: INFO: Pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 04/25/23 21:13:52.785
    STEP: updating the pod 04/25/23 21:13:52.799
    Apr 25 21:13:53.336: INFO: Successfully updated pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f"
    Apr 25 21:13:53.336: INFO: Waiting up to 5m0s for pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f" in namespace "pods-69" to be "running"
    Apr 25 21:13:53.347: INFO: Pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f": Phase="Running", Reason="", readiness=true. Elapsed: 10.607294ms
    Apr 25 21:13:53.347: INFO: Pod "pod-update-fe6b0aaf-388a-4881-8cd2-c8d7a957234f" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 04/25/23 21:13:53.347
    Apr 25 21:13:53.358: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 25 21:13:53.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-69" for this suite. 04/25/23 21:13:53.383
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:13:53.408
Apr 25 21:13:53.408: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 21:13:53.409
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:53.452
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:53.465
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 21:13:53.518
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 21:13:53.751
STEP: Deploying the webhook pod 04/25/23 21:13:53.771
STEP: Wait for the deployment to be ready 04/25/23 21:13:53.802
Apr 25 21:13:53.829: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/25/23 21:13:55.936
STEP: Verifying the service has paired with the endpoint 04/25/23 21:13:55.971
Apr 25 21:13:56.973: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 04/25/23 21:13:56.987
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 04/25/23 21:13:56.993
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 04/25/23 21:13:56.993
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 04/25/23 21:13:56.994
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 04/25/23 21:13:57
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 04/25/23 21:13:57
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 04/25/23 21:13:57.006
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 21:13:57.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5616" for this suite. 04/25/23 21:13:57.025
STEP: Destroying namespace "webhook-5616-markers" for this suite. 04/25/23 21:13:57.047
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":351,"skipped":6594,"failed":0}
------------------------------
• [3.781 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:13:53.408
    Apr 25 21:13:53.408: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 21:13:53.409
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:53.452
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:53.465
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 21:13:53.518
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 21:13:53.751
    STEP: Deploying the webhook pod 04/25/23 21:13:53.771
    STEP: Wait for the deployment to be ready 04/25/23 21:13:53.802
    Apr 25 21:13:53.829: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/25/23 21:13:55.936
    STEP: Verifying the service has paired with the endpoint 04/25/23 21:13:55.971
    Apr 25 21:13:56.973: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 04/25/23 21:13:56.987
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 04/25/23 21:13:56.993
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 04/25/23 21:13:56.993
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 04/25/23 21:13:56.994
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 04/25/23 21:13:57
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 04/25/23 21:13:57
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 04/25/23 21:13:57.006
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 21:13:57.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5616" for this suite. 04/25/23 21:13:57.025
    STEP: Destroying namespace "webhook-5616-markers" for this suite. 04/25/23 21:13:57.047
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:13:57.189
Apr 25 21:13:57.189: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename webhook 04/25/23 21:13:57.192
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:57.242
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:57.254
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/25/23 21:13:57.304
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 21:13:57.546
STEP: Deploying the webhook pod 04/25/23 21:13:57.562
STEP: Wait for the deployment to be ready 04/25/23 21:13:57.594
Apr 25 21:13:57.623: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/25/23 21:13:59.664
STEP: Verifying the service has paired with the endpoint 04/25/23 21:13:59.694
Apr 25 21:14:00.695: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 04/25/23 21:14:00.709
STEP: create a pod that should be updated by the webhook 04/25/23 21:14:00.786
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 21:14:00.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1866" for this suite. 04/25/23 21:14:00.907
STEP: Destroying namespace "webhook-1866-markers" for this suite. 04/25/23 21:14:00.924
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":352,"skipped":6595,"failed":0}
------------------------------
• [3.876 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:13:57.189
    Apr 25 21:13:57.189: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename webhook 04/25/23 21:13:57.192
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:13:57.242
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:13:57.254
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/25/23 21:13:57.304
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/25/23 21:13:57.546
    STEP: Deploying the webhook pod 04/25/23 21:13:57.562
    STEP: Wait for the deployment to be ready 04/25/23 21:13:57.594
    Apr 25 21:13:57.623: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/25/23 21:13:59.664
    STEP: Verifying the service has paired with the endpoint 04/25/23 21:13:59.694
    Apr 25 21:14:00.695: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 04/25/23 21:14:00.709
    STEP: create a pod that should be updated by the webhook 04/25/23 21:14:00.786
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 21:14:00.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1866" for this suite. 04/25/23 21:14:00.907
    STEP: Destroying namespace "webhook-1866-markers" for this suite. 04/25/23 21:14:00.924
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:14:01.068
Apr 25 21:14:01.068: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename sched-pred 04/25/23 21:14:01.07
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:01.116
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:01.125
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 25 21:14:01.136: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 25 21:14:01.178: INFO: Waiting for terminating namespaces to be deleted...
Apr 25 21:14:01.198: INFO: 
Logging pods the apiserver thinks is on node 10.10.21.136 before test
Apr 25 21:14:01.229: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-nzg9s from ibm-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.229: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
Apr 25 21:14:01.229: INFO: calico-node-q95vg from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.229: INFO: 	Container calico-node ready: true, restart count 0
Apr 25 21:14:01.229: INFO: calico-typha-677688fdc5-5f8fr from kube-system started at 2023-04-25 17:14:29 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.229: INFO: 	Container calico-typha ready: true, restart count 0
Apr 25 21:14:01.230: INFO: coredns-6754846f95-cn7xr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.230: INFO: 	Container coredns ready: true, restart count 0
Apr 25 21:14:01.230: INFO: coredns-6754846f95-dnk45 from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.230: INFO: 	Container coredns ready: true, restart count 0
Apr 25 21:14:01.230: INFO: ibm-keepalived-watcher-p87jk from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.230: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 25 21:14:01.230: INFO: ibm-master-proxy-static-10.10.21.136 from kube-system started at 2023-04-25 17:13:57 +0000 UTC (2 container statuses recorded)
Apr 25 21:14:01.230: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 25 21:14:01.230: INFO: 	Container pause ready: true, restart count 0
Apr 25 21:14:01.230: INFO: ibmcloud-block-storage-driver-fm7g7 from kube-system started at 2023-04-25 17:14:07 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.231: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Apr 25 21:14:01.231: INFO: konnectivity-agent-mv6tj from kube-system started at 2023-04-25 17:26:45 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.231: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 25 21:14:01.231: INFO: metrics-server-c785bfcff-b2n5l from kube-system started at 2023-04-25 18:05:55 +0000 UTC (3 container statuses recorded)
Apr 25 21:14:01.231: INFO: 	Container config-watcher ready: true, restart count 0
Apr 25 21:14:01.231: INFO: 	Container metrics-server ready: true, restart count 0
Apr 25 21:14:01.231: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr 25 21:14:01.231: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-p575r from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.231: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 25 21:14:01.231: INFO: sonobuoy from sonobuoy started at 2023-04-25 19:35:04 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.231: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 25 21:14:01.232: INFO: sonobuoy-e2e-job-38c24e91f58b4d35 from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 21:14:01.232: INFO: 	Container e2e ready: true, restart count 0
Apr 25 21:14:01.232: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 21:14:01.232: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-88nhh from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 21:14:01.232: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 21:14:01.232: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 25 21:14:01.232: INFO: 
Logging pods the apiserver thinks is on node 10.10.21.161 before test
Apr 25 21:14:01.265: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-g4ql4 from ibm-system started at 2023-04-25 17:18:17 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.265: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
Apr 25 21:14:01.265: INFO: calico-kube-controllers-5754dfd4dd-jfqrl from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.265: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 25 21:14:01.265: INFO: calico-node-mqpqg from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.265: INFO: 	Container calico-node ready: true, restart count 0
Apr 25 21:14:01.265: INFO: calico-typha-677688fdc5-bt4pk from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.265: INFO: 	Container calico-typha ready: true, restart count 0
Apr 25 21:14:01.265: INFO: coredns-6754846f95-8fzmk from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.265: INFO: 	Container coredns ready: true, restart count 0
Apr 25 21:14:01.265: INFO: coredns-autoscaler-669cf746f6-hnjbg from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.265: INFO: 	Container autoscaler ready: true, restart count 0
Apr 25 21:14:01.265: INFO: dashboard-metrics-scraper-c964d5594-wvstn from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.265: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 25 21:14:01.265: INFO: ibm-file-plugin-84d44c69b5-kz8hc from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.265: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Apr 25 21:14:01.265: INFO: ibm-keepalived-watcher-9dj6q from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.265: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 25 21:14:01.265: INFO: ibm-master-proxy-static-10.10.21.161 from kube-system started at 2023-04-25 17:13:31 +0000 UTC (2 container statuses recorded)
Apr 25 21:14:01.265: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 25 21:14:01.265: INFO: 	Container pause ready: true, restart count 0
Apr 25 21:14:01.265: INFO: ibm-storage-watcher-65957667f-vtkpm from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.266: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Apr 25 21:14:01.266: INFO: ibmcloud-block-storage-driver-wstqs from kube-system started at 2023-04-25 17:13:40 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.266: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Apr 25 21:14:01.266: INFO: ibmcloud-block-storage-plugin-6d48895c6b-bh5sb from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.266: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Apr 25 21:14:01.266: INFO: ingress-cluster-healthcheck-6f7f6b87df-nfchz from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.266: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Apr 25 21:14:01.266: INFO: konnectivity-agent-ghrrh from kube-system started at 2023-04-25 17:26:42 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.266: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 25 21:14:01.266: INFO: kubernetes-dashboard-55c4d56798-pm8jr from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.266: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 25 21:14:01.266: INFO: metrics-server-c785bfcff-jltfr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (3 container statuses recorded)
Apr 25 21:14:01.266: INFO: 	Container config-watcher ready: true, restart count 0
Apr 25 21:14:01.266: INFO: 	Container metrics-server ready: true, restart count 0
Apr 25 21:14:01.266: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr 25 21:14:01.266: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-bvz72 from kube-system started at 2023-04-25 17:18:07 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.266: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 25 21:14:01.266: INFO: snapshot-controller-c5c6dddff-2s9qq from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.267: INFO: 	Container snapshot-controller ready: true, restart count 0
Apr 25 21:14:01.267: INFO: snapshot-controller-c5c6dddff-55rkz from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.267: INFO: 	Container snapshot-controller ready: true, restart count 0
Apr 25 21:14:01.267: INFO: snapshot-controller-c5c6dddff-mxcw7 from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.267: INFO: 	Container snapshot-controller ready: true, restart count 0
Apr 25 21:14:01.267: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-w68zf from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 21:14:01.267: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 21:14:01.267: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 25 21:14:01.267: INFO: 
Logging pods the apiserver thinks is on node 10.10.21.190 before test
Apr 25 21:14:01.293: INFO: calico-node-4mqrc from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.293: INFO: 	Container calico-node ready: true, restart count 0
Apr 25 21:14:01.293: INFO: calico-typha-677688fdc5-mnnwk from kube-system started at 2023-04-25 20:31:28 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.293: INFO: 	Container calico-typha ready: true, restart count 0
Apr 25 21:14:01.293: INFO: ibm-keepalived-watcher-r8lvr from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.293: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 25 21:14:01.293: INFO: ibm-master-proxy-static-10.10.21.190 from kube-system started at 2023-04-25 17:14:39 +0000 UTC (2 container statuses recorded)
Apr 25 21:14:01.293: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 25 21:14:01.293: INFO: 	Container pause ready: true, restart count 0
Apr 25 21:14:01.293: INFO: ibmcloud-block-storage-driver-gpzl6 from kube-system started at 2023-04-25 17:14:49 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.293: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Apr 25 21:14:01.293: INFO: konnectivity-agent-hkzc4 from kube-system started at 2023-04-25 17:26:39 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.293: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 25 21:14:01.293: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-gq2qk from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
Apr 25 21:14:01.293: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 21:14:01.293: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 25 21:14:01.293: INFO: webhook-to-be-mutated from webhook-1866 started at 2023-04-25 21:14:00 +0000 UTC (1 container statuses recorded)
Apr 25 21:14:01.293: INFO: 	Container example ready: false, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/25/23 21:14:01.294
Apr 25 21:14:01.317: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-5550" to be "running"
Apr 25 21:14:01.329: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 12.008409ms
Apr 25 21:14:03.343: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025441316s
Apr 25 21:14:05.343: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.025282716s
Apr 25 21:14:05.343: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/25/23 21:14:05.354
STEP: Trying to apply a random label on the found node. 04/25/23 21:14:05.388
STEP: verifying the node has the label kubernetes.io/e2e-fb436518-cd3b-4443-860a-8775d8e2d9eb 42 04/25/23 21:14:05.422
STEP: Trying to relaunch the pod, now with labels. 04/25/23 21:14:05.434
Apr 25 21:14:05.447: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-5550" to be "not pending"
Apr 25 21:14:05.464: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 16.088897ms
Apr 25 21:14:07.478: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030379408s
Apr 25 21:14:09.477: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 4.029608571s
Apr 25 21:14:09.477: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-fb436518-cd3b-4443-860a-8775d8e2d9eb off the node 10.10.21.190 04/25/23 21:14:09.489
STEP: verifying the node doesn't have the label kubernetes.io/e2e-fb436518-cd3b-4443-860a-8775d8e2d9eb 04/25/23 21:14:09.535
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 25 21:14:09.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5550" for this suite. 04/25/23 21:14:09.57
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":353,"skipped":6613,"failed":0}
------------------------------
• [SLOW TEST] [8.526 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:14:01.068
    Apr 25 21:14:01.068: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename sched-pred 04/25/23 21:14:01.07
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:01.116
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:01.125
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 25 21:14:01.136: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 25 21:14:01.178: INFO: Waiting for terminating namespaces to be deleted...
    Apr 25 21:14:01.198: INFO: 
    Logging pods the apiserver thinks is on node 10.10.21.136 before test
    Apr 25 21:14:01.229: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-nzg9s from ibm-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.229: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
    Apr 25 21:14:01.229: INFO: calico-node-q95vg from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.229: INFO: 	Container calico-node ready: true, restart count 0
    Apr 25 21:14:01.229: INFO: calico-typha-677688fdc5-5f8fr from kube-system started at 2023-04-25 17:14:29 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.229: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 25 21:14:01.230: INFO: coredns-6754846f95-cn7xr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.230: INFO: 	Container coredns ready: true, restart count 0
    Apr 25 21:14:01.230: INFO: coredns-6754846f95-dnk45 from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.230: INFO: 	Container coredns ready: true, restart count 0
    Apr 25 21:14:01.230: INFO: ibm-keepalived-watcher-p87jk from kube-system started at 2023-04-25 17:13:58 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.230: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Apr 25 21:14:01.230: INFO: ibm-master-proxy-static-10.10.21.136 from kube-system started at 2023-04-25 17:13:57 +0000 UTC (2 container statuses recorded)
    Apr 25 21:14:01.230: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Apr 25 21:14:01.230: INFO: 	Container pause ready: true, restart count 0
    Apr 25 21:14:01.230: INFO: ibmcloud-block-storage-driver-fm7g7 from kube-system started at 2023-04-25 17:14:07 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.231: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Apr 25 21:14:01.231: INFO: konnectivity-agent-mv6tj from kube-system started at 2023-04-25 17:26:45 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.231: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Apr 25 21:14:01.231: INFO: metrics-server-c785bfcff-b2n5l from kube-system started at 2023-04-25 18:05:55 +0000 UTC (3 container statuses recorded)
    Apr 25 21:14:01.231: INFO: 	Container config-watcher ready: true, restart count 0
    Apr 25 21:14:01.231: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 25 21:14:01.231: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Apr 25 21:14:01.231: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-p575r from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.231: INFO: 	Container nginx-ingress ready: true, restart count 0
    Apr 25 21:14:01.231: INFO: sonobuoy from sonobuoy started at 2023-04-25 19:35:04 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.231: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 25 21:14:01.232: INFO: sonobuoy-e2e-job-38c24e91f58b4d35 from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 21:14:01.232: INFO: 	Container e2e ready: true, restart count 0
    Apr 25 21:14:01.232: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 21:14:01.232: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-88nhh from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 21:14:01.232: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 21:14:01.232: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 25 21:14:01.232: INFO: 
    Logging pods the apiserver thinks is on node 10.10.21.161 before test
    Apr 25 21:14:01.265: INFO: ibm-cloud-provider-ip-163-73-66-210-59b467d7cb-g4ql4 from ibm-system started at 2023-04-25 17:18:17 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.265: INFO: 	Container ibm-cloud-provider-ip-163-73-66-210 ready: true, restart count 0
    Apr 25 21:14:01.265: INFO: calico-kube-controllers-5754dfd4dd-jfqrl from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.265: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Apr 25 21:14:01.265: INFO: calico-node-mqpqg from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.265: INFO: 	Container calico-node ready: true, restart count 0
    Apr 25 21:14:01.265: INFO: calico-typha-677688fdc5-bt4pk from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.265: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 25 21:14:01.265: INFO: coredns-6754846f95-8fzmk from kube-system started at 2023-04-25 17:27:18 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.265: INFO: 	Container coredns ready: true, restart count 0
    Apr 25 21:14:01.265: INFO: coredns-autoscaler-669cf746f6-hnjbg from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.265: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 25 21:14:01.265: INFO: dashboard-metrics-scraper-c964d5594-wvstn from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.265: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Apr 25 21:14:01.265: INFO: ibm-file-plugin-84d44c69b5-kz8hc from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.265: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Apr 25 21:14:01.265: INFO: ibm-keepalived-watcher-9dj6q from kube-system started at 2023-04-25 17:13:32 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.265: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Apr 25 21:14:01.265: INFO: ibm-master-proxy-static-10.10.21.161 from kube-system started at 2023-04-25 17:13:31 +0000 UTC (2 container statuses recorded)
    Apr 25 21:14:01.265: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Apr 25 21:14:01.265: INFO: 	Container pause ready: true, restart count 0
    Apr 25 21:14:01.265: INFO: ibm-storage-watcher-65957667f-vtkpm from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.266: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Apr 25 21:14:01.266: INFO: ibmcloud-block-storage-driver-wstqs from kube-system started at 2023-04-25 17:13:40 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.266: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Apr 25 21:14:01.266: INFO: ibmcloud-block-storage-plugin-6d48895c6b-bh5sb from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.266: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Apr 25 21:14:01.266: INFO: ingress-cluster-healthcheck-6f7f6b87df-nfchz from kube-system started at 2023-04-25 19:37:06 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.266: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Apr 25 21:14:01.266: INFO: konnectivity-agent-ghrrh from kube-system started at 2023-04-25 17:26:42 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.266: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Apr 25 21:14:01.266: INFO: kubernetes-dashboard-55c4d56798-pm8jr from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.266: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Apr 25 21:14:01.266: INFO: metrics-server-c785bfcff-jltfr from kube-system started at 2023-04-25 19:37:06 +0000 UTC (3 container statuses recorded)
    Apr 25 21:14:01.266: INFO: 	Container config-watcher ready: true, restart count 0
    Apr 25 21:14:01.266: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 25 21:14:01.266: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Apr 25 21:14:01.266: INFO: public-crch40dmlo0r3ao1g695p0-alb1-69877d954d-bvz72 from kube-system started at 2023-04-25 17:18:07 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.266: INFO: 	Container nginx-ingress ready: true, restart count 0
    Apr 25 21:14:01.266: INFO: snapshot-controller-c5c6dddff-2s9qq from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.267: INFO: 	Container snapshot-controller ready: true, restart count 0
    Apr 25 21:14:01.267: INFO: snapshot-controller-c5c6dddff-55rkz from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.267: INFO: 	Container snapshot-controller ready: true, restart count 0
    Apr 25 21:14:01.267: INFO: snapshot-controller-c5c6dddff-mxcw7 from kube-system started at 2023-04-25 17:14:03 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.267: INFO: 	Container snapshot-controller ready: true, restart count 0
    Apr 25 21:14:01.267: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-w68zf from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 21:14:01.267: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 21:14:01.267: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 25 21:14:01.267: INFO: 
    Logging pods the apiserver thinks is on node 10.10.21.190 before test
    Apr 25 21:14:01.293: INFO: calico-node-4mqrc from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.293: INFO: 	Container calico-node ready: true, restart count 0
    Apr 25 21:14:01.293: INFO: calico-typha-677688fdc5-mnnwk from kube-system started at 2023-04-25 20:31:28 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.293: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 25 21:14:01.293: INFO: ibm-keepalived-watcher-r8lvr from kube-system started at 2023-04-25 17:14:41 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.293: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Apr 25 21:14:01.293: INFO: ibm-master-proxy-static-10.10.21.190 from kube-system started at 2023-04-25 17:14:39 +0000 UTC (2 container statuses recorded)
    Apr 25 21:14:01.293: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Apr 25 21:14:01.293: INFO: 	Container pause ready: true, restart count 0
    Apr 25 21:14:01.293: INFO: ibmcloud-block-storage-driver-gpzl6 from kube-system started at 2023-04-25 17:14:49 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.293: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Apr 25 21:14:01.293: INFO: konnectivity-agent-hkzc4 from kube-system started at 2023-04-25 17:26:39 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.293: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Apr 25 21:14:01.293: INFO: sonobuoy-systemd-logs-daemon-set-9f2936bae14e4cc6-gq2qk from sonobuoy started at 2023-04-25 19:35:11 +0000 UTC (2 container statuses recorded)
    Apr 25 21:14:01.293: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 25 21:14:01.293: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 25 21:14:01.293: INFO: webhook-to-be-mutated from webhook-1866 started at 2023-04-25 21:14:00 +0000 UTC (1 container statuses recorded)
    Apr 25 21:14:01.293: INFO: 	Container example ready: false, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/25/23 21:14:01.294
    Apr 25 21:14:01.317: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-5550" to be "running"
    Apr 25 21:14:01.329: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 12.008409ms
    Apr 25 21:14:03.343: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025441316s
    Apr 25 21:14:05.343: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.025282716s
    Apr 25 21:14:05.343: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/25/23 21:14:05.354
    STEP: Trying to apply a random label on the found node. 04/25/23 21:14:05.388
    STEP: verifying the node has the label kubernetes.io/e2e-fb436518-cd3b-4443-860a-8775d8e2d9eb 42 04/25/23 21:14:05.422
    STEP: Trying to relaunch the pod, now with labels. 04/25/23 21:14:05.434
    Apr 25 21:14:05.447: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-5550" to be "not pending"
    Apr 25 21:14:05.464: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 16.088897ms
    Apr 25 21:14:07.478: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030379408s
    Apr 25 21:14:09.477: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 4.029608571s
    Apr 25 21:14:09.477: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-fb436518-cd3b-4443-860a-8775d8e2d9eb off the node 10.10.21.190 04/25/23 21:14:09.489
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-fb436518-cd3b-4443-860a-8775d8e2d9eb 04/25/23 21:14:09.535
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 25 21:14:09.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-5550" for this suite. 04/25/23 21:14:09.57
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:14:09.595
Apr 25 21:14:09.595: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename projected 04/25/23 21:14:09.596
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:09.642
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:09.656
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-f441b9dd-3f7d-4c57-85ba-accc74c80a93 04/25/23 21:14:09.67
STEP: Creating a pod to test consume configMaps 04/25/23 21:14:09.688
Apr 25 21:14:09.710: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f" in namespace "projected-3206" to be "Succeeded or Failed"
Apr 25 21:14:09.724: INFO: Pod "pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.911839ms
Apr 25 21:14:11.736: INFO: Pod "pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026518544s
Apr 25 21:14:13.736: INFO: Pod "pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02650513s
STEP: Saw pod success 04/25/23 21:14:13.737
Apr 25 21:14:13.737: INFO: Pod "pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f" satisfied condition "Succeeded or Failed"
Apr 25 21:14:13.749: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f container projected-configmap-volume-test: <nil>
STEP: delete the pod 04/25/23 21:14:13.78
Apr 25 21:14:13.866: INFO: Waiting for pod pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f to disappear
Apr 25 21:14:13.877: INFO: Pod pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 25 21:14:13.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3206" for this suite. 04/25/23 21:14:13.899
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":354,"skipped":6617,"failed":0}
------------------------------
• [4.323 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:14:09.595
    Apr 25 21:14:09.595: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename projected 04/25/23 21:14:09.596
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:09.642
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:09.656
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-f441b9dd-3f7d-4c57-85ba-accc74c80a93 04/25/23 21:14:09.67
    STEP: Creating a pod to test consume configMaps 04/25/23 21:14:09.688
    Apr 25 21:14:09.710: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f" in namespace "projected-3206" to be "Succeeded or Failed"
    Apr 25 21:14:09.724: INFO: Pod "pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.911839ms
    Apr 25 21:14:11.736: INFO: Pod "pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026518544s
    Apr 25 21:14:13.736: INFO: Pod "pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02650513s
    STEP: Saw pod success 04/25/23 21:14:13.737
    Apr 25 21:14:13.737: INFO: Pod "pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f" satisfied condition "Succeeded or Failed"
    Apr 25 21:14:13.749: INFO: Trying to get logs from node 10.10.21.190 pod pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f container projected-configmap-volume-test: <nil>
    STEP: delete the pod 04/25/23 21:14:13.78
    Apr 25 21:14:13.866: INFO: Waiting for pod pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f to disappear
    Apr 25 21:14:13.877: INFO: Pod pod-projected-configmaps-d28ac9e6-d3db-43f6-98fd-62b3c9ff204f no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 25 21:14:13.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3206" for this suite. 04/25/23 21:14:13.899
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:14:13.922
Apr 25 21:14:13.923: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename certificates 04/25/23 21:14:13.925
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:13.971
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:13.984
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 04/25/23 21:14:14.683
STEP: getting /apis/certificates.k8s.io 04/25/23 21:14:14.692
STEP: getting /apis/certificates.k8s.io/v1 04/25/23 21:14:14.697
STEP: creating 04/25/23 21:14:14.701
STEP: getting 04/25/23 21:14:14.742
STEP: listing 04/25/23 21:14:14.756
STEP: watching 04/25/23 21:14:14.771
Apr 25 21:14:14.771: INFO: starting watch
STEP: patching 04/25/23 21:14:14.776
STEP: updating 04/25/23 21:14:14.796
Apr 25 21:14:14.809: INFO: waiting for watch events with expected annotations
Apr 25 21:14:14.810: INFO: saw patched and updated annotations
STEP: getting /approval 04/25/23 21:14:14.81
STEP: patching /approval 04/25/23 21:14:14.823
STEP: updating /approval 04/25/23 21:14:14.838
STEP: getting /status 04/25/23 21:14:14.853
STEP: patching /status 04/25/23 21:14:14.865
STEP: updating /status 04/25/23 21:14:14.881
STEP: deleting 04/25/23 21:14:14.897
STEP: deleting a collection 04/25/23 21:14:14.951
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 25 21:14:15.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-7238" for this suite. 04/25/23 21:14:15.037
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":355,"skipped":6621,"failed":0}
------------------------------
• [1.135 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:14:13.922
    Apr 25 21:14:13.923: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename certificates 04/25/23 21:14:13.925
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:13.971
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:13.984
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 04/25/23 21:14:14.683
    STEP: getting /apis/certificates.k8s.io 04/25/23 21:14:14.692
    STEP: getting /apis/certificates.k8s.io/v1 04/25/23 21:14:14.697
    STEP: creating 04/25/23 21:14:14.701
    STEP: getting 04/25/23 21:14:14.742
    STEP: listing 04/25/23 21:14:14.756
    STEP: watching 04/25/23 21:14:14.771
    Apr 25 21:14:14.771: INFO: starting watch
    STEP: patching 04/25/23 21:14:14.776
    STEP: updating 04/25/23 21:14:14.796
    Apr 25 21:14:14.809: INFO: waiting for watch events with expected annotations
    Apr 25 21:14:14.810: INFO: saw patched and updated annotations
    STEP: getting /approval 04/25/23 21:14:14.81
    STEP: patching /approval 04/25/23 21:14:14.823
    STEP: updating /approval 04/25/23 21:14:14.838
    STEP: getting /status 04/25/23 21:14:14.853
    STEP: patching /status 04/25/23 21:14:14.865
    STEP: updating /status 04/25/23 21:14:14.881
    STEP: deleting 04/25/23 21:14:14.897
    STEP: deleting a collection 04/25/23 21:14:14.951
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 25 21:14:15.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-7238" for this suite. 04/25/23 21:14:15.037
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:14:15.072
Apr 25 21:14:15.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename pods 04/25/23 21:14:15.074
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:15.118
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:15.13
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Apr 25 21:14:15.162: INFO: Waiting up to 5m0s for pod "server-envvars-ce418516-9660-49d3-b224-467bf3d1d847" in namespace "pods-1539" to be "running and ready"
Apr 25 21:14:15.175: INFO: Pod "server-envvars-ce418516-9660-49d3-b224-467bf3d1d847": Phase="Pending", Reason="", readiness=false. Elapsed: 12.332109ms
Apr 25 21:14:15.175: INFO: The phase of Pod server-envvars-ce418516-9660-49d3-b224-467bf3d1d847 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 21:14:17.187: INFO: Pod "server-envvars-ce418516-9660-49d3-b224-467bf3d1d847": Phase="Running", Reason="", readiness=true. Elapsed: 2.024464183s
Apr 25 21:14:17.187: INFO: The phase of Pod server-envvars-ce418516-9660-49d3-b224-467bf3d1d847 is Running (Ready = true)
Apr 25 21:14:17.188: INFO: Pod "server-envvars-ce418516-9660-49d3-b224-467bf3d1d847" satisfied condition "running and ready"
Apr 25 21:14:17.249: INFO: Waiting up to 5m0s for pod "client-envvars-72589022-1466-44b1-bfb6-ae9e73822594" in namespace "pods-1539" to be "Succeeded or Failed"
Apr 25 21:14:17.259: INFO: Pod "client-envvars-72589022-1466-44b1-bfb6-ae9e73822594": Phase="Pending", Reason="", readiness=false. Elapsed: 10.290181ms
Apr 25 21:14:19.274: INFO: Pod "client-envvars-72589022-1466-44b1-bfb6-ae9e73822594": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025027762s
Apr 25 21:14:21.287: INFO: Pod "client-envvars-72589022-1466-44b1-bfb6-ae9e73822594": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037642835s
STEP: Saw pod success 04/25/23 21:14:21.287
Apr 25 21:14:21.287: INFO: Pod "client-envvars-72589022-1466-44b1-bfb6-ae9e73822594" satisfied condition "Succeeded or Failed"
Apr 25 21:14:21.297: INFO: Trying to get logs from node 10.10.21.190 pod client-envvars-72589022-1466-44b1-bfb6-ae9e73822594 container env3cont: <nil>
STEP: delete the pod 04/25/23 21:14:21.331
Apr 25 21:14:21.364: INFO: Waiting for pod client-envvars-72589022-1466-44b1-bfb6-ae9e73822594 to disappear
Apr 25 21:14:21.376: INFO: Pod client-envvars-72589022-1466-44b1-bfb6-ae9e73822594 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 25 21:14:21.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1539" for this suite. 04/25/23 21:14:21.397
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":356,"skipped":6633,"failed":0}
------------------------------
• [SLOW TEST] [6.345 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:14:15.072
    Apr 25 21:14:15.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename pods 04/25/23 21:14:15.074
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:15.118
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:15.13
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Apr 25 21:14:15.162: INFO: Waiting up to 5m0s for pod "server-envvars-ce418516-9660-49d3-b224-467bf3d1d847" in namespace "pods-1539" to be "running and ready"
    Apr 25 21:14:15.175: INFO: Pod "server-envvars-ce418516-9660-49d3-b224-467bf3d1d847": Phase="Pending", Reason="", readiness=false. Elapsed: 12.332109ms
    Apr 25 21:14:15.175: INFO: The phase of Pod server-envvars-ce418516-9660-49d3-b224-467bf3d1d847 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 21:14:17.187: INFO: Pod "server-envvars-ce418516-9660-49d3-b224-467bf3d1d847": Phase="Running", Reason="", readiness=true. Elapsed: 2.024464183s
    Apr 25 21:14:17.187: INFO: The phase of Pod server-envvars-ce418516-9660-49d3-b224-467bf3d1d847 is Running (Ready = true)
    Apr 25 21:14:17.188: INFO: Pod "server-envvars-ce418516-9660-49d3-b224-467bf3d1d847" satisfied condition "running and ready"
    Apr 25 21:14:17.249: INFO: Waiting up to 5m0s for pod "client-envvars-72589022-1466-44b1-bfb6-ae9e73822594" in namespace "pods-1539" to be "Succeeded or Failed"
    Apr 25 21:14:17.259: INFO: Pod "client-envvars-72589022-1466-44b1-bfb6-ae9e73822594": Phase="Pending", Reason="", readiness=false. Elapsed: 10.290181ms
    Apr 25 21:14:19.274: INFO: Pod "client-envvars-72589022-1466-44b1-bfb6-ae9e73822594": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025027762s
    Apr 25 21:14:21.287: INFO: Pod "client-envvars-72589022-1466-44b1-bfb6-ae9e73822594": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037642835s
    STEP: Saw pod success 04/25/23 21:14:21.287
    Apr 25 21:14:21.287: INFO: Pod "client-envvars-72589022-1466-44b1-bfb6-ae9e73822594" satisfied condition "Succeeded or Failed"
    Apr 25 21:14:21.297: INFO: Trying to get logs from node 10.10.21.190 pod client-envvars-72589022-1466-44b1-bfb6-ae9e73822594 container env3cont: <nil>
    STEP: delete the pod 04/25/23 21:14:21.331
    Apr 25 21:14:21.364: INFO: Waiting for pod client-envvars-72589022-1466-44b1-bfb6-ae9e73822594 to disappear
    Apr 25 21:14:21.376: INFO: Pod client-envvars-72589022-1466-44b1-bfb6-ae9e73822594 no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 25 21:14:21.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1539" for this suite. 04/25/23 21:14:21.397
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:14:21.426
Apr 25 21:14:21.426: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename svc-latency 04/25/23 21:14:21.429
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:21.474
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:21.485
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Apr 25 21:14:21.511: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2685 04/25/23 21:14:21.514
I0425 21:14:21.527880      23 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2685, replica count: 1
I0425 21:14:22.579522      23 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0425 21:14:23.580069      23 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 25 21:14:23.714: INFO: Created: latency-svc-hb4jk
Apr 25 21:14:23.723: INFO: Got endpoints: latency-svc-hb4jk [42.06242ms]
Apr 25 21:14:23.756: INFO: Created: latency-svc-b4g5k
Apr 25 21:14:23.774: INFO: Got endpoints: latency-svc-b4g5k [50.206883ms]
Apr 25 21:14:23.775: INFO: Created: latency-svc-4h2qn
Apr 25 21:14:23.795: INFO: Got endpoints: latency-svc-4h2qn [71.165187ms]
Apr 25 21:14:23.810: INFO: Created: latency-svc-ll78g
Apr 25 21:14:23.824: INFO: Got endpoints: latency-svc-ll78g [99.828429ms]
Apr 25 21:14:23.839: INFO: Created: latency-svc-ccfzq
Apr 25 21:14:23.842: INFO: Got endpoints: latency-svc-ccfzq [117.245441ms]
Apr 25 21:14:23.847: INFO: Created: latency-svc-wcltg
Apr 25 21:14:23.864: INFO: Got endpoints: latency-svc-wcltg [138.815196ms]
Apr 25 21:14:23.872: INFO: Created: latency-svc-s5fkl
Apr 25 21:14:23.881: INFO: Got endpoints: latency-svc-s5fkl [155.5255ms]
Apr 25 21:14:23.886: INFO: Created: latency-svc-79mbt
Apr 25 21:14:23.900: INFO: Got endpoints: latency-svc-79mbt [174.765443ms]
Apr 25 21:14:23.907: INFO: Created: latency-svc-b4mfk
Apr 25 21:14:23.914: INFO: Got endpoints: latency-svc-b4mfk [187.974253ms]
Apr 25 21:14:23.922: INFO: Created: latency-svc-mk98n
Apr 25 21:14:23.936: INFO: Got endpoints: latency-svc-mk98n [210.406766ms]
Apr 25 21:14:23.942: INFO: Created: latency-svc-fwgrb
Apr 25 21:14:23.959: INFO: Got endpoints: latency-svc-fwgrb [233.446683ms]
Apr 25 21:14:23.966: INFO: Created: latency-svc-xqd4t
Apr 25 21:14:23.974: INFO: Got endpoints: latency-svc-xqd4t [247.953531ms]
Apr 25 21:14:23.978: INFO: Created: latency-svc-vvv5f
Apr 25 21:14:23.995: INFO: Got endpoints: latency-svc-vvv5f [269.594178ms]
Apr 25 21:14:24.003: INFO: Created: latency-svc-6k4zj
Apr 25 21:14:24.008: INFO: Got endpoints: latency-svc-6k4zj [283.099373ms]
Apr 25 21:14:24.023: INFO: Created: latency-svc-pkmc9
Apr 25 21:14:24.033: INFO: Got endpoints: latency-svc-pkmc9 [307.017101ms]
Apr 25 21:14:24.047: INFO: Created: latency-svc-zvgrl
Apr 25 21:14:24.063: INFO: Created: latency-svc-wdbll
Apr 25 21:14:24.064: INFO: Got endpoints: latency-svc-zvgrl [338.171947ms]
Apr 25 21:14:24.072: INFO: Got endpoints: latency-svc-wdbll [63.426944ms]
Apr 25 21:14:24.081: INFO: Created: latency-svc-hbgz6
Apr 25 21:14:24.089: INFO: Got endpoints: latency-svc-hbgz6 [315.403825ms]
Apr 25 21:14:24.103: INFO: Created: latency-svc-72pjd
Apr 25 21:14:24.129: INFO: Got endpoints: latency-svc-72pjd [133.211453ms]
Apr 25 21:14:24.138: INFO: Created: latency-svc-26qgx
Apr 25 21:14:24.152: INFO: Created: latency-svc-zkkcm
Apr 25 21:14:24.155: INFO: Got endpoints: latency-svc-26qgx [359.349549ms]
Apr 25 21:14:24.162: INFO: Got endpoints: latency-svc-zkkcm [129.346957ms]
Apr 25 21:14:24.165: INFO: Created: latency-svc-5qc6q
Apr 25 21:14:24.204: INFO: Got endpoints: latency-svc-5qc6q [379.417855ms]
Apr 25 21:14:24.204: INFO: Created: latency-svc-6wj8g
Apr 25 21:14:24.222: INFO: Got endpoints: latency-svc-6wj8g [379.468955ms]
Apr 25 21:14:24.228: INFO: Created: latency-svc-qrdmb
Apr 25 21:14:24.243: INFO: Got endpoints: latency-svc-qrdmb [178.960452ms]
Apr 25 21:14:24.252: INFO: Created: latency-svc-blkll
Apr 25 21:14:24.262: INFO: Got endpoints: latency-svc-blkll [398.285456ms]
Apr 25 21:14:24.273: INFO: Created: latency-svc-rs7w8
Apr 25 21:14:24.282: INFO: Created: latency-svc-mkggr
Apr 25 21:14:24.299: INFO: Got endpoints: latency-svc-rs7w8 [226.841932ms]
Apr 25 21:14:24.301: INFO: Got endpoints: latency-svc-mkggr [419.062084ms]
Apr 25 21:14:24.310: INFO: Created: latency-svc-dbp86
Apr 25 21:14:24.322: INFO: Got endpoints: latency-svc-dbp86 [418.567017ms]
Apr 25 21:14:24.332: INFO: Created: latency-svc-7vmsm
Apr 25 21:14:24.353: INFO: Created: latency-svc-q5gbn
Apr 25 21:14:24.356: INFO: Got endpoints: latency-svc-7vmsm [266.110315ms]
Apr 25 21:14:24.358: INFO: Got endpoints: latency-svc-q5gbn [443.876087ms]
Apr 25 21:14:24.367: INFO: Created: latency-svc-x27bt
Apr 25 21:14:24.391: INFO: Got endpoints: latency-svc-x27bt [455.063986ms]
Apr 25 21:14:24.392: INFO: Created: latency-svc-wjpcr
Apr 25 21:14:24.402: INFO: Got endpoints: latency-svc-wjpcr [442.429784ms]
Apr 25 21:14:24.443: INFO: Created: latency-svc-ttqbq
Apr 25 21:14:24.450: INFO: Got endpoints: latency-svc-ttqbq [476.178656ms]
Apr 25 21:14:24.456: INFO: Created: latency-svc-hcp7p
Apr 25 21:14:24.467: INFO: Got endpoints: latency-svc-hcp7p [338.667023ms]
Apr 25 21:14:24.499: INFO: Created: latency-svc-r46w6
Apr 25 21:14:24.523: INFO: Got endpoints: latency-svc-r46w6 [368.574058ms]
Apr 25 21:14:24.530: INFO: Created: latency-svc-4hd7j
Apr 25 21:14:24.561: INFO: Got endpoints: latency-svc-4hd7j [397.97926ms]
Apr 25 21:14:24.584: INFO: Created: latency-svc-6t7h4
Apr 25 21:14:24.592: INFO: Got endpoints: latency-svc-6t7h4 [388.22933ms]
Apr 25 21:14:24.615: INFO: Created: latency-svc-4kt8c
Apr 25 21:14:24.655: INFO: Got endpoints: latency-svc-4kt8c [433.429795ms]
Apr 25 21:14:24.671: INFO: Created: latency-svc-rxr2h
Apr 25 21:14:24.693: INFO: Got endpoints: latency-svc-rxr2h [449.834911ms]
Apr 25 21:14:24.702: INFO: Created: latency-svc-h9wbw
Apr 25 21:14:24.714: INFO: Got endpoints: latency-svc-h9wbw [449.7967ms]
Apr 25 21:14:24.726: INFO: Created: latency-svc-rnhgp
Apr 25 21:14:24.736: INFO: Got endpoints: latency-svc-rnhgp [436.73385ms]
Apr 25 21:14:24.746: INFO: Created: latency-svc-j4xmp
Apr 25 21:14:24.755: INFO: Got endpoints: latency-svc-j4xmp [453.885704ms]
Apr 25 21:14:24.767: INFO: Created: latency-svc-h4v4g
Apr 25 21:14:24.799: INFO: Got endpoints: latency-svc-h4v4g [477.344991ms]
Apr 25 21:14:24.807: INFO: Created: latency-svc-x8q4c
Apr 25 21:14:24.814: INFO: Got endpoints: latency-svc-x8q4c [458.23341ms]
Apr 25 21:14:24.825: INFO: Created: latency-svc-7ql5g
Apr 25 21:14:24.837: INFO: Got endpoints: latency-svc-7ql5g [478.880708ms]
Apr 25 21:14:24.844: INFO: Created: latency-svc-4dhrs
Apr 25 21:14:24.859: INFO: Got endpoints: latency-svc-4dhrs [468.025971ms]
Apr 25 21:14:24.866: INFO: Created: latency-svc-gf9v2
Apr 25 21:14:24.879: INFO: Got endpoints: latency-svc-gf9v2 [477.499799ms]
Apr 25 21:14:24.888: INFO: Created: latency-svc-lfhss
Apr 25 21:14:24.895: INFO: Got endpoints: latency-svc-lfhss [444.887552ms]
Apr 25 21:14:24.905: INFO: Created: latency-svc-rz4k9
Apr 25 21:14:24.918: INFO: Got endpoints: latency-svc-rz4k9 [450.098282ms]
Apr 25 21:14:24.926: INFO: Created: latency-svc-srjgh
Apr 25 21:14:24.938: INFO: Got endpoints: latency-svc-srjgh [414.388763ms]
Apr 25 21:14:24.949: INFO: Created: latency-svc-vrvms
Apr 25 21:14:24.961: INFO: Got endpoints: latency-svc-vrvms [400.257918ms]
Apr 25 21:14:24.968: INFO: Created: latency-svc-b9qft
Apr 25 21:14:24.992: INFO: Got endpoints: latency-svc-b9qft [399.941647ms]
Apr 25 21:14:25.004: INFO: Created: latency-svc-qvf94
Apr 25 21:14:25.010: INFO: Got endpoints: latency-svc-qvf94 [354.315932ms]
Apr 25 21:14:25.036: INFO: Created: latency-svc-cn2kl
Apr 25 21:14:25.050: INFO: Got endpoints: latency-svc-cn2kl [356.308607ms]
Apr 25 21:14:25.060: INFO: Created: latency-svc-rm8cs
Apr 25 21:14:25.076: INFO: Got endpoints: latency-svc-rm8cs [361.678758ms]
Apr 25 21:14:25.081: INFO: Created: latency-svc-6fftj
Apr 25 21:14:25.098: INFO: Got endpoints: latency-svc-6fftj [360.246033ms]
Apr 25 21:14:25.103: INFO: Created: latency-svc-hxdj5
Apr 25 21:14:25.112: INFO: Got endpoints: latency-svc-hxdj5 [357.712915ms]
Apr 25 21:14:25.125: INFO: Created: latency-svc-52mr6
Apr 25 21:14:25.147: INFO: Got endpoints: latency-svc-52mr6 [347.847046ms]
Apr 25 21:14:25.156: INFO: Created: latency-svc-2lnv6
Apr 25 21:14:25.166: INFO: Got endpoints: latency-svc-2lnv6 [352.035193ms]
Apr 25 21:14:25.181: INFO: Created: latency-svc-kcmxl
Apr 25 21:14:25.188: INFO: Got endpoints: latency-svc-kcmxl [351.33378ms]
Apr 25 21:14:25.205: INFO: Created: latency-svc-mdj6h
Apr 25 21:14:25.217: INFO: Got endpoints: latency-svc-mdj6h [357.671074ms]
Apr 25 21:14:25.228: INFO: Created: latency-svc-c4j5m
Apr 25 21:14:25.235: INFO: Got endpoints: latency-svc-c4j5m [355.509944ms]
Apr 25 21:14:25.245: INFO: Created: latency-svc-f2p89
Apr 25 21:14:25.256: INFO: Got endpoints: latency-svc-f2p89 [360.444042ms]
Apr 25 21:14:25.266: INFO: Created: latency-svc-cmzdq
Apr 25 21:14:25.275: INFO: Got endpoints: latency-svc-cmzdq [356.734087ms]
Apr 25 21:14:25.285: INFO: Created: latency-svc-zvw5g
Apr 25 21:14:25.296: INFO: Got endpoints: latency-svc-zvw5g [357.565368ms]
Apr 25 21:14:25.304: INFO: Created: latency-svc-9nf24
Apr 25 21:14:25.325: INFO: Got endpoints: latency-svc-9nf24 [363.328038ms]
Apr 25 21:14:25.330: INFO: Created: latency-svc-dntdd
Apr 25 21:14:25.343: INFO: Got endpoints: latency-svc-dntdd [350.916759ms]
Apr 25 21:14:25.350: INFO: Created: latency-svc-ll48b
Apr 25 21:14:25.362: INFO: Got endpoints: latency-svc-ll48b [352.348893ms]
Apr 25 21:14:25.376: INFO: Created: latency-svc-7t8p4
Apr 25 21:14:25.394: INFO: Got endpoints: latency-svc-7t8p4 [341.64696ms]
Apr 25 21:14:25.400: INFO: Created: latency-svc-85sj4
Apr 25 21:14:25.418: INFO: Got endpoints: latency-svc-85sj4 [342.587633ms]
Apr 25 21:14:25.457: INFO: Created: latency-svc-qpbdm
Apr 25 21:14:25.466: INFO: Got endpoints: latency-svc-qpbdm [368.05964ms]
Apr 25 21:14:25.474: INFO: Created: latency-svc-4mptq
Apr 25 21:14:25.493: INFO: Got endpoints: latency-svc-4mptq [380.701316ms]
Apr 25 21:14:25.503: INFO: Created: latency-svc-h8wmn
Apr 25 21:14:25.513: INFO: Got endpoints: latency-svc-h8wmn [365.906974ms]
Apr 25 21:14:25.526: INFO: Created: latency-svc-76tbc
Apr 25 21:14:25.531: INFO: Got endpoints: latency-svc-76tbc [363.83602ms]
Apr 25 21:14:25.542: INFO: Created: latency-svc-tw2d7
Apr 25 21:14:25.552: INFO: Got endpoints: latency-svc-tw2d7 [363.544484ms]
Apr 25 21:14:25.560: INFO: Created: latency-svc-vcdxm
Apr 25 21:14:25.570: INFO: Got endpoints: latency-svc-vcdxm [352.663155ms]
Apr 25 21:14:25.580: INFO: Created: latency-svc-xqvbf
Apr 25 21:14:25.590: INFO: Got endpoints: latency-svc-xqvbf [353.729377ms]
Apr 25 21:14:25.600: INFO: Created: latency-svc-lb9r4
Apr 25 21:14:25.612: INFO: Got endpoints: latency-svc-lb9r4 [355.782202ms]
Apr 25 21:14:25.630: INFO: Created: latency-svc-79dx7
Apr 25 21:14:25.637: INFO: Got endpoints: latency-svc-79dx7 [362.440815ms]
Apr 25 21:14:25.645: INFO: Created: latency-svc-fsngz
Apr 25 21:14:25.672: INFO: Got endpoints: latency-svc-fsngz [374.666549ms]
Apr 25 21:14:25.689: INFO: Created: latency-svc-lpbc6
Apr 25 21:14:25.702: INFO: Got endpoints: latency-svc-lpbc6 [374.694245ms]
Apr 25 21:14:25.711: INFO: Created: latency-svc-2rtb2
Apr 25 21:14:25.728: INFO: Got endpoints: latency-svc-2rtb2 [384.090716ms]
Apr 25 21:14:25.735: INFO: Created: latency-svc-kz45z
Apr 25 21:14:25.747: INFO: Got endpoints: latency-svc-kz45z [384.633868ms]
Apr 25 21:14:25.754: INFO: Created: latency-svc-pj5pq
Apr 25 21:14:25.765: INFO: Got endpoints: latency-svc-pj5pq [368.728507ms]
Apr 25 21:14:25.786: INFO: Created: latency-svc-7s8lw
Apr 25 21:14:25.795: INFO: Got endpoints: latency-svc-7s8lw [377.141422ms]
Apr 25 21:14:25.803: INFO: Created: latency-svc-qssv5
Apr 25 21:14:25.827: INFO: Created: latency-svc-fpptd
Apr 25 21:14:25.845: INFO: Got endpoints: latency-svc-fpptd [351.716459ms]
Apr 25 21:14:25.846: INFO: Got endpoints: latency-svc-qssv5 [379.504034ms]
Apr 25 21:14:25.852: INFO: Created: latency-svc-rgn7k
Apr 25 21:14:25.865: INFO: Got endpoints: latency-svc-rgn7k [351.503769ms]
Apr 25 21:14:25.877: INFO: Created: latency-svc-n5nph
Apr 25 21:14:25.889: INFO: Got endpoints: latency-svc-n5nph [357.820702ms]
Apr 25 21:14:25.900: INFO: Created: latency-svc-vgm46
Apr 25 21:14:25.912: INFO: Got endpoints: latency-svc-vgm46 [359.036214ms]
Apr 25 21:14:25.923: INFO: Created: latency-svc-2kw9g
Apr 25 21:14:25.937: INFO: Got endpoints: latency-svc-2kw9g [366.225965ms]
Apr 25 21:14:25.948: INFO: Created: latency-svc-vl8jv
Apr 25 21:14:25.961: INFO: Got endpoints: latency-svc-vl8jv [371.141776ms]
Apr 25 21:14:25.967: INFO: Created: latency-svc-xvrmt
Apr 25 21:14:25.978: INFO: Got endpoints: latency-svc-xvrmt [365.592129ms]
Apr 25 21:14:25.992: INFO: Created: latency-svc-rfvp2
Apr 25 21:14:26.004: INFO: Got endpoints: latency-svc-rfvp2 [365.91883ms]
Apr 25 21:14:26.018: INFO: Created: latency-svc-g92bd
Apr 25 21:14:26.031: INFO: Got endpoints: latency-svc-g92bd [358.584759ms]
Apr 25 21:14:26.037: INFO: Created: latency-svc-j6fgr
Apr 25 21:14:26.047: INFO: Got endpoints: latency-svc-j6fgr [344.885321ms]
Apr 25 21:14:26.059: INFO: Created: latency-svc-ktfgk
Apr 25 21:14:26.072: INFO: Got endpoints: latency-svc-ktfgk [343.891813ms]
Apr 25 21:14:26.073: INFO: Created: latency-svc-ntx99
Apr 25 21:14:26.084: INFO: Got endpoints: latency-svc-ntx99 [336.738382ms]
Apr 25 21:14:26.097: INFO: Created: latency-svc-q5jxk
Apr 25 21:14:26.112: INFO: Got endpoints: latency-svc-q5jxk [347.308702ms]
Apr 25 21:14:26.122: INFO: Created: latency-svc-b54b5
Apr 25 21:14:26.128: INFO: Got endpoints: latency-svc-b54b5 [332.52441ms]
Apr 25 21:14:26.139: INFO: Created: latency-svc-72qjg
Apr 25 21:14:26.150: INFO: Got endpoints: latency-svc-72qjg [304.631491ms]
Apr 25 21:14:26.158: INFO: Created: latency-svc-p7gx6
Apr 25 21:14:26.174: INFO: Got endpoints: latency-svc-p7gx6 [328.474564ms]
Apr 25 21:14:26.177: INFO: Created: latency-svc-qz2hc
Apr 25 21:14:26.188: INFO: Got endpoints: latency-svc-qz2hc [322.790634ms]
Apr 25 21:14:26.199: INFO: Created: latency-svc-wx96h
Apr 25 21:14:26.215: INFO: Got endpoints: latency-svc-wx96h [325.853591ms]
Apr 25 21:14:26.220: INFO: Created: latency-svc-v5vk2
Apr 25 21:14:26.237: INFO: Got endpoints: latency-svc-v5vk2 [325.028884ms]
Apr 25 21:14:26.244: INFO: Created: latency-svc-96gj9
Apr 25 21:14:26.268: INFO: Got endpoints: latency-svc-96gj9 [330.45442ms]
Apr 25 21:14:26.274: INFO: Created: latency-svc-blkg6
Apr 25 21:14:26.285: INFO: Got endpoints: latency-svc-blkg6 [323.545311ms]
Apr 25 21:14:26.296: INFO: Created: latency-svc-wl74q
Apr 25 21:14:26.306: INFO: Got endpoints: latency-svc-wl74q [327.550852ms]
Apr 25 21:14:26.313: INFO: Created: latency-svc-htzt7
Apr 25 21:14:26.322: INFO: Got endpoints: latency-svc-htzt7 [318.657865ms]
Apr 25 21:14:26.329: INFO: Created: latency-svc-b2slf
Apr 25 21:14:26.340: INFO: Got endpoints: latency-svc-b2slf [308.907758ms]
Apr 25 21:14:26.347: INFO: Created: latency-svc-fnk85
Apr 25 21:14:26.361: INFO: Got endpoints: latency-svc-fnk85 [314.300078ms]
Apr 25 21:14:26.366: INFO: Created: latency-svc-9b69n
Apr 25 21:14:26.382: INFO: Got endpoints: latency-svc-9b69n [309.827061ms]
Apr 25 21:14:26.393: INFO: Created: latency-svc-q9dhf
Apr 25 21:14:26.413: INFO: Got endpoints: latency-svc-q9dhf [328.776232ms]
Apr 25 21:14:26.440: INFO: Created: latency-svc-6xpmf
Apr 25 21:14:26.456: INFO: Got endpoints: latency-svc-6xpmf [343.618406ms]
Apr 25 21:14:26.466: INFO: Created: latency-svc-tfh6x
Apr 25 21:14:26.504: INFO: Got endpoints: latency-svc-tfh6x [375.005808ms]
Apr 25 21:14:26.510: INFO: Created: latency-svc-75jfn
Apr 25 21:14:26.519: INFO: Got endpoints: latency-svc-75jfn [368.177904ms]
Apr 25 21:14:26.545: INFO: Created: latency-svc-rhvrp
Apr 25 21:14:26.582: INFO: Got endpoints: latency-svc-rhvrp [407.955358ms]
Apr 25 21:14:26.591: INFO: Created: latency-svc-89b2h
Apr 25 21:14:26.626: INFO: Got endpoints: latency-svc-89b2h [437.610215ms]
Apr 25 21:14:26.642: INFO: Created: latency-svc-5p9mh
Apr 25 21:14:26.656: INFO: Got endpoints: latency-svc-5p9mh [440.460028ms]
Apr 25 21:14:26.666: INFO: Created: latency-svc-z8nwv
Apr 25 21:14:26.677: INFO: Got endpoints: latency-svc-z8nwv [439.428522ms]
Apr 25 21:14:26.685: INFO: Created: latency-svc-sxsvn
Apr 25 21:14:26.698: INFO: Got endpoints: latency-svc-sxsvn [429.723549ms]
Apr 25 21:14:26.707: INFO: Created: latency-svc-bghk8
Apr 25 21:14:26.716: INFO: Got endpoints: latency-svc-bghk8 [431.062958ms]
Apr 25 21:14:26.752: INFO: Created: latency-svc-w72b4
Apr 25 21:14:26.776: INFO: Created: latency-svc-mzlf2
Apr 25 21:14:26.776: INFO: Got endpoints: latency-svc-w72b4 [470.149889ms]
Apr 25 21:14:26.808: INFO: Got endpoints: latency-svc-mzlf2 [485.145955ms]
Apr 25 21:14:26.816: INFO: Created: latency-svc-zp7rq
Apr 25 21:14:26.840: INFO: Got endpoints: latency-svc-zp7rq [499.694063ms]
Apr 25 21:14:26.851: INFO: Created: latency-svc-9xxjl
Apr 25 21:14:26.861: INFO: Got endpoints: latency-svc-9xxjl [499.329991ms]
Apr 25 21:14:26.882: INFO: Created: latency-svc-g5nxw
Apr 25 21:14:26.919: INFO: Got endpoints: latency-svc-g5nxw [536.493587ms]
Apr 25 21:14:26.927: INFO: Created: latency-svc-xrk2m
Apr 25 21:14:26.945: INFO: Got endpoints: latency-svc-xrk2m [531.643952ms]
Apr 25 21:14:26.958: INFO: Created: latency-svc-l62wl
Apr 25 21:14:26.989: INFO: Created: latency-svc-h72bn
Apr 25 21:14:26.990: INFO: Got endpoints: latency-svc-l62wl [534.160027ms]
Apr 25 21:14:27.021: INFO: Got endpoints: latency-svc-h72bn [517.421813ms]
Apr 25 21:14:27.037: INFO: Created: latency-svc-qj9dj
Apr 25 21:14:27.048: INFO: Got endpoints: latency-svc-qj9dj [528.350579ms]
Apr 25 21:14:27.059: INFO: Created: latency-svc-ppdzl
Apr 25 21:14:27.071: INFO: Got endpoints: latency-svc-ppdzl [488.575575ms]
Apr 25 21:14:27.080: INFO: Created: latency-svc-mp489
Apr 25 21:14:27.091: INFO: Got endpoints: latency-svc-mp489 [465.192433ms]
Apr 25 21:14:27.103: INFO: Created: latency-svc-p5mhq
Apr 25 21:14:27.117: INFO: Got endpoints: latency-svc-p5mhq [461.190912ms]
Apr 25 21:14:27.121: INFO: Created: latency-svc-zf9bv
Apr 25 21:14:27.131: INFO: Got endpoints: latency-svc-zf9bv [454.168782ms]
Apr 25 21:14:27.139: INFO: Created: latency-svc-jzlww
Apr 25 21:14:27.144: INFO: Got endpoints: latency-svc-jzlww [445.944683ms]
Apr 25 21:14:27.176: INFO: Created: latency-svc-mlvc2
Apr 25 21:14:27.188: INFO: Got endpoints: latency-svc-mlvc2 [472.093681ms]
Apr 25 21:14:27.199: INFO: Created: latency-svc-9zk4b
Apr 25 21:14:27.218: INFO: Got endpoints: latency-svc-9zk4b [442.189035ms]
Apr 25 21:14:27.226: INFO: Created: latency-svc-kdhvq
Apr 25 21:14:27.234: INFO: Got endpoints: latency-svc-kdhvq [425.93105ms]
Apr 25 21:14:27.253: INFO: Created: latency-svc-4plsc
Apr 25 21:14:27.261: INFO: Got endpoints: latency-svc-4plsc [420.370338ms]
Apr 25 21:14:27.265: INFO: Created: latency-svc-wj8x4
Apr 25 21:14:27.277: INFO: Got endpoints: latency-svc-wj8x4 [415.439168ms]
Apr 25 21:14:27.290: INFO: Created: latency-svc-2cz8n
Apr 25 21:14:27.294: INFO: Got endpoints: latency-svc-2cz8n [374.215331ms]
Apr 25 21:14:27.324: INFO: Created: latency-svc-zxjpd
Apr 25 21:14:27.333: INFO: Got endpoints: latency-svc-zxjpd [387.795145ms]
Apr 25 21:14:27.347: INFO: Created: latency-svc-5tgbs
Apr 25 21:14:27.368: INFO: Got endpoints: latency-svc-5tgbs [377.121267ms]
Apr 25 21:14:27.370: INFO: Created: latency-svc-v4tv2
Apr 25 21:14:27.384: INFO: Got endpoints: latency-svc-v4tv2 [362.372681ms]
Apr 25 21:14:27.394: INFO: Created: latency-svc-7jhwc
Apr 25 21:14:27.404: INFO: Got endpoints: latency-svc-7jhwc [355.888723ms]
Apr 25 21:14:27.412: INFO: Created: latency-svc-4lqs5
Apr 25 21:14:27.424: INFO: Got endpoints: latency-svc-4lqs5 [352.270583ms]
Apr 25 21:14:27.433: INFO: Created: latency-svc-fqtb9
Apr 25 21:14:27.439: INFO: Got endpoints: latency-svc-fqtb9 [347.158792ms]
Apr 25 21:14:27.453: INFO: Created: latency-svc-qngjc
Apr 25 21:14:27.468: INFO: Got endpoints: latency-svc-qngjc [350.701211ms]
Apr 25 21:14:27.476: INFO: Created: latency-svc-sl58p
Apr 25 21:14:27.483: INFO: Got endpoints: latency-svc-sl58p [351.881299ms]
Apr 25 21:14:27.494: INFO: Created: latency-svc-8m4hm
Apr 25 21:14:27.515: INFO: Got endpoints: latency-svc-8m4hm [371.173573ms]
Apr 25 21:14:27.540: INFO: Created: latency-svc-7mnxj
Apr 25 21:14:27.549: INFO: Got endpoints: latency-svc-7mnxj [360.459236ms]
Apr 25 21:14:27.558: INFO: Created: latency-svc-qbgdx
Apr 25 21:14:27.576: INFO: Got endpoints: latency-svc-qbgdx [357.374641ms]
Apr 25 21:14:27.605: INFO: Created: latency-svc-j6f87
Apr 25 21:14:27.626: INFO: Got endpoints: latency-svc-j6f87 [391.295499ms]
Apr 25 21:14:27.636: INFO: Created: latency-svc-7qsk7
Apr 25 21:14:27.654: INFO: Got endpoints: latency-svc-7qsk7 [393.467645ms]
Apr 25 21:14:27.656: INFO: Created: latency-svc-zsp8c
Apr 25 21:14:27.669: INFO: Got endpoints: latency-svc-zsp8c [392.558284ms]
Apr 25 21:14:27.687: INFO: Created: latency-svc-mmw4q
Apr 25 21:14:27.701: INFO: Got endpoints: latency-svc-mmw4q [407.074916ms]
Apr 25 21:14:27.729: INFO: Created: latency-svc-vdcmc
Apr 25 21:14:27.740: INFO: Got endpoints: latency-svc-vdcmc [403.579003ms]
Apr 25 21:14:27.754: INFO: Created: latency-svc-b6vgd
Apr 25 21:14:27.772: INFO: Got endpoints: latency-svc-b6vgd [403.74446ms]
Apr 25 21:14:27.778: INFO: Created: latency-svc-8v6m5
Apr 25 21:14:27.797: INFO: Got endpoints: latency-svc-8v6m5 [413.394639ms]
Apr 25 21:14:27.805: INFO: Created: latency-svc-92565
Apr 25 21:14:27.830: INFO: Created: latency-svc-jkn22
Apr 25 21:14:27.831: INFO: Got endpoints: latency-svc-92565 [426.250866ms]
Apr 25 21:14:27.838: INFO: Got endpoints: latency-svc-jkn22 [414.141542ms]
Apr 25 21:14:27.853: INFO: Created: latency-svc-bmtcr
Apr 25 21:14:27.884: INFO: Got endpoints: latency-svc-bmtcr [443.929213ms]
Apr 25 21:14:28.192: INFO: Created: latency-svc-8nj5g
Apr 25 21:14:28.199: INFO: Created: latency-svc-r4jm8
Apr 25 21:14:28.223: INFO: Created: latency-svc-2gtdc
Apr 25 21:14:28.223: INFO: Got endpoints: latency-svc-r4jm8 [553.999565ms]
Apr 25 21:14:28.223: INFO: Created: latency-svc-cn7g6
Apr 25 21:14:28.224: INFO: Got endpoints: latency-svc-8nj5g [647.228141ms]
Apr 25 21:14:28.224: INFO: Created: latency-svc-69r6l
Apr 25 21:14:28.224: INFO: Created: latency-svc-gxshx
Apr 25 21:14:28.224: INFO: Created: latency-svc-x76r7
Apr 25 21:14:28.224: INFO: Created: latency-svc-dg7hr
Apr 25 21:14:28.224: INFO: Created: latency-svc-g5pzt
Apr 25 21:14:28.224: INFO: Created: latency-svc-x8lj2
Apr 25 21:14:28.224: INFO: Created: latency-svc-dk2h5
Apr 25 21:14:28.225: INFO: Created: latency-svc-6scmc
Apr 25 21:14:28.225: INFO: Created: latency-svc-xcs5x
Apr 25 21:14:28.225: INFO: Created: latency-svc-5vwwr
Apr 25 21:14:28.226: INFO: Created: latency-svc-tqpvv
Apr 25 21:14:28.226: INFO: Got endpoints: latency-svc-5vwwr [742.276564ms]
Apr 25 21:14:28.228: INFO: Got endpoints: latency-svc-tqpvv [573.829573ms]
Apr 25 21:14:28.230: INFO: Got endpoints: latency-svc-gxshx [762.313365ms]
Apr 25 21:14:28.231: INFO: Got endpoints: latency-svc-dg7hr [491.027493ms]
Apr 25 21:14:28.231: INFO: Got endpoints: latency-svc-cn7g6 [433.873464ms]
Apr 25 21:14:28.234: INFO: Got endpoints: latency-svc-69r6l [532.360318ms]
Apr 25 21:14:28.244: INFO: Got endpoints: latency-svc-xcs5x [472.245995ms]
Apr 25 21:14:28.244: INFO: Got endpoints: latency-svc-6scmc [618.715269ms]
Apr 25 21:14:28.249: INFO: Got endpoints: latency-svc-2gtdc [410.468013ms]
Apr 25 21:14:28.258: INFO: Got endpoints: latency-svc-dk2h5 [743.082929ms]
Apr 25 21:14:28.259: INFO: Got endpoints: latency-svc-x8lj2 [709.243986ms]
Apr 25 21:14:28.279: INFO: Got endpoints: latency-svc-g5pzt [448.526055ms]
Apr 25 21:14:28.282: INFO: Got endpoints: latency-svc-x76r7 [397.650335ms]
Apr 25 21:14:28.284: INFO: Created: latency-svc-zdhcm
Apr 25 21:14:28.296: INFO: Got endpoints: latency-svc-zdhcm [72.782417ms]
Apr 25 21:14:28.299: INFO: Created: latency-svc-wp7r6
Apr 25 21:14:28.313: INFO: Got endpoints: latency-svc-wp7r6 [89.213114ms]
Apr 25 21:14:28.320: INFO: Created: latency-svc-qf8hx
Apr 25 21:14:28.332: INFO: Got endpoints: latency-svc-qf8hx [106.140556ms]
Apr 25 21:14:28.337: INFO: Created: latency-svc-m26mn
Apr 25 21:14:28.349: INFO: Got endpoints: latency-svc-m26mn [118.497539ms]
Apr 25 21:14:28.368: INFO: Created: latency-svc-8zrvp
Apr 25 21:14:28.380: INFO: Got endpoints: latency-svc-8zrvp [148.809208ms]
Apr 25 21:14:28.388: INFO: Created: latency-svc-4kp2w
Apr 25 21:14:28.412: INFO: Got endpoints: latency-svc-4kp2w [183.965962ms]
Apr 25 21:14:28.423: INFO: Created: latency-svc-4l5kv
Apr 25 21:14:28.434: INFO: Got endpoints: latency-svc-4l5kv [202.721895ms]
Apr 25 21:14:28.438: INFO: Created: latency-svc-vcd5w
Apr 25 21:14:28.450: INFO: Got endpoints: latency-svc-vcd5w [215.752227ms]
Apr 25 21:14:28.460: INFO: Created: latency-svc-qfjws
Apr 25 21:14:28.470: INFO: Got endpoints: latency-svc-qfjws [226.059673ms]
Apr 25 21:14:28.480: INFO: Created: latency-svc-gtp6b
Apr 25 21:14:28.493: INFO: Got endpoints: latency-svc-gtp6b [248.528347ms]
Apr 25 21:14:28.502: INFO: Created: latency-svc-fhmqv
Apr 25 21:14:28.513: INFO: Got endpoints: latency-svc-fhmqv [263.888185ms]
Apr 25 21:14:28.524: INFO: Created: latency-svc-5tt8q
Apr 25 21:14:28.539: INFO: Got endpoints: latency-svc-5tt8q [279.917824ms]
Apr 25 21:14:28.547: INFO: Created: latency-svc-8srf4
Apr 25 21:14:28.574: INFO: Created: latency-svc-tzr5f
Apr 25 21:14:28.574: INFO: Got endpoints: latency-svc-8srf4 [316.008739ms]
Apr 25 21:14:28.583: INFO: Got endpoints: latency-svc-tzr5f [303.306645ms]
Apr 25 21:14:28.595: INFO: Created: latency-svc-jl6xz
Apr 25 21:14:28.608: INFO: Got endpoints: latency-svc-jl6xz [325.50866ms]
Apr 25 21:14:28.629: INFO: Created: latency-svc-kdd72
Apr 25 21:14:28.643: INFO: Got endpoints: latency-svc-kdd72 [346.250705ms]
Apr 25 21:14:28.652: INFO: Created: latency-svc-dh6qr
Apr 25 21:14:28.672: INFO: Got endpoints: latency-svc-dh6qr [359.14794ms]
Apr 25 21:14:28.681: INFO: Created: latency-svc-sjc4r
Apr 25 21:14:28.700: INFO: Got endpoints: latency-svc-sjc4r [367.400022ms]
Apr 25 21:14:28.706: INFO: Created: latency-svc-p2ptr
Apr 25 21:14:28.717: INFO: Got endpoints: latency-svc-p2ptr [367.983812ms]
Apr 25 21:14:28.745: INFO: Created: latency-svc-bssvk
Apr 25 21:14:28.760: INFO: Got endpoints: latency-svc-bssvk [378.98143ms]
Apr 25 21:14:28.767: INFO: Created: latency-svc-9st7p
Apr 25 21:14:28.798: INFO: Got endpoints: latency-svc-9st7p [385.543906ms]
Apr 25 21:14:28.804: INFO: Created: latency-svc-k8bwx
Apr 25 21:14:28.811: INFO: Got endpoints: latency-svc-k8bwx [376.27182ms]
Apr 25 21:14:28.828: INFO: Created: latency-svc-4wstq
Apr 25 21:14:28.842: INFO: Got endpoints: latency-svc-4wstq [392.245176ms]
Apr 25 21:14:28.842: INFO: Latencies: [50.206883ms 63.426944ms 71.165187ms 72.782417ms 89.213114ms 99.828429ms 106.140556ms 117.245441ms 118.497539ms 129.346957ms 133.211453ms 138.815196ms 148.809208ms 155.5255ms 174.765443ms 178.960452ms 183.965962ms 187.974253ms 202.721895ms 210.406766ms 215.752227ms 226.059673ms 226.841932ms 233.446683ms 247.953531ms 248.528347ms 263.888185ms 266.110315ms 269.594178ms 279.917824ms 283.099373ms 303.306645ms 304.631491ms 307.017101ms 308.907758ms 309.827061ms 314.300078ms 315.403825ms 316.008739ms 318.657865ms 322.790634ms 323.545311ms 325.028884ms 325.50866ms 325.853591ms 327.550852ms 328.474564ms 328.776232ms 330.45442ms 332.52441ms 336.738382ms 338.171947ms 338.667023ms 341.64696ms 342.587633ms 343.618406ms 343.891813ms 344.885321ms 346.250705ms 347.158792ms 347.308702ms 347.847046ms 350.701211ms 350.916759ms 351.33378ms 351.503769ms 351.716459ms 351.881299ms 352.035193ms 352.270583ms 352.348893ms 352.663155ms 353.729377ms 354.315932ms 355.509944ms 355.782202ms 355.888723ms 356.308607ms 356.734087ms 357.374641ms 357.565368ms 357.671074ms 357.712915ms 357.820702ms 358.584759ms 359.036214ms 359.14794ms 359.349549ms 360.246033ms 360.444042ms 360.459236ms 361.678758ms 362.372681ms 362.440815ms 363.328038ms 363.544484ms 363.83602ms 365.592129ms 365.906974ms 365.91883ms 366.225965ms 367.400022ms 367.983812ms 368.05964ms 368.177904ms 368.574058ms 368.728507ms 371.141776ms 371.173573ms 374.215331ms 374.666549ms 374.694245ms 375.005808ms 376.27182ms 377.121267ms 377.141422ms 378.98143ms 379.417855ms 379.468955ms 379.504034ms 380.701316ms 384.090716ms 384.633868ms 385.543906ms 387.795145ms 388.22933ms 391.295499ms 392.245176ms 392.558284ms 393.467645ms 397.650335ms 397.97926ms 398.285456ms 399.941647ms 400.257918ms 403.579003ms 403.74446ms 407.074916ms 407.955358ms 410.468013ms 413.394639ms 414.141542ms 414.388763ms 415.439168ms 418.567017ms 419.062084ms 420.370338ms 425.93105ms 426.250866ms 429.723549ms 431.062958ms 433.429795ms 433.873464ms 436.73385ms 437.610215ms 439.428522ms 440.460028ms 442.189035ms 442.429784ms 443.876087ms 443.929213ms 444.887552ms 445.944683ms 448.526055ms 449.7967ms 449.834911ms 450.098282ms 453.885704ms 454.168782ms 455.063986ms 458.23341ms 461.190912ms 465.192433ms 468.025971ms 470.149889ms 472.093681ms 472.245995ms 476.178656ms 477.344991ms 477.499799ms 478.880708ms 485.145955ms 488.575575ms 491.027493ms 499.329991ms 499.694063ms 517.421813ms 528.350579ms 531.643952ms 532.360318ms 534.160027ms 536.493587ms 553.999565ms 573.829573ms 618.715269ms 647.228141ms 709.243986ms 742.276564ms 743.082929ms 762.313365ms]
Apr 25 21:14:28.842: INFO: 50 %ile: 366.225965ms
Apr 25 21:14:28.842: INFO: 90 %ile: 478.880708ms
Apr 25 21:14:28.842: INFO: 99 %ile: 743.082929ms
Apr 25 21:14:28.842: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Apr 25 21:14:28.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2685" for this suite. 04/25/23 21:14:28.863
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":357,"skipped":6638,"failed":0}
------------------------------
• [SLOW TEST] [7.462 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:14:21.426
    Apr 25 21:14:21.426: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename svc-latency 04/25/23 21:14:21.429
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:21.474
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:21.485
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Apr 25 21:14:21.511: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-2685 04/25/23 21:14:21.514
    I0425 21:14:21.527880      23 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2685, replica count: 1
    I0425 21:14:22.579522      23 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0425 21:14:23.580069      23 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 25 21:14:23.714: INFO: Created: latency-svc-hb4jk
    Apr 25 21:14:23.723: INFO: Got endpoints: latency-svc-hb4jk [42.06242ms]
    Apr 25 21:14:23.756: INFO: Created: latency-svc-b4g5k
    Apr 25 21:14:23.774: INFO: Got endpoints: latency-svc-b4g5k [50.206883ms]
    Apr 25 21:14:23.775: INFO: Created: latency-svc-4h2qn
    Apr 25 21:14:23.795: INFO: Got endpoints: latency-svc-4h2qn [71.165187ms]
    Apr 25 21:14:23.810: INFO: Created: latency-svc-ll78g
    Apr 25 21:14:23.824: INFO: Got endpoints: latency-svc-ll78g [99.828429ms]
    Apr 25 21:14:23.839: INFO: Created: latency-svc-ccfzq
    Apr 25 21:14:23.842: INFO: Got endpoints: latency-svc-ccfzq [117.245441ms]
    Apr 25 21:14:23.847: INFO: Created: latency-svc-wcltg
    Apr 25 21:14:23.864: INFO: Got endpoints: latency-svc-wcltg [138.815196ms]
    Apr 25 21:14:23.872: INFO: Created: latency-svc-s5fkl
    Apr 25 21:14:23.881: INFO: Got endpoints: latency-svc-s5fkl [155.5255ms]
    Apr 25 21:14:23.886: INFO: Created: latency-svc-79mbt
    Apr 25 21:14:23.900: INFO: Got endpoints: latency-svc-79mbt [174.765443ms]
    Apr 25 21:14:23.907: INFO: Created: latency-svc-b4mfk
    Apr 25 21:14:23.914: INFO: Got endpoints: latency-svc-b4mfk [187.974253ms]
    Apr 25 21:14:23.922: INFO: Created: latency-svc-mk98n
    Apr 25 21:14:23.936: INFO: Got endpoints: latency-svc-mk98n [210.406766ms]
    Apr 25 21:14:23.942: INFO: Created: latency-svc-fwgrb
    Apr 25 21:14:23.959: INFO: Got endpoints: latency-svc-fwgrb [233.446683ms]
    Apr 25 21:14:23.966: INFO: Created: latency-svc-xqd4t
    Apr 25 21:14:23.974: INFO: Got endpoints: latency-svc-xqd4t [247.953531ms]
    Apr 25 21:14:23.978: INFO: Created: latency-svc-vvv5f
    Apr 25 21:14:23.995: INFO: Got endpoints: latency-svc-vvv5f [269.594178ms]
    Apr 25 21:14:24.003: INFO: Created: latency-svc-6k4zj
    Apr 25 21:14:24.008: INFO: Got endpoints: latency-svc-6k4zj [283.099373ms]
    Apr 25 21:14:24.023: INFO: Created: latency-svc-pkmc9
    Apr 25 21:14:24.033: INFO: Got endpoints: latency-svc-pkmc9 [307.017101ms]
    Apr 25 21:14:24.047: INFO: Created: latency-svc-zvgrl
    Apr 25 21:14:24.063: INFO: Created: latency-svc-wdbll
    Apr 25 21:14:24.064: INFO: Got endpoints: latency-svc-zvgrl [338.171947ms]
    Apr 25 21:14:24.072: INFO: Got endpoints: latency-svc-wdbll [63.426944ms]
    Apr 25 21:14:24.081: INFO: Created: latency-svc-hbgz6
    Apr 25 21:14:24.089: INFO: Got endpoints: latency-svc-hbgz6 [315.403825ms]
    Apr 25 21:14:24.103: INFO: Created: latency-svc-72pjd
    Apr 25 21:14:24.129: INFO: Got endpoints: latency-svc-72pjd [133.211453ms]
    Apr 25 21:14:24.138: INFO: Created: latency-svc-26qgx
    Apr 25 21:14:24.152: INFO: Created: latency-svc-zkkcm
    Apr 25 21:14:24.155: INFO: Got endpoints: latency-svc-26qgx [359.349549ms]
    Apr 25 21:14:24.162: INFO: Got endpoints: latency-svc-zkkcm [129.346957ms]
    Apr 25 21:14:24.165: INFO: Created: latency-svc-5qc6q
    Apr 25 21:14:24.204: INFO: Got endpoints: latency-svc-5qc6q [379.417855ms]
    Apr 25 21:14:24.204: INFO: Created: latency-svc-6wj8g
    Apr 25 21:14:24.222: INFO: Got endpoints: latency-svc-6wj8g [379.468955ms]
    Apr 25 21:14:24.228: INFO: Created: latency-svc-qrdmb
    Apr 25 21:14:24.243: INFO: Got endpoints: latency-svc-qrdmb [178.960452ms]
    Apr 25 21:14:24.252: INFO: Created: latency-svc-blkll
    Apr 25 21:14:24.262: INFO: Got endpoints: latency-svc-blkll [398.285456ms]
    Apr 25 21:14:24.273: INFO: Created: latency-svc-rs7w8
    Apr 25 21:14:24.282: INFO: Created: latency-svc-mkggr
    Apr 25 21:14:24.299: INFO: Got endpoints: latency-svc-rs7w8 [226.841932ms]
    Apr 25 21:14:24.301: INFO: Got endpoints: latency-svc-mkggr [419.062084ms]
    Apr 25 21:14:24.310: INFO: Created: latency-svc-dbp86
    Apr 25 21:14:24.322: INFO: Got endpoints: latency-svc-dbp86 [418.567017ms]
    Apr 25 21:14:24.332: INFO: Created: latency-svc-7vmsm
    Apr 25 21:14:24.353: INFO: Created: latency-svc-q5gbn
    Apr 25 21:14:24.356: INFO: Got endpoints: latency-svc-7vmsm [266.110315ms]
    Apr 25 21:14:24.358: INFO: Got endpoints: latency-svc-q5gbn [443.876087ms]
    Apr 25 21:14:24.367: INFO: Created: latency-svc-x27bt
    Apr 25 21:14:24.391: INFO: Got endpoints: latency-svc-x27bt [455.063986ms]
    Apr 25 21:14:24.392: INFO: Created: latency-svc-wjpcr
    Apr 25 21:14:24.402: INFO: Got endpoints: latency-svc-wjpcr [442.429784ms]
    Apr 25 21:14:24.443: INFO: Created: latency-svc-ttqbq
    Apr 25 21:14:24.450: INFO: Got endpoints: latency-svc-ttqbq [476.178656ms]
    Apr 25 21:14:24.456: INFO: Created: latency-svc-hcp7p
    Apr 25 21:14:24.467: INFO: Got endpoints: latency-svc-hcp7p [338.667023ms]
    Apr 25 21:14:24.499: INFO: Created: latency-svc-r46w6
    Apr 25 21:14:24.523: INFO: Got endpoints: latency-svc-r46w6 [368.574058ms]
    Apr 25 21:14:24.530: INFO: Created: latency-svc-4hd7j
    Apr 25 21:14:24.561: INFO: Got endpoints: latency-svc-4hd7j [397.97926ms]
    Apr 25 21:14:24.584: INFO: Created: latency-svc-6t7h4
    Apr 25 21:14:24.592: INFO: Got endpoints: latency-svc-6t7h4 [388.22933ms]
    Apr 25 21:14:24.615: INFO: Created: latency-svc-4kt8c
    Apr 25 21:14:24.655: INFO: Got endpoints: latency-svc-4kt8c [433.429795ms]
    Apr 25 21:14:24.671: INFO: Created: latency-svc-rxr2h
    Apr 25 21:14:24.693: INFO: Got endpoints: latency-svc-rxr2h [449.834911ms]
    Apr 25 21:14:24.702: INFO: Created: latency-svc-h9wbw
    Apr 25 21:14:24.714: INFO: Got endpoints: latency-svc-h9wbw [449.7967ms]
    Apr 25 21:14:24.726: INFO: Created: latency-svc-rnhgp
    Apr 25 21:14:24.736: INFO: Got endpoints: latency-svc-rnhgp [436.73385ms]
    Apr 25 21:14:24.746: INFO: Created: latency-svc-j4xmp
    Apr 25 21:14:24.755: INFO: Got endpoints: latency-svc-j4xmp [453.885704ms]
    Apr 25 21:14:24.767: INFO: Created: latency-svc-h4v4g
    Apr 25 21:14:24.799: INFO: Got endpoints: latency-svc-h4v4g [477.344991ms]
    Apr 25 21:14:24.807: INFO: Created: latency-svc-x8q4c
    Apr 25 21:14:24.814: INFO: Got endpoints: latency-svc-x8q4c [458.23341ms]
    Apr 25 21:14:24.825: INFO: Created: latency-svc-7ql5g
    Apr 25 21:14:24.837: INFO: Got endpoints: latency-svc-7ql5g [478.880708ms]
    Apr 25 21:14:24.844: INFO: Created: latency-svc-4dhrs
    Apr 25 21:14:24.859: INFO: Got endpoints: latency-svc-4dhrs [468.025971ms]
    Apr 25 21:14:24.866: INFO: Created: latency-svc-gf9v2
    Apr 25 21:14:24.879: INFO: Got endpoints: latency-svc-gf9v2 [477.499799ms]
    Apr 25 21:14:24.888: INFO: Created: latency-svc-lfhss
    Apr 25 21:14:24.895: INFO: Got endpoints: latency-svc-lfhss [444.887552ms]
    Apr 25 21:14:24.905: INFO: Created: latency-svc-rz4k9
    Apr 25 21:14:24.918: INFO: Got endpoints: latency-svc-rz4k9 [450.098282ms]
    Apr 25 21:14:24.926: INFO: Created: latency-svc-srjgh
    Apr 25 21:14:24.938: INFO: Got endpoints: latency-svc-srjgh [414.388763ms]
    Apr 25 21:14:24.949: INFO: Created: latency-svc-vrvms
    Apr 25 21:14:24.961: INFO: Got endpoints: latency-svc-vrvms [400.257918ms]
    Apr 25 21:14:24.968: INFO: Created: latency-svc-b9qft
    Apr 25 21:14:24.992: INFO: Got endpoints: latency-svc-b9qft [399.941647ms]
    Apr 25 21:14:25.004: INFO: Created: latency-svc-qvf94
    Apr 25 21:14:25.010: INFO: Got endpoints: latency-svc-qvf94 [354.315932ms]
    Apr 25 21:14:25.036: INFO: Created: latency-svc-cn2kl
    Apr 25 21:14:25.050: INFO: Got endpoints: latency-svc-cn2kl [356.308607ms]
    Apr 25 21:14:25.060: INFO: Created: latency-svc-rm8cs
    Apr 25 21:14:25.076: INFO: Got endpoints: latency-svc-rm8cs [361.678758ms]
    Apr 25 21:14:25.081: INFO: Created: latency-svc-6fftj
    Apr 25 21:14:25.098: INFO: Got endpoints: latency-svc-6fftj [360.246033ms]
    Apr 25 21:14:25.103: INFO: Created: latency-svc-hxdj5
    Apr 25 21:14:25.112: INFO: Got endpoints: latency-svc-hxdj5 [357.712915ms]
    Apr 25 21:14:25.125: INFO: Created: latency-svc-52mr6
    Apr 25 21:14:25.147: INFO: Got endpoints: latency-svc-52mr6 [347.847046ms]
    Apr 25 21:14:25.156: INFO: Created: latency-svc-2lnv6
    Apr 25 21:14:25.166: INFO: Got endpoints: latency-svc-2lnv6 [352.035193ms]
    Apr 25 21:14:25.181: INFO: Created: latency-svc-kcmxl
    Apr 25 21:14:25.188: INFO: Got endpoints: latency-svc-kcmxl [351.33378ms]
    Apr 25 21:14:25.205: INFO: Created: latency-svc-mdj6h
    Apr 25 21:14:25.217: INFO: Got endpoints: latency-svc-mdj6h [357.671074ms]
    Apr 25 21:14:25.228: INFO: Created: latency-svc-c4j5m
    Apr 25 21:14:25.235: INFO: Got endpoints: latency-svc-c4j5m [355.509944ms]
    Apr 25 21:14:25.245: INFO: Created: latency-svc-f2p89
    Apr 25 21:14:25.256: INFO: Got endpoints: latency-svc-f2p89 [360.444042ms]
    Apr 25 21:14:25.266: INFO: Created: latency-svc-cmzdq
    Apr 25 21:14:25.275: INFO: Got endpoints: latency-svc-cmzdq [356.734087ms]
    Apr 25 21:14:25.285: INFO: Created: latency-svc-zvw5g
    Apr 25 21:14:25.296: INFO: Got endpoints: latency-svc-zvw5g [357.565368ms]
    Apr 25 21:14:25.304: INFO: Created: latency-svc-9nf24
    Apr 25 21:14:25.325: INFO: Got endpoints: latency-svc-9nf24 [363.328038ms]
    Apr 25 21:14:25.330: INFO: Created: latency-svc-dntdd
    Apr 25 21:14:25.343: INFO: Got endpoints: latency-svc-dntdd [350.916759ms]
    Apr 25 21:14:25.350: INFO: Created: latency-svc-ll48b
    Apr 25 21:14:25.362: INFO: Got endpoints: latency-svc-ll48b [352.348893ms]
    Apr 25 21:14:25.376: INFO: Created: latency-svc-7t8p4
    Apr 25 21:14:25.394: INFO: Got endpoints: latency-svc-7t8p4 [341.64696ms]
    Apr 25 21:14:25.400: INFO: Created: latency-svc-85sj4
    Apr 25 21:14:25.418: INFO: Got endpoints: latency-svc-85sj4 [342.587633ms]
    Apr 25 21:14:25.457: INFO: Created: latency-svc-qpbdm
    Apr 25 21:14:25.466: INFO: Got endpoints: latency-svc-qpbdm [368.05964ms]
    Apr 25 21:14:25.474: INFO: Created: latency-svc-4mptq
    Apr 25 21:14:25.493: INFO: Got endpoints: latency-svc-4mptq [380.701316ms]
    Apr 25 21:14:25.503: INFO: Created: latency-svc-h8wmn
    Apr 25 21:14:25.513: INFO: Got endpoints: latency-svc-h8wmn [365.906974ms]
    Apr 25 21:14:25.526: INFO: Created: latency-svc-76tbc
    Apr 25 21:14:25.531: INFO: Got endpoints: latency-svc-76tbc [363.83602ms]
    Apr 25 21:14:25.542: INFO: Created: latency-svc-tw2d7
    Apr 25 21:14:25.552: INFO: Got endpoints: latency-svc-tw2d7 [363.544484ms]
    Apr 25 21:14:25.560: INFO: Created: latency-svc-vcdxm
    Apr 25 21:14:25.570: INFO: Got endpoints: latency-svc-vcdxm [352.663155ms]
    Apr 25 21:14:25.580: INFO: Created: latency-svc-xqvbf
    Apr 25 21:14:25.590: INFO: Got endpoints: latency-svc-xqvbf [353.729377ms]
    Apr 25 21:14:25.600: INFO: Created: latency-svc-lb9r4
    Apr 25 21:14:25.612: INFO: Got endpoints: latency-svc-lb9r4 [355.782202ms]
    Apr 25 21:14:25.630: INFO: Created: latency-svc-79dx7
    Apr 25 21:14:25.637: INFO: Got endpoints: latency-svc-79dx7 [362.440815ms]
    Apr 25 21:14:25.645: INFO: Created: latency-svc-fsngz
    Apr 25 21:14:25.672: INFO: Got endpoints: latency-svc-fsngz [374.666549ms]
    Apr 25 21:14:25.689: INFO: Created: latency-svc-lpbc6
    Apr 25 21:14:25.702: INFO: Got endpoints: latency-svc-lpbc6 [374.694245ms]
    Apr 25 21:14:25.711: INFO: Created: latency-svc-2rtb2
    Apr 25 21:14:25.728: INFO: Got endpoints: latency-svc-2rtb2 [384.090716ms]
    Apr 25 21:14:25.735: INFO: Created: latency-svc-kz45z
    Apr 25 21:14:25.747: INFO: Got endpoints: latency-svc-kz45z [384.633868ms]
    Apr 25 21:14:25.754: INFO: Created: latency-svc-pj5pq
    Apr 25 21:14:25.765: INFO: Got endpoints: latency-svc-pj5pq [368.728507ms]
    Apr 25 21:14:25.786: INFO: Created: latency-svc-7s8lw
    Apr 25 21:14:25.795: INFO: Got endpoints: latency-svc-7s8lw [377.141422ms]
    Apr 25 21:14:25.803: INFO: Created: latency-svc-qssv5
    Apr 25 21:14:25.827: INFO: Created: latency-svc-fpptd
    Apr 25 21:14:25.845: INFO: Got endpoints: latency-svc-fpptd [351.716459ms]
    Apr 25 21:14:25.846: INFO: Got endpoints: latency-svc-qssv5 [379.504034ms]
    Apr 25 21:14:25.852: INFO: Created: latency-svc-rgn7k
    Apr 25 21:14:25.865: INFO: Got endpoints: latency-svc-rgn7k [351.503769ms]
    Apr 25 21:14:25.877: INFO: Created: latency-svc-n5nph
    Apr 25 21:14:25.889: INFO: Got endpoints: latency-svc-n5nph [357.820702ms]
    Apr 25 21:14:25.900: INFO: Created: latency-svc-vgm46
    Apr 25 21:14:25.912: INFO: Got endpoints: latency-svc-vgm46 [359.036214ms]
    Apr 25 21:14:25.923: INFO: Created: latency-svc-2kw9g
    Apr 25 21:14:25.937: INFO: Got endpoints: latency-svc-2kw9g [366.225965ms]
    Apr 25 21:14:25.948: INFO: Created: latency-svc-vl8jv
    Apr 25 21:14:25.961: INFO: Got endpoints: latency-svc-vl8jv [371.141776ms]
    Apr 25 21:14:25.967: INFO: Created: latency-svc-xvrmt
    Apr 25 21:14:25.978: INFO: Got endpoints: latency-svc-xvrmt [365.592129ms]
    Apr 25 21:14:25.992: INFO: Created: latency-svc-rfvp2
    Apr 25 21:14:26.004: INFO: Got endpoints: latency-svc-rfvp2 [365.91883ms]
    Apr 25 21:14:26.018: INFO: Created: latency-svc-g92bd
    Apr 25 21:14:26.031: INFO: Got endpoints: latency-svc-g92bd [358.584759ms]
    Apr 25 21:14:26.037: INFO: Created: latency-svc-j6fgr
    Apr 25 21:14:26.047: INFO: Got endpoints: latency-svc-j6fgr [344.885321ms]
    Apr 25 21:14:26.059: INFO: Created: latency-svc-ktfgk
    Apr 25 21:14:26.072: INFO: Got endpoints: latency-svc-ktfgk [343.891813ms]
    Apr 25 21:14:26.073: INFO: Created: latency-svc-ntx99
    Apr 25 21:14:26.084: INFO: Got endpoints: latency-svc-ntx99 [336.738382ms]
    Apr 25 21:14:26.097: INFO: Created: latency-svc-q5jxk
    Apr 25 21:14:26.112: INFO: Got endpoints: latency-svc-q5jxk [347.308702ms]
    Apr 25 21:14:26.122: INFO: Created: latency-svc-b54b5
    Apr 25 21:14:26.128: INFO: Got endpoints: latency-svc-b54b5 [332.52441ms]
    Apr 25 21:14:26.139: INFO: Created: latency-svc-72qjg
    Apr 25 21:14:26.150: INFO: Got endpoints: latency-svc-72qjg [304.631491ms]
    Apr 25 21:14:26.158: INFO: Created: latency-svc-p7gx6
    Apr 25 21:14:26.174: INFO: Got endpoints: latency-svc-p7gx6 [328.474564ms]
    Apr 25 21:14:26.177: INFO: Created: latency-svc-qz2hc
    Apr 25 21:14:26.188: INFO: Got endpoints: latency-svc-qz2hc [322.790634ms]
    Apr 25 21:14:26.199: INFO: Created: latency-svc-wx96h
    Apr 25 21:14:26.215: INFO: Got endpoints: latency-svc-wx96h [325.853591ms]
    Apr 25 21:14:26.220: INFO: Created: latency-svc-v5vk2
    Apr 25 21:14:26.237: INFO: Got endpoints: latency-svc-v5vk2 [325.028884ms]
    Apr 25 21:14:26.244: INFO: Created: latency-svc-96gj9
    Apr 25 21:14:26.268: INFO: Got endpoints: latency-svc-96gj9 [330.45442ms]
    Apr 25 21:14:26.274: INFO: Created: latency-svc-blkg6
    Apr 25 21:14:26.285: INFO: Got endpoints: latency-svc-blkg6 [323.545311ms]
    Apr 25 21:14:26.296: INFO: Created: latency-svc-wl74q
    Apr 25 21:14:26.306: INFO: Got endpoints: latency-svc-wl74q [327.550852ms]
    Apr 25 21:14:26.313: INFO: Created: latency-svc-htzt7
    Apr 25 21:14:26.322: INFO: Got endpoints: latency-svc-htzt7 [318.657865ms]
    Apr 25 21:14:26.329: INFO: Created: latency-svc-b2slf
    Apr 25 21:14:26.340: INFO: Got endpoints: latency-svc-b2slf [308.907758ms]
    Apr 25 21:14:26.347: INFO: Created: latency-svc-fnk85
    Apr 25 21:14:26.361: INFO: Got endpoints: latency-svc-fnk85 [314.300078ms]
    Apr 25 21:14:26.366: INFO: Created: latency-svc-9b69n
    Apr 25 21:14:26.382: INFO: Got endpoints: latency-svc-9b69n [309.827061ms]
    Apr 25 21:14:26.393: INFO: Created: latency-svc-q9dhf
    Apr 25 21:14:26.413: INFO: Got endpoints: latency-svc-q9dhf [328.776232ms]
    Apr 25 21:14:26.440: INFO: Created: latency-svc-6xpmf
    Apr 25 21:14:26.456: INFO: Got endpoints: latency-svc-6xpmf [343.618406ms]
    Apr 25 21:14:26.466: INFO: Created: latency-svc-tfh6x
    Apr 25 21:14:26.504: INFO: Got endpoints: latency-svc-tfh6x [375.005808ms]
    Apr 25 21:14:26.510: INFO: Created: latency-svc-75jfn
    Apr 25 21:14:26.519: INFO: Got endpoints: latency-svc-75jfn [368.177904ms]
    Apr 25 21:14:26.545: INFO: Created: latency-svc-rhvrp
    Apr 25 21:14:26.582: INFO: Got endpoints: latency-svc-rhvrp [407.955358ms]
    Apr 25 21:14:26.591: INFO: Created: latency-svc-89b2h
    Apr 25 21:14:26.626: INFO: Got endpoints: latency-svc-89b2h [437.610215ms]
    Apr 25 21:14:26.642: INFO: Created: latency-svc-5p9mh
    Apr 25 21:14:26.656: INFO: Got endpoints: latency-svc-5p9mh [440.460028ms]
    Apr 25 21:14:26.666: INFO: Created: latency-svc-z8nwv
    Apr 25 21:14:26.677: INFO: Got endpoints: latency-svc-z8nwv [439.428522ms]
    Apr 25 21:14:26.685: INFO: Created: latency-svc-sxsvn
    Apr 25 21:14:26.698: INFO: Got endpoints: latency-svc-sxsvn [429.723549ms]
    Apr 25 21:14:26.707: INFO: Created: latency-svc-bghk8
    Apr 25 21:14:26.716: INFO: Got endpoints: latency-svc-bghk8 [431.062958ms]
    Apr 25 21:14:26.752: INFO: Created: latency-svc-w72b4
    Apr 25 21:14:26.776: INFO: Created: latency-svc-mzlf2
    Apr 25 21:14:26.776: INFO: Got endpoints: latency-svc-w72b4 [470.149889ms]
    Apr 25 21:14:26.808: INFO: Got endpoints: latency-svc-mzlf2 [485.145955ms]
    Apr 25 21:14:26.816: INFO: Created: latency-svc-zp7rq
    Apr 25 21:14:26.840: INFO: Got endpoints: latency-svc-zp7rq [499.694063ms]
    Apr 25 21:14:26.851: INFO: Created: latency-svc-9xxjl
    Apr 25 21:14:26.861: INFO: Got endpoints: latency-svc-9xxjl [499.329991ms]
    Apr 25 21:14:26.882: INFO: Created: latency-svc-g5nxw
    Apr 25 21:14:26.919: INFO: Got endpoints: latency-svc-g5nxw [536.493587ms]
    Apr 25 21:14:26.927: INFO: Created: latency-svc-xrk2m
    Apr 25 21:14:26.945: INFO: Got endpoints: latency-svc-xrk2m [531.643952ms]
    Apr 25 21:14:26.958: INFO: Created: latency-svc-l62wl
    Apr 25 21:14:26.989: INFO: Created: latency-svc-h72bn
    Apr 25 21:14:26.990: INFO: Got endpoints: latency-svc-l62wl [534.160027ms]
    Apr 25 21:14:27.021: INFO: Got endpoints: latency-svc-h72bn [517.421813ms]
    Apr 25 21:14:27.037: INFO: Created: latency-svc-qj9dj
    Apr 25 21:14:27.048: INFO: Got endpoints: latency-svc-qj9dj [528.350579ms]
    Apr 25 21:14:27.059: INFO: Created: latency-svc-ppdzl
    Apr 25 21:14:27.071: INFO: Got endpoints: latency-svc-ppdzl [488.575575ms]
    Apr 25 21:14:27.080: INFO: Created: latency-svc-mp489
    Apr 25 21:14:27.091: INFO: Got endpoints: latency-svc-mp489 [465.192433ms]
    Apr 25 21:14:27.103: INFO: Created: latency-svc-p5mhq
    Apr 25 21:14:27.117: INFO: Got endpoints: latency-svc-p5mhq [461.190912ms]
    Apr 25 21:14:27.121: INFO: Created: latency-svc-zf9bv
    Apr 25 21:14:27.131: INFO: Got endpoints: latency-svc-zf9bv [454.168782ms]
    Apr 25 21:14:27.139: INFO: Created: latency-svc-jzlww
    Apr 25 21:14:27.144: INFO: Got endpoints: latency-svc-jzlww [445.944683ms]
    Apr 25 21:14:27.176: INFO: Created: latency-svc-mlvc2
    Apr 25 21:14:27.188: INFO: Got endpoints: latency-svc-mlvc2 [472.093681ms]
    Apr 25 21:14:27.199: INFO: Created: latency-svc-9zk4b
    Apr 25 21:14:27.218: INFO: Got endpoints: latency-svc-9zk4b [442.189035ms]
    Apr 25 21:14:27.226: INFO: Created: latency-svc-kdhvq
    Apr 25 21:14:27.234: INFO: Got endpoints: latency-svc-kdhvq [425.93105ms]
    Apr 25 21:14:27.253: INFO: Created: latency-svc-4plsc
    Apr 25 21:14:27.261: INFO: Got endpoints: latency-svc-4plsc [420.370338ms]
    Apr 25 21:14:27.265: INFO: Created: latency-svc-wj8x4
    Apr 25 21:14:27.277: INFO: Got endpoints: latency-svc-wj8x4 [415.439168ms]
    Apr 25 21:14:27.290: INFO: Created: latency-svc-2cz8n
    Apr 25 21:14:27.294: INFO: Got endpoints: latency-svc-2cz8n [374.215331ms]
    Apr 25 21:14:27.324: INFO: Created: latency-svc-zxjpd
    Apr 25 21:14:27.333: INFO: Got endpoints: latency-svc-zxjpd [387.795145ms]
    Apr 25 21:14:27.347: INFO: Created: latency-svc-5tgbs
    Apr 25 21:14:27.368: INFO: Got endpoints: latency-svc-5tgbs [377.121267ms]
    Apr 25 21:14:27.370: INFO: Created: latency-svc-v4tv2
    Apr 25 21:14:27.384: INFO: Got endpoints: latency-svc-v4tv2 [362.372681ms]
    Apr 25 21:14:27.394: INFO: Created: latency-svc-7jhwc
    Apr 25 21:14:27.404: INFO: Got endpoints: latency-svc-7jhwc [355.888723ms]
    Apr 25 21:14:27.412: INFO: Created: latency-svc-4lqs5
    Apr 25 21:14:27.424: INFO: Got endpoints: latency-svc-4lqs5 [352.270583ms]
    Apr 25 21:14:27.433: INFO: Created: latency-svc-fqtb9
    Apr 25 21:14:27.439: INFO: Got endpoints: latency-svc-fqtb9 [347.158792ms]
    Apr 25 21:14:27.453: INFO: Created: latency-svc-qngjc
    Apr 25 21:14:27.468: INFO: Got endpoints: latency-svc-qngjc [350.701211ms]
    Apr 25 21:14:27.476: INFO: Created: latency-svc-sl58p
    Apr 25 21:14:27.483: INFO: Got endpoints: latency-svc-sl58p [351.881299ms]
    Apr 25 21:14:27.494: INFO: Created: latency-svc-8m4hm
    Apr 25 21:14:27.515: INFO: Got endpoints: latency-svc-8m4hm [371.173573ms]
    Apr 25 21:14:27.540: INFO: Created: latency-svc-7mnxj
    Apr 25 21:14:27.549: INFO: Got endpoints: latency-svc-7mnxj [360.459236ms]
    Apr 25 21:14:27.558: INFO: Created: latency-svc-qbgdx
    Apr 25 21:14:27.576: INFO: Got endpoints: latency-svc-qbgdx [357.374641ms]
    Apr 25 21:14:27.605: INFO: Created: latency-svc-j6f87
    Apr 25 21:14:27.626: INFO: Got endpoints: latency-svc-j6f87 [391.295499ms]
    Apr 25 21:14:27.636: INFO: Created: latency-svc-7qsk7
    Apr 25 21:14:27.654: INFO: Got endpoints: latency-svc-7qsk7 [393.467645ms]
    Apr 25 21:14:27.656: INFO: Created: latency-svc-zsp8c
    Apr 25 21:14:27.669: INFO: Got endpoints: latency-svc-zsp8c [392.558284ms]
    Apr 25 21:14:27.687: INFO: Created: latency-svc-mmw4q
    Apr 25 21:14:27.701: INFO: Got endpoints: latency-svc-mmw4q [407.074916ms]
    Apr 25 21:14:27.729: INFO: Created: latency-svc-vdcmc
    Apr 25 21:14:27.740: INFO: Got endpoints: latency-svc-vdcmc [403.579003ms]
    Apr 25 21:14:27.754: INFO: Created: latency-svc-b6vgd
    Apr 25 21:14:27.772: INFO: Got endpoints: latency-svc-b6vgd [403.74446ms]
    Apr 25 21:14:27.778: INFO: Created: latency-svc-8v6m5
    Apr 25 21:14:27.797: INFO: Got endpoints: latency-svc-8v6m5 [413.394639ms]
    Apr 25 21:14:27.805: INFO: Created: latency-svc-92565
    Apr 25 21:14:27.830: INFO: Created: latency-svc-jkn22
    Apr 25 21:14:27.831: INFO: Got endpoints: latency-svc-92565 [426.250866ms]
    Apr 25 21:14:27.838: INFO: Got endpoints: latency-svc-jkn22 [414.141542ms]
    Apr 25 21:14:27.853: INFO: Created: latency-svc-bmtcr
    Apr 25 21:14:27.884: INFO: Got endpoints: latency-svc-bmtcr [443.929213ms]
    Apr 25 21:14:28.192: INFO: Created: latency-svc-8nj5g
    Apr 25 21:14:28.199: INFO: Created: latency-svc-r4jm8
    Apr 25 21:14:28.223: INFO: Created: latency-svc-2gtdc
    Apr 25 21:14:28.223: INFO: Got endpoints: latency-svc-r4jm8 [553.999565ms]
    Apr 25 21:14:28.223: INFO: Created: latency-svc-cn7g6
    Apr 25 21:14:28.224: INFO: Got endpoints: latency-svc-8nj5g [647.228141ms]
    Apr 25 21:14:28.224: INFO: Created: latency-svc-69r6l
    Apr 25 21:14:28.224: INFO: Created: latency-svc-gxshx
    Apr 25 21:14:28.224: INFO: Created: latency-svc-x76r7
    Apr 25 21:14:28.224: INFO: Created: latency-svc-dg7hr
    Apr 25 21:14:28.224: INFO: Created: latency-svc-g5pzt
    Apr 25 21:14:28.224: INFO: Created: latency-svc-x8lj2
    Apr 25 21:14:28.224: INFO: Created: latency-svc-dk2h5
    Apr 25 21:14:28.225: INFO: Created: latency-svc-6scmc
    Apr 25 21:14:28.225: INFO: Created: latency-svc-xcs5x
    Apr 25 21:14:28.225: INFO: Created: latency-svc-5vwwr
    Apr 25 21:14:28.226: INFO: Created: latency-svc-tqpvv
    Apr 25 21:14:28.226: INFO: Got endpoints: latency-svc-5vwwr [742.276564ms]
    Apr 25 21:14:28.228: INFO: Got endpoints: latency-svc-tqpvv [573.829573ms]
    Apr 25 21:14:28.230: INFO: Got endpoints: latency-svc-gxshx [762.313365ms]
    Apr 25 21:14:28.231: INFO: Got endpoints: latency-svc-dg7hr [491.027493ms]
    Apr 25 21:14:28.231: INFO: Got endpoints: latency-svc-cn7g6 [433.873464ms]
    Apr 25 21:14:28.234: INFO: Got endpoints: latency-svc-69r6l [532.360318ms]
    Apr 25 21:14:28.244: INFO: Got endpoints: latency-svc-xcs5x [472.245995ms]
    Apr 25 21:14:28.244: INFO: Got endpoints: latency-svc-6scmc [618.715269ms]
    Apr 25 21:14:28.249: INFO: Got endpoints: latency-svc-2gtdc [410.468013ms]
    Apr 25 21:14:28.258: INFO: Got endpoints: latency-svc-dk2h5 [743.082929ms]
    Apr 25 21:14:28.259: INFO: Got endpoints: latency-svc-x8lj2 [709.243986ms]
    Apr 25 21:14:28.279: INFO: Got endpoints: latency-svc-g5pzt [448.526055ms]
    Apr 25 21:14:28.282: INFO: Got endpoints: latency-svc-x76r7 [397.650335ms]
    Apr 25 21:14:28.284: INFO: Created: latency-svc-zdhcm
    Apr 25 21:14:28.296: INFO: Got endpoints: latency-svc-zdhcm [72.782417ms]
    Apr 25 21:14:28.299: INFO: Created: latency-svc-wp7r6
    Apr 25 21:14:28.313: INFO: Got endpoints: latency-svc-wp7r6 [89.213114ms]
    Apr 25 21:14:28.320: INFO: Created: latency-svc-qf8hx
    Apr 25 21:14:28.332: INFO: Got endpoints: latency-svc-qf8hx [106.140556ms]
    Apr 25 21:14:28.337: INFO: Created: latency-svc-m26mn
    Apr 25 21:14:28.349: INFO: Got endpoints: latency-svc-m26mn [118.497539ms]
    Apr 25 21:14:28.368: INFO: Created: latency-svc-8zrvp
    Apr 25 21:14:28.380: INFO: Got endpoints: latency-svc-8zrvp [148.809208ms]
    Apr 25 21:14:28.388: INFO: Created: latency-svc-4kp2w
    Apr 25 21:14:28.412: INFO: Got endpoints: latency-svc-4kp2w [183.965962ms]
    Apr 25 21:14:28.423: INFO: Created: latency-svc-4l5kv
    Apr 25 21:14:28.434: INFO: Got endpoints: latency-svc-4l5kv [202.721895ms]
    Apr 25 21:14:28.438: INFO: Created: latency-svc-vcd5w
    Apr 25 21:14:28.450: INFO: Got endpoints: latency-svc-vcd5w [215.752227ms]
    Apr 25 21:14:28.460: INFO: Created: latency-svc-qfjws
    Apr 25 21:14:28.470: INFO: Got endpoints: latency-svc-qfjws [226.059673ms]
    Apr 25 21:14:28.480: INFO: Created: latency-svc-gtp6b
    Apr 25 21:14:28.493: INFO: Got endpoints: latency-svc-gtp6b [248.528347ms]
    Apr 25 21:14:28.502: INFO: Created: latency-svc-fhmqv
    Apr 25 21:14:28.513: INFO: Got endpoints: latency-svc-fhmqv [263.888185ms]
    Apr 25 21:14:28.524: INFO: Created: latency-svc-5tt8q
    Apr 25 21:14:28.539: INFO: Got endpoints: latency-svc-5tt8q [279.917824ms]
    Apr 25 21:14:28.547: INFO: Created: latency-svc-8srf4
    Apr 25 21:14:28.574: INFO: Created: latency-svc-tzr5f
    Apr 25 21:14:28.574: INFO: Got endpoints: latency-svc-8srf4 [316.008739ms]
    Apr 25 21:14:28.583: INFO: Got endpoints: latency-svc-tzr5f [303.306645ms]
    Apr 25 21:14:28.595: INFO: Created: latency-svc-jl6xz
    Apr 25 21:14:28.608: INFO: Got endpoints: latency-svc-jl6xz [325.50866ms]
    Apr 25 21:14:28.629: INFO: Created: latency-svc-kdd72
    Apr 25 21:14:28.643: INFO: Got endpoints: latency-svc-kdd72 [346.250705ms]
    Apr 25 21:14:28.652: INFO: Created: latency-svc-dh6qr
    Apr 25 21:14:28.672: INFO: Got endpoints: latency-svc-dh6qr [359.14794ms]
    Apr 25 21:14:28.681: INFO: Created: latency-svc-sjc4r
    Apr 25 21:14:28.700: INFO: Got endpoints: latency-svc-sjc4r [367.400022ms]
    Apr 25 21:14:28.706: INFO: Created: latency-svc-p2ptr
    Apr 25 21:14:28.717: INFO: Got endpoints: latency-svc-p2ptr [367.983812ms]
    Apr 25 21:14:28.745: INFO: Created: latency-svc-bssvk
    Apr 25 21:14:28.760: INFO: Got endpoints: latency-svc-bssvk [378.98143ms]
    Apr 25 21:14:28.767: INFO: Created: latency-svc-9st7p
    Apr 25 21:14:28.798: INFO: Got endpoints: latency-svc-9st7p [385.543906ms]
    Apr 25 21:14:28.804: INFO: Created: latency-svc-k8bwx
    Apr 25 21:14:28.811: INFO: Got endpoints: latency-svc-k8bwx [376.27182ms]
    Apr 25 21:14:28.828: INFO: Created: latency-svc-4wstq
    Apr 25 21:14:28.842: INFO: Got endpoints: latency-svc-4wstq [392.245176ms]
    Apr 25 21:14:28.842: INFO: Latencies: [50.206883ms 63.426944ms 71.165187ms 72.782417ms 89.213114ms 99.828429ms 106.140556ms 117.245441ms 118.497539ms 129.346957ms 133.211453ms 138.815196ms 148.809208ms 155.5255ms 174.765443ms 178.960452ms 183.965962ms 187.974253ms 202.721895ms 210.406766ms 215.752227ms 226.059673ms 226.841932ms 233.446683ms 247.953531ms 248.528347ms 263.888185ms 266.110315ms 269.594178ms 279.917824ms 283.099373ms 303.306645ms 304.631491ms 307.017101ms 308.907758ms 309.827061ms 314.300078ms 315.403825ms 316.008739ms 318.657865ms 322.790634ms 323.545311ms 325.028884ms 325.50866ms 325.853591ms 327.550852ms 328.474564ms 328.776232ms 330.45442ms 332.52441ms 336.738382ms 338.171947ms 338.667023ms 341.64696ms 342.587633ms 343.618406ms 343.891813ms 344.885321ms 346.250705ms 347.158792ms 347.308702ms 347.847046ms 350.701211ms 350.916759ms 351.33378ms 351.503769ms 351.716459ms 351.881299ms 352.035193ms 352.270583ms 352.348893ms 352.663155ms 353.729377ms 354.315932ms 355.509944ms 355.782202ms 355.888723ms 356.308607ms 356.734087ms 357.374641ms 357.565368ms 357.671074ms 357.712915ms 357.820702ms 358.584759ms 359.036214ms 359.14794ms 359.349549ms 360.246033ms 360.444042ms 360.459236ms 361.678758ms 362.372681ms 362.440815ms 363.328038ms 363.544484ms 363.83602ms 365.592129ms 365.906974ms 365.91883ms 366.225965ms 367.400022ms 367.983812ms 368.05964ms 368.177904ms 368.574058ms 368.728507ms 371.141776ms 371.173573ms 374.215331ms 374.666549ms 374.694245ms 375.005808ms 376.27182ms 377.121267ms 377.141422ms 378.98143ms 379.417855ms 379.468955ms 379.504034ms 380.701316ms 384.090716ms 384.633868ms 385.543906ms 387.795145ms 388.22933ms 391.295499ms 392.245176ms 392.558284ms 393.467645ms 397.650335ms 397.97926ms 398.285456ms 399.941647ms 400.257918ms 403.579003ms 403.74446ms 407.074916ms 407.955358ms 410.468013ms 413.394639ms 414.141542ms 414.388763ms 415.439168ms 418.567017ms 419.062084ms 420.370338ms 425.93105ms 426.250866ms 429.723549ms 431.062958ms 433.429795ms 433.873464ms 436.73385ms 437.610215ms 439.428522ms 440.460028ms 442.189035ms 442.429784ms 443.876087ms 443.929213ms 444.887552ms 445.944683ms 448.526055ms 449.7967ms 449.834911ms 450.098282ms 453.885704ms 454.168782ms 455.063986ms 458.23341ms 461.190912ms 465.192433ms 468.025971ms 470.149889ms 472.093681ms 472.245995ms 476.178656ms 477.344991ms 477.499799ms 478.880708ms 485.145955ms 488.575575ms 491.027493ms 499.329991ms 499.694063ms 517.421813ms 528.350579ms 531.643952ms 532.360318ms 534.160027ms 536.493587ms 553.999565ms 573.829573ms 618.715269ms 647.228141ms 709.243986ms 742.276564ms 743.082929ms 762.313365ms]
    Apr 25 21:14:28.842: INFO: 50 %ile: 366.225965ms
    Apr 25 21:14:28.842: INFO: 90 %ile: 478.880708ms
    Apr 25 21:14:28.842: INFO: 99 %ile: 743.082929ms
    Apr 25 21:14:28.842: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Apr 25 21:14:28.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-2685" for this suite. 04/25/23 21:14:28.863
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:14:28.89
Apr 25 21:14:28.891: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename replication-controller 04/25/23 21:14:28.895
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:28.937
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:28.95
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6 04/25/23 21:14:28.963
Apr 25 21:14:28.992: INFO: Pod name my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6: Found 0 pods out of 1
Apr 25 21:14:34.015: INFO: Pod name my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6: Found 1 pods out of 1
Apr 25 21:14:34.016: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6" are running
Apr 25 21:14:34.016: INFO: Waiting up to 5m0s for pod "my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6-57ps2" in namespace "replication-controller-9544" to be "running"
Apr 25 21:14:34.031: INFO: Pod "my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6-57ps2": Phase="Running", Reason="", readiness=true. Elapsed: 14.940304ms
Apr 25 21:14:34.032: INFO: Pod "my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6-57ps2" satisfied condition "running"
Apr 25 21:14:34.032: INFO: Pod "my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6-57ps2" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:14:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:14:30 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:14:30 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:14:29 +0000 UTC Reason: Message:}])
Apr 25 21:14:34.032: INFO: Trying to dial the pod
Apr 25 21:14:39.137: INFO: Controller my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6: Got expected result from replica 1 [my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6-57ps2]: "my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6-57ps2", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 25 21:14:39.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9544" for this suite. 04/25/23 21:14:39.164
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":358,"skipped":6654,"failed":0}
------------------------------
• [SLOW TEST] [10.300 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:14:28.89
    Apr 25 21:14:28.891: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename replication-controller 04/25/23 21:14:28.895
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:28.937
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:28.95
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6 04/25/23 21:14:28.963
    Apr 25 21:14:28.992: INFO: Pod name my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6: Found 0 pods out of 1
    Apr 25 21:14:34.015: INFO: Pod name my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6: Found 1 pods out of 1
    Apr 25 21:14:34.016: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6" are running
    Apr 25 21:14:34.016: INFO: Waiting up to 5m0s for pod "my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6-57ps2" in namespace "replication-controller-9544" to be "running"
    Apr 25 21:14:34.031: INFO: Pod "my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6-57ps2": Phase="Running", Reason="", readiness=true. Elapsed: 14.940304ms
    Apr 25 21:14:34.032: INFO: Pod "my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6-57ps2" satisfied condition "running"
    Apr 25 21:14:34.032: INFO: Pod "my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6-57ps2" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:14:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:14:30 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:14:30 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-25 21:14:29 +0000 UTC Reason: Message:}])
    Apr 25 21:14:34.032: INFO: Trying to dial the pod
    Apr 25 21:14:39.137: INFO: Controller my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6: Got expected result from replica 1 [my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6-57ps2]: "my-hostname-basic-8cfa7ec9-4b79-4d89-a14c-cb6a32ff66f6-57ps2", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 25 21:14:39.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-9544" for this suite. 04/25/23 21:14:39.164
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:14:39.203
Apr 25 21:14:39.203: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename services 04/25/23 21:14:39.204
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:39.251
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:39.268
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-5050 04/25/23 21:14:39.279
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5050 to expose endpoints map[] 04/25/23 21:14:39.334
Apr 25 21:14:39.371: INFO: successfully validated that service multi-endpoint-test in namespace services-5050 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-5050 04/25/23 21:14:39.371
Apr 25 21:14:39.403: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5050" to be "running and ready"
Apr 25 21:14:39.418: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.889341ms
Apr 25 21:14:39.418: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 21:14:41.439: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.036031231s
Apr 25 21:14:41.439: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 25 21:14:41.439: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5050 to expose endpoints map[pod1:[100]] 04/25/23 21:14:41.483
Apr 25 21:14:41.580: INFO: successfully validated that service multi-endpoint-test in namespace services-5050 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-5050 04/25/23 21:14:41.58
Apr 25 21:14:41.603: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5050" to be "running and ready"
Apr 25 21:14:41.627: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 23.536083ms
Apr 25 21:14:41.627: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 21:14:43.646: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043276035s
Apr 25 21:14:43.647: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 25 21:14:45.646: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.042405744s
Apr 25 21:14:45.646: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 25 21:14:45.646: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5050 to expose endpoints map[pod1:[100] pod2:[101]] 04/25/23 21:14:45.66
Apr 25 21:14:45.725: INFO: successfully validated that service multi-endpoint-test in namespace services-5050 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 04/25/23 21:14:45.725
Apr 25 21:14:45.725: INFO: Creating new exec pod
Apr 25 21:14:45.754: INFO: Waiting up to 5m0s for pod "execpodjvx57" in namespace "services-5050" to be "running"
Apr 25 21:14:45.777: INFO: Pod "execpodjvx57": Phase="Pending", Reason="", readiness=false. Elapsed: 23.437654ms
Apr 25 21:14:47.797: INFO: Pod "execpodjvx57": Phase="Running", Reason="", readiness=true. Elapsed: 2.042933792s
Apr 25 21:14:47.797: INFO: Pod "execpodjvx57" satisfied condition "running"
Apr 25 21:14:48.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-5050 exec execpodjvx57 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Apr 25 21:14:49.206: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Apr 25 21:14:49.206: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 21:14:49.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-5050 exec execpodjvx57 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.243.139 80'
Apr 25 21:14:49.541: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.243.139 80\nConnection to 172.21.243.139 80 port [tcp/http] succeeded!\n"
Apr 25 21:14:49.541: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 21:14:49.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-5050 exec execpodjvx57 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Apr 25 21:14:49.909: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Apr 25 21:14:49.910: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 25 21:14:49.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-5050 exec execpodjvx57 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.243.139 81'
Apr 25 21:14:50.254: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.243.139 81\nConnection to 172.21.243.139 81 port [tcp/*] succeeded!\n"
Apr 25 21:14:50.254: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-5050 04/25/23 21:14:50.254
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5050 to expose endpoints map[pod2:[101]] 04/25/23 21:14:50.297
Apr 25 21:14:50.365: INFO: successfully validated that service multi-endpoint-test in namespace services-5050 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-5050 04/25/23 21:14:50.365
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5050 to expose endpoints map[] 04/25/23 21:14:50.418
Apr 25 21:14:50.457: INFO: successfully validated that service multi-endpoint-test in namespace services-5050 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 25 21:14:50.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5050" for this suite. 04/25/23 21:14:50.54
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":359,"skipped":6665,"failed":0}
------------------------------
• [SLOW TEST] [11.360 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:14:39.203
    Apr 25 21:14:39.203: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename services 04/25/23 21:14:39.204
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:39.251
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:39.268
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-5050 04/25/23 21:14:39.279
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5050 to expose endpoints map[] 04/25/23 21:14:39.334
    Apr 25 21:14:39.371: INFO: successfully validated that service multi-endpoint-test in namespace services-5050 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-5050 04/25/23 21:14:39.371
    Apr 25 21:14:39.403: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5050" to be "running and ready"
    Apr 25 21:14:39.418: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.889341ms
    Apr 25 21:14:39.418: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 21:14:41.439: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.036031231s
    Apr 25 21:14:41.439: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 25 21:14:41.439: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5050 to expose endpoints map[pod1:[100]] 04/25/23 21:14:41.483
    Apr 25 21:14:41.580: INFO: successfully validated that service multi-endpoint-test in namespace services-5050 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-5050 04/25/23 21:14:41.58
    Apr 25 21:14:41.603: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5050" to be "running and ready"
    Apr 25 21:14:41.627: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 23.536083ms
    Apr 25 21:14:41.627: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 21:14:43.646: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043276035s
    Apr 25 21:14:43.647: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 25 21:14:45.646: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.042405744s
    Apr 25 21:14:45.646: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 25 21:14:45.646: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5050 to expose endpoints map[pod1:[100] pod2:[101]] 04/25/23 21:14:45.66
    Apr 25 21:14:45.725: INFO: successfully validated that service multi-endpoint-test in namespace services-5050 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 04/25/23 21:14:45.725
    Apr 25 21:14:45.725: INFO: Creating new exec pod
    Apr 25 21:14:45.754: INFO: Waiting up to 5m0s for pod "execpodjvx57" in namespace "services-5050" to be "running"
    Apr 25 21:14:45.777: INFO: Pod "execpodjvx57": Phase="Pending", Reason="", readiness=false. Elapsed: 23.437654ms
    Apr 25 21:14:47.797: INFO: Pod "execpodjvx57": Phase="Running", Reason="", readiness=true. Elapsed: 2.042933792s
    Apr 25 21:14:47.797: INFO: Pod "execpodjvx57" satisfied condition "running"
    Apr 25 21:14:48.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-5050 exec execpodjvx57 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Apr 25 21:14:49.206: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Apr 25 21:14:49.206: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 21:14:49.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-5050 exec execpodjvx57 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.243.139 80'
    Apr 25 21:14:49.541: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.243.139 80\nConnection to 172.21.243.139 80 port [tcp/http] succeeded!\n"
    Apr 25 21:14:49.541: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 21:14:49.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-5050 exec execpodjvx57 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Apr 25 21:14:49.909: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Apr 25 21:14:49.910: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 25 21:14:49.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2175352479 --namespace=services-5050 exec execpodjvx57 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.243.139 81'
    Apr 25 21:14:50.254: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.243.139 81\nConnection to 172.21.243.139 81 port [tcp/*] succeeded!\n"
    Apr 25 21:14:50.254: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-5050 04/25/23 21:14:50.254
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5050 to expose endpoints map[pod2:[101]] 04/25/23 21:14:50.297
    Apr 25 21:14:50.365: INFO: successfully validated that service multi-endpoint-test in namespace services-5050 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-5050 04/25/23 21:14:50.365
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5050 to expose endpoints map[] 04/25/23 21:14:50.418
    Apr 25 21:14:50.457: INFO: successfully validated that service multi-endpoint-test in namespace services-5050 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 25 21:14:50.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5050" for this suite. 04/25/23 21:14:50.54
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/25/23 21:14:50.578
Apr 25 21:14:50.579: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
STEP: Building a namespace api object, basename subpath 04/25/23 21:14:50.582
STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:50.626
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:50.642
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/25/23 21:14:50.657
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-qlzk 04/25/23 21:14:50.694
STEP: Creating a pod to test atomic-volume-subpath 04/25/23 21:14:50.695
Apr 25 21:14:50.723: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-qlzk" in namespace "subpath-1616" to be "Succeeded or Failed"
Apr 25 21:14:50.737: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Pending", Reason="", readiness=false. Elapsed: 14.06886ms
Apr 25 21:14:52.754: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03057334s
Apr 25 21:14:54.754: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 4.031283777s
Apr 25 21:14:56.752: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 6.029389317s
Apr 25 21:14:58.754: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 8.031088466s
Apr 25 21:15:00.753: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 10.029778573s
Apr 25 21:15:02.752: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 12.028660895s
Apr 25 21:15:04.756: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 14.032840419s
Apr 25 21:15:06.755: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 16.031735905s
Apr 25 21:15:08.753: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 18.029958356s
Apr 25 21:15:10.753: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 20.029825272s
Apr 25 21:15:12.752: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 22.029331566s
Apr 25 21:15:14.760: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=false. Elapsed: 24.037094652s
Apr 25 21:15:16.753: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.029633928s
STEP: Saw pod success 04/25/23 21:15:16.753
Apr 25 21:15:16.753: INFO: Pod "pod-subpath-test-configmap-qlzk" satisfied condition "Succeeded or Failed"
Apr 25 21:15:16.771: INFO: Trying to get logs from node 10.10.21.190 pod pod-subpath-test-configmap-qlzk container test-container-subpath-configmap-qlzk: <nil>
STEP: delete the pod 04/25/23 21:15:16.863
Apr 25 21:15:16.918: INFO: Waiting for pod pod-subpath-test-configmap-qlzk to disappear
Apr 25 21:15:16.936: INFO: Pod pod-subpath-test-configmap-qlzk no longer exists
STEP: Deleting pod pod-subpath-test-configmap-qlzk 04/25/23 21:15:16.936
Apr 25 21:15:16.937: INFO: Deleting pod "pod-subpath-test-configmap-qlzk" in namespace "subpath-1616"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 25 21:15:16.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1616" for this suite. 04/25/23 21:15:16.968
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":360,"skipped":6697,"failed":0}
------------------------------
• [SLOW TEST] [26.420 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/25/23 21:14:50.578
    Apr 25 21:14:50.579: INFO: >>> kubeConfig: /tmp/kubeconfig-2175352479
    STEP: Building a namespace api object, basename subpath 04/25/23 21:14:50.582
    STEP: Waiting for a default service account to be provisioned in namespace 04/25/23 21:14:50.626
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/25/23 21:14:50.642
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/25/23 21:14:50.657
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-qlzk 04/25/23 21:14:50.694
    STEP: Creating a pod to test atomic-volume-subpath 04/25/23 21:14:50.695
    Apr 25 21:14:50.723: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-qlzk" in namespace "subpath-1616" to be "Succeeded or Failed"
    Apr 25 21:14:50.737: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Pending", Reason="", readiness=false. Elapsed: 14.06886ms
    Apr 25 21:14:52.754: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03057334s
    Apr 25 21:14:54.754: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 4.031283777s
    Apr 25 21:14:56.752: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 6.029389317s
    Apr 25 21:14:58.754: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 8.031088466s
    Apr 25 21:15:00.753: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 10.029778573s
    Apr 25 21:15:02.752: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 12.028660895s
    Apr 25 21:15:04.756: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 14.032840419s
    Apr 25 21:15:06.755: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 16.031735905s
    Apr 25 21:15:08.753: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 18.029958356s
    Apr 25 21:15:10.753: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 20.029825272s
    Apr 25 21:15:12.752: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=true. Elapsed: 22.029331566s
    Apr 25 21:15:14.760: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Running", Reason="", readiness=false. Elapsed: 24.037094652s
    Apr 25 21:15:16.753: INFO: Pod "pod-subpath-test-configmap-qlzk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.029633928s
    STEP: Saw pod success 04/25/23 21:15:16.753
    Apr 25 21:15:16.753: INFO: Pod "pod-subpath-test-configmap-qlzk" satisfied condition "Succeeded or Failed"
    Apr 25 21:15:16.771: INFO: Trying to get logs from node 10.10.21.190 pod pod-subpath-test-configmap-qlzk container test-container-subpath-configmap-qlzk: <nil>
    STEP: delete the pod 04/25/23 21:15:16.863
    Apr 25 21:15:16.918: INFO: Waiting for pod pod-subpath-test-configmap-qlzk to disappear
    Apr 25 21:15:16.936: INFO: Pod pod-subpath-test-configmap-qlzk no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-qlzk 04/25/23 21:15:16.936
    Apr 25 21:15:16.937: INFO: Deleting pod "pod-subpath-test-configmap-qlzk" in namespace "subpath-1616"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 25 21:15:16.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-1616" for this suite. 04/25/23 21:15:16.968
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":360,"skipped":6706,"failed":0}
Apr 25 21:15:17.004: INFO: Running AfterSuite actions on all nodes
Apr 25 21:15:17.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Apr 25 21:15:17.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Apr 25 21:15:17.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Apr 25 21:15:17.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Apr 25 21:15:17.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Apr 25 21:15:17.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Apr 25 21:15:17.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Apr 25 21:15:17.004: INFO: Running AfterSuite actions on node 1
Apr 25 21:15:17.004: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Apr 25 21:15:17.004: INFO: Running AfterSuite actions on all nodes
    Apr 25 21:15:17.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Apr 25 21:15:17.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Apr 25 21:15:17.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Apr 25 21:15:17.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Apr 25 21:15:17.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Apr 25 21:15:17.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Apr 25 21:15:17.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Apr 25 21:15:17.004: INFO: Running AfterSuite actions on node 1
    Apr 25 21:15:17.004: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.102 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 360 of 7066 Specs in 5995.305 seconds
SUCCESS! -- 360 Passed | 0 Failed | 0 Pending | 6706 Skipped
PASS

Ginkgo ran 1 suite in 1h39m55.767973918s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m

