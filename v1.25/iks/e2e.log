I1003 19:13:55.241882      22 e2e.go:116] Starting e2e run "c016e225-6064-4d03-943e-dc46bcf079b7" on Ginkgo node 1
Oct  3 19:13:55.285: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1664824435 - will randomize all specs

Will run 362 of 7067 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Oct  3 19:13:55.461: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 19:13:55.463: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
E1003 19:13:55.469201      22 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
E1003 19:13:55.469201      22 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
Oct  3 19:13:55.515: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct  3 19:13:55.633: INFO: 36 / 36 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct  3 19:13:55.633: INFO: expected 21 pod replicas in namespace 'kube-system', 21 are Running and Ready.
Oct  3 19:13:55.634: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct  3 19:13:55.684: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Oct  3 19:13:55.684: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Oct  3 19:13:55.684: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibmcloud-block-storage-driver' (0 seconds elapsed)
Oct  3 19:13:55.684: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'konnectivity-agent' (0 seconds elapsed)
Oct  3 19:13:55.684: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Oct  3 19:13:55.684: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Oct  3 19:13:55.684: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Oct  3 19:13:55.684: INFO: e2e test version: v1.25.2
Oct  3 19:13:55.689: INFO: kube-apiserver version: v1.25.2+IKS
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Oct  3 19:13:55.689: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 19:13:55.733: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.272 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Oct  3 19:13:55.461: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 19:13:55.463: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    E1003 19:13:55.469201      22 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
    Oct  3 19:13:55.515: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Oct  3 19:13:55.633: INFO: 36 / 36 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Oct  3 19:13:55.633: INFO: expected 21 pod replicas in namespace 'kube-system', 21 are Running and Ready.
    Oct  3 19:13:55.634: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Oct  3 19:13:55.684: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
    Oct  3 19:13:55.684: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
    Oct  3 19:13:55.684: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibmcloud-block-storage-driver' (0 seconds elapsed)
    Oct  3 19:13:55.684: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'konnectivity-agent' (0 seconds elapsed)
    Oct  3 19:13:55.684: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
    Oct  3 19:13:55.684: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
    Oct  3 19:13:55.684: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
    Oct  3 19:13:55.684: INFO: e2e test version: v1.25.2
    Oct  3 19:13:55.689: INFO: kube-apiserver version: v1.25.2+IKS
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Oct  3 19:13:55.689: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 19:13:55.733: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:13:55.766
Oct  3 19:13:55.766: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename ingressclass 10/03/22 19:13:55.769
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:13:55.814
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:13:55.82
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 10/03/22 19:13:55.825
STEP: getting /apis/networking.k8s.io 10/03/22 19:13:55.861
STEP: getting /apis/networking.k8s.iov1 10/03/22 19:13:55.863
STEP: creating 10/03/22 19:13:55.894
STEP: getting 10/03/22 19:13:55.926
STEP: listing 10/03/22 19:13:55.935
STEP: watching 10/03/22 19:13:55.943
Oct  3 19:13:55.944: INFO: starting watch
STEP: patching 10/03/22 19:13:55.946
STEP: updating 10/03/22 19:13:55.957
Oct  3 19:13:55.968: INFO: waiting for watch events with expected annotations
Oct  3 19:13:55.968: INFO: saw patched and updated annotations
STEP: deleting 10/03/22 19:13:55.969
STEP: deleting a collection 10/03/22 19:13:56
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Oct  3 19:13:56.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-9587" for this suite. 10/03/22 19:13:56.062
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":1,"skipped":24,"failed":0}
------------------------------
• [0.313 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:13:55.766
    Oct  3 19:13:55.766: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename ingressclass 10/03/22 19:13:55.769
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:13:55.814
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:13:55.82
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 10/03/22 19:13:55.825
    STEP: getting /apis/networking.k8s.io 10/03/22 19:13:55.861
    STEP: getting /apis/networking.k8s.iov1 10/03/22 19:13:55.863
    STEP: creating 10/03/22 19:13:55.894
    STEP: getting 10/03/22 19:13:55.926
    STEP: listing 10/03/22 19:13:55.935
    STEP: watching 10/03/22 19:13:55.943
    Oct  3 19:13:55.944: INFO: starting watch
    STEP: patching 10/03/22 19:13:55.946
    STEP: updating 10/03/22 19:13:55.957
    Oct  3 19:13:55.968: INFO: waiting for watch events with expected annotations
    Oct  3 19:13:55.968: INFO: saw patched and updated annotations
    STEP: deleting 10/03/22 19:13:55.969
    STEP: deleting a collection 10/03/22 19:13:56
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Oct  3 19:13:56.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-9587" for this suite. 10/03/22 19:13:56.062
  << End Captured GinkgoWriter Output
------------------------------
SE1003 19:13:56.080473      22 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
SSSSE1003 19:13:56.080473      22 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:13:56.082
Oct  3 19:13:56.083: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 19:13:56.084
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:13:56.114
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:13:56.125
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-77427a77-f841-4c58-869e-0c01a033f62d 10/03/22 19:13:56.133
STEP: Creating a pod to test consume configMaps 10/03/22 19:13:56.145
Oct  3 19:13:56.165: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602" in namespace "projected-3777" to be "Succeeded or Failed"
Oct  3 19:13:56.175: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Pending", Reason="", readiness=false. Elapsed: 10.683011ms
Oct  3 19:13:58.185: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020625606s
Oct  3 19:14:00.186: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021488357s
Oct  3 19:14:02.186: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021533227s
Oct  3 19:14:04.184: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019712867s
Oct  3 19:14:06.186: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Pending", Reason="", readiness=false. Elapsed: 10.021326935s
Oct  3 19:14:08.185: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Running", Reason="", readiness=true. Elapsed: 12.020361326s
Oct  3 19:14:10.186: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Running", Reason="", readiness=false. Elapsed: 14.021056369s
Oct  3 19:14:12.186: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.021096977s
STEP: Saw pod success 10/03/22 19:14:12.186
Oct  3 19:14:12.186: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602" satisfied condition "Succeeded or Failed"
Oct  3 19:14:12.194: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602 container agnhost-container: <nil>
STEP: delete the pod 10/03/22 19:14:12.219
Oct  3 19:14:12.242: INFO: Waiting for pod pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602 to disappear
Oct  3 19:14:12.252: INFO: Pod pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Oct  3 19:14:12.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3777" for this suite. 10/03/22 19:14:12.264
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":2,"skipped":54,"failed":0}
------------------------------
• [SLOW TEST] [16.197 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:13:56.082
    Oct  3 19:13:56.083: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 19:13:56.084
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:13:56.114
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:13:56.125
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-77427a77-f841-4c58-869e-0c01a033f62d 10/03/22 19:13:56.133
    STEP: Creating a pod to test consume configMaps 10/03/22 19:13:56.145
    Oct  3 19:13:56.165: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602" in namespace "projected-3777" to be "Succeeded or Failed"
    Oct  3 19:13:56.175: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Pending", Reason="", readiness=false. Elapsed: 10.683011ms
    Oct  3 19:13:58.185: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020625606s
    Oct  3 19:14:00.186: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021488357s
    Oct  3 19:14:02.186: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021533227s
    Oct  3 19:14:04.184: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019712867s
    Oct  3 19:14:06.186: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Pending", Reason="", readiness=false. Elapsed: 10.021326935s
    Oct  3 19:14:08.185: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Running", Reason="", readiness=true. Elapsed: 12.020361326s
    Oct  3 19:14:10.186: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Running", Reason="", readiness=false. Elapsed: 14.021056369s
    Oct  3 19:14:12.186: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.021096977s
    STEP: Saw pod success 10/03/22 19:14:12.186
    Oct  3 19:14:12.186: INFO: Pod "pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602" satisfied condition "Succeeded or Failed"
    Oct  3 19:14:12.194: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602 container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 19:14:12.219
    Oct  3 19:14:12.242: INFO: Waiting for pod pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602 to disappear
    Oct  3 19:14:12.252: INFO: Pod pod-projected-configmaps-cebe5ea2-249e-4b0b-9a9f-1dcdde51c602 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Oct  3 19:14:12.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3777" for this suite. 10/03/22 19:14:12.264
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:14:12.287
Oct  3 19:14:12.287: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 19:14:12.288
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:14:12.316
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:14:12.321
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 19:14:12.355
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 19:14:13.34
STEP: Deploying the webhook pod 10/03/22 19:14:13.358
STEP: Wait for the deployment to be ready 10/03/22 19:14:13.381
Oct  3 19:14:13.402: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  3 19:14:15.430: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 14, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 14, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 14, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 14, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 10/03/22 19:14:17.441
STEP: Verifying the service has paired with the endpoint 10/03/22 19:14:17.473
Oct  3 19:14:18.474: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 10/03/22 19:14:18.614
STEP: Creating a configMap that should be mutated 10/03/22 19:14:18.681
STEP: Deleting the collection of validation webhooks 10/03/22 19:14:18.825
STEP: Creating a configMap that should not be mutated 10/03/22 19:14:18.997
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 19:14:19.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6530" for this suite. 10/03/22 19:14:19.04
STEP: Destroying namespace "webhook-6530-markers" for this suite. 10/03/22 19:14:19.058
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":3,"skipped":61,"failed":0}
------------------------------
• [SLOW TEST] [6.879 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:14:12.287
    Oct  3 19:14:12.287: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 19:14:12.288
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:14:12.316
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:14:12.321
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 19:14:12.355
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 19:14:13.34
    STEP: Deploying the webhook pod 10/03/22 19:14:13.358
    STEP: Wait for the deployment to be ready 10/03/22 19:14:13.381
    Oct  3 19:14:13.402: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Oct  3 19:14:15.430: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 14, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 14, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 14, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 14, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 10/03/22 19:14:17.441
    STEP: Verifying the service has paired with the endpoint 10/03/22 19:14:17.473
    Oct  3 19:14:18.474: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 10/03/22 19:14:18.614
    STEP: Creating a configMap that should be mutated 10/03/22 19:14:18.681
    STEP: Deleting the collection of validation webhooks 10/03/22 19:14:18.825
    STEP: Creating a configMap that should not be mutated 10/03/22 19:14:18.997
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 19:14:19.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6530" for this suite. 10/03/22 19:14:19.04
    STEP: Destroying namespace "webhook-6530-markers" for this suite. 10/03/22 19:14:19.058
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:14:19.167
Oct  3 19:14:19.167: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 19:14:19.168
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:14:19.204
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:14:19.21
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 10/03/22 19:14:19.215
Oct  3 19:14:19.234: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375" in namespace "downward-api-1128" to be "Succeeded or Failed"
Oct  3 19:14:19.242: INFO: Pod "downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375": Phase="Pending", Reason="", readiness=false. Elapsed: 8.123832ms
Oct  3 19:14:21.252: INFO: Pod "downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018510864s
Oct  3 19:14:23.251: INFO: Pod "downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017408854s
Oct  3 19:14:25.251: INFO: Pod "downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017890985s
STEP: Saw pod success 10/03/22 19:14:25.252
Oct  3 19:14:25.252: INFO: Pod "downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375" satisfied condition "Succeeded or Failed"
Oct  3 19:14:25.283: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375 container client-container: <nil>
STEP: delete the pod 10/03/22 19:14:25.311
Oct  3 19:14:25.337: INFO: Waiting for pod downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375 to disappear
Oct  3 19:14:25.345: INFO: Pod downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Oct  3 19:14:25.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1128" for this suite. 10/03/22 19:14:25.359
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":4,"skipped":68,"failed":0}
------------------------------
• [SLOW TEST] [6.211 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:14:19.167
    Oct  3 19:14:19.167: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 19:14:19.168
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:14:19.204
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:14:19.21
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 10/03/22 19:14:19.215
    Oct  3 19:14:19.234: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375" in namespace "downward-api-1128" to be "Succeeded or Failed"
    Oct  3 19:14:19.242: INFO: Pod "downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375": Phase="Pending", Reason="", readiness=false. Elapsed: 8.123832ms
    Oct  3 19:14:21.252: INFO: Pod "downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018510864s
    Oct  3 19:14:23.251: INFO: Pod "downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017408854s
    Oct  3 19:14:25.251: INFO: Pod "downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017890985s
    STEP: Saw pod success 10/03/22 19:14:25.252
    Oct  3 19:14:25.252: INFO: Pod "downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375" satisfied condition "Succeeded or Failed"
    Oct  3 19:14:25.283: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375 container client-container: <nil>
    STEP: delete the pod 10/03/22 19:14:25.311
    Oct  3 19:14:25.337: INFO: Waiting for pod downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375 to disappear
    Oct  3 19:14:25.345: INFO: Pod downwardapi-volume-f8b04f37-a98d-4704-a70d-fc66df1ab375 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Oct  3 19:14:25.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1128" for this suite. 10/03/22 19:14:25.359
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:14:25.383
Oct  3 19:14:25.383: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 19:14:25.385
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:14:25.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:14:25.421
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 10/03/22 19:14:25.426
Oct  3 19:14:25.445: INFO: Waiting up to 5m0s for pod "downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94" in namespace "projected-269" to be "Succeeded or Failed"
Oct  3 19:14:25.470: INFO: Pod "downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94": Phase="Pending", Reason="", readiness=false. Elapsed: 24.879835ms
Oct  3 19:14:27.481: INFO: Pod "downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035619627s
Oct  3 19:14:29.481: INFO: Pod "downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035577109s
Oct  3 19:14:31.480: INFO: Pod "downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034812905s
STEP: Saw pod success 10/03/22 19:14:31.48
Oct  3 19:14:31.481: INFO: Pod "downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94" satisfied condition "Succeeded or Failed"
Oct  3 19:14:31.489: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94 container client-container: <nil>
STEP: delete the pod 10/03/22 19:14:31.515
Oct  3 19:14:31.544: INFO: Waiting for pod downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94 to disappear
Oct  3 19:14:31.552: INFO: Pod downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Oct  3 19:14:31.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-269" for this suite. 10/03/22 19:14:31.564
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":5,"skipped":124,"failed":0}
------------------------------
• [SLOW TEST] [6.197 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:14:25.383
    Oct  3 19:14:25.383: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 19:14:25.385
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:14:25.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:14:25.421
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 10/03/22 19:14:25.426
    Oct  3 19:14:25.445: INFO: Waiting up to 5m0s for pod "downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94" in namespace "projected-269" to be "Succeeded or Failed"
    Oct  3 19:14:25.470: INFO: Pod "downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94": Phase="Pending", Reason="", readiness=false. Elapsed: 24.879835ms
    Oct  3 19:14:27.481: INFO: Pod "downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035619627s
    Oct  3 19:14:29.481: INFO: Pod "downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035577109s
    Oct  3 19:14:31.480: INFO: Pod "downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034812905s
    STEP: Saw pod success 10/03/22 19:14:31.48
    Oct  3 19:14:31.481: INFO: Pod "downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94" satisfied condition "Succeeded or Failed"
    Oct  3 19:14:31.489: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94 container client-container: <nil>
    STEP: delete the pod 10/03/22 19:14:31.515
    Oct  3 19:14:31.544: INFO: Waiting for pod downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94 to disappear
    Oct  3 19:14:31.552: INFO: Pod downwardapi-volume-488d0938-6719-4bc2-9fbc-8b3d75d75d94 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Oct  3 19:14:31.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-269" for this suite. 10/03/22 19:14:31.564
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:14:31.582
Oct  3 19:14:31.582: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 19:14:31.584
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:14:31.612
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:14:31.617
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-9108 10/03/22 19:14:31.622
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 10/03/22 19:14:31.648
STEP: creating service externalsvc in namespace services-9108 10/03/22 19:14:31.648
STEP: creating replication controller externalsvc in namespace services-9108 10/03/22 19:14:31.675
I1003 19:14:31.688958      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-9108, replica count: 2
I1003 19:14:34.739495      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1003 19:14:37.742295      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1003 19:14:40.742576      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 10/03/22 19:14:40.751
Oct  3 19:14:40.783: INFO: Creating new exec pod
Oct  3 19:14:40.794: INFO: Waiting up to 5m0s for pod "execpodjtdhv" in namespace "services-9108" to be "running"
Oct  3 19:14:40.803: INFO: Pod "execpodjtdhv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.537352ms
Oct  3 19:14:42.812: INFO: Pod "execpodjtdhv": Phase="Running", Reason="", readiness=true. Elapsed: 2.018309516s
Oct  3 19:14:42.812: INFO: Pod "execpodjtdhv" satisfied condition "running"
Oct  3 19:14:42.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9108 exec execpodjtdhv -- /bin/sh -x -c nslookup clusterip-service.services-9108.svc.cluster.local'
Oct  3 19:14:43.202: INFO: stderr: "+ nslookup clusterip-service.services-9108.svc.cluster.local\n"
Oct  3 19:14:43.202: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nclusterip-service.services-9108.svc.cluster.local\tcanonical name = externalsvc.services-9108.svc.cluster.local.\nName:\texternalsvc.services-9108.svc.cluster.local\nAddress: 172.21.69.249\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9108, will wait for the garbage collector to delete the pods 10/03/22 19:14:43.202
Oct  3 19:14:43.281: INFO: Deleting ReplicationController externalsvc took: 18.030056ms
Oct  3 19:14:43.381: INFO: Terminating ReplicationController externalsvc pods took: 100.641346ms
Oct  3 19:14:45.929: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 19:14:45.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9108" for this suite. 10/03/22 19:14:46.008
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":6,"skipped":133,"failed":0}
------------------------------
• [SLOW TEST] [14.442 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:14:31.582
    Oct  3 19:14:31.582: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 19:14:31.584
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:14:31.612
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:14:31.617
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-9108 10/03/22 19:14:31.622
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 10/03/22 19:14:31.648
    STEP: creating service externalsvc in namespace services-9108 10/03/22 19:14:31.648
    STEP: creating replication controller externalsvc in namespace services-9108 10/03/22 19:14:31.675
    I1003 19:14:31.688958      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-9108, replica count: 2
    I1003 19:14:34.739495      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1003 19:14:37.742295      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1003 19:14:40.742576      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 10/03/22 19:14:40.751
    Oct  3 19:14:40.783: INFO: Creating new exec pod
    Oct  3 19:14:40.794: INFO: Waiting up to 5m0s for pod "execpodjtdhv" in namespace "services-9108" to be "running"
    Oct  3 19:14:40.803: INFO: Pod "execpodjtdhv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.537352ms
    Oct  3 19:14:42.812: INFO: Pod "execpodjtdhv": Phase="Running", Reason="", readiness=true. Elapsed: 2.018309516s
    Oct  3 19:14:42.812: INFO: Pod "execpodjtdhv" satisfied condition "running"
    Oct  3 19:14:42.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9108 exec execpodjtdhv -- /bin/sh -x -c nslookup clusterip-service.services-9108.svc.cluster.local'
    Oct  3 19:14:43.202: INFO: stderr: "+ nslookup clusterip-service.services-9108.svc.cluster.local\n"
    Oct  3 19:14:43.202: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nclusterip-service.services-9108.svc.cluster.local\tcanonical name = externalsvc.services-9108.svc.cluster.local.\nName:\texternalsvc.services-9108.svc.cluster.local\nAddress: 172.21.69.249\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-9108, will wait for the garbage collector to delete the pods 10/03/22 19:14:43.202
    Oct  3 19:14:43.281: INFO: Deleting ReplicationController externalsvc took: 18.030056ms
    Oct  3 19:14:43.381: INFO: Terminating ReplicationController externalsvc pods took: 100.641346ms
    Oct  3 19:14:45.929: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 19:14:45.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9108" for this suite. 10/03/22 19:14:46.008
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:14:46.026
Oct  3 19:14:46.026: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename daemonsets 10/03/22 19:14:46.027
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:14:46.057
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:14:46.064
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 10/03/22 19:14:46.129
STEP: Check that daemon pods launch on every node of the cluster. 10/03/22 19:14:46.139
Oct  3 19:14:46.161: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:14:46.161: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:14:47.210: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:14:47.210: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:14:48.183: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:14:48.183: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:14:49.184: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:14:49.184: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:14:50.184: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:14:50.184: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:14:51.193: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:14:51.193: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:14:52.214: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:14:52.214: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:14:53.185: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:14:53.185: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:14:54.185: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Oct  3 19:14:54.185: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:14:55.186: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct  3 19:14:55.186: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:14:56.184: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct  3 19:14:56.184: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 10/03/22 19:14:56.192
Oct  3 19:14:56.214: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 10/03/22 19:14:56.214
Oct  3 19:14:56.235: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 10/03/22 19:14:56.235
Oct  3 19:14:56.239: INFO: Observed &DaemonSet event: ADDED
Oct  3 19:14:56.239: INFO: Observed &DaemonSet event: MODIFIED
Oct  3 19:14:56.239: INFO: Observed &DaemonSet event: MODIFIED
Oct  3 19:14:56.240: INFO: Observed &DaemonSet event: MODIFIED
Oct  3 19:14:56.240: INFO: Observed &DaemonSet event: MODIFIED
Oct  3 19:14:56.240: INFO: Found daemon set daemon-set in namespace daemonsets-6828 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Oct  3 19:14:56.240: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 10/03/22 19:14:56.24
STEP: watching for the daemon set status to be patched 10/03/22 19:14:56.253
Oct  3 19:14:56.257: INFO: Observed &DaemonSet event: ADDED
Oct  3 19:14:56.257: INFO: Observed &DaemonSet event: MODIFIED
Oct  3 19:14:56.257: INFO: Observed &DaemonSet event: MODIFIED
Oct  3 19:14:56.257: INFO: Observed &DaemonSet event: MODIFIED
Oct  3 19:14:56.258: INFO: Observed &DaemonSet event: MODIFIED
Oct  3 19:14:56.258: INFO: Observed daemon set daemon-set in namespace daemonsets-6828 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Oct  3 19:14:56.258: INFO: Observed &DaemonSet event: MODIFIED
Oct  3 19:14:56.258: INFO: Found daemon set daemon-set in namespace daemonsets-6828 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Oct  3 19:14:56.258: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 10/03/22 19:14:56.267
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6828, will wait for the garbage collector to delete the pods 10/03/22 19:14:56.267
Oct  3 19:14:56.340: INFO: Deleting DaemonSet.extensions daemon-set took: 14.160533ms
Oct  3 19:14:56.441: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.722847ms
Oct  3 19:14:59.750: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:14:59.750: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct  3 19:14:59.759: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"16262"},"items":null}

Oct  3 19:14:59.768: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"16262"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Oct  3 19:14:59.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6828" for this suite. 10/03/22 19:14:59.817
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":7,"skipped":135,"failed":0}
------------------------------
• [SLOW TEST] [13.808 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:14:46.026
    Oct  3 19:14:46.026: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename daemonsets 10/03/22 19:14:46.027
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:14:46.057
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:14:46.064
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 10/03/22 19:14:46.129
    STEP: Check that daemon pods launch on every node of the cluster. 10/03/22 19:14:46.139
    Oct  3 19:14:46.161: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:14:46.161: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:14:47.210: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:14:47.210: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:14:48.183: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:14:48.183: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:14:49.184: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:14:49.184: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:14:50.184: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:14:50.184: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:14:51.193: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:14:51.193: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:14:52.214: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:14:52.214: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:14:53.185: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:14:53.185: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:14:54.185: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Oct  3 19:14:54.185: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:14:55.186: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct  3 19:14:55.186: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:14:56.184: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct  3 19:14:56.184: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 10/03/22 19:14:56.192
    Oct  3 19:14:56.214: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 10/03/22 19:14:56.214
    Oct  3 19:14:56.235: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 10/03/22 19:14:56.235
    Oct  3 19:14:56.239: INFO: Observed &DaemonSet event: ADDED
    Oct  3 19:14:56.239: INFO: Observed &DaemonSet event: MODIFIED
    Oct  3 19:14:56.239: INFO: Observed &DaemonSet event: MODIFIED
    Oct  3 19:14:56.240: INFO: Observed &DaemonSet event: MODIFIED
    Oct  3 19:14:56.240: INFO: Observed &DaemonSet event: MODIFIED
    Oct  3 19:14:56.240: INFO: Found daemon set daemon-set in namespace daemonsets-6828 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Oct  3 19:14:56.240: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 10/03/22 19:14:56.24
    STEP: watching for the daemon set status to be patched 10/03/22 19:14:56.253
    Oct  3 19:14:56.257: INFO: Observed &DaemonSet event: ADDED
    Oct  3 19:14:56.257: INFO: Observed &DaemonSet event: MODIFIED
    Oct  3 19:14:56.257: INFO: Observed &DaemonSet event: MODIFIED
    Oct  3 19:14:56.257: INFO: Observed &DaemonSet event: MODIFIED
    Oct  3 19:14:56.258: INFO: Observed &DaemonSet event: MODIFIED
    Oct  3 19:14:56.258: INFO: Observed daemon set daemon-set in namespace daemonsets-6828 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Oct  3 19:14:56.258: INFO: Observed &DaemonSet event: MODIFIED
    Oct  3 19:14:56.258: INFO: Found daemon set daemon-set in namespace daemonsets-6828 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Oct  3 19:14:56.258: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 10/03/22 19:14:56.267
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6828, will wait for the garbage collector to delete the pods 10/03/22 19:14:56.267
    Oct  3 19:14:56.340: INFO: Deleting DaemonSet.extensions daemon-set took: 14.160533ms
    Oct  3 19:14:56.441: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.722847ms
    Oct  3 19:14:59.750: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:14:59.750: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Oct  3 19:14:59.759: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"16262"},"items":null}

    Oct  3 19:14:59.768: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"16262"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 19:14:59.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-6828" for this suite. 10/03/22 19:14:59.817
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:14:59.842
Oct  3 19:14:59.842: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename deployment 10/03/22 19:14:59.843
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:14:59.87
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:14:59.877
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 10/03/22 19:14:59.898
Oct  3 19:14:59.898: INFO: Creating simple deployment test-deployment-dkf6z
Oct  3 19:14:59.928: INFO: deployment "test-deployment-dkf6z" doesn't have the required revision set
STEP: Getting /status 10/03/22 19:15:01.967
Oct  3 19:15:01.977: INFO: Deployment test-deployment-dkf6z has Conditions: [{Available True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:15:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-dkf6z-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 10/03/22 19:15:01.977
Oct  3 19:15:01.998: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 15, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 15, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 15, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 14, 59, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-dkf6z-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 10/03/22 19:15:01.998
Oct  3 19:15:02.001: INFO: Observed &Deployment event: ADDED
Oct  3 19:15:02.001: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-dkf6z-777898ffcc"}
Oct  3 19:15:02.002: INFO: Observed &Deployment event: MODIFIED
Oct  3 19:15:02.002: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-dkf6z-777898ffcc"}
Oct  3 19:15:02.002: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Oct  3 19:15:02.003: INFO: Observed &Deployment event: MODIFIED
Oct  3 19:15:02.003: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Oct  3 19:15:02.003: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-dkf6z-777898ffcc" is progressing.}
Oct  3 19:15:02.003: INFO: Observed &Deployment event: MODIFIED
Oct  3 19:15:02.003: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:15:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Oct  3 19:15:02.003: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-dkf6z-777898ffcc" has successfully progressed.}
Oct  3 19:15:02.003: INFO: Observed &Deployment event: MODIFIED
Oct  3 19:15:02.003: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:15:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Oct  3 19:15:02.003: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-dkf6z-777898ffcc" has successfully progressed.}
Oct  3 19:15:02.003: INFO: Found Deployment test-deployment-dkf6z in namespace deployment-3168 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Oct  3 19:15:02.003: INFO: Deployment test-deployment-dkf6z has an updated status
STEP: patching the Statefulset Status 10/03/22 19:15:02.003
Oct  3 19:15:02.004: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Oct  3 19:15:02.017: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 10/03/22 19:15:02.017
Oct  3 19:15:02.020: INFO: Observed &Deployment event: ADDED
Oct  3 19:15:02.020: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-dkf6z-777898ffcc"}
Oct  3 19:15:02.021: INFO: Observed &Deployment event: MODIFIED
Oct  3 19:15:02.021: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-dkf6z-777898ffcc"}
Oct  3 19:15:02.021: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Oct  3 19:15:02.021: INFO: Observed &Deployment event: MODIFIED
Oct  3 19:15:02.021: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Oct  3 19:15:02.021: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-dkf6z-777898ffcc" is progressing.}
Oct  3 19:15:02.021: INFO: Observed &Deployment event: MODIFIED
Oct  3 19:15:02.022: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:15:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Oct  3 19:15:02.022: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-dkf6z-777898ffcc" has successfully progressed.}
Oct  3 19:15:02.022: INFO: Observed &Deployment event: MODIFIED
Oct  3 19:15:02.022: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:15:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Oct  3 19:15:02.022: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-dkf6z-777898ffcc" has successfully progressed.}
Oct  3 19:15:02.022: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Oct  3 19:15:02.022: INFO: Observed &Deployment event: MODIFIED
Oct  3 19:15:02.022: INFO: Found deployment test-deployment-dkf6z in namespace deployment-3168 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Oct  3 19:15:02.022: INFO: Deployment test-deployment-dkf6z has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct  3 19:15:02.032: INFO: Deployment "test-deployment-dkf6z":
&Deployment{ObjectMeta:{test-deployment-dkf6z  deployment-3168  594ff308-0c5c-4ed3-b0bc-9e1e078d6917 16294 1 2022-10-03 19:14:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-10-03 19:14:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-10-03 19:15:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-10-03 19:15:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0036a9d18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-dkf6z-777898ffcc",LastUpdateTime:2022-10-03 19:15:02 +0000 UTC,LastTransitionTime:2022-10-03 19:15:02 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct  3 19:15:02.041: INFO: New ReplicaSet "test-deployment-dkf6z-777898ffcc" of Deployment "test-deployment-dkf6z":
&ReplicaSet{ObjectMeta:{test-deployment-dkf6z-777898ffcc  deployment-3168  83b0fd95-65d7-4031-89b6-173540d5e817 16290 1 2022-10-03 19:14:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-dkf6z 594ff308-0c5c-4ed3-b0bc-9e1e078d6917 0xc0030401d0 0xc0030401d1}] [] [{kube-controller-manager Update apps/v1 2022-10-03 19:14:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"594ff308-0c5c-4ed3-b0bc-9e1e078d6917\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:15:01 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003040278 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct  3 19:15:02.051: INFO: Pod "test-deployment-dkf6z-777898ffcc-h2rmm" is available:
&Pod{ObjectMeta:{test-deployment-dkf6z-777898ffcc-h2rmm test-deployment-dkf6z-777898ffcc- deployment-3168  f5b20a8b-d0af-40ab-b0ef-7d41a02592ce 16289 0 2022-10-03 19:14:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:1c7904ca7e789ee03e72a56e58028ae5d3f9264462789cf7be48639ad8517dc1 cni.projectcalico.org/podIP:172.30.49.17/32 cni.projectcalico.org/podIPs:172.30.49.17/32] [{apps/v1 ReplicaSet test-deployment-dkf6z-777898ffcc 83b0fd95-65d7-4031-89b6-173540d5e817 0xc002844de0 0xc002844de1}] [] [{kube-controller-manager Update v1 2022-10-03 19:14:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83b0fd95-65d7-4031-89b6-173540d5e817\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:15:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:15:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.17\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9s5mq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9s5mq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:14:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:15:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:15:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:14:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.17,StartTime:2022-10-03 19:14:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:15:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://0e463161cb254a88b6c01f0cd2f20d9c87c58aade939f070857ae99abe57e0c7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.17,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Oct  3 19:15:02.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3168" for this suite. 10/03/22 19:15:02.064
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":8,"skipped":187,"failed":0}
------------------------------
• [2.242 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:14:59.842
    Oct  3 19:14:59.842: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename deployment 10/03/22 19:14:59.843
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:14:59.87
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:14:59.877
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 10/03/22 19:14:59.898
    Oct  3 19:14:59.898: INFO: Creating simple deployment test-deployment-dkf6z
    Oct  3 19:14:59.928: INFO: deployment "test-deployment-dkf6z" doesn't have the required revision set
    STEP: Getting /status 10/03/22 19:15:01.967
    Oct  3 19:15:01.977: INFO: Deployment test-deployment-dkf6z has Conditions: [{Available True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:15:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-dkf6z-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 10/03/22 19:15:01.977
    Oct  3 19:15:01.998: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 15, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 15, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 15, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 14, 59, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-dkf6z-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 10/03/22 19:15:01.998
    Oct  3 19:15:02.001: INFO: Observed &Deployment event: ADDED
    Oct  3 19:15:02.001: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-dkf6z-777898ffcc"}
    Oct  3 19:15:02.002: INFO: Observed &Deployment event: MODIFIED
    Oct  3 19:15:02.002: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-dkf6z-777898ffcc"}
    Oct  3 19:15:02.002: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Oct  3 19:15:02.003: INFO: Observed &Deployment event: MODIFIED
    Oct  3 19:15:02.003: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Oct  3 19:15:02.003: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-dkf6z-777898ffcc" is progressing.}
    Oct  3 19:15:02.003: INFO: Observed &Deployment event: MODIFIED
    Oct  3 19:15:02.003: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:15:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Oct  3 19:15:02.003: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-dkf6z-777898ffcc" has successfully progressed.}
    Oct  3 19:15:02.003: INFO: Observed &Deployment event: MODIFIED
    Oct  3 19:15:02.003: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:15:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Oct  3 19:15:02.003: INFO: Observed Deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-dkf6z-777898ffcc" has successfully progressed.}
    Oct  3 19:15:02.003: INFO: Found Deployment test-deployment-dkf6z in namespace deployment-3168 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Oct  3 19:15:02.003: INFO: Deployment test-deployment-dkf6z has an updated status
    STEP: patching the Statefulset Status 10/03/22 19:15:02.003
    Oct  3 19:15:02.004: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Oct  3 19:15:02.017: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 10/03/22 19:15:02.017
    Oct  3 19:15:02.020: INFO: Observed &Deployment event: ADDED
    Oct  3 19:15:02.020: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-dkf6z-777898ffcc"}
    Oct  3 19:15:02.021: INFO: Observed &Deployment event: MODIFIED
    Oct  3 19:15:02.021: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-dkf6z-777898ffcc"}
    Oct  3 19:15:02.021: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Oct  3 19:15:02.021: INFO: Observed &Deployment event: MODIFIED
    Oct  3 19:15:02.021: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Oct  3 19:15:02.021: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:14:59 +0000 UTC 2022-10-03 19:14:59 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-dkf6z-777898ffcc" is progressing.}
    Oct  3 19:15:02.021: INFO: Observed &Deployment event: MODIFIED
    Oct  3 19:15:02.022: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:15:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Oct  3 19:15:02.022: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-dkf6z-777898ffcc" has successfully progressed.}
    Oct  3 19:15:02.022: INFO: Observed &Deployment event: MODIFIED
    Oct  3 19:15:02.022: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:15:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Oct  3 19:15:02.022: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-03 19:15:01 +0000 UTC 2022-10-03 19:14:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-dkf6z-777898ffcc" has successfully progressed.}
    Oct  3 19:15:02.022: INFO: Observed deployment test-deployment-dkf6z in namespace deployment-3168 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Oct  3 19:15:02.022: INFO: Observed &Deployment event: MODIFIED
    Oct  3 19:15:02.022: INFO: Found deployment test-deployment-dkf6z in namespace deployment-3168 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Oct  3 19:15:02.022: INFO: Deployment test-deployment-dkf6z has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct  3 19:15:02.032: INFO: Deployment "test-deployment-dkf6z":
    &Deployment{ObjectMeta:{test-deployment-dkf6z  deployment-3168  594ff308-0c5c-4ed3-b0bc-9e1e078d6917 16294 1 2022-10-03 19:14:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-10-03 19:14:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-10-03 19:15:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-10-03 19:15:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0036a9d18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-dkf6z-777898ffcc",LastUpdateTime:2022-10-03 19:15:02 +0000 UTC,LastTransitionTime:2022-10-03 19:15:02 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Oct  3 19:15:02.041: INFO: New ReplicaSet "test-deployment-dkf6z-777898ffcc" of Deployment "test-deployment-dkf6z":
    &ReplicaSet{ObjectMeta:{test-deployment-dkf6z-777898ffcc  deployment-3168  83b0fd95-65d7-4031-89b6-173540d5e817 16290 1 2022-10-03 19:14:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-dkf6z 594ff308-0c5c-4ed3-b0bc-9e1e078d6917 0xc0030401d0 0xc0030401d1}] [] [{kube-controller-manager Update apps/v1 2022-10-03 19:14:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"594ff308-0c5c-4ed3-b0bc-9e1e078d6917\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:15:01 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003040278 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Oct  3 19:15:02.051: INFO: Pod "test-deployment-dkf6z-777898ffcc-h2rmm" is available:
    &Pod{ObjectMeta:{test-deployment-dkf6z-777898ffcc-h2rmm test-deployment-dkf6z-777898ffcc- deployment-3168  f5b20a8b-d0af-40ab-b0ef-7d41a02592ce 16289 0 2022-10-03 19:14:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:1c7904ca7e789ee03e72a56e58028ae5d3f9264462789cf7be48639ad8517dc1 cni.projectcalico.org/podIP:172.30.49.17/32 cni.projectcalico.org/podIPs:172.30.49.17/32] [{apps/v1 ReplicaSet test-deployment-dkf6z-777898ffcc 83b0fd95-65d7-4031-89b6-173540d5e817 0xc002844de0 0xc002844de1}] [] [{kube-controller-manager Update v1 2022-10-03 19:14:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83b0fd95-65d7-4031-89b6-173540d5e817\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:15:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:15:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.17\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9s5mq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9s5mq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:14:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:15:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:15:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:14:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.17,StartTime:2022-10-03 19:14:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:15:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://0e463161cb254a88b6c01f0cd2f20d9c87c58aade939f070857ae99abe57e0c7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.17,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Oct  3 19:15:02.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3168" for this suite. 10/03/22 19:15:02.064
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:15:02.085
Oct  3 19:15:02.085: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 19:15:02.086
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:15:02.117
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:15:02.122
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 10/03/22 19:15:02.128
Oct  3 19:15:02.128: INFO: namespace kubectl-561
Oct  3 19:15:02.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-561 create -f -'
Oct  3 19:15:02.539: INFO: stderr: ""
Oct  3 19:15:02.539: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 10/03/22 19:15:02.539
Oct  3 19:15:03.548: INFO: Selector matched 1 pods for map[app:agnhost]
Oct  3 19:15:03.548: INFO: Found 0 / 1
Oct  3 19:15:04.549: INFO: Selector matched 1 pods for map[app:agnhost]
Oct  3 19:15:04.549: INFO: Found 0 / 1
Oct  3 19:15:05.548: INFO: Selector matched 1 pods for map[app:agnhost]
Oct  3 19:15:05.548: INFO: Found 1 / 1
Oct  3 19:15:05.548: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct  3 19:15:05.557: INFO: Selector matched 1 pods for map[app:agnhost]
Oct  3 19:15:05.557: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct  3 19:15:05.557: INFO: wait on agnhost-primary startup in kubectl-561 
Oct  3 19:15:05.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-561 logs agnhost-primary-4k9lb agnhost-primary'
Oct  3 19:15:05.727: INFO: stderr: ""
Oct  3 19:15:05.727: INFO: stdout: "Paused\n"
STEP: exposing RC 10/03/22 19:15:05.727
Oct  3 19:15:05.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-561 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Oct  3 19:15:05.865: INFO: stderr: ""
Oct  3 19:15:05.865: INFO: stdout: "service/rm2 exposed\n"
Oct  3 19:15:05.873: INFO: Service rm2 in namespace kubectl-561 found.
STEP: exposing service 10/03/22 19:15:07.89
Oct  3 19:15:07.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-561 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Oct  3 19:15:08.032: INFO: stderr: ""
Oct  3 19:15:08.032: INFO: stdout: "service/rm3 exposed\n"
Oct  3 19:15:08.042: INFO: Service rm3 in namespace kubectl-561 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 19:15:10.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-561" for this suite. 10/03/22 19:15:10.072
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":9,"skipped":190,"failed":0}
------------------------------
• [SLOW TEST] [8.003 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:15:02.085
    Oct  3 19:15:02.085: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 19:15:02.086
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:15:02.117
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:15:02.122
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 10/03/22 19:15:02.128
    Oct  3 19:15:02.128: INFO: namespace kubectl-561
    Oct  3 19:15:02.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-561 create -f -'
    Oct  3 19:15:02.539: INFO: stderr: ""
    Oct  3 19:15:02.539: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 10/03/22 19:15:02.539
    Oct  3 19:15:03.548: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct  3 19:15:03.548: INFO: Found 0 / 1
    Oct  3 19:15:04.549: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct  3 19:15:04.549: INFO: Found 0 / 1
    Oct  3 19:15:05.548: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct  3 19:15:05.548: INFO: Found 1 / 1
    Oct  3 19:15:05.548: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Oct  3 19:15:05.557: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct  3 19:15:05.557: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Oct  3 19:15:05.557: INFO: wait on agnhost-primary startup in kubectl-561 
    Oct  3 19:15:05.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-561 logs agnhost-primary-4k9lb agnhost-primary'
    Oct  3 19:15:05.727: INFO: stderr: ""
    Oct  3 19:15:05.727: INFO: stdout: "Paused\n"
    STEP: exposing RC 10/03/22 19:15:05.727
    Oct  3 19:15:05.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-561 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Oct  3 19:15:05.865: INFO: stderr: ""
    Oct  3 19:15:05.865: INFO: stdout: "service/rm2 exposed\n"
    Oct  3 19:15:05.873: INFO: Service rm2 in namespace kubectl-561 found.
    STEP: exposing service 10/03/22 19:15:07.89
    Oct  3 19:15:07.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-561 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Oct  3 19:15:08.032: INFO: stderr: ""
    Oct  3 19:15:08.032: INFO: stdout: "service/rm3 exposed\n"
    Oct  3 19:15:08.042: INFO: Service rm3 in namespace kubectl-561 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 19:15:10.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-561" for this suite. 10/03/22 19:15:10.072
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:15:10.097
Oct  3 19:15:10.097: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename limitrange 10/03/22 19:15:10.098
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:15:10.133
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:15:10.139
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 10/03/22 19:15:10.144
STEP: Setting up watch 10/03/22 19:15:10.144
STEP: Submitting a LimitRange 10/03/22 19:15:10.255
STEP: Verifying LimitRange creation was observed 10/03/22 19:15:10.266
STEP: Fetching the LimitRange to ensure it has proper values 10/03/22 19:15:10.267
Oct  3 19:15:10.275: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Oct  3 19:15:10.275: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 10/03/22 19:15:10.276
STEP: Ensuring Pod has resource requirements applied from LimitRange 10/03/22 19:15:10.288
Oct  3 19:15:10.299: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Oct  3 19:15:10.299: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 10/03/22 19:15:10.299
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 10/03/22 19:15:10.31
Oct  3 19:15:10.318: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Oct  3 19:15:10.318: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 10/03/22 19:15:10.318
STEP: Failing to create a Pod with more than max resources 10/03/22 19:15:10.322
STEP: Updating a LimitRange 10/03/22 19:15:10.326
STEP: Verifying LimitRange updating is effective 10/03/22 19:15:10.336
STEP: Creating a Pod with less than former min resources 10/03/22 19:15:12.347
STEP: Failing to create a Pod with more than max resources 10/03/22 19:15:12.358
STEP: Deleting a LimitRange 10/03/22 19:15:12.362
STEP: Verifying the LimitRange was deleted 10/03/22 19:15:12.407
Oct  3 19:15:17.418: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 10/03/22 19:15:17.418
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Oct  3 19:15:17.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-9242" for this suite. 10/03/22 19:15:17.464
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":10,"skipped":227,"failed":0}
------------------------------
• [SLOW TEST] [7.386 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:15:10.097
    Oct  3 19:15:10.097: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename limitrange 10/03/22 19:15:10.098
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:15:10.133
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:15:10.139
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 10/03/22 19:15:10.144
    STEP: Setting up watch 10/03/22 19:15:10.144
    STEP: Submitting a LimitRange 10/03/22 19:15:10.255
    STEP: Verifying LimitRange creation was observed 10/03/22 19:15:10.266
    STEP: Fetching the LimitRange to ensure it has proper values 10/03/22 19:15:10.267
    Oct  3 19:15:10.275: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Oct  3 19:15:10.275: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 10/03/22 19:15:10.276
    STEP: Ensuring Pod has resource requirements applied from LimitRange 10/03/22 19:15:10.288
    Oct  3 19:15:10.299: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Oct  3 19:15:10.299: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 10/03/22 19:15:10.299
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 10/03/22 19:15:10.31
    Oct  3 19:15:10.318: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Oct  3 19:15:10.318: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 10/03/22 19:15:10.318
    STEP: Failing to create a Pod with more than max resources 10/03/22 19:15:10.322
    STEP: Updating a LimitRange 10/03/22 19:15:10.326
    STEP: Verifying LimitRange updating is effective 10/03/22 19:15:10.336
    STEP: Creating a Pod with less than former min resources 10/03/22 19:15:12.347
    STEP: Failing to create a Pod with more than max resources 10/03/22 19:15:12.358
    STEP: Deleting a LimitRange 10/03/22 19:15:12.362
    STEP: Verifying the LimitRange was deleted 10/03/22 19:15:12.407
    Oct  3 19:15:17.418: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 10/03/22 19:15:17.418
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Oct  3 19:15:17.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-9242" for this suite. 10/03/22 19:15:17.464
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:15:17.484
Oct  3 19:15:17.484: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename var-expansion 10/03/22 19:15:17.486
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:15:17.517
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:15:17.523
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 10/03/22 19:15:17.528
Oct  3 19:15:17.548: INFO: Waiting up to 2m0s for pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9" in namespace "var-expansion-756" to be "running"
Oct  3 19:15:17.557: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.042216ms
Oct  3 19:15:19.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019391735s
Oct  3 19:15:21.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02009014s
Oct  3 19:15:23.570: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021220497s
Oct  3 19:15:25.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.018380229s
Oct  3 19:15:27.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.018888095s
Oct  3 19:15:29.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.020018746s
Oct  3 19:15:31.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.019553868s
Oct  3 19:15:33.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.020115715s
Oct  3 19:15:35.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.01985287s
Oct  3 19:15:37.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 20.020169193s
Oct  3 19:15:39.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 22.019554024s
Oct  3 19:15:41.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 24.019973424s
Oct  3 19:15:43.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 26.018420277s
Oct  3 19:15:45.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 28.019189432s
Oct  3 19:15:47.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 30.019814306s
Oct  3 19:15:49.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 32.019369728s
Oct  3 19:15:51.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 34.018724577s
Oct  3 19:15:53.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 36.020618316s
Oct  3 19:15:55.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 38.019838997s
Oct  3 19:15:57.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 40.020978189s
Oct  3 19:15:59.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 42.019974108s
Oct  3 19:16:01.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 44.019219993s
Oct  3 19:16:03.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 46.020460896s
Oct  3 19:16:05.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 48.019033902s
Oct  3 19:16:07.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 50.020498458s
Oct  3 19:16:09.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 52.018908078s
Oct  3 19:16:11.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 54.019263848s
Oct  3 19:16:13.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 56.019056924s
Oct  3 19:16:15.587: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 58.038809293s
Oct  3 19:16:17.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.020051826s
Oct  3 19:16:19.570: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.021662371s
Oct  3 19:16:21.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.019312829s
Oct  3 19:16:23.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.02007119s
Oct  3 19:16:25.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.019582656s
Oct  3 19:16:27.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.019673991s
Oct  3 19:16:29.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.019673697s
Oct  3 19:16:31.571: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.022762317s
Oct  3 19:16:33.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.020259105s
Oct  3 19:16:35.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.019725093s
Oct  3 19:16:37.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.020463015s
Oct  3 19:16:39.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.019765829s
Oct  3 19:16:41.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.019478598s
Oct  3 19:16:43.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.020161579s
Oct  3 19:16:45.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.019168027s
Oct  3 19:16:47.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.019040846s
Oct  3 19:16:49.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.020187531s
Oct  3 19:16:51.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.020157053s
Oct  3 19:16:53.570: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.021195303s
Oct  3 19:16:55.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.019613341s
Oct  3 19:16:57.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.019639582s
Oct  3 19:16:59.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.019707582s
Oct  3 19:17:01.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.020033763s
Oct  3 19:17:03.570: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.021365055s
Oct  3 19:17:05.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.019346879s
Oct  3 19:17:07.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.02022774s
Oct  3 19:17:09.570: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.02134884s
Oct  3 19:17:11.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.020473442s
Oct  3 19:17:13.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.020795273s
Oct  3 19:17:15.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.019498122s
Oct  3 19:17:17.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.019905128s
Oct  3 19:17:17.577: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.028545873s
STEP: updating the pod 10/03/22 19:17:17.577
Oct  3 19:17:18.103: INFO: Successfully updated pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9"
STEP: waiting for pod running 10/03/22 19:17:18.103
Oct  3 19:17:18.103: INFO: Waiting up to 2m0s for pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9" in namespace "var-expansion-756" to be "running"
Oct  3 19:17:18.112: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.211241ms
Oct  3 19:17:20.123: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Running", Reason="", readiness=true. Elapsed: 2.01997854s
Oct  3 19:17:20.123: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9" satisfied condition "running"
STEP: deleting the pod gracefully 10/03/22 19:17:20.123
Oct  3 19:17:20.123: INFO: Deleting pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9" in namespace "var-expansion-756"
Oct  3 19:17:20.141: INFO: Wait up to 5m0s for pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Oct  3 19:17:52.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-756" for this suite. 10/03/22 19:17:52.175
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":11,"skipped":248,"failed":0}
------------------------------
• [SLOW TEST] [154.710 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:15:17.484
    Oct  3 19:15:17.484: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename var-expansion 10/03/22 19:15:17.486
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:15:17.517
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:15:17.523
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 10/03/22 19:15:17.528
    Oct  3 19:15:17.548: INFO: Waiting up to 2m0s for pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9" in namespace "var-expansion-756" to be "running"
    Oct  3 19:15:17.557: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.042216ms
    Oct  3 19:15:19.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019391735s
    Oct  3 19:15:21.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02009014s
    Oct  3 19:15:23.570: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021220497s
    Oct  3 19:15:25.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.018380229s
    Oct  3 19:15:27.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.018888095s
    Oct  3 19:15:29.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.020018746s
    Oct  3 19:15:31.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.019553868s
    Oct  3 19:15:33.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.020115715s
    Oct  3 19:15:35.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.01985287s
    Oct  3 19:15:37.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 20.020169193s
    Oct  3 19:15:39.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 22.019554024s
    Oct  3 19:15:41.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 24.019973424s
    Oct  3 19:15:43.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 26.018420277s
    Oct  3 19:15:45.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 28.019189432s
    Oct  3 19:15:47.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 30.019814306s
    Oct  3 19:15:49.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 32.019369728s
    Oct  3 19:15:51.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 34.018724577s
    Oct  3 19:15:53.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 36.020618316s
    Oct  3 19:15:55.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 38.019838997s
    Oct  3 19:15:57.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 40.020978189s
    Oct  3 19:15:59.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 42.019974108s
    Oct  3 19:16:01.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 44.019219993s
    Oct  3 19:16:03.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 46.020460896s
    Oct  3 19:16:05.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 48.019033902s
    Oct  3 19:16:07.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 50.020498458s
    Oct  3 19:16:09.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 52.018908078s
    Oct  3 19:16:11.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 54.019263848s
    Oct  3 19:16:13.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 56.019056924s
    Oct  3 19:16:15.587: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 58.038809293s
    Oct  3 19:16:17.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.020051826s
    Oct  3 19:16:19.570: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.021662371s
    Oct  3 19:16:21.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.019312829s
    Oct  3 19:16:23.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.02007119s
    Oct  3 19:16:25.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.019582656s
    Oct  3 19:16:27.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.019673991s
    Oct  3 19:16:29.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.019673697s
    Oct  3 19:16:31.571: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.022762317s
    Oct  3 19:16:33.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.020259105s
    Oct  3 19:16:35.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.019725093s
    Oct  3 19:16:37.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.020463015s
    Oct  3 19:16:39.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.019765829s
    Oct  3 19:16:41.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.019478598s
    Oct  3 19:16:43.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.020161579s
    Oct  3 19:16:45.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.019168027s
    Oct  3 19:16:47.567: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.019040846s
    Oct  3 19:16:49.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.020187531s
    Oct  3 19:16:51.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.020157053s
    Oct  3 19:16:53.570: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.021195303s
    Oct  3 19:16:55.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.019613341s
    Oct  3 19:16:57.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.019639582s
    Oct  3 19:16:59.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.019707582s
    Oct  3 19:17:01.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.020033763s
    Oct  3 19:17:03.570: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.021365055s
    Oct  3 19:17:05.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.019346879s
    Oct  3 19:17:07.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.02022774s
    Oct  3 19:17:09.570: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.02134884s
    Oct  3 19:17:11.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.020473442s
    Oct  3 19:17:13.569: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.020795273s
    Oct  3 19:17:15.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.019498122s
    Oct  3 19:17:17.568: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.019905128s
    Oct  3 19:17:17.577: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.028545873s
    STEP: updating the pod 10/03/22 19:17:17.577
    Oct  3 19:17:18.103: INFO: Successfully updated pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9"
    STEP: waiting for pod running 10/03/22 19:17:18.103
    Oct  3 19:17:18.103: INFO: Waiting up to 2m0s for pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9" in namespace "var-expansion-756" to be "running"
    Oct  3 19:17:18.112: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.211241ms
    Oct  3 19:17:20.123: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9": Phase="Running", Reason="", readiness=true. Elapsed: 2.01997854s
    Oct  3 19:17:20.123: INFO: Pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9" satisfied condition "running"
    STEP: deleting the pod gracefully 10/03/22 19:17:20.123
    Oct  3 19:17:20.123: INFO: Deleting pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9" in namespace "var-expansion-756"
    Oct  3 19:17:20.141: INFO: Wait up to 5m0s for pod "var-expansion-c4fa20b5-4700-4fa6-b7b1-afb211ffcbe9" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Oct  3 19:17:52.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-756" for this suite. 10/03/22 19:17:52.175
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:17:52.199
Oct  3 19:17:52.199: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename resourcequota 10/03/22 19:17:52.201
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:17:52.254
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:17:52.273
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 10/03/22 19:17:52.279
STEP: Ensuring ResourceQuota status is calculated 10/03/22 19:17:52.292
STEP: Creating a ResourceQuota with not best effort scope 10/03/22 19:17:54.308
STEP: Ensuring ResourceQuota status is calculated 10/03/22 19:17:54.32
STEP: Creating a best-effort pod 10/03/22 19:17:56.33
STEP: Ensuring resource quota with best effort scope captures the pod usage 10/03/22 19:17:56.358
STEP: Ensuring resource quota with not best effort ignored the pod usage 10/03/22 19:17:58.37
STEP: Deleting the pod 10/03/22 19:18:00.381
STEP: Ensuring resource quota status released the pod usage 10/03/22 19:18:00.411
STEP: Creating a not best-effort pod 10/03/22 19:18:02.424
STEP: Ensuring resource quota with not best effort scope captures the pod usage 10/03/22 19:18:02.451
STEP: Ensuring resource quota with best effort scope ignored the pod usage 10/03/22 19:18:04.463
STEP: Deleting the pod 10/03/22 19:18:06.473
STEP: Ensuring resource quota status released the pod usage 10/03/22 19:18:06.497
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Oct  3 19:18:08.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4507" for this suite. 10/03/22 19:18:08.521
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":12,"skipped":275,"failed":0}
------------------------------
• [SLOW TEST] [16.356 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:17:52.199
    Oct  3 19:17:52.199: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename resourcequota 10/03/22 19:17:52.201
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:17:52.254
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:17:52.273
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 10/03/22 19:17:52.279
    STEP: Ensuring ResourceQuota status is calculated 10/03/22 19:17:52.292
    STEP: Creating a ResourceQuota with not best effort scope 10/03/22 19:17:54.308
    STEP: Ensuring ResourceQuota status is calculated 10/03/22 19:17:54.32
    STEP: Creating a best-effort pod 10/03/22 19:17:56.33
    STEP: Ensuring resource quota with best effort scope captures the pod usage 10/03/22 19:17:56.358
    STEP: Ensuring resource quota with not best effort ignored the pod usage 10/03/22 19:17:58.37
    STEP: Deleting the pod 10/03/22 19:18:00.381
    STEP: Ensuring resource quota status released the pod usage 10/03/22 19:18:00.411
    STEP: Creating a not best-effort pod 10/03/22 19:18:02.424
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 10/03/22 19:18:02.451
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 10/03/22 19:18:04.463
    STEP: Deleting the pod 10/03/22 19:18:06.473
    STEP: Ensuring resource quota status released the pod usage 10/03/22 19:18:06.497
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Oct  3 19:18:08.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4507" for this suite. 10/03/22 19:18:08.521
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:18:08.556
Oct  3 19:18:08.556: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 19:18:08.557
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:18:08.586
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:18:08.592
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 10/03/22 19:18:08.598
Oct  3 19:18:08.619: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b" in namespace "projected-9016" to be "Succeeded or Failed"
Oct  3 19:18:08.627: INFO: Pod "downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.223555ms
Oct  3 19:18:10.637: INFO: Pod "downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018088383s
Oct  3 19:18:12.637: INFO: Pod "downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018199837s
Oct  3 19:18:14.638: INFO: Pod "downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018804153s
STEP: Saw pod success 10/03/22 19:18:14.638
Oct  3 19:18:14.638: INFO: Pod "downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b" satisfied condition "Succeeded or Failed"
Oct  3 19:18:14.647: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b container client-container: <nil>
STEP: delete the pod 10/03/22 19:18:14.74
Oct  3 19:18:14.772: INFO: Waiting for pod downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b to disappear
Oct  3 19:18:14.781: INFO: Pod downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Oct  3 19:18:14.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9016" for this suite. 10/03/22 19:18:14.795
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":13,"skipped":275,"failed":0}
------------------------------
• [SLOW TEST] [6.257 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:18:08.556
    Oct  3 19:18:08.556: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 19:18:08.557
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:18:08.586
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:18:08.592
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 10/03/22 19:18:08.598
    Oct  3 19:18:08.619: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b" in namespace "projected-9016" to be "Succeeded or Failed"
    Oct  3 19:18:08.627: INFO: Pod "downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.223555ms
    Oct  3 19:18:10.637: INFO: Pod "downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018088383s
    Oct  3 19:18:12.637: INFO: Pod "downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018199837s
    Oct  3 19:18:14.638: INFO: Pod "downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018804153s
    STEP: Saw pod success 10/03/22 19:18:14.638
    Oct  3 19:18:14.638: INFO: Pod "downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b" satisfied condition "Succeeded or Failed"
    Oct  3 19:18:14.647: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b container client-container: <nil>
    STEP: delete the pod 10/03/22 19:18:14.74
    Oct  3 19:18:14.772: INFO: Waiting for pod downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b to disappear
    Oct  3 19:18:14.781: INFO: Pod downwardapi-volume-e37bba85-54ce-47a1-9226-c74bef18d31b no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Oct  3 19:18:14.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9016" for this suite. 10/03/22 19:18:14.795
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:18:14.816
Oct  3 19:18:14.816: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 19:18:14.817
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:18:14.853
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:18:14.859
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 10/03/22 19:18:14.869
Oct  3 19:18:14.888: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2" in namespace "projected-5789" to be "Succeeded or Failed"
Oct  3 19:18:14.897: INFO: Pod "downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.842768ms
Oct  3 19:18:16.908: INFO: Pod "downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019898855s
Oct  3 19:18:18.906: INFO: Pod "downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018358383s
STEP: Saw pod success 10/03/22 19:18:18.906
Oct  3 19:18:18.906: INFO: Pod "downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2" satisfied condition "Succeeded or Failed"
Oct  3 19:18:18.915: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2 container client-container: <nil>
STEP: delete the pod 10/03/22 19:18:18.939
Oct  3 19:18:18.964: INFO: Waiting for pod downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2 to disappear
Oct  3 19:18:18.973: INFO: Pod downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Oct  3 19:18:18.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5789" for this suite. 10/03/22 19:18:18.986
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":14,"skipped":300,"failed":0}
------------------------------
• [4.189 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:18:14.816
    Oct  3 19:18:14.816: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 19:18:14.817
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:18:14.853
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:18:14.859
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 10/03/22 19:18:14.869
    Oct  3 19:18:14.888: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2" in namespace "projected-5789" to be "Succeeded or Failed"
    Oct  3 19:18:14.897: INFO: Pod "downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.842768ms
    Oct  3 19:18:16.908: INFO: Pod "downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019898855s
    Oct  3 19:18:18.906: INFO: Pod "downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018358383s
    STEP: Saw pod success 10/03/22 19:18:18.906
    Oct  3 19:18:18.906: INFO: Pod "downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2" satisfied condition "Succeeded or Failed"
    Oct  3 19:18:18.915: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2 container client-container: <nil>
    STEP: delete the pod 10/03/22 19:18:18.939
    Oct  3 19:18:18.964: INFO: Waiting for pod downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2 to disappear
    Oct  3 19:18:18.973: INFO: Pod downwardapi-volume-5778503b-1862-4d7b-941e-b9cd7ca29dc2 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Oct  3 19:18:18.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5789" for this suite. 10/03/22 19:18:18.986
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:18:19.007
Oct  3 19:18:19.007: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename secrets 10/03/22 19:18:19.008
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:18:19.038
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:18:19.043
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-a5543c1b-d147-494b-9239-bb8e6454354f 10/03/22 19:18:19.049
STEP: Creating a pod to test consume secrets 10/03/22 19:18:19.061
Oct  3 19:18:19.079: INFO: Waiting up to 5m0s for pod "pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8" in namespace "secrets-4418" to be "Succeeded or Failed"
Oct  3 19:18:19.092: INFO: Pod "pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.235763ms
Oct  3 19:18:21.115: INFO: Pod "pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035527621s
Oct  3 19:18:23.102: INFO: Pod "pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022568596s
STEP: Saw pod success 10/03/22 19:18:23.102
Oct  3 19:18:23.102: INFO: Pod "pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8" satisfied condition "Succeeded or Failed"
Oct  3 19:18:23.110: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8 container secret-env-test: <nil>
STEP: delete the pod 10/03/22 19:18:23.133
Oct  3 19:18:23.156: INFO: Waiting for pod pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8 to disappear
Oct  3 19:18:23.165: INFO: Pod pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Oct  3 19:18:23.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4418" for this suite. 10/03/22 19:18:23.179
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":15,"skipped":325,"failed":0}
------------------------------
• [4.194 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:18:19.007
    Oct  3 19:18:19.007: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename secrets 10/03/22 19:18:19.008
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:18:19.038
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:18:19.043
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-a5543c1b-d147-494b-9239-bb8e6454354f 10/03/22 19:18:19.049
    STEP: Creating a pod to test consume secrets 10/03/22 19:18:19.061
    Oct  3 19:18:19.079: INFO: Waiting up to 5m0s for pod "pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8" in namespace "secrets-4418" to be "Succeeded or Failed"
    Oct  3 19:18:19.092: INFO: Pod "pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.235763ms
    Oct  3 19:18:21.115: INFO: Pod "pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035527621s
    Oct  3 19:18:23.102: INFO: Pod "pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022568596s
    STEP: Saw pod success 10/03/22 19:18:23.102
    Oct  3 19:18:23.102: INFO: Pod "pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8" satisfied condition "Succeeded or Failed"
    Oct  3 19:18:23.110: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8 container secret-env-test: <nil>
    STEP: delete the pod 10/03/22 19:18:23.133
    Oct  3 19:18:23.156: INFO: Waiting for pod pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8 to disappear
    Oct  3 19:18:23.165: INFO: Pod pod-secrets-ea160078-a52e-4f45-9177-f4e54a3c84e8 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Oct  3 19:18:23.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4418" for this suite. 10/03/22 19:18:23.179
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:18:23.204
Oct  3 19:18:23.204: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 19:18:23.205
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:18:23.236
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:18:23.242
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 19:18:23.279
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 19:18:23.749
STEP: Deploying the webhook pod 10/03/22 19:18:23.77
STEP: Wait for the deployment to be ready 10/03/22 19:18:23.795
Oct  3 19:18:23.815: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  3 19:18:25.845: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 18, 23, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 18, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 18, 23, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 18, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 10/03/22 19:18:27.859
STEP: Verifying the service has paired with the endpoint 10/03/22 19:18:27.889
Oct  3 19:18:28.890: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Oct  3 19:18:28.902: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6575-crds.webhook.example.com via the AdmissionRegistration API 10/03/22 19:18:29.421
STEP: Creating a custom resource that should be mutated by the webhook 10/03/22 19:18:29.484
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 19:18:32.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-688" for this suite. 10/03/22 19:18:32.189
STEP: Destroying namespace "webhook-688-markers" for this suite. 10/03/22 19:18:32.207
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":16,"skipped":351,"failed":0}
------------------------------
• [SLOW TEST] [9.128 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:18:23.204
    Oct  3 19:18:23.204: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 19:18:23.205
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:18:23.236
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:18:23.242
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 19:18:23.279
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 19:18:23.749
    STEP: Deploying the webhook pod 10/03/22 19:18:23.77
    STEP: Wait for the deployment to be ready 10/03/22 19:18:23.795
    Oct  3 19:18:23.815: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Oct  3 19:18:25.845: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 18, 23, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 18, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 18, 23, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 18, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 10/03/22 19:18:27.859
    STEP: Verifying the service has paired with the endpoint 10/03/22 19:18:27.889
    Oct  3 19:18:28.890: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Oct  3 19:18:28.902: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6575-crds.webhook.example.com via the AdmissionRegistration API 10/03/22 19:18:29.421
    STEP: Creating a custom resource that should be mutated by the webhook 10/03/22 19:18:29.484
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 19:18:32.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-688" for this suite. 10/03/22 19:18:32.189
    STEP: Destroying namespace "webhook-688-markers" for this suite. 10/03/22 19:18:32.207
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:18:32.337
Oct  3 19:18:32.338: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename crd-watch 10/03/22 19:18:32.338
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:18:32.377
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:18:32.383
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Oct  3 19:18:32.388: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Creating first CR  10/03/22 19:18:34.978
Oct  3 19:18:34.991: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-03T19:18:34Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-03T19:18:34Z]] name:name1 resourceVersion:16918 uid:8d54b0ed-d19a-413c-8cd1-fa7674d6f07b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 10/03/22 19:18:44.994
Oct  3 19:18:45.007: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-03T19:18:44Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-03T19:18:44Z]] name:name2 resourceVersion:16942 uid:650fb527-0563-470b-8560-6a75c65a8407] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 10/03/22 19:18:55.012
Oct  3 19:18:55.026: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-03T19:18:34Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-03T19:18:55Z]] name:name1 resourceVersion:16951 uid:8d54b0ed-d19a-413c-8cd1-fa7674d6f07b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 10/03/22 19:19:05.027
Oct  3 19:19:05.040: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-03T19:18:44Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-03T19:19:05Z]] name:name2 resourceVersion:16962 uid:650fb527-0563-470b-8560-6a75c65a8407] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 10/03/22 19:19:15.044
Oct  3 19:19:15.064: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-03T19:18:34Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-03T19:18:55Z]] name:name1 resourceVersion:16971 uid:8d54b0ed-d19a-413c-8cd1-fa7674d6f07b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 10/03/22 19:19:25.064
Oct  3 19:19:25.084: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-03T19:18:44Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-03T19:19:05Z]] name:name2 resourceVersion:16981 uid:650fb527-0563-470b-8560-6a75c65a8407] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 19:19:35.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-7396" for this suite. 10/03/22 19:19:35.627
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":17,"skipped":357,"failed":0}
------------------------------
• [SLOW TEST] [63.306 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:18:32.337
    Oct  3 19:18:32.338: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename crd-watch 10/03/22 19:18:32.338
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:18:32.377
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:18:32.383
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Oct  3 19:18:32.388: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Creating first CR  10/03/22 19:18:34.978
    Oct  3 19:18:34.991: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-03T19:18:34Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-03T19:18:34Z]] name:name1 resourceVersion:16918 uid:8d54b0ed-d19a-413c-8cd1-fa7674d6f07b] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 10/03/22 19:18:44.994
    Oct  3 19:18:45.007: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-03T19:18:44Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-03T19:18:44Z]] name:name2 resourceVersion:16942 uid:650fb527-0563-470b-8560-6a75c65a8407] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 10/03/22 19:18:55.012
    Oct  3 19:18:55.026: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-03T19:18:34Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-03T19:18:55Z]] name:name1 resourceVersion:16951 uid:8d54b0ed-d19a-413c-8cd1-fa7674d6f07b] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 10/03/22 19:19:05.027
    Oct  3 19:19:05.040: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-03T19:18:44Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-03T19:19:05Z]] name:name2 resourceVersion:16962 uid:650fb527-0563-470b-8560-6a75c65a8407] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 10/03/22 19:19:15.044
    Oct  3 19:19:15.064: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-03T19:18:34Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-03T19:18:55Z]] name:name1 resourceVersion:16971 uid:8d54b0ed-d19a-413c-8cd1-fa7674d6f07b] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 10/03/22 19:19:25.064
    Oct  3 19:19:25.084: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-03T19:18:44Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-03T19:19:05Z]] name:name2 resourceVersion:16981 uid:650fb527-0563-470b-8560-6a75c65a8407] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 19:19:35.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-7396" for this suite. 10/03/22 19:19:35.627
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:19:35.647
Oct  3 19:19:35.647: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename pods 10/03/22 19:19:35.649
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:19:35.689
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:19:35.694
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Oct  3 19:19:35.700: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: creating the pod 10/03/22 19:19:35.701
STEP: submitting the pod to kubernetes 10/03/22 19:19:35.702
Oct  3 19:19:35.720: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30" in namespace "pods-4280" to be "running and ready"
Oct  3 19:19:35.735: INFO: Pod "pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30": Phase="Pending", Reason="", readiness=false. Elapsed: 15.155556ms
Oct  3 19:19:35.736: INFO: The phase of Pod pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:19:37.746: INFO: Pod "pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025816496s
Oct  3 19:19:37.746: INFO: The phase of Pod pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:19:39.745: INFO: Pod "pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30": Phase="Running", Reason="", readiness=true. Elapsed: 4.024991787s
Oct  3 19:19:39.745: INFO: The phase of Pod pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30 is Running (Ready = true)
Oct  3 19:19:39.746: INFO: Pod "pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Oct  3 19:19:39.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4280" for this suite. 10/03/22 19:19:39.837
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":18,"skipped":395,"failed":0}
------------------------------
• [4.207 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:19:35.647
    Oct  3 19:19:35.647: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename pods 10/03/22 19:19:35.649
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:19:35.689
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:19:35.694
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Oct  3 19:19:35.700: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: creating the pod 10/03/22 19:19:35.701
    STEP: submitting the pod to kubernetes 10/03/22 19:19:35.702
    Oct  3 19:19:35.720: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30" in namespace "pods-4280" to be "running and ready"
    Oct  3 19:19:35.735: INFO: Pod "pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30": Phase="Pending", Reason="", readiness=false. Elapsed: 15.155556ms
    Oct  3 19:19:35.736: INFO: The phase of Pod pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:19:37.746: INFO: Pod "pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025816496s
    Oct  3 19:19:37.746: INFO: The phase of Pod pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:19:39.745: INFO: Pod "pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30": Phase="Running", Reason="", readiness=true. Elapsed: 4.024991787s
    Oct  3 19:19:39.745: INFO: The phase of Pod pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30 is Running (Ready = true)
    Oct  3 19:19:39.746: INFO: Pod "pod-logs-websocket-8d6930d7-e609-4cea-9092-109a64bd4b30" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Oct  3 19:19:39.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4280" for this suite. 10/03/22 19:19:39.837
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:19:39.855
Oct  3 19:19:39.855: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename pods 10/03/22 19:19:39.856
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:19:39.885
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:19:39.89
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 10/03/22 19:19:39.896
STEP: setting up watch 10/03/22 19:19:39.896
STEP: submitting the pod to kubernetes 10/03/22 19:19:40.005
STEP: verifying the pod is in kubernetes 10/03/22 19:19:40.023
STEP: verifying pod creation was observed 10/03/22 19:19:40.031
Oct  3 19:19:40.031: INFO: Waiting up to 5m0s for pod "pod-submit-remove-034122bb-5d09-4e3d-ac79-cd71f89a6527" in namespace "pods-6695" to be "running"
Oct  3 19:19:40.039: INFO: Pod "pod-submit-remove-034122bb-5d09-4e3d-ac79-cd71f89a6527": Phase="Pending", Reason="", readiness=false. Elapsed: 7.952631ms
Oct  3 19:19:42.049: INFO: Pod "pod-submit-remove-034122bb-5d09-4e3d-ac79-cd71f89a6527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017320915s
Oct  3 19:19:44.050: INFO: Pod "pod-submit-remove-034122bb-5d09-4e3d-ac79-cd71f89a6527": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018627564s
Oct  3 19:19:46.050: INFO: Pod "pod-submit-remove-034122bb-5d09-4e3d-ac79-cd71f89a6527": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018220235s
Oct  3 19:19:48.050: INFO: Pod "pod-submit-remove-034122bb-5d09-4e3d-ac79-cd71f89a6527": Phase="Running", Reason="", readiness=true. Elapsed: 8.018465107s
Oct  3 19:19:48.050: INFO: Pod "pod-submit-remove-034122bb-5d09-4e3d-ac79-cd71f89a6527" satisfied condition "running"
STEP: deleting the pod gracefully 10/03/22 19:19:48.06
STEP: verifying pod deletion was observed 10/03/22 19:19:48.078
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Oct  3 19:19:49.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6695" for this suite. 10/03/22 19:19:49.413
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":19,"skipped":400,"failed":0}
------------------------------
• [SLOW TEST] [9.579 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:19:39.855
    Oct  3 19:19:39.855: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename pods 10/03/22 19:19:39.856
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:19:39.885
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:19:39.89
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 10/03/22 19:19:39.896
    STEP: setting up watch 10/03/22 19:19:39.896
    STEP: submitting the pod to kubernetes 10/03/22 19:19:40.005
    STEP: verifying the pod is in kubernetes 10/03/22 19:19:40.023
    STEP: verifying pod creation was observed 10/03/22 19:19:40.031
    Oct  3 19:19:40.031: INFO: Waiting up to 5m0s for pod "pod-submit-remove-034122bb-5d09-4e3d-ac79-cd71f89a6527" in namespace "pods-6695" to be "running"
    Oct  3 19:19:40.039: INFO: Pod "pod-submit-remove-034122bb-5d09-4e3d-ac79-cd71f89a6527": Phase="Pending", Reason="", readiness=false. Elapsed: 7.952631ms
    Oct  3 19:19:42.049: INFO: Pod "pod-submit-remove-034122bb-5d09-4e3d-ac79-cd71f89a6527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017320915s
    Oct  3 19:19:44.050: INFO: Pod "pod-submit-remove-034122bb-5d09-4e3d-ac79-cd71f89a6527": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018627564s
    Oct  3 19:19:46.050: INFO: Pod "pod-submit-remove-034122bb-5d09-4e3d-ac79-cd71f89a6527": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018220235s
    Oct  3 19:19:48.050: INFO: Pod "pod-submit-remove-034122bb-5d09-4e3d-ac79-cd71f89a6527": Phase="Running", Reason="", readiness=true. Elapsed: 8.018465107s
    Oct  3 19:19:48.050: INFO: Pod "pod-submit-remove-034122bb-5d09-4e3d-ac79-cd71f89a6527" satisfied condition "running"
    STEP: deleting the pod gracefully 10/03/22 19:19:48.06
    STEP: verifying pod deletion was observed 10/03/22 19:19:48.078
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Oct  3 19:19:49.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6695" for this suite. 10/03/22 19:19:49.413
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:19:49.435
Oct  3 19:19:49.435: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename taint-multiple-pods 10/03/22 19:19:49.436
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:19:49.466
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:19:49.472
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Oct  3 19:19:49.479: INFO: Waiting up to 1m0s for all nodes to be ready
Oct  3 19:20:49.535: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Oct  3 19:20:49.546: INFO: Starting informer...
STEP: Starting pods... 10/03/22 19:20:49.546
Oct  3 19:20:49.791: INFO: Pod1 is running on 10.63.128.3. Tainting Node
Oct  3 19:20:50.009: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-1552" to be "running"
Oct  3 19:20:50.017: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.26124ms
Oct  3 19:20:52.028: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.019427045s
Oct  3 19:20:52.029: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Oct  3 19:20:52.029: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-1552" to be "running"
Oct  3 19:20:52.038: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 9.606335ms
Oct  3 19:20:52.038: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Oct  3 19:20:52.038: INFO: Pod2 is running on 10.63.128.3. Tainting Node
STEP: Trying to apply a taint on the Node 10/03/22 19:20:52.038
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/03/22 19:20:52.067
STEP: Waiting for Pod1 and Pod2 to be deleted 10/03/22 19:20:52.077
Oct  3 19:20:58.772: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Oct  3 19:21:18.869: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/03/22 19:21:18.902
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Oct  3 19:21:18.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-1552" for this suite. 10/03/22 19:21:18.926
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":20,"skipped":405,"failed":0}
------------------------------
• [SLOW TEST] [89.508 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:19:49.435
    Oct  3 19:19:49.435: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename taint-multiple-pods 10/03/22 19:19:49.436
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:19:49.466
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:19:49.472
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Oct  3 19:19:49.479: INFO: Waiting up to 1m0s for all nodes to be ready
    Oct  3 19:20:49.535: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Oct  3 19:20:49.546: INFO: Starting informer...
    STEP: Starting pods... 10/03/22 19:20:49.546
    Oct  3 19:20:49.791: INFO: Pod1 is running on 10.63.128.3. Tainting Node
    Oct  3 19:20:50.009: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-1552" to be "running"
    Oct  3 19:20:50.017: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.26124ms
    Oct  3 19:20:52.028: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.019427045s
    Oct  3 19:20:52.029: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Oct  3 19:20:52.029: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-1552" to be "running"
    Oct  3 19:20:52.038: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 9.606335ms
    Oct  3 19:20:52.038: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Oct  3 19:20:52.038: INFO: Pod2 is running on 10.63.128.3. Tainting Node
    STEP: Trying to apply a taint on the Node 10/03/22 19:20:52.038
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/03/22 19:20:52.067
    STEP: Waiting for Pod1 and Pod2 to be deleted 10/03/22 19:20:52.077
    Oct  3 19:20:58.772: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Oct  3 19:21:18.869: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/03/22 19:21:18.902
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 19:21:18.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-1552" for this suite. 10/03/22 19:21:18.926
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:21:18.946
Oct  3 19:21:18.946: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 19:21:18.947
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:21:18.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:21:18.982
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-59ed9107-f9d4-4cd4-8da7-69d05a183614 10/03/22 19:21:18.987
STEP: Creating a pod to test consume configMaps 10/03/22 19:21:18.998
Oct  3 19:21:19.016: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a" in namespace "projected-1510" to be "Succeeded or Failed"
Oct  3 19:21:19.024: INFO: Pod "pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.080419ms
Oct  3 19:21:21.033: INFO: Pod "pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017301511s
Oct  3 19:21:23.034: INFO: Pod "pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017938555s
STEP: Saw pod success 10/03/22 19:21:23.034
Oct  3 19:21:23.034: INFO: Pod "pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a" satisfied condition "Succeeded or Failed"
Oct  3 19:21:23.043: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a container agnhost-container: <nil>
STEP: delete the pod 10/03/22 19:21:23.104
Oct  3 19:21:23.134: INFO: Waiting for pod pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a to disappear
Oct  3 19:21:23.142: INFO: Pod pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Oct  3 19:21:23.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1510" for this suite. 10/03/22 19:21:23.157
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":21,"skipped":430,"failed":0}
------------------------------
• [4.227 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:21:18.946
    Oct  3 19:21:18.946: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 19:21:18.947
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:21:18.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:21:18.982
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-59ed9107-f9d4-4cd4-8da7-69d05a183614 10/03/22 19:21:18.987
    STEP: Creating a pod to test consume configMaps 10/03/22 19:21:18.998
    Oct  3 19:21:19.016: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a" in namespace "projected-1510" to be "Succeeded or Failed"
    Oct  3 19:21:19.024: INFO: Pod "pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.080419ms
    Oct  3 19:21:21.033: INFO: Pod "pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017301511s
    Oct  3 19:21:23.034: INFO: Pod "pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017938555s
    STEP: Saw pod success 10/03/22 19:21:23.034
    Oct  3 19:21:23.034: INFO: Pod "pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a" satisfied condition "Succeeded or Failed"
    Oct  3 19:21:23.043: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 19:21:23.104
    Oct  3 19:21:23.134: INFO: Waiting for pod pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a to disappear
    Oct  3 19:21:23.142: INFO: Pod pod-projected-configmaps-67017e96-1668-41da-8cc1-209baa486d8a no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Oct  3 19:21:23.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1510" for this suite. 10/03/22 19:21:23.157
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:21:23.197
Oct  3 19:21:23.197: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-probe 10/03/22 19:21:23.198
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:21:23.228
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:21:23.238
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Oct  3 19:21:23.262: INFO: Waiting up to 5m0s for pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268" in namespace "container-probe-7731" to be "running and ready"
Oct  3 19:21:23.270: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Pending", Reason="", readiness=false. Elapsed: 8.071533ms
Oct  3 19:21:23.270: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:21:25.280: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 2.018441908s
Oct  3 19:21:25.280: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
Oct  3 19:21:27.281: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 4.019153427s
Oct  3 19:21:27.281: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
Oct  3 19:21:29.282: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 6.019820608s
Oct  3 19:21:29.282: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
Oct  3 19:21:31.280: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 8.018326185s
Oct  3 19:21:31.280: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
Oct  3 19:21:33.283: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 10.021746294s
Oct  3 19:21:33.284: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
Oct  3 19:21:35.280: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 12.018345984s
Oct  3 19:21:35.280: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
Oct  3 19:21:37.283: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 14.020863341s
Oct  3 19:21:37.283: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
Oct  3 19:21:39.282: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 16.020449898s
Oct  3 19:21:39.282: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
Oct  3 19:21:41.280: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 18.018792193s
Oct  3 19:21:41.281: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
Oct  3 19:21:43.280: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 20.017933794s
Oct  3 19:21:43.280: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
Oct  3 19:21:45.280: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=true. Elapsed: 22.018164878s
Oct  3 19:21:45.280: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = true)
Oct  3 19:21:45.280: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268" satisfied condition "running and ready"
Oct  3 19:21:45.288: INFO: Container started at 2022-10-03 19:21:24 +0000 UTC, pod became ready at 2022-10-03 19:21:43 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Oct  3 19:21:45.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7731" for this suite. 10/03/22 19:21:45.3
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":22,"skipped":506,"failed":0}
------------------------------
• [SLOW TEST] [22.120 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:21:23.197
    Oct  3 19:21:23.197: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-probe 10/03/22 19:21:23.198
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:21:23.228
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:21:23.238
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Oct  3 19:21:23.262: INFO: Waiting up to 5m0s for pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268" in namespace "container-probe-7731" to be "running and ready"
    Oct  3 19:21:23.270: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Pending", Reason="", readiness=false. Elapsed: 8.071533ms
    Oct  3 19:21:23.270: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:21:25.280: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 2.018441908s
    Oct  3 19:21:25.280: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
    Oct  3 19:21:27.281: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 4.019153427s
    Oct  3 19:21:27.281: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
    Oct  3 19:21:29.282: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 6.019820608s
    Oct  3 19:21:29.282: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
    Oct  3 19:21:31.280: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 8.018326185s
    Oct  3 19:21:31.280: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
    Oct  3 19:21:33.283: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 10.021746294s
    Oct  3 19:21:33.284: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
    Oct  3 19:21:35.280: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 12.018345984s
    Oct  3 19:21:35.280: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
    Oct  3 19:21:37.283: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 14.020863341s
    Oct  3 19:21:37.283: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
    Oct  3 19:21:39.282: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 16.020449898s
    Oct  3 19:21:39.282: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
    Oct  3 19:21:41.280: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 18.018792193s
    Oct  3 19:21:41.281: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
    Oct  3 19:21:43.280: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=false. Elapsed: 20.017933794s
    Oct  3 19:21:43.280: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = false)
    Oct  3 19:21:45.280: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268": Phase="Running", Reason="", readiness=true. Elapsed: 22.018164878s
    Oct  3 19:21:45.280: INFO: The phase of Pod test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268 is Running (Ready = true)
    Oct  3 19:21:45.280: INFO: Pod "test-webserver-c5d10a67-fd75-42b0-b7b4-86a2beb62268" satisfied condition "running and ready"
    Oct  3 19:21:45.288: INFO: Container started at 2022-10-03 19:21:24 +0000 UTC, pod became ready at 2022-10-03 19:21:43 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Oct  3 19:21:45.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7731" for this suite. 10/03/22 19:21:45.3
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:21:45.319
Oct  3 19:21:45.319: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename init-container 10/03/22 19:21:45.32
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:21:45.349
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:21:45.354
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 10/03/22 19:21:45.36
Oct  3 19:21:45.360: INFO: PodSpec: initContainers in spec.initContainers
Oct  3 19:22:31.257: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-b3ff3e2b-418a-4e1e-ab35-c3102738ca06", GenerateName:"", Namespace:"init-container-7643", SelfLink:"", UID:"e3c2349e-87f7-4ee5-91ab-177bdc4e673a", ResourceVersion:"17595", Generation:0, CreationTimestamp:time.Date(2022, time.October, 3, 19, 21, 45, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"360729834"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"030838f0183c968b353601d7f97559d50db721adec95360fd3c1b689adb19753", "cni.projectcalico.org/podIP":"172.30.49.30/32", "cni.projectcalico.org/podIPs":"172.30.49.30/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.October, 3, 19, 21, 45, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001068948), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.October, 3, 19, 21, 46, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001068990), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.October, 3, 19, 22, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0010689c0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-brkgd", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0035e9080), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-brkgd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-brkgd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-brkgd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0024968c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.63.128.3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000597650), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002496950)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002496970)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002496978), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00249697c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000217300), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.October, 3, 19, 21, 45, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.October, 3, 19, 21, 45, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.October, 3, 19, 21, 45, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.October, 3, 19, 21, 45, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.63.128.3", PodIP:"172.30.49.30", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.30.49.30"}}, StartTime:time.Date(2022, time.October, 3, 19, 21, 45, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000597810)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000597880)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://ac49cc0d574a12e3a7fda828263fcaf00def947b7f3f5630b5b8c27c99793278", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0035e9100), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0035e90e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc0024969ff)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Oct  3 19:22:31.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7643" for this suite. 10/03/22 19:22:31.271
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":23,"skipped":513,"failed":0}
------------------------------
• [SLOW TEST] [45.968 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:21:45.319
    Oct  3 19:21:45.319: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename init-container 10/03/22 19:21:45.32
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:21:45.349
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:21:45.354
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 10/03/22 19:21:45.36
    Oct  3 19:21:45.360: INFO: PodSpec: initContainers in spec.initContainers
    Oct  3 19:22:31.257: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-b3ff3e2b-418a-4e1e-ab35-c3102738ca06", GenerateName:"", Namespace:"init-container-7643", SelfLink:"", UID:"e3c2349e-87f7-4ee5-91ab-177bdc4e673a", ResourceVersion:"17595", Generation:0, CreationTimestamp:time.Date(2022, time.October, 3, 19, 21, 45, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"360729834"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"030838f0183c968b353601d7f97559d50db721adec95360fd3c1b689adb19753", "cni.projectcalico.org/podIP":"172.30.49.30/32", "cni.projectcalico.org/podIPs":"172.30.49.30/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.October, 3, 19, 21, 45, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001068948), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.October, 3, 19, 21, 46, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001068990), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.October, 3, 19, 22, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0010689c0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-brkgd", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0035e9080), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-brkgd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-brkgd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-brkgd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0024968c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.63.128.3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000597650), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002496950)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002496970)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002496978), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00249697c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000217300), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.October, 3, 19, 21, 45, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.October, 3, 19, 21, 45, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.October, 3, 19, 21, 45, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.October, 3, 19, 21, 45, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.63.128.3", PodIP:"172.30.49.30", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.30.49.30"}}, StartTime:time.Date(2022, time.October, 3, 19, 21, 45, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000597810)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000597880)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://ac49cc0d574a12e3a7fda828263fcaf00def947b7f3f5630b5b8c27c99793278", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0035e9100), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0035e90e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc0024969ff)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Oct  3 19:22:31.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-7643" for this suite. 10/03/22 19:22:31.271
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:22:31.288
Oct  3 19:22:31.288: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename cronjob 10/03/22 19:22:31.29
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:22:31.318
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:22:31.329
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 10/03/22 19:22:31.334
STEP: Ensuring a job is scheduled 10/03/22 19:22:31.346
STEP: Ensuring exactly one is scheduled 10/03/22 19:23:01.385
STEP: Ensuring exactly one running job exists by listing jobs explicitly 10/03/22 19:23:01.392
STEP: Ensuring the job is replaced with a new one 10/03/22 19:23:01.399
STEP: Removing cronjob 10/03/22 19:24:01.41
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Oct  3 19:24:01.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6373" for this suite. 10/03/22 19:24:01.471
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":24,"skipped":515,"failed":0}
------------------------------
• [SLOW TEST] [90.203 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:22:31.288
    Oct  3 19:22:31.288: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename cronjob 10/03/22 19:22:31.29
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:22:31.318
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:22:31.329
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 10/03/22 19:22:31.334
    STEP: Ensuring a job is scheduled 10/03/22 19:22:31.346
    STEP: Ensuring exactly one is scheduled 10/03/22 19:23:01.385
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 10/03/22 19:23:01.392
    STEP: Ensuring the job is replaced with a new one 10/03/22 19:23:01.399
    STEP: Removing cronjob 10/03/22 19:24:01.41
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Oct  3 19:24:01.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-6373" for this suite. 10/03/22 19:24:01.471
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:24:01.496
Oct  3 19:24:01.496: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename events 10/03/22 19:24:01.498
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:24:01.528
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:24:01.535
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 10/03/22 19:24:01.541
STEP: listing events in all namespaces 10/03/22 19:24:01.562
STEP: listing events in test namespace 10/03/22 19:24:01.635
STEP: listing events with field selection filtering on source 10/03/22 19:24:01.646
STEP: listing events with field selection filtering on reportingController 10/03/22 19:24:01.658
STEP: getting the test event 10/03/22 19:24:01.668
STEP: patching the test event 10/03/22 19:24:01.677
STEP: getting the test event 10/03/22 19:24:01.701
STEP: updating the test event 10/03/22 19:24:01.711
STEP: getting the test event 10/03/22 19:24:01.729
STEP: deleting the test event 10/03/22 19:24:01.739
STEP: listing events in all namespaces 10/03/22 19:24:01.765
STEP: listing events in test namespace 10/03/22 19:24:01.799
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Oct  3 19:24:01.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1987" for this suite. 10/03/22 19:24:01.823
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":25,"skipped":540,"failed":0}
------------------------------
• [0.345 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:24:01.496
    Oct  3 19:24:01.496: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename events 10/03/22 19:24:01.498
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:24:01.528
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:24:01.535
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 10/03/22 19:24:01.541
    STEP: listing events in all namespaces 10/03/22 19:24:01.562
    STEP: listing events in test namespace 10/03/22 19:24:01.635
    STEP: listing events with field selection filtering on source 10/03/22 19:24:01.646
    STEP: listing events with field selection filtering on reportingController 10/03/22 19:24:01.658
    STEP: getting the test event 10/03/22 19:24:01.668
    STEP: patching the test event 10/03/22 19:24:01.677
    STEP: getting the test event 10/03/22 19:24:01.701
    STEP: updating the test event 10/03/22 19:24:01.711
    STEP: getting the test event 10/03/22 19:24:01.729
    STEP: deleting the test event 10/03/22 19:24:01.739
    STEP: listing events in all namespaces 10/03/22 19:24:01.765
    STEP: listing events in test namespace 10/03/22 19:24:01.799
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Oct  3 19:24:01.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-1987" for this suite. 10/03/22 19:24:01.823
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:24:01.846
Oct  3 19:24:01.846: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename replicaset 10/03/22 19:24:01.847
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:24:01.878
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:24:01.884
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 10/03/22 19:24:01.889
STEP: Verify that the required pods have come up 10/03/22 19:24:01.91
Oct  3 19:24:01.920: INFO: Pod name sample-pod: Found 0 pods out of 3
Oct  3 19:24:06.931: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 10/03/22 19:24:06.931
Oct  3 19:24:06.940: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 10/03/22 19:24:06.94
STEP: DeleteCollection of the ReplicaSets 10/03/22 19:24:06.95
STEP: After DeleteCollection verify that ReplicaSets have been deleted 10/03/22 19:24:06.975
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Oct  3 19:24:06.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4857" for this suite. 10/03/22 19:24:07.004
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":26,"skipped":551,"failed":0}
------------------------------
• [SLOW TEST] [5.183 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:24:01.846
    Oct  3 19:24:01.846: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename replicaset 10/03/22 19:24:01.847
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:24:01.878
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:24:01.884
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 10/03/22 19:24:01.889
    STEP: Verify that the required pods have come up 10/03/22 19:24:01.91
    Oct  3 19:24:01.920: INFO: Pod name sample-pod: Found 0 pods out of 3
    Oct  3 19:24:06.931: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 10/03/22 19:24:06.931
    Oct  3 19:24:06.940: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 10/03/22 19:24:06.94
    STEP: DeleteCollection of the ReplicaSets 10/03/22 19:24:06.95
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 10/03/22 19:24:06.975
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Oct  3 19:24:06.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4857" for this suite. 10/03/22 19:24:07.004
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:24:07.031
Oct  3 19:24:07.031: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename events 10/03/22 19:24:07.038
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:24:07.07
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:24:07.076
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 10/03/22 19:24:07.081
STEP: listing all events in all namespaces 10/03/22 19:24:07.093
STEP: patching the test event 10/03/22 19:24:07.153
STEP: fetching the test event 10/03/22 19:24:07.171
STEP: updating the test event 10/03/22 19:24:07.184
STEP: getting the test event 10/03/22 19:24:07.213
STEP: deleting the test event 10/03/22 19:24:07.222
STEP: listing all events in all namespaces 10/03/22 19:24:07.257
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Oct  3 19:24:07.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2698" for this suite. 10/03/22 19:24:07.311
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":27,"skipped":559,"failed":0}
------------------------------
• [0.301 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:24:07.031
    Oct  3 19:24:07.031: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename events 10/03/22 19:24:07.038
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:24:07.07
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:24:07.076
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 10/03/22 19:24:07.081
    STEP: listing all events in all namespaces 10/03/22 19:24:07.093
    STEP: patching the test event 10/03/22 19:24:07.153
    STEP: fetching the test event 10/03/22 19:24:07.171
    STEP: updating the test event 10/03/22 19:24:07.184
    STEP: getting the test event 10/03/22 19:24:07.213
    STEP: deleting the test event 10/03/22 19:24:07.222
    STEP: listing all events in all namespaces 10/03/22 19:24:07.257
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Oct  3 19:24:07.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-2698" for this suite. 10/03/22 19:24:07.311
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:24:07.34
Oct  3 19:24:07.341: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename deployment 10/03/22 19:24:07.342
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:24:07.387
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:24:07.393
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Oct  3 19:24:07.419: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct  3 19:24:12.429: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 10/03/22 19:24:12.429
Oct  3 19:24:12.430: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct  3 19:24:14.439: INFO: Creating deployment "test-rollover-deployment"
Oct  3 19:24:14.463: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct  3 19:24:16.483: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct  3 19:24:16.501: INFO: Ensure that both replica sets have 1 created replica
Oct  3 19:24:16.517: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct  3 19:24:16.539: INFO: Updating deployment test-rollover-deployment
Oct  3 19:24:16.539: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct  3 19:24:18.560: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct  3 19:24:18.578: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct  3 19:24:18.596: INFO: all replica sets need to contain the pod-template-hash label
Oct  3 19:24:18.596: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:24:20.615: INFO: all replica sets need to contain the pod-template-hash label
Oct  3 19:24:20.615: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:24:22.616: INFO: all replica sets need to contain the pod-template-hash label
Oct  3 19:24:22.616: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:24:24.615: INFO: all replica sets need to contain the pod-template-hash label
Oct  3 19:24:24.615: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:24:26.616: INFO: all replica sets need to contain the pod-template-hash label
Oct  3 19:24:26.616: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:24:28.616: INFO: all replica sets need to contain the pod-template-hash label
Oct  3 19:24:28.616: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:24:30.617: INFO: 
Oct  3 19:24:30.617: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct  3 19:24:30.645: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-1454  710bd530-2e2a-4e9e-bd74-021e1df826be 17976 2 2022-10-03 19:24:14 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-10-03 19:24:16 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e31508 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-10-03 19:24:14 +0000 UTC,LastTransitionTime:2022-10-03 19:24:14 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-10-03 19:24:28 +0000 UTC,LastTransitionTime:2022-10-03 19:24:14 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct  3 19:24:30.654: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-1454  0ad2e091-798f-4b09-afed-294f7829262c 17966 2 2022-10-03 19:24:16 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 710bd530-2e2a-4e9e-bd74-021e1df826be 0xc003361ad7 0xc003361ad8}] [] [{kube-controller-manager Update apps/v1 2022-10-03 19:24:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"710bd530-2e2a-4e9e-bd74-021e1df826be\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:24:28 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003361b88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct  3 19:24:30.654: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct  3 19:24:30.654: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-1454  53576498-2f3a-4819-9b61-3578dfdd40e8 17974 2 2022-10-03 19:24:07 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 710bd530-2e2a-4e9e-bd74-021e1df826be 0xc003361887 0xc003361888}] [] [{e2e.test Update apps/v1 2022-10-03 19:24:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"710bd530-2e2a-4e9e-bd74-021e1df826be\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:24:28 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003361948 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  3 19:24:30.655: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-1454  48331d22-7f7d-44f3-ac66-a24b402c804b 17935 2 2022-10-03 19:24:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 710bd530-2e2a-4e9e-bd74-021e1df826be 0xc0033619b7 0xc0033619b8}] [] [{kube-controller-manager Update apps/v1 2022-10-03 19:24:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"710bd530-2e2a-4e9e-bd74-021e1df826be\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:24:16 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003361a68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  3 19:24:30.664: INFO: Pod "test-rollover-deployment-6d45fd857b-9hks9" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-9hks9 test-rollover-deployment-6d45fd857b- deployment-1454  461a7881-32e9-476d-a8dc-d2a86e388a3b 17955 0 2022-10-03 19:24:16 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:b6a0a969b486310224b477974041fb65d74c2d365829b60fcd3affeb713129c9 cni.projectcalico.org/podIP:172.30.49.37/32 cni.projectcalico.org/podIPs:172.30.49.37/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 0ad2e091-798f-4b09-afed-294f7829262c 0xc003dde1a7 0xc003dde1a8}] [] [{kube-controller-manager Update v1 2022-10-03 19:24:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0ad2e091-798f-4b09-afed-294f7829262c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:24:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:24:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.37\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r844d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r844d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:24:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:24:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:24:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:24:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.37,StartTime:2022-10-03 19:24:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:24:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://ca3e01ebf1ee2f3f4bf21ee968301e706679d618a7170f3689b64e6b6c01b618,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Oct  3 19:24:30.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1454" for this suite. 10/03/22 19:24:30.676
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":28,"skipped":593,"failed":0}
------------------------------
• [SLOW TEST] [23.354 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:24:07.34
    Oct  3 19:24:07.341: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename deployment 10/03/22 19:24:07.342
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:24:07.387
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:24:07.393
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Oct  3 19:24:07.419: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Oct  3 19:24:12.429: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 10/03/22 19:24:12.429
    Oct  3 19:24:12.430: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Oct  3 19:24:14.439: INFO: Creating deployment "test-rollover-deployment"
    Oct  3 19:24:14.463: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Oct  3 19:24:16.483: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Oct  3 19:24:16.501: INFO: Ensure that both replica sets have 1 created replica
    Oct  3 19:24:16.517: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Oct  3 19:24:16.539: INFO: Updating deployment test-rollover-deployment
    Oct  3 19:24:16.539: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Oct  3 19:24:18.560: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Oct  3 19:24:18.578: INFO: Make sure deployment "test-rollover-deployment" is complete
    Oct  3 19:24:18.596: INFO: all replica sets need to contain the pod-template-hash label
    Oct  3 19:24:18.596: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:24:20.615: INFO: all replica sets need to contain the pod-template-hash label
    Oct  3 19:24:20.615: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:24:22.616: INFO: all replica sets need to contain the pod-template-hash label
    Oct  3 19:24:22.616: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:24:24.615: INFO: all replica sets need to contain the pod-template-hash label
    Oct  3 19:24:24.615: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:24:26.616: INFO: all replica sets need to contain the pod-template-hash label
    Oct  3 19:24:26.616: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:24:28.616: INFO: all replica sets need to contain the pod-template-hash label
    Oct  3 19:24:28.616: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 24, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 24, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:24:30.617: INFO: 
    Oct  3 19:24:30.617: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct  3 19:24:30.645: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-1454  710bd530-2e2a-4e9e-bd74-021e1df826be 17976 2 2022-10-03 19:24:14 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-10-03 19:24:16 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e31508 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-10-03 19:24:14 +0000 UTC,LastTransitionTime:2022-10-03 19:24:14 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-10-03 19:24:28 +0000 UTC,LastTransitionTime:2022-10-03 19:24:14 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Oct  3 19:24:30.654: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-1454  0ad2e091-798f-4b09-afed-294f7829262c 17966 2 2022-10-03 19:24:16 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 710bd530-2e2a-4e9e-bd74-021e1df826be 0xc003361ad7 0xc003361ad8}] [] [{kube-controller-manager Update apps/v1 2022-10-03 19:24:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"710bd530-2e2a-4e9e-bd74-021e1df826be\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:24:28 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003361b88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Oct  3 19:24:30.654: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Oct  3 19:24:30.654: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-1454  53576498-2f3a-4819-9b61-3578dfdd40e8 17974 2 2022-10-03 19:24:07 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 710bd530-2e2a-4e9e-bd74-021e1df826be 0xc003361887 0xc003361888}] [] [{e2e.test Update apps/v1 2022-10-03 19:24:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"710bd530-2e2a-4e9e-bd74-021e1df826be\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:24:28 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003361948 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Oct  3 19:24:30.655: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-1454  48331d22-7f7d-44f3-ac66-a24b402c804b 17935 2 2022-10-03 19:24:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 710bd530-2e2a-4e9e-bd74-021e1df826be 0xc0033619b7 0xc0033619b8}] [] [{kube-controller-manager Update apps/v1 2022-10-03 19:24:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"710bd530-2e2a-4e9e-bd74-021e1df826be\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:24:16 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003361a68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Oct  3 19:24:30.664: INFO: Pod "test-rollover-deployment-6d45fd857b-9hks9" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-9hks9 test-rollover-deployment-6d45fd857b- deployment-1454  461a7881-32e9-476d-a8dc-d2a86e388a3b 17955 0 2022-10-03 19:24:16 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:b6a0a969b486310224b477974041fb65d74c2d365829b60fcd3affeb713129c9 cni.projectcalico.org/podIP:172.30.49.37/32 cni.projectcalico.org/podIPs:172.30.49.37/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 0ad2e091-798f-4b09-afed-294f7829262c 0xc003dde1a7 0xc003dde1a8}] [] [{kube-controller-manager Update v1 2022-10-03 19:24:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0ad2e091-798f-4b09-afed-294f7829262c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:24:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:24:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.37\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r844d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r844d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:24:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:24:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:24:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:24:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.37,StartTime:2022-10-03 19:24:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:24:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://ca3e01ebf1ee2f3f4bf21ee968301e706679d618a7170f3689b64e6b6c01b618,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Oct  3 19:24:30.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-1454" for this suite. 10/03/22 19:24:30.676
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:24:30.701
Oct  3 19:24:30.701: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename subpath 10/03/22 19:24:30.702
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:24:30.733
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:24:30.738
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 10/03/22 19:24:30.744
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-7bng 10/03/22 19:24:30.769
STEP: Creating a pod to test atomic-volume-subpath 10/03/22 19:24:30.77
Oct  3 19:24:30.788: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-7bng" in namespace "subpath-4917" to be "Succeeded or Failed"
Oct  3 19:24:30.798: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Pending", Reason="", readiness=false. Elapsed: 9.029733ms
Oct  3 19:24:32.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020026063s
Oct  3 19:24:34.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 4.020137994s
Oct  3 19:24:36.819: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 6.030612132s
Oct  3 19:24:38.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 8.020338165s
Oct  3 19:24:40.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 10.019969357s
Oct  3 19:24:42.808: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 12.019622779s
Oct  3 19:24:44.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 14.020760679s
Oct  3 19:24:46.834: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 16.045477622s
Oct  3 19:24:48.808: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 18.019015783s
Oct  3 19:24:50.808: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 20.01979924s
Oct  3 19:24:52.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 22.020381526s
Oct  3 19:24:54.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=false. Elapsed: 24.020159899s
Oct  3 19:24:56.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.020656866s
STEP: Saw pod success 10/03/22 19:24:56.809
Oct  3 19:24:56.810: INFO: Pod "pod-subpath-test-configmap-7bng" satisfied condition "Succeeded or Failed"
Oct  3 19:24:56.819: INFO: Trying to get logs from node 10.63.128.3 pod pod-subpath-test-configmap-7bng container test-container-subpath-configmap-7bng: <nil>
STEP: delete the pod 10/03/22 19:24:56.896
Oct  3 19:24:56.930: INFO: Waiting for pod pod-subpath-test-configmap-7bng to disappear
Oct  3 19:24:56.939: INFO: Pod pod-subpath-test-configmap-7bng no longer exists
STEP: Deleting pod pod-subpath-test-configmap-7bng 10/03/22 19:24:56.939
Oct  3 19:24:56.939: INFO: Deleting pod "pod-subpath-test-configmap-7bng" in namespace "subpath-4917"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Oct  3 19:24:56.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4917" for this suite. 10/03/22 19:24:56.961
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":29,"skipped":631,"failed":0}
------------------------------
• [SLOW TEST] [26.280 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:24:30.701
    Oct  3 19:24:30.701: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename subpath 10/03/22 19:24:30.702
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:24:30.733
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:24:30.738
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 10/03/22 19:24:30.744
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-7bng 10/03/22 19:24:30.769
    STEP: Creating a pod to test atomic-volume-subpath 10/03/22 19:24:30.77
    Oct  3 19:24:30.788: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-7bng" in namespace "subpath-4917" to be "Succeeded or Failed"
    Oct  3 19:24:30.798: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Pending", Reason="", readiness=false. Elapsed: 9.029733ms
    Oct  3 19:24:32.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020026063s
    Oct  3 19:24:34.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 4.020137994s
    Oct  3 19:24:36.819: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 6.030612132s
    Oct  3 19:24:38.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 8.020338165s
    Oct  3 19:24:40.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 10.019969357s
    Oct  3 19:24:42.808: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 12.019622779s
    Oct  3 19:24:44.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 14.020760679s
    Oct  3 19:24:46.834: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 16.045477622s
    Oct  3 19:24:48.808: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 18.019015783s
    Oct  3 19:24:50.808: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 20.01979924s
    Oct  3 19:24:52.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=true. Elapsed: 22.020381526s
    Oct  3 19:24:54.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Running", Reason="", readiness=false. Elapsed: 24.020159899s
    Oct  3 19:24:56.809: INFO: Pod "pod-subpath-test-configmap-7bng": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.020656866s
    STEP: Saw pod success 10/03/22 19:24:56.809
    Oct  3 19:24:56.810: INFO: Pod "pod-subpath-test-configmap-7bng" satisfied condition "Succeeded or Failed"
    Oct  3 19:24:56.819: INFO: Trying to get logs from node 10.63.128.3 pod pod-subpath-test-configmap-7bng container test-container-subpath-configmap-7bng: <nil>
    STEP: delete the pod 10/03/22 19:24:56.896
    Oct  3 19:24:56.930: INFO: Waiting for pod pod-subpath-test-configmap-7bng to disappear
    Oct  3 19:24:56.939: INFO: Pod pod-subpath-test-configmap-7bng no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-7bng 10/03/22 19:24:56.939
    Oct  3 19:24:56.939: INFO: Deleting pod "pod-subpath-test-configmap-7bng" in namespace "subpath-4917"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Oct  3 19:24:56.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-4917" for this suite. 10/03/22 19:24:56.961
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:24:56.983
Oct  3 19:24:56.983: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename containers 10/03/22 19:24:56.984
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:24:57.018
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:24:57.024
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 10/03/22 19:24:57.03
Oct  3 19:24:57.053: INFO: Waiting up to 5m0s for pod "client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7" in namespace "containers-1773" to be "Succeeded or Failed"
Oct  3 19:24:57.062: INFO: Pod "client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.764396ms
Oct  3 19:24:59.071: INFO: Pod "client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018376503s
Oct  3 19:25:01.072: INFO: Pod "client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019267158s
STEP: Saw pod success 10/03/22 19:25:01.072
Oct  3 19:25:01.072: INFO: Pod "client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7" satisfied condition "Succeeded or Failed"
Oct  3 19:25:01.081: INFO: Trying to get logs from node 10.63.128.3 pod client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7 container agnhost-container: <nil>
STEP: delete the pod 10/03/22 19:25:01.109
Oct  3 19:25:01.140: INFO: Waiting for pod client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7 to disappear
Oct  3 19:25:01.150: INFO: Pod client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Oct  3 19:25:01.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1773" for this suite. 10/03/22 19:25:01.163
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":30,"skipped":653,"failed":0}
------------------------------
• [4.201 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:24:56.983
    Oct  3 19:24:56.983: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename containers 10/03/22 19:24:56.984
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:24:57.018
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:24:57.024
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 10/03/22 19:24:57.03
    Oct  3 19:24:57.053: INFO: Waiting up to 5m0s for pod "client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7" in namespace "containers-1773" to be "Succeeded or Failed"
    Oct  3 19:24:57.062: INFO: Pod "client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.764396ms
    Oct  3 19:24:59.071: INFO: Pod "client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018376503s
    Oct  3 19:25:01.072: INFO: Pod "client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019267158s
    STEP: Saw pod success 10/03/22 19:25:01.072
    Oct  3 19:25:01.072: INFO: Pod "client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7" satisfied condition "Succeeded or Failed"
    Oct  3 19:25:01.081: INFO: Trying to get logs from node 10.63.128.3 pod client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7 container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 19:25:01.109
    Oct  3 19:25:01.140: INFO: Waiting for pod client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7 to disappear
    Oct  3 19:25:01.150: INFO: Pod client-containers-fede1195-ac5e-4b7d-b27c-b3254f0e1dc7 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Oct  3 19:25:01.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-1773" for this suite. 10/03/22 19:25:01.163
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:25:01.185
Oct  3 19:25:01.185: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename sysctl 10/03/22 19:25:01.186
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:25:01.225
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:25:01.231
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 10/03/22 19:25:01.236
STEP: Watching for error events or started pod 10/03/22 19:25:01.256
STEP: Waiting for pod completion 10/03/22 19:25:03.268
Oct  3 19:25:03.269: INFO: Waiting up to 3m0s for pod "sysctl-56b23f39-861d-43d8-b5dd-7aa95f4bcdc8" in namespace "sysctl-5607" to be "completed"
Oct  3 19:25:03.278: INFO: Pod "sysctl-56b23f39-861d-43d8-b5dd-7aa95f4bcdc8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.993285ms
Oct  3 19:25:05.288: INFO: Pod "sysctl-56b23f39-861d-43d8-b5dd-7aa95f4bcdc8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019283474s
Oct  3 19:25:07.288: INFO: Pod "sysctl-56b23f39-861d-43d8-b5dd-7aa95f4bcdc8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019521045s
Oct  3 19:25:07.288: INFO: Pod "sysctl-56b23f39-861d-43d8-b5dd-7aa95f4bcdc8" satisfied condition "completed"
STEP: Checking that the pod succeeded 10/03/22 19:25:07.298
STEP: Getting logs from the pod 10/03/22 19:25:07.298
STEP: Checking that the sysctl is actually updated 10/03/22 19:25:07.324
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Oct  3 19:25:07.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-5607" for this suite. 10/03/22 19:25:07.338
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":31,"skipped":666,"failed":0}
------------------------------
• [SLOW TEST] [6.172 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:25:01.185
    Oct  3 19:25:01.185: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename sysctl 10/03/22 19:25:01.186
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:25:01.225
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:25:01.231
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 10/03/22 19:25:01.236
    STEP: Watching for error events or started pod 10/03/22 19:25:01.256
    STEP: Waiting for pod completion 10/03/22 19:25:03.268
    Oct  3 19:25:03.269: INFO: Waiting up to 3m0s for pod "sysctl-56b23f39-861d-43d8-b5dd-7aa95f4bcdc8" in namespace "sysctl-5607" to be "completed"
    Oct  3 19:25:03.278: INFO: Pod "sysctl-56b23f39-861d-43d8-b5dd-7aa95f4bcdc8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.993285ms
    Oct  3 19:25:05.288: INFO: Pod "sysctl-56b23f39-861d-43d8-b5dd-7aa95f4bcdc8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019283474s
    Oct  3 19:25:07.288: INFO: Pod "sysctl-56b23f39-861d-43d8-b5dd-7aa95f4bcdc8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019521045s
    Oct  3 19:25:07.288: INFO: Pod "sysctl-56b23f39-861d-43d8-b5dd-7aa95f4bcdc8" satisfied condition "completed"
    STEP: Checking that the pod succeeded 10/03/22 19:25:07.298
    STEP: Getting logs from the pod 10/03/22 19:25:07.298
    STEP: Checking that the sysctl is actually updated 10/03/22 19:25:07.324
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Oct  3 19:25:07.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-5607" for this suite. 10/03/22 19:25:07.338
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:25:07.363
Oct  3 19:25:07.363: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 19:25:07.364
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:25:07.394
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:25:07.399
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 10/03/22 19:25:07.405
Oct  3 19:25:07.424: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006" in namespace "projected-8480" to be "Succeeded or Failed"
Oct  3 19:25:07.432: INFO: Pod "downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006": Phase="Pending", Reason="", readiness=false. Elapsed: 8.658342ms
Oct  3 19:25:09.442: INFO: Pod "downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018545826s
Oct  3 19:25:11.444: INFO: Pod "downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020620707s
Oct  3 19:25:13.444: INFO: Pod "downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020534266s
STEP: Saw pod success 10/03/22 19:25:13.444
Oct  3 19:25:13.444: INFO: Pod "downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006" satisfied condition "Succeeded or Failed"
Oct  3 19:25:13.454: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006 container client-container: <nil>
STEP: delete the pod 10/03/22 19:25:13.48
Oct  3 19:25:13.513: INFO: Waiting for pod downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006 to disappear
Oct  3 19:25:13.521: INFO: Pod downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Oct  3 19:25:13.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8480" for this suite. 10/03/22 19:25:13.535
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":32,"skipped":717,"failed":0}
------------------------------
• [SLOW TEST] [6.190 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:25:07.363
    Oct  3 19:25:07.363: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 19:25:07.364
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:25:07.394
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:25:07.399
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 10/03/22 19:25:07.405
    Oct  3 19:25:07.424: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006" in namespace "projected-8480" to be "Succeeded or Failed"
    Oct  3 19:25:07.432: INFO: Pod "downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006": Phase="Pending", Reason="", readiness=false. Elapsed: 8.658342ms
    Oct  3 19:25:09.442: INFO: Pod "downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018545826s
    Oct  3 19:25:11.444: INFO: Pod "downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020620707s
    Oct  3 19:25:13.444: INFO: Pod "downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020534266s
    STEP: Saw pod success 10/03/22 19:25:13.444
    Oct  3 19:25:13.444: INFO: Pod "downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006" satisfied condition "Succeeded or Failed"
    Oct  3 19:25:13.454: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006 container client-container: <nil>
    STEP: delete the pod 10/03/22 19:25:13.48
    Oct  3 19:25:13.513: INFO: Waiting for pod downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006 to disappear
    Oct  3 19:25:13.521: INFO: Pod downwardapi-volume-6c8d353d-c742-44f1-a0a3-5bc3f62ab006 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Oct  3 19:25:13.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8480" for this suite. 10/03/22 19:25:13.535
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:25:13.556
Oct  3 19:25:13.556: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename job 10/03/22 19:25:13.557
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:25:13.587
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:25:13.593
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 10/03/22 19:25:13.598
STEP: Ensuring job reaches completions 10/03/22 19:25:13.61
STEP: Ensuring pods with index for job exist 10/03/22 19:25:23.62
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Oct  3 19:25:23.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8314" for this suite. 10/03/22 19:25:23.642
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":33,"skipped":763,"failed":0}
------------------------------
• [SLOW TEST] [10.105 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:25:13.556
    Oct  3 19:25:13.556: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename job 10/03/22 19:25:13.557
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:25:13.587
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:25:13.593
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 10/03/22 19:25:13.598
    STEP: Ensuring job reaches completions 10/03/22 19:25:13.61
    STEP: Ensuring pods with index for job exist 10/03/22 19:25:23.62
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Oct  3 19:25:23.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-8314" for this suite. 10/03/22 19:25:23.642
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:25:23.662
Oct  3 19:25:23.662: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-runtime 10/03/22 19:25:23.663
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:25:23.693
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:25:23.699
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 10/03/22 19:25:23.719
STEP: wait for the container to reach Succeeded 10/03/22 19:25:23.747
STEP: get the container status 10/03/22 19:25:28.823
STEP: the container should be terminated 10/03/22 19:25:28.835
STEP: the termination message should be set 10/03/22 19:25:28.835
Oct  3 19:25:28.835: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 10/03/22 19:25:28.835
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Oct  3 19:25:28.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-998" for this suite. 10/03/22 19:25:28.9
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":34,"skipped":777,"failed":0}
------------------------------
• [SLOW TEST] [5.258 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:25:23.662
    Oct  3 19:25:23.662: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-runtime 10/03/22 19:25:23.663
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:25:23.693
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:25:23.699
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 10/03/22 19:25:23.719
    STEP: wait for the container to reach Succeeded 10/03/22 19:25:23.747
    STEP: get the container status 10/03/22 19:25:28.823
    STEP: the container should be terminated 10/03/22 19:25:28.835
    STEP: the termination message should be set 10/03/22 19:25:28.835
    Oct  3 19:25:28.835: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 10/03/22 19:25:28.835
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Oct  3 19:25:28.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-998" for this suite. 10/03/22 19:25:28.9
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:25:28.922
Oct  3 19:25:28.922: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 19:25:28.923
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:25:28.963
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:25:28.971
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5448 10/03/22 19:25:28.979
STEP: changing the ExternalName service to type=NodePort 10/03/22 19:25:28.994
STEP: creating replication controller externalname-service in namespace services-5448 10/03/22 19:25:29.05
I1003 19:25:29.063258      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5448, replica count: 2
I1003 19:25:32.114577      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  3 19:25:32.114: INFO: Creating new exec pod
Oct  3 19:25:32.162: INFO: Waiting up to 5m0s for pod "execpod8z6tc" in namespace "services-5448" to be "running"
Oct  3 19:25:32.174: INFO: Pod "execpod8z6tc": Phase="Pending", Reason="", readiness=false. Elapsed: 12.368169ms
Oct  3 19:25:34.187: INFO: Pod "execpod8z6tc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025223915s
Oct  3 19:25:36.186: INFO: Pod "execpod8z6tc": Phase="Running", Reason="", readiness=true. Elapsed: 4.024468883s
Oct  3 19:25:36.186: INFO: Pod "execpod8z6tc" satisfied condition "running"
Oct  3 19:25:37.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5448 exec execpod8z6tc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Oct  3 19:25:37.525: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct  3 19:25:37.525: INFO: stdout: "externalname-service-kcfn6"
Oct  3 19:25:37.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5448 exec execpod8z6tc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.215.241 80'
Oct  3 19:25:37.810: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.215.241 80\nConnection to 172.21.215.241 80 port [tcp/http] succeeded!\n"
Oct  3 19:25:37.810: INFO: stdout: ""
Oct  3 19:25:38.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5448 exec execpod8z6tc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.215.241 80'
Oct  3 19:25:39.116: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.215.241 80\nConnection to 172.21.215.241 80 port [tcp/http] succeeded!\n"
Oct  3 19:25:39.116: INFO: stdout: "externalname-service-kcfn6"
Oct  3 19:25:39.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5448 exec execpod8z6tc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.13 30934'
Oct  3 19:25:39.429: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.13 30934\nConnection to 10.63.128.13 30934 port [tcp/*] succeeded!\n"
Oct  3 19:25:39.429: INFO: stdout: ""
Oct  3 19:25:40.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5448 exec execpod8z6tc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.13 30934'
Oct  3 19:25:40.705: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.13 30934\nConnection to 10.63.128.13 30934 port [tcp/*] succeeded!\n"
Oct  3 19:25:40.705: INFO: stdout: "externalname-service-kcfn6"
Oct  3 19:25:40.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5448 exec execpod8z6tc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.51 30934'
Oct  3 19:25:41.081: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.51 30934\nConnection to 10.63.128.51 30934 port [tcp/*] succeeded!\n"
Oct  3 19:25:41.081: INFO: stdout: ""
Oct  3 19:25:42.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5448 exec execpod8z6tc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.51 30934'
Oct  3 19:25:42.373: INFO: stderr: "+ + echo hostNamenc\n -v -t -w 2 10.63.128.51 30934\nConnection to 10.63.128.51 30934 port [tcp/*] succeeded!\n"
Oct  3 19:25:42.373: INFO: stdout: "externalname-service-kc2tn"
Oct  3 19:25:42.373: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 19:25:42.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5448" for this suite. 10/03/22 19:25:42.452
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":35,"skipped":793,"failed":0}
------------------------------
• [SLOW TEST] [13.550 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:25:28.922
    Oct  3 19:25:28.922: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 19:25:28.923
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:25:28.963
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:25:28.971
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-5448 10/03/22 19:25:28.979
    STEP: changing the ExternalName service to type=NodePort 10/03/22 19:25:28.994
    STEP: creating replication controller externalname-service in namespace services-5448 10/03/22 19:25:29.05
    I1003 19:25:29.063258      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5448, replica count: 2
    I1003 19:25:32.114577      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct  3 19:25:32.114: INFO: Creating new exec pod
    Oct  3 19:25:32.162: INFO: Waiting up to 5m0s for pod "execpod8z6tc" in namespace "services-5448" to be "running"
    Oct  3 19:25:32.174: INFO: Pod "execpod8z6tc": Phase="Pending", Reason="", readiness=false. Elapsed: 12.368169ms
    Oct  3 19:25:34.187: INFO: Pod "execpod8z6tc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025223915s
    Oct  3 19:25:36.186: INFO: Pod "execpod8z6tc": Phase="Running", Reason="", readiness=true. Elapsed: 4.024468883s
    Oct  3 19:25:36.186: INFO: Pod "execpod8z6tc" satisfied condition "running"
    Oct  3 19:25:37.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5448 exec execpod8z6tc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Oct  3 19:25:37.525: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Oct  3 19:25:37.525: INFO: stdout: "externalname-service-kcfn6"
    Oct  3 19:25:37.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5448 exec execpod8z6tc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.215.241 80'
    Oct  3 19:25:37.810: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.215.241 80\nConnection to 172.21.215.241 80 port [tcp/http] succeeded!\n"
    Oct  3 19:25:37.810: INFO: stdout: ""
    Oct  3 19:25:38.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5448 exec execpod8z6tc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.215.241 80'
    Oct  3 19:25:39.116: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.215.241 80\nConnection to 172.21.215.241 80 port [tcp/http] succeeded!\n"
    Oct  3 19:25:39.116: INFO: stdout: "externalname-service-kcfn6"
    Oct  3 19:25:39.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5448 exec execpod8z6tc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.13 30934'
    Oct  3 19:25:39.429: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.13 30934\nConnection to 10.63.128.13 30934 port [tcp/*] succeeded!\n"
    Oct  3 19:25:39.429: INFO: stdout: ""
    Oct  3 19:25:40.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5448 exec execpod8z6tc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.13 30934'
    Oct  3 19:25:40.705: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.13 30934\nConnection to 10.63.128.13 30934 port [tcp/*] succeeded!\n"
    Oct  3 19:25:40.705: INFO: stdout: "externalname-service-kcfn6"
    Oct  3 19:25:40.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5448 exec execpod8z6tc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.51 30934'
    Oct  3 19:25:41.081: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.51 30934\nConnection to 10.63.128.51 30934 port [tcp/*] succeeded!\n"
    Oct  3 19:25:41.081: INFO: stdout: ""
    Oct  3 19:25:42.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5448 exec execpod8z6tc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.51 30934'
    Oct  3 19:25:42.373: INFO: stderr: "+ + echo hostNamenc\n -v -t -w 2 10.63.128.51 30934\nConnection to 10.63.128.51 30934 port [tcp/*] succeeded!\n"
    Oct  3 19:25:42.373: INFO: stdout: "externalname-service-kc2tn"
    Oct  3 19:25:42.373: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 19:25:42.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5448" for this suite. 10/03/22 19:25:42.452
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:25:42.473
Oct  3 19:25:42.473: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename watch 10/03/22 19:25:42.474
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:25:42.519
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:25:42.527
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 10/03/22 19:25:42.535
STEP: creating a new configmap 10/03/22 19:25:42.539
STEP: modifying the configmap once 10/03/22 19:25:42.551
STEP: changing the label value of the configmap 10/03/22 19:25:42.57
STEP: Expecting to observe a delete notification for the watched object 10/03/22 19:25:42.59
Oct  3 19:25:42.590: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4801  27c67c1e-92ae-47b4-b55a-28b43a73d344 18443 0 2022-10-03 19:25:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-10-03 19:25:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Oct  3 19:25:42.590: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4801  27c67c1e-92ae-47b4-b55a-28b43a73d344 18444 0 2022-10-03 19:25:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-10-03 19:25:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct  3 19:25:42.591: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4801  27c67c1e-92ae-47b4-b55a-28b43a73d344 18445 0 2022-10-03 19:25:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-10-03 19:25:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 10/03/22 19:25:42.591
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 10/03/22 19:25:42.611
STEP: changing the label value of the configmap back 10/03/22 19:25:52.611
STEP: modifying the configmap a third time 10/03/22 19:25:52.644
STEP: deleting the configmap 10/03/22 19:25:52.665
STEP: Expecting to observe an add notification for the watched object when the label value was restored 10/03/22 19:25:52.68
Oct  3 19:25:52.680: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4801  27c67c1e-92ae-47b4-b55a-28b43a73d344 18498 0 2022-10-03 19:25:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-10-03 19:25:52 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct  3 19:25:52.680: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4801  27c67c1e-92ae-47b4-b55a-28b43a73d344 18499 0 2022-10-03 19:25:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-10-03 19:25:52 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct  3 19:25:52.681: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4801  27c67c1e-92ae-47b4-b55a-28b43a73d344 18500 0 2022-10-03 19:25:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-10-03 19:25:52 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Oct  3 19:25:52.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4801" for this suite. 10/03/22 19:25:52.696
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":36,"skipped":798,"failed":0}
------------------------------
• [SLOW TEST] [10.242 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:25:42.473
    Oct  3 19:25:42.473: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename watch 10/03/22 19:25:42.474
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:25:42.519
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:25:42.527
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 10/03/22 19:25:42.535
    STEP: creating a new configmap 10/03/22 19:25:42.539
    STEP: modifying the configmap once 10/03/22 19:25:42.551
    STEP: changing the label value of the configmap 10/03/22 19:25:42.57
    STEP: Expecting to observe a delete notification for the watched object 10/03/22 19:25:42.59
    Oct  3 19:25:42.590: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4801  27c67c1e-92ae-47b4-b55a-28b43a73d344 18443 0 2022-10-03 19:25:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-10-03 19:25:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct  3 19:25:42.590: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4801  27c67c1e-92ae-47b4-b55a-28b43a73d344 18444 0 2022-10-03 19:25:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-10-03 19:25:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct  3 19:25:42.591: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4801  27c67c1e-92ae-47b4-b55a-28b43a73d344 18445 0 2022-10-03 19:25:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-10-03 19:25:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 10/03/22 19:25:42.591
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 10/03/22 19:25:42.611
    STEP: changing the label value of the configmap back 10/03/22 19:25:52.611
    STEP: modifying the configmap a third time 10/03/22 19:25:52.644
    STEP: deleting the configmap 10/03/22 19:25:52.665
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 10/03/22 19:25:52.68
    Oct  3 19:25:52.680: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4801  27c67c1e-92ae-47b4-b55a-28b43a73d344 18498 0 2022-10-03 19:25:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-10-03 19:25:52 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct  3 19:25:52.680: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4801  27c67c1e-92ae-47b4-b55a-28b43a73d344 18499 0 2022-10-03 19:25:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-10-03 19:25:52 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct  3 19:25:52.681: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4801  27c67c1e-92ae-47b4-b55a-28b43a73d344 18500 0 2022-10-03 19:25:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-10-03 19:25:52 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Oct  3 19:25:52.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-4801" for this suite. 10/03/22 19:25:52.696
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:25:52.722
Oct  3 19:25:52.722: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 19:25:52.723
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:25:52.792
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:25:52.801
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Oct  3 19:25:52.810: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 10/03/22 19:25:58.484
Oct  3 19:25:58.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-6372 --namespace=crd-publish-openapi-6372 create -f -'
Oct  3 19:25:59.309: INFO: stderr: ""
Oct  3 19:25:59.309: INFO: stdout: "e2e-test-crd-publish-openapi-1212-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Oct  3 19:25:59.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-6372 --namespace=crd-publish-openapi-6372 delete e2e-test-crd-publish-openapi-1212-crds test-cr'
Oct  3 19:25:59.427: INFO: stderr: ""
Oct  3 19:25:59.427: INFO: stdout: "e2e-test-crd-publish-openapi-1212-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Oct  3 19:25:59.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-6372 --namespace=crd-publish-openapi-6372 apply -f -'
Oct  3 19:26:00.114: INFO: stderr: ""
Oct  3 19:26:00.114: INFO: stdout: "e2e-test-crd-publish-openapi-1212-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Oct  3 19:26:00.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-6372 --namespace=crd-publish-openapi-6372 delete e2e-test-crd-publish-openapi-1212-crds test-cr'
Oct  3 19:26:00.228: INFO: stderr: ""
Oct  3 19:26:00.228: INFO: stdout: "e2e-test-crd-publish-openapi-1212-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 10/03/22 19:26:00.228
Oct  3 19:26:00.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-6372 explain e2e-test-crd-publish-openapi-1212-crds'
Oct  3 19:26:00.521: INFO: stderr: ""
Oct  3 19:26:00.521: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1212-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 19:26:03.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6372" for this suite. 10/03/22 19:26:03.921
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":37,"skipped":843,"failed":0}
------------------------------
• [SLOW TEST] [11.219 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:25:52.722
    Oct  3 19:25:52.722: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 19:25:52.723
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:25:52.792
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:25:52.801
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Oct  3 19:25:52.810: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 10/03/22 19:25:58.484
    Oct  3 19:25:58.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-6372 --namespace=crd-publish-openapi-6372 create -f -'
    Oct  3 19:25:59.309: INFO: stderr: ""
    Oct  3 19:25:59.309: INFO: stdout: "e2e-test-crd-publish-openapi-1212-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Oct  3 19:25:59.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-6372 --namespace=crd-publish-openapi-6372 delete e2e-test-crd-publish-openapi-1212-crds test-cr'
    Oct  3 19:25:59.427: INFO: stderr: ""
    Oct  3 19:25:59.427: INFO: stdout: "e2e-test-crd-publish-openapi-1212-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Oct  3 19:25:59.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-6372 --namespace=crd-publish-openapi-6372 apply -f -'
    Oct  3 19:26:00.114: INFO: stderr: ""
    Oct  3 19:26:00.114: INFO: stdout: "e2e-test-crd-publish-openapi-1212-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Oct  3 19:26:00.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-6372 --namespace=crd-publish-openapi-6372 delete e2e-test-crd-publish-openapi-1212-crds test-cr'
    Oct  3 19:26:00.228: INFO: stderr: ""
    Oct  3 19:26:00.228: INFO: stdout: "e2e-test-crd-publish-openapi-1212-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 10/03/22 19:26:00.228
    Oct  3 19:26:00.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-6372 explain e2e-test-crd-publish-openapi-1212-crds'
    Oct  3 19:26:00.521: INFO: stderr: ""
    Oct  3 19:26:00.521: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1212-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 19:26:03.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6372" for this suite. 10/03/22 19:26:03.921
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:26:03.944
Oct  3 19:26:03.944: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 19:26:03.946
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:26:03.985
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:26:03.996
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-1388 10/03/22 19:26:04.006
STEP: creating service affinity-clusterip in namespace services-1388 10/03/22 19:26:04.006
STEP: creating replication controller affinity-clusterip in namespace services-1388 10/03/22 19:26:04.041
I1003 19:26:04.055186      22 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-1388, replica count: 3
I1003 19:26:07.107069      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1003 19:26:10.108337      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1003 19:26:13.110380      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  3 19:26:13.132: INFO: Creating new exec pod
Oct  3 19:26:13.145: INFO: Waiting up to 5m0s for pod "execpod-affinity6sh6x" in namespace "services-1388" to be "running"
Oct  3 19:26:13.155: INFO: Pod "execpod-affinity6sh6x": Phase="Pending", Reason="", readiness=false. Elapsed: 9.697254ms
Oct  3 19:26:15.168: INFO: Pod "execpod-affinity6sh6x": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022737506s
Oct  3 19:26:17.170: INFO: Pod "execpod-affinity6sh6x": Phase="Running", Reason="", readiness=true. Elapsed: 4.024700049s
Oct  3 19:26:17.170: INFO: Pod "execpod-affinity6sh6x" satisfied condition "running"
Oct  3 19:26:18.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-1388 exec execpod-affinity6sh6x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Oct  3 19:26:18.495: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Oct  3 19:26:18.495: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 19:26:18.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-1388 exec execpod-affinity6sh6x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.237.53 80'
Oct  3 19:26:18.787: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.237.53 80\nConnection to 172.21.237.53 80 port [tcp/http] succeeded!\n"
Oct  3 19:26:18.787: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 19:26:18.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-1388 exec execpod-affinity6sh6x -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.237.53:80/ ; done'
Oct  3 19:26:19.295: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n"
Oct  3 19:26:19.295: INFO: stdout: "\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl"
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
Oct  3 19:26:19.295: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-1388, will wait for the garbage collector to delete the pods 10/03/22 19:26:19.321
Oct  3 19:26:19.403: INFO: Deleting ReplicationController affinity-clusterip took: 19.005773ms
Oct  3 19:26:19.505: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.603639ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 19:26:22.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1388" for this suite. 10/03/22 19:26:22.414
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":38,"skipped":865,"failed":0}
------------------------------
• [SLOW TEST] [18.487 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:26:03.944
    Oct  3 19:26:03.944: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 19:26:03.946
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:26:03.985
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:26:03.996
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-1388 10/03/22 19:26:04.006
    STEP: creating service affinity-clusterip in namespace services-1388 10/03/22 19:26:04.006
    STEP: creating replication controller affinity-clusterip in namespace services-1388 10/03/22 19:26:04.041
    I1003 19:26:04.055186      22 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-1388, replica count: 3
    I1003 19:26:07.107069      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1003 19:26:10.108337      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1003 19:26:13.110380      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct  3 19:26:13.132: INFO: Creating new exec pod
    Oct  3 19:26:13.145: INFO: Waiting up to 5m0s for pod "execpod-affinity6sh6x" in namespace "services-1388" to be "running"
    Oct  3 19:26:13.155: INFO: Pod "execpod-affinity6sh6x": Phase="Pending", Reason="", readiness=false. Elapsed: 9.697254ms
    Oct  3 19:26:15.168: INFO: Pod "execpod-affinity6sh6x": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022737506s
    Oct  3 19:26:17.170: INFO: Pod "execpod-affinity6sh6x": Phase="Running", Reason="", readiness=true. Elapsed: 4.024700049s
    Oct  3 19:26:17.170: INFO: Pod "execpod-affinity6sh6x" satisfied condition "running"
    Oct  3 19:26:18.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-1388 exec execpod-affinity6sh6x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Oct  3 19:26:18.495: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Oct  3 19:26:18.495: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 19:26:18.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-1388 exec execpod-affinity6sh6x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.237.53 80'
    Oct  3 19:26:18.787: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.237.53 80\nConnection to 172.21.237.53 80 port [tcp/http] succeeded!\n"
    Oct  3 19:26:18.787: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 19:26:18.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-1388 exec execpod-affinity6sh6x -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.237.53:80/ ; done'
    Oct  3 19:26:19.295: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.237.53:80/\n"
    Oct  3 19:26:19.295: INFO: stdout: "\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl\naffinity-clusterip-567vl"
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Received response from host: affinity-clusterip-567vl
    Oct  3 19:26:19.295: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-1388, will wait for the garbage collector to delete the pods 10/03/22 19:26:19.321
    Oct  3 19:26:19.403: INFO: Deleting ReplicationController affinity-clusterip took: 19.005773ms
    Oct  3 19:26:19.505: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.603639ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 19:26:22.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1388" for this suite. 10/03/22 19:26:22.414
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:26:22.432
Oct  3 19:26:22.432: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 19:26:22.434
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:26:22.466
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:26:22.476
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 10/03/22 19:26:22.486
Oct  3 19:26:22.508: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb" in namespace "projected-2361" to be "Succeeded or Failed"
Oct  3 19:26:22.519: INFO: Pod "downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.0099ms
Oct  3 19:26:24.534: INFO: Pod "downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025116548s
Oct  3 19:26:26.532: INFO: Pod "downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023745269s
Oct  3 19:26:28.532: INFO: Pod "downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023917903s
STEP: Saw pod success 10/03/22 19:26:28.532
Oct  3 19:26:28.533: INFO: Pod "downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb" satisfied condition "Succeeded or Failed"
Oct  3 19:26:28.546: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb container client-container: <nil>
STEP: delete the pod 10/03/22 19:26:28.576
Oct  3 19:26:28.612: INFO: Waiting for pod downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb to disappear
Oct  3 19:26:28.625: INFO: Pod downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Oct  3 19:26:28.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2361" for this suite. 10/03/22 19:26:28.656
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":39,"skipped":865,"failed":0}
------------------------------
• [SLOW TEST] [6.257 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:26:22.432
    Oct  3 19:26:22.432: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 19:26:22.434
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:26:22.466
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:26:22.476
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 10/03/22 19:26:22.486
    Oct  3 19:26:22.508: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb" in namespace "projected-2361" to be "Succeeded or Failed"
    Oct  3 19:26:22.519: INFO: Pod "downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.0099ms
    Oct  3 19:26:24.534: INFO: Pod "downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025116548s
    Oct  3 19:26:26.532: INFO: Pod "downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023745269s
    Oct  3 19:26:28.532: INFO: Pod "downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023917903s
    STEP: Saw pod success 10/03/22 19:26:28.532
    Oct  3 19:26:28.533: INFO: Pod "downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb" satisfied condition "Succeeded or Failed"
    Oct  3 19:26:28.546: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb container client-container: <nil>
    STEP: delete the pod 10/03/22 19:26:28.576
    Oct  3 19:26:28.612: INFO: Waiting for pod downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb to disappear
    Oct  3 19:26:28.625: INFO: Pod downwardapi-volume-d9b5deef-7b8d-42f7-b500-8a350926f0cb no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Oct  3 19:26:28.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2361" for this suite. 10/03/22 19:26:28.656
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:26:28.69
Oct  3 19:26:28.690: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 19:26:28.691
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:26:28.729
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:26:28.739
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Oct  3 19:26:28.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-4262 version'
Oct  3 19:26:28.833: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Oct  3 19:26:28.833: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.2\", GitCommit:\"5835544ca568b757a8ecae5c153f317e5736700e\", GitTreeState:\"clean\", BuildDate:\"2022-09-21T14:33:49Z\", GoVersion:\"go1.19.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.2+IKS\", GitCommit:\"ea012d5e1199802327c951c002c89cb44ffd69f2\", GitTreeState:\"clean\", BuildDate:\"2022-09-21T22:55:11Z\", GoVersion:\"go1.19.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 19:26:28.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4262" for this suite. 10/03/22 19:26:28.85
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":40,"skipped":872,"failed":0}
------------------------------
• [0.181 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:26:28.69
    Oct  3 19:26:28.690: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 19:26:28.691
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:26:28.729
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:26:28.739
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Oct  3 19:26:28.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-4262 version'
    Oct  3 19:26:28.833: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Oct  3 19:26:28.833: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.2\", GitCommit:\"5835544ca568b757a8ecae5c153f317e5736700e\", GitTreeState:\"clean\", BuildDate:\"2022-09-21T14:33:49Z\", GoVersion:\"go1.19.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.2+IKS\", GitCommit:\"ea012d5e1199802327c951c002c89cb44ffd69f2\", GitTreeState:\"clean\", BuildDate:\"2022-09-21T22:55:11Z\", GoVersion:\"go1.19.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 19:26:28.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4262" for this suite. 10/03/22 19:26:28.85
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:26:28.873
Oct  3 19:26:28.873: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename configmap 10/03/22 19:26:28.874
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:26:28.908
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:26:28.919
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-fdaee8e3-1cba-4eaa-8e2b-7425c7e81cbc 10/03/22 19:26:28.945
STEP: Creating the pod 10/03/22 19:26:28.958
Oct  3 19:26:28.979: INFO: Waiting up to 5m0s for pod "pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674" in namespace "configmap-1928" to be "running and ready"
Oct  3 19:26:28.990: INFO: Pod "pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674": Phase="Pending", Reason="", readiness=false. Elapsed: 11.104084ms
Oct  3 19:26:28.990: INFO: The phase of Pod pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:26:31.002: INFO: Pod "pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023281163s
Oct  3 19:26:31.002: INFO: The phase of Pod pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:26:33.002: INFO: Pod "pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674": Phase="Running", Reason="", readiness=true. Elapsed: 4.022650046s
Oct  3 19:26:33.002: INFO: The phase of Pod pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674 is Running (Ready = true)
Oct  3 19:26:33.002: INFO: Pod "pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-fdaee8e3-1cba-4eaa-8e2b-7425c7e81cbc 10/03/22 19:26:33.041
STEP: waiting to observe update in volume 10/03/22 19:26:33.054
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Oct  3 19:27:52.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1928" for this suite. 10/03/22 19:27:52.325
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":41,"skipped":883,"failed":0}
------------------------------
• [SLOW TEST] [83.470 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:26:28.873
    Oct  3 19:26:28.873: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename configmap 10/03/22 19:26:28.874
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:26:28.908
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:26:28.919
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-fdaee8e3-1cba-4eaa-8e2b-7425c7e81cbc 10/03/22 19:26:28.945
    STEP: Creating the pod 10/03/22 19:26:28.958
    Oct  3 19:26:28.979: INFO: Waiting up to 5m0s for pod "pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674" in namespace "configmap-1928" to be "running and ready"
    Oct  3 19:26:28.990: INFO: Pod "pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674": Phase="Pending", Reason="", readiness=false. Elapsed: 11.104084ms
    Oct  3 19:26:28.990: INFO: The phase of Pod pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:26:31.002: INFO: Pod "pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023281163s
    Oct  3 19:26:31.002: INFO: The phase of Pod pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:26:33.002: INFO: Pod "pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674": Phase="Running", Reason="", readiness=true. Elapsed: 4.022650046s
    Oct  3 19:26:33.002: INFO: The phase of Pod pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674 is Running (Ready = true)
    Oct  3 19:26:33.002: INFO: Pod "pod-configmaps-d97649fc-736e-40ac-9551-1cfc46f0a674" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-fdaee8e3-1cba-4eaa-8e2b-7425c7e81cbc 10/03/22 19:26:33.041
    STEP: waiting to observe update in volume 10/03/22 19:26:33.054
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Oct  3 19:27:52.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1928" for this suite. 10/03/22 19:27:52.325
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:27:52.344
Oct  3 19:27:52.345: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename subpath 10/03/22 19:27:52.346
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:27:52.377
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:27:52.387
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 10/03/22 19:27:52.397
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-cb6g 10/03/22 19:27:52.423
STEP: Creating a pod to test atomic-volume-subpath 10/03/22 19:27:52.423
Oct  3 19:27:52.444: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-cb6g" in namespace "subpath-8231" to be "Succeeded or Failed"
Oct  3 19:27:52.456: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Pending", Reason="", readiness=false. Elapsed: 11.747924ms
Oct  3 19:27:54.476: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032446695s
Oct  3 19:27:56.468: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 4.024407988s
Oct  3 19:27:58.467: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 6.02350333s
Oct  3 19:28:00.468: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 8.024410242s
Oct  3 19:28:02.468: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 10.023786994s
Oct  3 19:28:04.467: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 12.023457196s
Oct  3 19:28:06.469: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 14.025077827s
Oct  3 19:28:08.469: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 16.02508956s
Oct  3 19:28:10.468: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 18.024222525s
Oct  3 19:28:12.468: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 20.024423577s
Oct  3 19:28:14.469: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 22.025143999s
Oct  3 19:28:16.468: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=false. Elapsed: 24.023647555s
Oct  3 19:28:18.469: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.025057011s
STEP: Saw pod success 10/03/22 19:28:18.469
Oct  3 19:28:18.469: INFO: Pod "pod-subpath-test-downwardapi-cb6g" satisfied condition "Succeeded or Failed"
Oct  3 19:28:18.480: INFO: Trying to get logs from node 10.63.128.3 pod pod-subpath-test-downwardapi-cb6g container test-container-subpath-downwardapi-cb6g: <nil>
STEP: delete the pod 10/03/22 19:28:18.51
Oct  3 19:28:18.536: INFO: Waiting for pod pod-subpath-test-downwardapi-cb6g to disappear
Oct  3 19:28:18.546: INFO: Pod pod-subpath-test-downwardapi-cb6g no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-cb6g 10/03/22 19:28:18.546
Oct  3 19:28:18.547: INFO: Deleting pod "pod-subpath-test-downwardapi-cb6g" in namespace "subpath-8231"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Oct  3 19:28:18.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8231" for this suite. 10/03/22 19:28:18.571
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":42,"skipped":891,"failed":0}
------------------------------
• [SLOW TEST] [26.244 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:27:52.344
    Oct  3 19:27:52.345: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename subpath 10/03/22 19:27:52.346
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:27:52.377
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:27:52.387
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 10/03/22 19:27:52.397
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-cb6g 10/03/22 19:27:52.423
    STEP: Creating a pod to test atomic-volume-subpath 10/03/22 19:27:52.423
    Oct  3 19:27:52.444: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-cb6g" in namespace "subpath-8231" to be "Succeeded or Failed"
    Oct  3 19:27:52.456: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Pending", Reason="", readiness=false. Elapsed: 11.747924ms
    Oct  3 19:27:54.476: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032446695s
    Oct  3 19:27:56.468: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 4.024407988s
    Oct  3 19:27:58.467: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 6.02350333s
    Oct  3 19:28:00.468: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 8.024410242s
    Oct  3 19:28:02.468: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 10.023786994s
    Oct  3 19:28:04.467: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 12.023457196s
    Oct  3 19:28:06.469: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 14.025077827s
    Oct  3 19:28:08.469: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 16.02508956s
    Oct  3 19:28:10.468: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 18.024222525s
    Oct  3 19:28:12.468: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 20.024423577s
    Oct  3 19:28:14.469: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=true. Elapsed: 22.025143999s
    Oct  3 19:28:16.468: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Running", Reason="", readiness=false. Elapsed: 24.023647555s
    Oct  3 19:28:18.469: INFO: Pod "pod-subpath-test-downwardapi-cb6g": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.025057011s
    STEP: Saw pod success 10/03/22 19:28:18.469
    Oct  3 19:28:18.469: INFO: Pod "pod-subpath-test-downwardapi-cb6g" satisfied condition "Succeeded or Failed"
    Oct  3 19:28:18.480: INFO: Trying to get logs from node 10.63.128.3 pod pod-subpath-test-downwardapi-cb6g container test-container-subpath-downwardapi-cb6g: <nil>
    STEP: delete the pod 10/03/22 19:28:18.51
    Oct  3 19:28:18.536: INFO: Waiting for pod pod-subpath-test-downwardapi-cb6g to disappear
    Oct  3 19:28:18.546: INFO: Pod pod-subpath-test-downwardapi-cb6g no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-cb6g 10/03/22 19:28:18.546
    Oct  3 19:28:18.547: INFO: Deleting pod "pod-subpath-test-downwardapi-cb6g" in namespace "subpath-8231"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Oct  3 19:28:18.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-8231" for this suite. 10/03/22 19:28:18.571
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:28:18.59
Oct  3 19:28:18.590: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename statefulset 10/03/22 19:28:18.592
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:28:18.628
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:28:18.639
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7961 10/03/22 19:28:18.648
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-7961 10/03/22 19:28:18.661
Oct  3 19:28:18.685: INFO: Found 0 stateful pods, waiting for 1
Oct  3 19:28:28.697: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 10/03/22 19:28:28.718
STEP: updating a scale subresource 10/03/22 19:28:28.729
STEP: verifying the statefulset Spec.Replicas was modified 10/03/22 19:28:28.743
STEP: Patch a scale subresource 10/03/22 19:28:28.757
STEP: verifying the statefulset Spec.Replicas was modified 10/03/22 19:28:28.79
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct  3 19:28:28.801: INFO: Deleting all statefulset in ns statefulset-7961
Oct  3 19:28:28.812: INFO: Scaling statefulset ss to 0
Oct  3 19:28:38.865: INFO: Waiting for statefulset status.replicas updated to 0
Oct  3 19:28:38.876: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Oct  3 19:28:38.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7961" for this suite. 10/03/22 19:28:38.929
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":43,"skipped":893,"failed":0}
------------------------------
• [SLOW TEST] [20.357 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:28:18.59
    Oct  3 19:28:18.590: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename statefulset 10/03/22 19:28:18.592
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:28:18.628
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:28:18.639
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-7961 10/03/22 19:28:18.648
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-7961 10/03/22 19:28:18.661
    Oct  3 19:28:18.685: INFO: Found 0 stateful pods, waiting for 1
    Oct  3 19:28:28.697: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 10/03/22 19:28:28.718
    STEP: updating a scale subresource 10/03/22 19:28:28.729
    STEP: verifying the statefulset Spec.Replicas was modified 10/03/22 19:28:28.743
    STEP: Patch a scale subresource 10/03/22 19:28:28.757
    STEP: verifying the statefulset Spec.Replicas was modified 10/03/22 19:28:28.79
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Oct  3 19:28:28.801: INFO: Deleting all statefulset in ns statefulset-7961
    Oct  3 19:28:28.812: INFO: Scaling statefulset ss to 0
    Oct  3 19:28:38.865: INFO: Waiting for statefulset status.replicas updated to 0
    Oct  3 19:28:38.876: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Oct  3 19:28:38.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-7961" for this suite. 10/03/22 19:28:38.929
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:28:38.949
Oct  3 19:28:38.949: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-lifecycle-hook 10/03/22 19:28:38.95
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:28:38.98
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:28:38.99
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 10/03/22 19:28:39.015
Oct  3 19:28:39.035: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4325" to be "running and ready"
Oct  3 19:28:39.048: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 12.340482ms
Oct  3 19:28:39.048: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:28:41.061: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.025317443s
Oct  3 19:28:41.061: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Oct  3 19:28:41.061: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 10/03/22 19:28:41.071
Oct  3 19:28:41.089: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-4325" to be "running and ready"
Oct  3 19:28:41.100: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 11.25176ms
Oct  3 19:28:41.100: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:28:43.113: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023582494s
Oct  3 19:28:43.113: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:28:45.112: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.023093647s
Oct  3 19:28:45.112: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Oct  3 19:28:45.112: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 10/03/22 19:28:45.123
STEP: delete the pod with lifecycle hook 10/03/22 19:28:45.196
Oct  3 19:28:45.216: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  3 19:28:45.226: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  3 19:28:47.227: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  3 19:28:47.239: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Oct  3 19:28:47.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4325" for this suite. 10/03/22 19:28:47.253
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":44,"skipped":900,"failed":0}
------------------------------
• [SLOW TEST] [8.327 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:28:38.949
    Oct  3 19:28:38.949: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-lifecycle-hook 10/03/22 19:28:38.95
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:28:38.98
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:28:38.99
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 10/03/22 19:28:39.015
    Oct  3 19:28:39.035: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4325" to be "running and ready"
    Oct  3 19:28:39.048: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 12.340482ms
    Oct  3 19:28:39.048: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:28:41.061: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.025317443s
    Oct  3 19:28:41.061: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Oct  3 19:28:41.061: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 10/03/22 19:28:41.071
    Oct  3 19:28:41.089: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-4325" to be "running and ready"
    Oct  3 19:28:41.100: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 11.25176ms
    Oct  3 19:28:41.100: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:28:43.113: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023582494s
    Oct  3 19:28:43.113: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:28:45.112: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.023093647s
    Oct  3 19:28:45.112: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Oct  3 19:28:45.112: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 10/03/22 19:28:45.123
    STEP: delete the pod with lifecycle hook 10/03/22 19:28:45.196
    Oct  3 19:28:45.216: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Oct  3 19:28:45.226: INFO: Pod pod-with-poststart-exec-hook still exists
    Oct  3 19:28:47.227: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Oct  3 19:28:47.239: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Oct  3 19:28:47.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-4325" for this suite. 10/03/22 19:28:47.253
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:28:47.283
Oct  3 19:28:47.283: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir 10/03/22 19:28:47.285
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:28:47.324
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:28:47.343
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 10/03/22 19:28:47.374
Oct  3 19:28:47.413: INFO: Waiting up to 5m0s for pod "pod-0d9886be-ce50-4a29-a9a3-5798570ca14c" in namespace "emptydir-8275" to be "Succeeded or Failed"
Oct  3 19:28:47.426: INFO: Pod "pod-0d9886be-ce50-4a29-a9a3-5798570ca14c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.456536ms
Oct  3 19:28:49.438: INFO: Pod "pod-0d9886be-ce50-4a29-a9a3-5798570ca14c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024762872s
Oct  3 19:28:51.438: INFO: Pod "pod-0d9886be-ce50-4a29-a9a3-5798570ca14c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024691123s
STEP: Saw pod success 10/03/22 19:28:51.438
Oct  3 19:28:51.438: INFO: Pod "pod-0d9886be-ce50-4a29-a9a3-5798570ca14c" satisfied condition "Succeeded or Failed"
Oct  3 19:28:51.449: INFO: Trying to get logs from node 10.63.128.3 pod pod-0d9886be-ce50-4a29-a9a3-5798570ca14c container test-container: <nil>
STEP: delete the pod 10/03/22 19:28:51.476
Oct  3 19:28:51.509: INFO: Waiting for pod pod-0d9886be-ce50-4a29-a9a3-5798570ca14c to disappear
Oct  3 19:28:51.520: INFO: Pod pod-0d9886be-ce50-4a29-a9a3-5798570ca14c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Oct  3 19:28:51.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8275" for this suite. 10/03/22 19:28:51.544
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":45,"skipped":923,"failed":0}
------------------------------
• [4.281 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:28:47.283
    Oct  3 19:28:47.283: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir 10/03/22 19:28:47.285
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:28:47.324
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:28:47.343
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 10/03/22 19:28:47.374
    Oct  3 19:28:47.413: INFO: Waiting up to 5m0s for pod "pod-0d9886be-ce50-4a29-a9a3-5798570ca14c" in namespace "emptydir-8275" to be "Succeeded or Failed"
    Oct  3 19:28:47.426: INFO: Pod "pod-0d9886be-ce50-4a29-a9a3-5798570ca14c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.456536ms
    Oct  3 19:28:49.438: INFO: Pod "pod-0d9886be-ce50-4a29-a9a3-5798570ca14c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024762872s
    Oct  3 19:28:51.438: INFO: Pod "pod-0d9886be-ce50-4a29-a9a3-5798570ca14c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024691123s
    STEP: Saw pod success 10/03/22 19:28:51.438
    Oct  3 19:28:51.438: INFO: Pod "pod-0d9886be-ce50-4a29-a9a3-5798570ca14c" satisfied condition "Succeeded or Failed"
    Oct  3 19:28:51.449: INFO: Trying to get logs from node 10.63.128.3 pod pod-0d9886be-ce50-4a29-a9a3-5798570ca14c container test-container: <nil>
    STEP: delete the pod 10/03/22 19:28:51.476
    Oct  3 19:28:51.509: INFO: Waiting for pod pod-0d9886be-ce50-4a29-a9a3-5798570ca14c to disappear
    Oct  3 19:28:51.520: INFO: Pod pod-0d9886be-ce50-4a29-a9a3-5798570ca14c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Oct  3 19:28:51.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8275" for this suite. 10/03/22 19:28:51.544
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:28:51.564
Oct  3 19:28:51.564: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename crd-webhook 10/03/22 19:28:51.566
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:28:51.6
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:28:51.61
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 10/03/22 19:28:51.62
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 10/03/22 19:28:52.162
STEP: Deploying the custom resource conversion webhook pod 10/03/22 19:28:52.183
STEP: Wait for the deployment to be ready 10/03/22 19:28:52.217
Oct  3 19:28:52.268: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Oct  3 19:28:54.303: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 28, 52, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 28, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 28, 52, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 28, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 10/03/22 19:28:56.317
STEP: Verifying the service has paired with the endpoint 10/03/22 19:28:56.351
Oct  3 19:28:57.352: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Oct  3 19:28:57.364: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Creating a v1 custom resource 10/03/22 19:29:00.122
STEP: Create a v2 custom resource 10/03/22 19:29:00.164
STEP: List CRs in v1 10/03/22 19:29:00.267
STEP: List CRs in v2 10/03/22 19:29:00.288
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 19:29:00.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-213" for this suite. 10/03/22 19:29:00.857
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":46,"skipped":928,"failed":0}
------------------------------
• [SLOW TEST] [9.469 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:28:51.564
    Oct  3 19:28:51.564: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename crd-webhook 10/03/22 19:28:51.566
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:28:51.6
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:28:51.61
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 10/03/22 19:28:51.62
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 10/03/22 19:28:52.162
    STEP: Deploying the custom resource conversion webhook pod 10/03/22 19:28:52.183
    STEP: Wait for the deployment to be ready 10/03/22 19:28:52.217
    Oct  3 19:28:52.268: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    Oct  3 19:28:54.303: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 28, 52, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 28, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 28, 52, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 28, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 10/03/22 19:28:56.317
    STEP: Verifying the service has paired with the endpoint 10/03/22 19:28:56.351
    Oct  3 19:28:57.352: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Oct  3 19:28:57.364: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Creating a v1 custom resource 10/03/22 19:29:00.122
    STEP: Create a v2 custom resource 10/03/22 19:29:00.164
    STEP: List CRs in v1 10/03/22 19:29:00.267
    STEP: List CRs in v2 10/03/22 19:29:00.288
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 19:29:00.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-213" for this suite. 10/03/22 19:29:00.857
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:29:01.035
Oct  3 19:29:01.035: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 19:29:01.036
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:01.068
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:01.078
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 10/03/22 19:29:01.092
Oct  3 19:29:01.113: INFO: Waiting up to 5m0s for pod "downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450" in namespace "projected-7002" to be "Succeeded or Failed"
Oct  3 19:29:01.125: INFO: Pod "downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450": Phase="Pending", Reason="", readiness=false. Elapsed: 12.405313ms
Oct  3 19:29:03.136: INFO: Pod "downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023227905s
Oct  3 19:29:05.137: INFO: Pod "downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023884892s
Oct  3 19:29:07.164: INFO: Pod "downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.051510601s
STEP: Saw pod success 10/03/22 19:29:07.164
Oct  3 19:29:07.165: INFO: Pod "downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450" satisfied condition "Succeeded or Failed"
Oct  3 19:29:07.179: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450 container client-container: <nil>
STEP: delete the pod 10/03/22 19:29:07.208
Oct  3 19:29:07.242: INFO: Waiting for pod downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450 to disappear
Oct  3 19:29:07.259: INFO: Pod downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Oct  3 19:29:07.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7002" for this suite. 10/03/22 19:29:07.275
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":47,"skipped":958,"failed":0}
------------------------------
• [SLOW TEST] [6.266 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:29:01.035
    Oct  3 19:29:01.035: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 19:29:01.036
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:01.068
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:01.078
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 10/03/22 19:29:01.092
    Oct  3 19:29:01.113: INFO: Waiting up to 5m0s for pod "downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450" in namespace "projected-7002" to be "Succeeded or Failed"
    Oct  3 19:29:01.125: INFO: Pod "downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450": Phase="Pending", Reason="", readiness=false. Elapsed: 12.405313ms
    Oct  3 19:29:03.136: INFO: Pod "downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023227905s
    Oct  3 19:29:05.137: INFO: Pod "downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023884892s
    Oct  3 19:29:07.164: INFO: Pod "downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.051510601s
    STEP: Saw pod success 10/03/22 19:29:07.164
    Oct  3 19:29:07.165: INFO: Pod "downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450" satisfied condition "Succeeded or Failed"
    Oct  3 19:29:07.179: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450 container client-container: <nil>
    STEP: delete the pod 10/03/22 19:29:07.208
    Oct  3 19:29:07.242: INFO: Waiting for pod downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450 to disappear
    Oct  3 19:29:07.259: INFO: Pod downwardapi-volume-21fd68d6-ea94-4f51-a4a1-466a7c964450 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Oct  3 19:29:07.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7002" for this suite. 10/03/22 19:29:07.275
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:29:07.304
Oct  3 19:29:07.304: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-runtime 10/03/22 19:29:07.305
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:07.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:07.352
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 10/03/22 19:29:07.362
STEP: wait for the container to reach Succeeded 10/03/22 19:29:07.385
STEP: get the container status 10/03/22 19:29:11.445
STEP: the container should be terminated 10/03/22 19:29:11.456
STEP: the termination message should be set 10/03/22 19:29:11.456
Oct  3 19:29:11.456: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 10/03/22 19:29:11.456
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Oct  3 19:29:11.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-398" for this suite. 10/03/22 19:29:11.511
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":48,"skipped":978,"failed":0}
------------------------------
• [4.226 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:29:07.304
    Oct  3 19:29:07.304: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-runtime 10/03/22 19:29:07.305
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:07.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:07.352
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 10/03/22 19:29:07.362
    STEP: wait for the container to reach Succeeded 10/03/22 19:29:07.385
    STEP: get the container status 10/03/22 19:29:11.445
    STEP: the container should be terminated 10/03/22 19:29:11.456
    STEP: the termination message should be set 10/03/22 19:29:11.456
    Oct  3 19:29:11.456: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 10/03/22 19:29:11.456
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Oct  3 19:29:11.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-398" for this suite. 10/03/22 19:29:11.511
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:29:11.538
Oct  3 19:29:11.538: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename daemonsets 10/03/22 19:29:11.539
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:11.571
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:11.58
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Oct  3 19:29:11.653: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 10/03/22 19:29:11.667
Oct  3 19:29:11.678: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:29:11.678: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 10/03/22 19:29:11.678
Oct  3 19:29:11.735: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:29:11.735: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:29:12.752: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:29:12.753: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:29:13.748: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Oct  3 19:29:13.748: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 10/03/22 19:29:13.759
Oct  3 19:29:13.812: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:29:13.812: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 10/03/22 19:29:13.812
Oct  3 19:29:13.843: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:29:13.843: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:29:14.855: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:29:14.855: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:29:15.853: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:29:15.853: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:29:16.854: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:29:16.854: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:29:17.873: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:29:17.873: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:29:18.855: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Oct  3 19:29:18.855: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 10/03/22 19:29:18.877
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9281, will wait for the garbage collector to delete the pods 10/03/22 19:29:18.877
Oct  3 19:29:18.955: INFO: Deleting DaemonSet.extensions daemon-set took: 17.334441ms
Oct  3 19:29:19.056: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.640174ms
Oct  3 19:29:21.469: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:29:21.470: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct  3 19:29:21.481: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19361"},"items":null}

Oct  3 19:29:21.492: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19361"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Oct  3 19:29:21.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9281" for this suite. 10/03/22 19:29:21.588
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":49,"skipped":1074,"failed":0}
------------------------------
• [SLOW TEST] [10.069 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:29:11.538
    Oct  3 19:29:11.538: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename daemonsets 10/03/22 19:29:11.539
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:11.571
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:11.58
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Oct  3 19:29:11.653: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 10/03/22 19:29:11.667
    Oct  3 19:29:11.678: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:29:11.678: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 10/03/22 19:29:11.678
    Oct  3 19:29:11.735: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:29:11.735: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:29:12.752: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:29:12.753: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:29:13.748: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Oct  3 19:29:13.748: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 10/03/22 19:29:13.759
    Oct  3 19:29:13.812: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:29:13.812: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 10/03/22 19:29:13.812
    Oct  3 19:29:13.843: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:29:13.843: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:29:14.855: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:29:14.855: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:29:15.853: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:29:15.853: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:29:16.854: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:29:16.854: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:29:17.873: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:29:17.873: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:29:18.855: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Oct  3 19:29:18.855: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 10/03/22 19:29:18.877
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9281, will wait for the garbage collector to delete the pods 10/03/22 19:29:18.877
    Oct  3 19:29:18.955: INFO: Deleting DaemonSet.extensions daemon-set took: 17.334441ms
    Oct  3 19:29:19.056: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.640174ms
    Oct  3 19:29:21.469: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:29:21.470: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Oct  3 19:29:21.481: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19361"},"items":null}

    Oct  3 19:29:21.492: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19361"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 19:29:21.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-9281" for this suite. 10/03/22 19:29:21.588
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:29:21.613
Oct  3 19:29:21.613: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 19:29:21.614
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:21.643
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:21.653
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 10/03/22 19:29:21.664
Oct  3 19:29:21.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 create -f -'
Oct  3 19:29:22.707: INFO: stderr: ""
Oct  3 19:29:22.707: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 10/03/22 19:29:22.707
Oct  3 19:29:22.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct  3 19:29:22.845: INFO: stderr: ""
Oct  3 19:29:22.845: INFO: stdout: "update-demo-nautilus-89vl6 update-demo-nautilus-x7bpg "
Oct  3 19:29:22.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods update-demo-nautilus-89vl6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct  3 19:29:22.941: INFO: stderr: ""
Oct  3 19:29:22.942: INFO: stdout: ""
Oct  3 19:29:22.942: INFO: update-demo-nautilus-89vl6 is created but not running
Oct  3 19:29:27.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct  3 19:29:28.221: INFO: stderr: ""
Oct  3 19:29:28.221: INFO: stdout: "update-demo-nautilus-89vl6 update-demo-nautilus-x7bpg "
Oct  3 19:29:28.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods update-demo-nautilus-89vl6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct  3 19:29:28.363: INFO: stderr: ""
Oct  3 19:29:28.363: INFO: stdout: ""
Oct  3 19:29:28.363: INFO: update-demo-nautilus-89vl6 is created but not running
Oct  3 19:29:33.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct  3 19:29:33.471: INFO: stderr: ""
Oct  3 19:29:33.471: INFO: stdout: "update-demo-nautilus-89vl6 update-demo-nautilus-x7bpg "
Oct  3 19:29:33.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods update-demo-nautilus-89vl6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct  3 19:29:33.580: INFO: stderr: ""
Oct  3 19:29:33.580: INFO: stdout: "true"
Oct  3 19:29:33.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods update-demo-nautilus-89vl6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct  3 19:29:33.695: INFO: stderr: ""
Oct  3 19:29:33.695: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Oct  3 19:29:33.695: INFO: validating pod update-demo-nautilus-89vl6
Oct  3 19:29:33.739: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  3 19:29:33.739: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  3 19:29:33.739: INFO: update-demo-nautilus-89vl6 is verified up and running
Oct  3 19:29:33.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods update-demo-nautilus-x7bpg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct  3 19:29:33.862: INFO: stderr: ""
Oct  3 19:29:33.862: INFO: stdout: "true"
Oct  3 19:29:33.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods update-demo-nautilus-x7bpg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct  3 19:29:33.972: INFO: stderr: ""
Oct  3 19:29:33.972: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Oct  3 19:29:33.972: INFO: validating pod update-demo-nautilus-x7bpg
Oct  3 19:29:34.010: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  3 19:29:34.010: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  3 19:29:34.010: INFO: update-demo-nautilus-x7bpg is verified up and running
STEP: using delete to clean up resources 10/03/22 19:29:34.01
Oct  3 19:29:34.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 delete --grace-period=0 --force -f -'
Oct  3 19:29:34.119: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  3 19:29:34.119: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct  3 19:29:34.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get rc,svc -l name=update-demo --no-headers'
Oct  3 19:29:34.255: INFO: stderr: "No resources found in kubectl-2051 namespace.\n"
Oct  3 19:29:34.255: INFO: stdout: ""
Oct  3 19:29:34.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  3 19:29:34.486: INFO: stderr: ""
Oct  3 19:29:34.486: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 19:29:34.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2051" for this suite. 10/03/22 19:29:34.501
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":50,"skipped":1100,"failed":0}
------------------------------
• [SLOW TEST] [12.909 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:29:21.613
    Oct  3 19:29:21.613: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 19:29:21.614
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:21.643
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:21.653
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 10/03/22 19:29:21.664
    Oct  3 19:29:21.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 create -f -'
    Oct  3 19:29:22.707: INFO: stderr: ""
    Oct  3 19:29:22.707: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 10/03/22 19:29:22.707
    Oct  3 19:29:22.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct  3 19:29:22.845: INFO: stderr: ""
    Oct  3 19:29:22.845: INFO: stdout: "update-demo-nautilus-89vl6 update-demo-nautilus-x7bpg "
    Oct  3 19:29:22.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods update-demo-nautilus-89vl6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct  3 19:29:22.941: INFO: stderr: ""
    Oct  3 19:29:22.942: INFO: stdout: ""
    Oct  3 19:29:22.942: INFO: update-demo-nautilus-89vl6 is created but not running
    Oct  3 19:29:27.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct  3 19:29:28.221: INFO: stderr: ""
    Oct  3 19:29:28.221: INFO: stdout: "update-demo-nautilus-89vl6 update-demo-nautilus-x7bpg "
    Oct  3 19:29:28.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods update-demo-nautilus-89vl6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct  3 19:29:28.363: INFO: stderr: ""
    Oct  3 19:29:28.363: INFO: stdout: ""
    Oct  3 19:29:28.363: INFO: update-demo-nautilus-89vl6 is created but not running
    Oct  3 19:29:33.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct  3 19:29:33.471: INFO: stderr: ""
    Oct  3 19:29:33.471: INFO: stdout: "update-demo-nautilus-89vl6 update-demo-nautilus-x7bpg "
    Oct  3 19:29:33.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods update-demo-nautilus-89vl6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct  3 19:29:33.580: INFO: stderr: ""
    Oct  3 19:29:33.580: INFO: stdout: "true"
    Oct  3 19:29:33.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods update-demo-nautilus-89vl6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Oct  3 19:29:33.695: INFO: stderr: ""
    Oct  3 19:29:33.695: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Oct  3 19:29:33.695: INFO: validating pod update-demo-nautilus-89vl6
    Oct  3 19:29:33.739: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Oct  3 19:29:33.739: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Oct  3 19:29:33.739: INFO: update-demo-nautilus-89vl6 is verified up and running
    Oct  3 19:29:33.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods update-demo-nautilus-x7bpg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct  3 19:29:33.862: INFO: stderr: ""
    Oct  3 19:29:33.862: INFO: stdout: "true"
    Oct  3 19:29:33.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods update-demo-nautilus-x7bpg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Oct  3 19:29:33.972: INFO: stderr: ""
    Oct  3 19:29:33.972: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Oct  3 19:29:33.972: INFO: validating pod update-demo-nautilus-x7bpg
    Oct  3 19:29:34.010: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Oct  3 19:29:34.010: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Oct  3 19:29:34.010: INFO: update-demo-nautilus-x7bpg is verified up and running
    STEP: using delete to clean up resources 10/03/22 19:29:34.01
    Oct  3 19:29:34.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 delete --grace-period=0 --force -f -'
    Oct  3 19:29:34.119: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct  3 19:29:34.119: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Oct  3 19:29:34.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get rc,svc -l name=update-demo --no-headers'
    Oct  3 19:29:34.255: INFO: stderr: "No resources found in kubectl-2051 namespace.\n"
    Oct  3 19:29:34.255: INFO: stdout: ""
    Oct  3 19:29:34.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2051 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Oct  3 19:29:34.486: INFO: stderr: ""
    Oct  3 19:29:34.486: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 19:29:34.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2051" for this suite. 10/03/22 19:29:34.501
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:29:34.524
Oct  3 19:29:34.524: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 19:29:34.526
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:34.559
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:34.569
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 10/03/22 19:29:34.579
Oct  3 19:29:34.602: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2" in namespace "downward-api-2890" to be "Succeeded or Failed"
Oct  3 19:29:34.613: INFO: Pod "downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.47737ms
Oct  3 19:29:36.626: INFO: Pod "downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023749174s
Oct  3 19:29:38.626: INFO: Pod "downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023644279s
STEP: Saw pod success 10/03/22 19:29:38.626
Oct  3 19:29:38.626: INFO: Pod "downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2" satisfied condition "Succeeded or Failed"
Oct  3 19:29:38.642: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2 container client-container: <nil>
STEP: delete the pod 10/03/22 19:29:38.668
Oct  3 19:29:38.698: INFO: Waiting for pod downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2 to disappear
Oct  3 19:29:38.708: INFO: Pod downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Oct  3 19:29:38.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2890" for this suite. 10/03/22 19:29:38.722
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":51,"skipped":1112,"failed":0}
------------------------------
• [4.220 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:29:34.524
    Oct  3 19:29:34.524: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 19:29:34.526
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:34.559
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:34.569
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 10/03/22 19:29:34.579
    Oct  3 19:29:34.602: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2" in namespace "downward-api-2890" to be "Succeeded or Failed"
    Oct  3 19:29:34.613: INFO: Pod "downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.47737ms
    Oct  3 19:29:36.626: INFO: Pod "downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023749174s
    Oct  3 19:29:38.626: INFO: Pod "downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023644279s
    STEP: Saw pod success 10/03/22 19:29:38.626
    Oct  3 19:29:38.626: INFO: Pod "downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2" satisfied condition "Succeeded or Failed"
    Oct  3 19:29:38.642: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2 container client-container: <nil>
    STEP: delete the pod 10/03/22 19:29:38.668
    Oct  3 19:29:38.698: INFO: Waiting for pod downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2 to disappear
    Oct  3 19:29:38.708: INFO: Pod downwardapi-volume-5a2b59f8-40e2-44aa-b47b-07b46620bff2 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Oct  3 19:29:38.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2890" for this suite. 10/03/22 19:29:38.722
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:29:38.751
Oct  3 19:29:38.751: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 19:29:38.752
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:38.784
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:38.794
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 10/03/22 19:29:38.803
Oct  3 19:29:38.825: INFO: Waiting up to 5m0s for pod "downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c" in namespace "projected-889" to be "Succeeded or Failed"
Oct  3 19:29:38.837: INFO: Pod "downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.476772ms
Oct  3 19:29:40.849: INFO: Pod "downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c": Phase="Running", Reason="", readiness=true. Elapsed: 2.024086257s
Oct  3 19:29:42.848: INFO: Pod "downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c": Phase="Running", Reason="", readiness=false. Elapsed: 4.023184296s
Oct  3 19:29:44.849: INFO: Pod "downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023623431s
STEP: Saw pod success 10/03/22 19:29:44.849
Oct  3 19:29:44.849: INFO: Pod "downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c" satisfied condition "Succeeded or Failed"
Oct  3 19:29:44.861: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c container client-container: <nil>
STEP: delete the pod 10/03/22 19:29:44.888
Oct  3 19:29:44.916: INFO: Waiting for pod downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c to disappear
Oct  3 19:29:44.927: INFO: Pod downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Oct  3 19:29:44.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-889" for this suite. 10/03/22 19:29:44.955
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":52,"skipped":1142,"failed":0}
------------------------------
• [SLOW TEST] [6.223 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:29:38.751
    Oct  3 19:29:38.751: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 19:29:38.752
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:38.784
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:38.794
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 10/03/22 19:29:38.803
    Oct  3 19:29:38.825: INFO: Waiting up to 5m0s for pod "downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c" in namespace "projected-889" to be "Succeeded or Failed"
    Oct  3 19:29:38.837: INFO: Pod "downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.476772ms
    Oct  3 19:29:40.849: INFO: Pod "downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c": Phase="Running", Reason="", readiness=true. Elapsed: 2.024086257s
    Oct  3 19:29:42.848: INFO: Pod "downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c": Phase="Running", Reason="", readiness=false. Elapsed: 4.023184296s
    Oct  3 19:29:44.849: INFO: Pod "downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023623431s
    STEP: Saw pod success 10/03/22 19:29:44.849
    Oct  3 19:29:44.849: INFO: Pod "downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c" satisfied condition "Succeeded or Failed"
    Oct  3 19:29:44.861: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c container client-container: <nil>
    STEP: delete the pod 10/03/22 19:29:44.888
    Oct  3 19:29:44.916: INFO: Waiting for pod downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c to disappear
    Oct  3 19:29:44.927: INFO: Pod downwardapi-volume-97818538-7b46-4d69-a363-19d82964019c no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Oct  3 19:29:44.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-889" for this suite. 10/03/22 19:29:44.955
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:29:44.978
Oct  3 19:29:44.978: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename pods 10/03/22 19:29:44.979
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:45.012
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:45.022
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 10/03/22 19:29:45.032
Oct  3 19:29:45.054: INFO: created test-pod-1
Oct  3 19:29:45.067: INFO: created test-pod-2
Oct  3 19:29:45.080: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 10/03/22 19:29:45.08
Oct  3 19:29:45.081: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-9627' to be running and ready
Oct  3 19:29:45.115: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Oct  3 19:29:45.115: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Oct  3 19:29:45.115: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Oct  3 19:29:45.115: INFO: 0 / 3 pods in namespace 'pods-9627' are running and ready (0 seconds elapsed)
Oct  3 19:29:45.115: INFO: expected 0 pod replicas in namespace 'pods-9627', 0 are Running and Ready.
Oct  3 19:29:45.115: INFO: POD         NODE         PHASE    GRACE  CONDITIONS
Oct  3 19:29:45.115: INFO: test-pod-1  10.63.128.3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  }]
Oct  3 19:29:45.115: INFO: test-pod-2  10.63.128.3  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  }]
Oct  3 19:29:45.115: INFO: test-pod-3  10.63.128.3  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  }]
Oct  3 19:29:45.115: INFO: 
Oct  3 19:29:47.156: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Oct  3 19:29:47.156: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Oct  3 19:29:47.156: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Oct  3 19:29:47.156: INFO: 0 / 3 pods in namespace 'pods-9627' are running and ready (2 seconds elapsed)
Oct  3 19:29:47.156: INFO: expected 0 pod replicas in namespace 'pods-9627', 0 are Running and Ready.
Oct  3 19:29:47.156: INFO: POD         NODE         PHASE    GRACE  CONDITIONS
Oct  3 19:29:47.156: INFO: test-pod-1  10.63.128.3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  }]
Oct  3 19:29:47.156: INFO: test-pod-2  10.63.128.3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  }]
Oct  3 19:29:47.156: INFO: test-pod-3  10.63.128.3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  }]
Oct  3 19:29:47.156: INFO: 
Oct  3 19:29:49.148: INFO: 3 / 3 pods in namespace 'pods-9627' are running and ready (4 seconds elapsed)
Oct  3 19:29:49.148: INFO: expected 0 pod replicas in namespace 'pods-9627', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 10/03/22 19:29:49.199
Oct  3 19:29:49.212: INFO: Pod quantity 3 is different from expected quantity 0
Oct  3 19:29:50.224: INFO: Pod quantity 3 is different from expected quantity 0
Oct  3 19:29:51.225: INFO: Pod quantity 2 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Oct  3 19:29:52.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9627" for this suite. 10/03/22 19:29:52.24
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":53,"skipped":1171,"failed":0}
------------------------------
• [SLOW TEST] [7.281 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:29:44.978
    Oct  3 19:29:44.978: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename pods 10/03/22 19:29:44.979
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:45.012
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:45.022
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 10/03/22 19:29:45.032
    Oct  3 19:29:45.054: INFO: created test-pod-1
    Oct  3 19:29:45.067: INFO: created test-pod-2
    Oct  3 19:29:45.080: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 10/03/22 19:29:45.08
    Oct  3 19:29:45.081: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-9627' to be running and ready
    Oct  3 19:29:45.115: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Oct  3 19:29:45.115: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Oct  3 19:29:45.115: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Oct  3 19:29:45.115: INFO: 0 / 3 pods in namespace 'pods-9627' are running and ready (0 seconds elapsed)
    Oct  3 19:29:45.115: INFO: expected 0 pod replicas in namespace 'pods-9627', 0 are Running and Ready.
    Oct  3 19:29:45.115: INFO: POD         NODE         PHASE    GRACE  CONDITIONS
    Oct  3 19:29:45.115: INFO: test-pod-1  10.63.128.3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  }]
    Oct  3 19:29:45.115: INFO: test-pod-2  10.63.128.3  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  }]
    Oct  3 19:29:45.115: INFO: test-pod-3  10.63.128.3  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  }]
    Oct  3 19:29:45.115: INFO: 
    Oct  3 19:29:47.156: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Oct  3 19:29:47.156: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Oct  3 19:29:47.156: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Oct  3 19:29:47.156: INFO: 0 / 3 pods in namespace 'pods-9627' are running and ready (2 seconds elapsed)
    Oct  3 19:29:47.156: INFO: expected 0 pod replicas in namespace 'pods-9627', 0 are Running and Ready.
    Oct  3 19:29:47.156: INFO: POD         NODE         PHASE    GRACE  CONDITIONS
    Oct  3 19:29:47.156: INFO: test-pod-1  10.63.128.3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  }]
    Oct  3 19:29:47.156: INFO: test-pod-2  10.63.128.3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  }]
    Oct  3 19:29:47.156: INFO: test-pod-3  10.63.128.3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:45 +0000 UTC  }]
    Oct  3 19:29:47.156: INFO: 
    Oct  3 19:29:49.148: INFO: 3 / 3 pods in namespace 'pods-9627' are running and ready (4 seconds elapsed)
    Oct  3 19:29:49.148: INFO: expected 0 pod replicas in namespace 'pods-9627', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 10/03/22 19:29:49.199
    Oct  3 19:29:49.212: INFO: Pod quantity 3 is different from expected quantity 0
    Oct  3 19:29:50.224: INFO: Pod quantity 3 is different from expected quantity 0
    Oct  3 19:29:51.225: INFO: Pod quantity 2 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Oct  3 19:29:52.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9627" for this suite. 10/03/22 19:29:52.24
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:29:52.266
Oct  3 19:29:52.266: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename svcaccounts 10/03/22 19:29:52.267
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:52.31
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:52.319
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Oct  3 19:29:52.379: INFO: created pod pod-service-account-defaultsa
Oct  3 19:29:52.379: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct  3 19:29:52.392: INFO: created pod pod-service-account-mountsa
Oct  3 19:29:52.392: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct  3 19:29:52.406: INFO: created pod pod-service-account-nomountsa
Oct  3 19:29:52.406: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct  3 19:29:52.424: INFO: created pod pod-service-account-defaultsa-mountspec
Oct  3 19:29:52.424: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct  3 19:29:52.437: INFO: created pod pod-service-account-mountsa-mountspec
Oct  3 19:29:52.437: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct  3 19:29:52.460: INFO: created pod pod-service-account-nomountsa-mountspec
Oct  3 19:29:52.460: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct  3 19:29:52.486: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct  3 19:29:52.486: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct  3 19:29:52.500: INFO: created pod pod-service-account-mountsa-nomountspec
Oct  3 19:29:52.500: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct  3 19:29:52.518: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct  3 19:29:52.518: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Oct  3 19:29:52.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9789" for this suite. 10/03/22 19:29:52.535
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":54,"skipped":1188,"failed":0}
------------------------------
• [0.289 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:29:52.266
    Oct  3 19:29:52.266: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename svcaccounts 10/03/22 19:29:52.267
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:52.31
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:52.319
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Oct  3 19:29:52.379: INFO: created pod pod-service-account-defaultsa
    Oct  3 19:29:52.379: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Oct  3 19:29:52.392: INFO: created pod pod-service-account-mountsa
    Oct  3 19:29:52.392: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Oct  3 19:29:52.406: INFO: created pod pod-service-account-nomountsa
    Oct  3 19:29:52.406: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Oct  3 19:29:52.424: INFO: created pod pod-service-account-defaultsa-mountspec
    Oct  3 19:29:52.424: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Oct  3 19:29:52.437: INFO: created pod pod-service-account-mountsa-mountspec
    Oct  3 19:29:52.437: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Oct  3 19:29:52.460: INFO: created pod pod-service-account-nomountsa-mountspec
    Oct  3 19:29:52.460: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Oct  3 19:29:52.486: INFO: created pod pod-service-account-defaultsa-nomountspec
    Oct  3 19:29:52.486: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Oct  3 19:29:52.500: INFO: created pod pod-service-account-mountsa-nomountspec
    Oct  3 19:29:52.500: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Oct  3 19:29:52.518: INFO: created pod pod-service-account-nomountsa-nomountspec
    Oct  3 19:29:52.518: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Oct  3 19:29:52.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9789" for this suite. 10/03/22 19:29:52.535
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:29:52.572
Oct  3 19:29:52.572: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename pods 10/03/22 19:29:52.573
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:52.604
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:52.614
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 10/03/22 19:29:52.668
STEP: watching for Pod to be ready 10/03/22 19:29:52.688
Oct  3 19:29:52.693: INFO: observed Pod pod-test in namespace pods-5101 in phase Pending with labels: map[test-pod-static:true] & conditions []
Oct  3 19:29:52.698: INFO: observed Pod pod-test in namespace pods-5101 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC  }]
Oct  3 19:29:52.731: INFO: observed Pod pod-test in namespace pods-5101 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC  }]
Oct  3 19:29:53.686: INFO: observed Pod pod-test in namespace pods-5101 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC  }]
Oct  3 19:29:54.340: INFO: Found Pod pod-test in namespace pods-5101 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 10/03/22 19:29:54.351
STEP: getting the Pod and ensuring that it's patched 10/03/22 19:29:54.37
STEP: replacing the Pod's status Ready condition to False 10/03/22 19:29:54.38
STEP: check the Pod again to ensure its Ready conditions are False 10/03/22 19:29:54.406
STEP: deleting the Pod via a Collection with a LabelSelector 10/03/22 19:29:54.406
STEP: watching for the Pod to be deleted 10/03/22 19:29:54.43
Oct  3 19:29:54.435: INFO: observed event type MODIFIED
Oct  3 19:29:56.351: INFO: observed event type MODIFIED
Oct  3 19:29:56.731: INFO: observed event type MODIFIED
Oct  3 19:29:57.362: INFO: observed event type MODIFIED
Oct  3 19:29:57.381: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Oct  3 19:29:57.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5101" for this suite. 10/03/22 19:29:57.417
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":55,"skipped":1310,"failed":0}
------------------------------
• [4.864 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:29:52.572
    Oct  3 19:29:52.572: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename pods 10/03/22 19:29:52.573
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:52.604
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:52.614
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 10/03/22 19:29:52.668
    STEP: watching for Pod to be ready 10/03/22 19:29:52.688
    Oct  3 19:29:52.693: INFO: observed Pod pod-test in namespace pods-5101 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Oct  3 19:29:52.698: INFO: observed Pod pod-test in namespace pods-5101 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC  }]
    Oct  3 19:29:52.731: INFO: observed Pod pod-test in namespace pods-5101 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC  }]
    Oct  3 19:29:53.686: INFO: observed Pod pod-test in namespace pods-5101 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC  }]
    Oct  3 19:29:54.340: INFO: Found Pod pod-test in namespace pods-5101 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:29:52 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 10/03/22 19:29:54.351
    STEP: getting the Pod and ensuring that it's patched 10/03/22 19:29:54.37
    STEP: replacing the Pod's status Ready condition to False 10/03/22 19:29:54.38
    STEP: check the Pod again to ensure its Ready conditions are False 10/03/22 19:29:54.406
    STEP: deleting the Pod via a Collection with a LabelSelector 10/03/22 19:29:54.406
    STEP: watching for the Pod to be deleted 10/03/22 19:29:54.43
    Oct  3 19:29:54.435: INFO: observed event type MODIFIED
    Oct  3 19:29:56.351: INFO: observed event type MODIFIED
    Oct  3 19:29:56.731: INFO: observed event type MODIFIED
    Oct  3 19:29:57.362: INFO: observed event type MODIFIED
    Oct  3 19:29:57.381: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Oct  3 19:29:57.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5101" for this suite. 10/03/22 19:29:57.417
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:29:57.47
Oct  3 19:29:57.470: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 19:29:57.471
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:57.503
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:57.512
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 10/03/22 19:29:57.522
Oct  3 19:29:57.543: INFO: Waiting up to 5m0s for pod "downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f" in namespace "downward-api-849" to be "Succeeded or Failed"
Oct  3 19:29:57.556: INFO: Pod "downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.882612ms
Oct  3 19:29:59.569: INFO: Pod "downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025253484s
Oct  3 19:30:01.568: INFO: Pod "downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024417245s
Oct  3 19:30:03.568: INFO: Pod "downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024804292s
STEP: Saw pod success 10/03/22 19:30:03.568
Oct  3 19:30:03.568: INFO: Pod "downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f" satisfied condition "Succeeded or Failed"
Oct  3 19:30:03.579: INFO: Trying to get logs from node 10.63.128.3 pod downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f container dapi-container: <nil>
STEP: delete the pod 10/03/22 19:30:03.613
Oct  3 19:30:03.645: INFO: Waiting for pod downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f to disappear
Oct  3 19:30:03.656: INFO: Pod downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Oct  3 19:30:03.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-849" for this suite. 10/03/22 19:30:03.67
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":56,"skipped":1428,"failed":0}
------------------------------
• [SLOW TEST] [6.219 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:29:57.47
    Oct  3 19:29:57.470: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 19:29:57.471
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:29:57.503
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:29:57.512
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 10/03/22 19:29:57.522
    Oct  3 19:29:57.543: INFO: Waiting up to 5m0s for pod "downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f" in namespace "downward-api-849" to be "Succeeded or Failed"
    Oct  3 19:29:57.556: INFO: Pod "downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.882612ms
    Oct  3 19:29:59.569: INFO: Pod "downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025253484s
    Oct  3 19:30:01.568: INFO: Pod "downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024417245s
    Oct  3 19:30:03.568: INFO: Pod "downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024804292s
    STEP: Saw pod success 10/03/22 19:30:03.568
    Oct  3 19:30:03.568: INFO: Pod "downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f" satisfied condition "Succeeded or Failed"
    Oct  3 19:30:03.579: INFO: Trying to get logs from node 10.63.128.3 pod downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f container dapi-container: <nil>
    STEP: delete the pod 10/03/22 19:30:03.613
    Oct  3 19:30:03.645: INFO: Waiting for pod downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f to disappear
    Oct  3 19:30:03.656: INFO: Pod downward-api-be5a4ffb-6d7f-4ff0-bf64-30ef7dbfce4f no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Oct  3 19:30:03.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-849" for this suite. 10/03/22 19:30:03.67
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:30:03.69
Oct  3 19:30:03.690: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename svcaccounts 10/03/22 19:30:03.691
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:30:03.724
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:30:03.736
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 10/03/22 19:30:03.747
STEP: watching for the ServiceAccount to be added 10/03/22 19:30:03.774
STEP: patching the ServiceAccount 10/03/22 19:30:03.779
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 10/03/22 19:30:03.8
STEP: deleting the ServiceAccount 10/03/22 19:30:03.836
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Oct  3 19:30:03.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7894" for this suite. 10/03/22 19:30:03.886
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":57,"skipped":1449,"failed":0}
------------------------------
• [0.215 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:30:03.69
    Oct  3 19:30:03.690: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename svcaccounts 10/03/22 19:30:03.691
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:30:03.724
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:30:03.736
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 10/03/22 19:30:03.747
    STEP: watching for the ServiceAccount to be added 10/03/22 19:30:03.774
    STEP: patching the ServiceAccount 10/03/22 19:30:03.779
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 10/03/22 19:30:03.8
    STEP: deleting the ServiceAccount 10/03/22 19:30:03.836
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Oct  3 19:30:03.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-7894" for this suite. 10/03/22 19:30:03.886
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:30:03.911
Oct  3 19:30:03.911: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 19:30:03.912
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:30:03.944
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:30:03.954
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 19:30:04.002
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 19:30:04.895
STEP: Deploying the webhook pod 10/03/22 19:30:04.916
STEP: Wait for the deployment to be ready 10/03/22 19:30:04.944
Oct  3 19:30:04.967: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/03/22 19:30:07.003
STEP: Verifying the service has paired with the endpoint 10/03/22 19:30:07.032
Oct  3 19:30:08.033: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 10/03/22 19:30:08.046
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 10/03/22 19:30:08.051
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 10/03/22 19:30:08.051
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 10/03/22 19:30:08.052
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 10/03/22 19:30:08.056
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 10/03/22 19:30:08.057
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 10/03/22 19:30:08.061
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 19:30:08.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7802" for this suite. 10/03/22 19:30:08.075
STEP: Destroying namespace "webhook-7802-markers" for this suite. 10/03/22 19:30:08.094
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":58,"skipped":1463,"failed":0}
------------------------------
• [4.302 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:30:03.911
    Oct  3 19:30:03.911: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 19:30:03.912
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:30:03.944
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:30:03.954
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 19:30:04.002
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 19:30:04.895
    STEP: Deploying the webhook pod 10/03/22 19:30:04.916
    STEP: Wait for the deployment to be ready 10/03/22 19:30:04.944
    Oct  3 19:30:04.967: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/03/22 19:30:07.003
    STEP: Verifying the service has paired with the endpoint 10/03/22 19:30:07.032
    Oct  3 19:30:08.033: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 10/03/22 19:30:08.046
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 10/03/22 19:30:08.051
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 10/03/22 19:30:08.051
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 10/03/22 19:30:08.052
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 10/03/22 19:30:08.056
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 10/03/22 19:30:08.057
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 10/03/22 19:30:08.061
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 19:30:08.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7802" for this suite. 10/03/22 19:30:08.075
    STEP: Destroying namespace "webhook-7802-markers" for this suite. 10/03/22 19:30:08.094
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:30:08.213
Oct  3 19:30:08.214: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename crd-webhook 10/03/22 19:30:08.215
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:30:08.264
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:30:08.273
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 10/03/22 19:30:08.283
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 10/03/22 19:30:08.838
STEP: Deploying the custom resource conversion webhook pod 10/03/22 19:30:08.851
STEP: Wait for the deployment to be ready 10/03/22 19:30:08.891
Oct  3 19:30:08.941: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Oct  3 19:30:10.975: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 30, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 30, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 30, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 30, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 10/03/22 19:30:12.987
STEP: Verifying the service has paired with the endpoint 10/03/22 19:30:13.016
Oct  3 19:30:14.016: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Oct  3 19:30:14.028: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Creating a v1 custom resource 10/03/22 19:30:16.754
STEP: v2 custom resource should be converted 10/03/22 19:30:16.768
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 19:30:17.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3546" for this suite. 10/03/22 19:30:17.337
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":59,"skipped":1468,"failed":0}
------------------------------
• [SLOW TEST] [9.276 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:30:08.213
    Oct  3 19:30:08.214: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename crd-webhook 10/03/22 19:30:08.215
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:30:08.264
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:30:08.273
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 10/03/22 19:30:08.283
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 10/03/22 19:30:08.838
    STEP: Deploying the custom resource conversion webhook pod 10/03/22 19:30:08.851
    STEP: Wait for the deployment to be ready 10/03/22 19:30:08.891
    Oct  3 19:30:08.941: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    Oct  3 19:30:10.975: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 30, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 30, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 30, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 30, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 10/03/22 19:30:12.987
    STEP: Verifying the service has paired with the endpoint 10/03/22 19:30:13.016
    Oct  3 19:30:14.016: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Oct  3 19:30:14.028: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Creating a v1 custom resource 10/03/22 19:30:16.754
    STEP: v2 custom resource should be converted 10/03/22 19:30:16.768
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 19:30:17.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-3546" for this suite. 10/03/22 19:30:17.337
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:30:17.492
Oct  3 19:30:17.492: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename security-context 10/03/22 19:30:17.493
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:30:17.529
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:30:17.539
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 10/03/22 19:30:17.553
Oct  3 19:30:17.574: INFO: Waiting up to 5m0s for pod "security-context-048161fe-1f10-482f-be20-3c3c962b17b1" in namespace "security-context-7451" to be "Succeeded or Failed"
Oct  3 19:30:17.592: INFO: Pod "security-context-048161fe-1f10-482f-be20-3c3c962b17b1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.823968ms
Oct  3 19:30:19.605: INFO: Pod "security-context-048161fe-1f10-482f-be20-3c3c962b17b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030758371s
Oct  3 19:30:21.605: INFO: Pod "security-context-048161fe-1f10-482f-be20-3c3c962b17b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030685462s
Oct  3 19:30:23.604: INFO: Pod "security-context-048161fe-1f10-482f-be20-3c3c962b17b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029869793s
STEP: Saw pod success 10/03/22 19:30:23.604
Oct  3 19:30:23.605: INFO: Pod "security-context-048161fe-1f10-482f-be20-3c3c962b17b1" satisfied condition "Succeeded or Failed"
Oct  3 19:30:23.615: INFO: Trying to get logs from node 10.63.128.3 pod security-context-048161fe-1f10-482f-be20-3c3c962b17b1 container test-container: <nil>
STEP: delete the pod 10/03/22 19:30:23.642
Oct  3 19:30:23.669: INFO: Waiting for pod security-context-048161fe-1f10-482f-be20-3c3c962b17b1 to disappear
Oct  3 19:30:23.680: INFO: Pod security-context-048161fe-1f10-482f-be20-3c3c962b17b1 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Oct  3 19:30:23.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-7451" for this suite. 10/03/22 19:30:23.697
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":60,"skipped":1496,"failed":0}
------------------------------
• [SLOW TEST] [6.224 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:30:17.492
    Oct  3 19:30:17.492: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename security-context 10/03/22 19:30:17.493
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:30:17.529
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:30:17.539
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 10/03/22 19:30:17.553
    Oct  3 19:30:17.574: INFO: Waiting up to 5m0s for pod "security-context-048161fe-1f10-482f-be20-3c3c962b17b1" in namespace "security-context-7451" to be "Succeeded or Failed"
    Oct  3 19:30:17.592: INFO: Pod "security-context-048161fe-1f10-482f-be20-3c3c962b17b1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.823968ms
    Oct  3 19:30:19.605: INFO: Pod "security-context-048161fe-1f10-482f-be20-3c3c962b17b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030758371s
    Oct  3 19:30:21.605: INFO: Pod "security-context-048161fe-1f10-482f-be20-3c3c962b17b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030685462s
    Oct  3 19:30:23.604: INFO: Pod "security-context-048161fe-1f10-482f-be20-3c3c962b17b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029869793s
    STEP: Saw pod success 10/03/22 19:30:23.604
    Oct  3 19:30:23.605: INFO: Pod "security-context-048161fe-1f10-482f-be20-3c3c962b17b1" satisfied condition "Succeeded or Failed"
    Oct  3 19:30:23.615: INFO: Trying to get logs from node 10.63.128.3 pod security-context-048161fe-1f10-482f-be20-3c3c962b17b1 container test-container: <nil>
    STEP: delete the pod 10/03/22 19:30:23.642
    Oct  3 19:30:23.669: INFO: Waiting for pod security-context-048161fe-1f10-482f-be20-3c3c962b17b1 to disappear
    Oct  3 19:30:23.680: INFO: Pod security-context-048161fe-1f10-482f-be20-3c3c962b17b1 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Oct  3 19:30:23.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-7451" for this suite. 10/03/22 19:30:23.697
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:30:23.721
Oct  3 19:30:23.721: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename endpointslice 10/03/22 19:30:23.722
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:30:23.765
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:30:23.774
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 10/03/22 19:30:33.942
STEP: referencing matching pods with named port 10/03/22 19:30:38.968
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 10/03/22 19:30:43.997
STEP: recreating EndpointSlices after they've been deleted 10/03/22 19:30:49.022
Oct  3 19:30:49.084: INFO: EndpointSlice for Service endpointslice-1881/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Oct  3 19:30:59.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-1881" for this suite. 10/03/22 19:30:59.13
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":61,"skipped":1501,"failed":0}
------------------------------
• [SLOW TEST] [35.430 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:30:23.721
    Oct  3 19:30:23.721: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename endpointslice 10/03/22 19:30:23.722
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:30:23.765
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:30:23.774
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 10/03/22 19:30:33.942
    STEP: referencing matching pods with named port 10/03/22 19:30:38.968
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 10/03/22 19:30:43.997
    STEP: recreating EndpointSlices after they've been deleted 10/03/22 19:30:49.022
    Oct  3 19:30:49.084: INFO: EndpointSlice for Service endpointslice-1881/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Oct  3 19:30:59.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-1881" for this suite. 10/03/22 19:30:59.13
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:30:59.153
Oct  3 19:30:59.153: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename prestop 10/03/22 19:30:59.154
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:30:59.186
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:30:59.195
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-7037 10/03/22 19:30:59.205
STEP: Waiting for pods to come up. 10/03/22 19:30:59.226
Oct  3 19:30:59.227: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-7037" to be "running"
Oct  3 19:30:59.239: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 11.867355ms
Oct  3 19:31:01.251: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.023869026s
Oct  3 19:31:01.251: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-7037 10/03/22 19:31:01.262
Oct  3 19:31:01.292: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-7037" to be "running"
Oct  3 19:31:01.305: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 12.68495ms
Oct  3 19:31:03.317: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.024845027s
Oct  3 19:31:03.317: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 10/03/22 19:31:03.317
Oct  3 19:31:08.384: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 10/03/22 19:31:08.384
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Oct  3 19:31:08.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-7037" for this suite. 10/03/22 19:31:08.436
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":62,"skipped":1514,"failed":0}
------------------------------
• [SLOW TEST] [9.303 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:30:59.153
    Oct  3 19:30:59.153: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename prestop 10/03/22 19:30:59.154
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:30:59.186
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:30:59.195
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-7037 10/03/22 19:30:59.205
    STEP: Waiting for pods to come up. 10/03/22 19:30:59.226
    Oct  3 19:30:59.227: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-7037" to be "running"
    Oct  3 19:30:59.239: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 11.867355ms
    Oct  3 19:31:01.251: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.023869026s
    Oct  3 19:31:01.251: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-7037 10/03/22 19:31:01.262
    Oct  3 19:31:01.292: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-7037" to be "running"
    Oct  3 19:31:01.305: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 12.68495ms
    Oct  3 19:31:03.317: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.024845027s
    Oct  3 19:31:03.317: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 10/03/22 19:31:03.317
    Oct  3 19:31:08.384: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 10/03/22 19:31:08.384
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Oct  3 19:31:08.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-7037" for this suite. 10/03/22 19:31:08.436
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:31:08.456
Oct  3 19:31:08.457: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 19:31:08.458
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:31:08.494
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:31:08.504
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1877 10/03/22 19:31:08.514
STEP: changing the ExternalName service to type=ClusterIP 10/03/22 19:31:08.527
STEP: creating replication controller externalname-service in namespace services-1877 10/03/22 19:31:08.571
I1003 19:31:08.616883      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-1877, replica count: 2
I1003 19:31:11.672779      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  3 19:31:11.672: INFO: Creating new exec pod
Oct  3 19:31:11.686: INFO: Waiting up to 5m0s for pod "execpodxmk8t" in namespace "services-1877" to be "running"
Oct  3 19:31:11.701: INFO: Pod "execpodxmk8t": Phase="Pending", Reason="", readiness=false. Elapsed: 14.383006ms
Oct  3 19:31:13.713: INFO: Pod "execpodxmk8t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026767364s
Oct  3 19:31:15.717: INFO: Pod "execpodxmk8t": Phase="Running", Reason="", readiness=true. Elapsed: 4.030571852s
Oct  3 19:31:15.717: INFO: Pod "execpodxmk8t" satisfied condition "running"
Oct  3 19:31:16.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-1877 exec execpodxmk8t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Oct  3 19:31:17.005: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct  3 19:31:17.005: INFO: stdout: ""
Oct  3 19:31:18.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-1877 exec execpodxmk8t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Oct  3 19:31:18.283: INFO: stderr: "+ + echonc hostName -v -t\n -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct  3 19:31:18.284: INFO: stdout: "externalname-service-drw29"
Oct  3 19:31:18.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-1877 exec execpodxmk8t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.127.138 80'
Oct  3 19:31:18.580: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.127.138 80\nConnection to 172.21.127.138 80 port [tcp/http] succeeded!\n"
Oct  3 19:31:18.580: INFO: stdout: "externalname-service-645tz"
Oct  3 19:31:18.580: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 19:31:18.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1877" for this suite. 10/03/22 19:31:18.641
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":63,"skipped":1514,"failed":0}
------------------------------
• [SLOW TEST] [10.204 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:31:08.456
    Oct  3 19:31:08.457: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 19:31:08.458
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:31:08.494
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:31:08.504
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-1877 10/03/22 19:31:08.514
    STEP: changing the ExternalName service to type=ClusterIP 10/03/22 19:31:08.527
    STEP: creating replication controller externalname-service in namespace services-1877 10/03/22 19:31:08.571
    I1003 19:31:08.616883      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-1877, replica count: 2
    I1003 19:31:11.672779      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct  3 19:31:11.672: INFO: Creating new exec pod
    Oct  3 19:31:11.686: INFO: Waiting up to 5m0s for pod "execpodxmk8t" in namespace "services-1877" to be "running"
    Oct  3 19:31:11.701: INFO: Pod "execpodxmk8t": Phase="Pending", Reason="", readiness=false. Elapsed: 14.383006ms
    Oct  3 19:31:13.713: INFO: Pod "execpodxmk8t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026767364s
    Oct  3 19:31:15.717: INFO: Pod "execpodxmk8t": Phase="Running", Reason="", readiness=true. Elapsed: 4.030571852s
    Oct  3 19:31:15.717: INFO: Pod "execpodxmk8t" satisfied condition "running"
    Oct  3 19:31:16.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-1877 exec execpodxmk8t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Oct  3 19:31:17.005: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Oct  3 19:31:17.005: INFO: stdout: ""
    Oct  3 19:31:18.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-1877 exec execpodxmk8t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Oct  3 19:31:18.283: INFO: stderr: "+ + echonc hostName -v -t\n -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Oct  3 19:31:18.284: INFO: stdout: "externalname-service-drw29"
    Oct  3 19:31:18.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-1877 exec execpodxmk8t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.127.138 80'
    Oct  3 19:31:18.580: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.127.138 80\nConnection to 172.21.127.138 80 port [tcp/http] succeeded!\n"
    Oct  3 19:31:18.580: INFO: stdout: "externalname-service-645tz"
    Oct  3 19:31:18.580: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 19:31:18.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1877" for this suite. 10/03/22 19:31:18.641
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:31:18.663
Oct  3 19:31:18.663: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename controllerrevisions 10/03/22 19:31:18.664
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:31:18.697
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:31:18.707
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-z5gsm-daemon-set" 10/03/22 19:31:18.776
STEP: Check that daemon pods launch on every node of the cluster. 10/03/22 19:31:18.792
Oct  3 19:31:18.816: INFO: Number of nodes with available pods controlled by daemonset e2e-z5gsm-daemon-set: 0
Oct  3 19:31:18.816: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:31:19.844: INFO: Number of nodes with available pods controlled by daemonset e2e-z5gsm-daemon-set: 0
Oct  3 19:31:19.844: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:31:20.842: INFO: Number of nodes with available pods controlled by daemonset e2e-z5gsm-daemon-set: 1
Oct  3 19:31:20.843: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:31:21.842: INFO: Number of nodes with available pods controlled by daemonset e2e-z5gsm-daemon-set: 3
Oct  3 19:31:21.842: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-z5gsm-daemon-set
STEP: Confirm DaemonSet "e2e-z5gsm-daemon-set" successfully created with "daemonset-name=e2e-z5gsm-daemon-set" label 10/03/22 19:31:21.852
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-z5gsm-daemon-set" 10/03/22 19:31:21.873
Oct  3 19:31:21.887: INFO: Located ControllerRevision: "e2e-z5gsm-daemon-set-68bfb47d57"
STEP: Patching ControllerRevision "e2e-z5gsm-daemon-set-68bfb47d57" 10/03/22 19:31:21.898
Oct  3 19:31:21.912: INFO: e2e-z5gsm-daemon-set-68bfb47d57 has been patched
STEP: Create a new ControllerRevision 10/03/22 19:31:21.912
Oct  3 19:31:21.951: INFO: Created ControllerRevision: e2e-z5gsm-daemon-set-7699654665
STEP: Confirm that there are two ControllerRevisions 10/03/22 19:31:21.951
Oct  3 19:31:21.951: INFO: Requesting list of ControllerRevisions to confirm quantity
Oct  3 19:31:21.960: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-z5gsm-daemon-set-68bfb47d57" 10/03/22 19:31:21.96
STEP: Confirm that there is only one ControllerRevision 10/03/22 19:31:21.977
Oct  3 19:31:21.977: INFO: Requesting list of ControllerRevisions to confirm quantity
Oct  3 19:31:21.988: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-z5gsm-daemon-set-7699654665" 10/03/22 19:31:21.999
Oct  3 19:31:22.022: INFO: e2e-z5gsm-daemon-set-7699654665 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 10/03/22 19:31:22.022
W1003 19:31:22.035146      22 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 10/03/22 19:31:22.035
Oct  3 19:31:22.035: INFO: Requesting list of ControllerRevisions to confirm quantity
Oct  3 19:31:23.046: INFO: Requesting list of ControllerRevisions to confirm quantity
Oct  3 19:31:23.058: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-z5gsm-daemon-set-7699654665=updated" 10/03/22 19:31:23.058
STEP: Confirm that there is only one ControllerRevision 10/03/22 19:31:23.081
Oct  3 19:31:23.081: INFO: Requesting list of ControllerRevisions to confirm quantity
Oct  3 19:31:23.104: INFO: Found 1 ControllerRevisions
Oct  3 19:31:23.115: INFO: ControllerRevision "e2e-z5gsm-daemon-set-84789bb64" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-z5gsm-daemon-set" 10/03/22 19:31:23.125
STEP: deleting DaemonSet.extensions e2e-z5gsm-daemon-set in namespace controllerrevisions-313, will wait for the garbage collector to delete the pods 10/03/22 19:31:23.125
Oct  3 19:31:23.204: INFO: Deleting DaemonSet.extensions e2e-z5gsm-daemon-set took: 18.383503ms
Oct  3 19:31:23.304: INFO: Terminating DaemonSet.extensions e2e-z5gsm-daemon-set pods took: 100.151519ms
Oct  3 19:31:25.020: INFO: Number of nodes with available pods controlled by daemonset e2e-z5gsm-daemon-set: 0
Oct  3 19:31:25.020: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-z5gsm-daemon-set
Oct  3 19:31:25.032: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20384"},"items":null}

Oct  3 19:31:25.042: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20384"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Oct  3 19:31:25.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-313" for this suite. 10/03/22 19:31:25.104
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":64,"skipped":1537,"failed":0}
------------------------------
• [SLOW TEST] [6.467 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:31:18.663
    Oct  3 19:31:18.663: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename controllerrevisions 10/03/22 19:31:18.664
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:31:18.697
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:31:18.707
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-z5gsm-daemon-set" 10/03/22 19:31:18.776
    STEP: Check that daemon pods launch on every node of the cluster. 10/03/22 19:31:18.792
    Oct  3 19:31:18.816: INFO: Number of nodes with available pods controlled by daemonset e2e-z5gsm-daemon-set: 0
    Oct  3 19:31:18.816: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:31:19.844: INFO: Number of nodes with available pods controlled by daemonset e2e-z5gsm-daemon-set: 0
    Oct  3 19:31:19.844: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:31:20.842: INFO: Number of nodes with available pods controlled by daemonset e2e-z5gsm-daemon-set: 1
    Oct  3 19:31:20.843: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:31:21.842: INFO: Number of nodes with available pods controlled by daemonset e2e-z5gsm-daemon-set: 3
    Oct  3 19:31:21.842: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-z5gsm-daemon-set
    STEP: Confirm DaemonSet "e2e-z5gsm-daemon-set" successfully created with "daemonset-name=e2e-z5gsm-daemon-set" label 10/03/22 19:31:21.852
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-z5gsm-daemon-set" 10/03/22 19:31:21.873
    Oct  3 19:31:21.887: INFO: Located ControllerRevision: "e2e-z5gsm-daemon-set-68bfb47d57"
    STEP: Patching ControllerRevision "e2e-z5gsm-daemon-set-68bfb47d57" 10/03/22 19:31:21.898
    Oct  3 19:31:21.912: INFO: e2e-z5gsm-daemon-set-68bfb47d57 has been patched
    STEP: Create a new ControllerRevision 10/03/22 19:31:21.912
    Oct  3 19:31:21.951: INFO: Created ControllerRevision: e2e-z5gsm-daemon-set-7699654665
    STEP: Confirm that there are two ControllerRevisions 10/03/22 19:31:21.951
    Oct  3 19:31:21.951: INFO: Requesting list of ControllerRevisions to confirm quantity
    Oct  3 19:31:21.960: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-z5gsm-daemon-set-68bfb47d57" 10/03/22 19:31:21.96
    STEP: Confirm that there is only one ControllerRevision 10/03/22 19:31:21.977
    Oct  3 19:31:21.977: INFO: Requesting list of ControllerRevisions to confirm quantity
    Oct  3 19:31:21.988: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-z5gsm-daemon-set-7699654665" 10/03/22 19:31:21.999
    Oct  3 19:31:22.022: INFO: e2e-z5gsm-daemon-set-7699654665 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 10/03/22 19:31:22.022
    W1003 19:31:22.035146      22 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 10/03/22 19:31:22.035
    Oct  3 19:31:22.035: INFO: Requesting list of ControllerRevisions to confirm quantity
    Oct  3 19:31:23.046: INFO: Requesting list of ControllerRevisions to confirm quantity
    Oct  3 19:31:23.058: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-z5gsm-daemon-set-7699654665=updated" 10/03/22 19:31:23.058
    STEP: Confirm that there is only one ControllerRevision 10/03/22 19:31:23.081
    Oct  3 19:31:23.081: INFO: Requesting list of ControllerRevisions to confirm quantity
    Oct  3 19:31:23.104: INFO: Found 1 ControllerRevisions
    Oct  3 19:31:23.115: INFO: ControllerRevision "e2e-z5gsm-daemon-set-84789bb64" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-z5gsm-daemon-set" 10/03/22 19:31:23.125
    STEP: deleting DaemonSet.extensions e2e-z5gsm-daemon-set in namespace controllerrevisions-313, will wait for the garbage collector to delete the pods 10/03/22 19:31:23.125
    Oct  3 19:31:23.204: INFO: Deleting DaemonSet.extensions e2e-z5gsm-daemon-set took: 18.383503ms
    Oct  3 19:31:23.304: INFO: Terminating DaemonSet.extensions e2e-z5gsm-daemon-set pods took: 100.151519ms
    Oct  3 19:31:25.020: INFO: Number of nodes with available pods controlled by daemonset e2e-z5gsm-daemon-set: 0
    Oct  3 19:31:25.020: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-z5gsm-daemon-set
    Oct  3 19:31:25.032: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20384"},"items":null}

    Oct  3 19:31:25.042: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20384"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 19:31:25.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-313" for this suite. 10/03/22 19:31:25.104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:31:25.131
Oct  3 19:31:25.132: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename security-context-test 10/03/22 19:31:25.133
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:31:25.165
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:31:25.176
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Oct  3 19:31:25.205: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-d2acdabf-7bc3-4cdf-838f-25ebd63ff4ea" in namespace "security-context-test-177" to be "Succeeded or Failed"
Oct  3 19:31:25.219: INFO: Pod "busybox-readonly-false-d2acdabf-7bc3-4cdf-838f-25ebd63ff4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 13.462444ms
Oct  3 19:31:27.231: INFO: Pod "busybox-readonly-false-d2acdabf-7bc3-4cdf-838f-25ebd63ff4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025861752s
Oct  3 19:31:29.231: INFO: Pod "busybox-readonly-false-d2acdabf-7bc3-4cdf-838f-25ebd63ff4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02609221s
Oct  3 19:31:31.229: INFO: Pod "busybox-readonly-false-d2acdabf-7bc3-4cdf-838f-25ebd63ff4ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023900423s
Oct  3 19:31:31.229: INFO: Pod "busybox-readonly-false-d2acdabf-7bc3-4cdf-838f-25ebd63ff4ea" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Oct  3 19:31:31.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-177" for this suite. 10/03/22 19:31:31.244
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":65,"skipped":1543,"failed":0}
------------------------------
• [SLOW TEST] [6.132 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:31:25.131
    Oct  3 19:31:25.132: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename security-context-test 10/03/22 19:31:25.133
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:31:25.165
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:31:25.176
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Oct  3 19:31:25.205: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-d2acdabf-7bc3-4cdf-838f-25ebd63ff4ea" in namespace "security-context-test-177" to be "Succeeded or Failed"
    Oct  3 19:31:25.219: INFO: Pod "busybox-readonly-false-d2acdabf-7bc3-4cdf-838f-25ebd63ff4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 13.462444ms
    Oct  3 19:31:27.231: INFO: Pod "busybox-readonly-false-d2acdabf-7bc3-4cdf-838f-25ebd63ff4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025861752s
    Oct  3 19:31:29.231: INFO: Pod "busybox-readonly-false-d2acdabf-7bc3-4cdf-838f-25ebd63ff4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02609221s
    Oct  3 19:31:31.229: INFO: Pod "busybox-readonly-false-d2acdabf-7bc3-4cdf-838f-25ebd63ff4ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023900423s
    Oct  3 19:31:31.229: INFO: Pod "busybox-readonly-false-d2acdabf-7bc3-4cdf-838f-25ebd63ff4ea" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Oct  3 19:31:31.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-177" for this suite. 10/03/22 19:31:31.244
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:31:31.266
Oct  3 19:31:31.266: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 19:31:31.267
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:31:31.299
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:31:31.309
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Oct  3 19:31:31.318: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 10/03/22 19:31:34.886
Oct  3 19:31:34.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2529 --namespace=crd-publish-openapi-2529 create -f -'
Oct  3 19:31:35.767: INFO: stderr: ""
Oct  3 19:31:35.767: INFO: stdout: "e2e-test-crd-publish-openapi-1375-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Oct  3 19:31:35.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2529 --namespace=crd-publish-openapi-2529 delete e2e-test-crd-publish-openapi-1375-crds test-cr'
Oct  3 19:31:35.972: INFO: stderr: ""
Oct  3 19:31:35.972: INFO: stdout: "e2e-test-crd-publish-openapi-1375-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Oct  3 19:31:35.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2529 --namespace=crd-publish-openapi-2529 apply -f -'
Oct  3 19:31:36.304: INFO: stderr: ""
Oct  3 19:31:36.304: INFO: stdout: "e2e-test-crd-publish-openapi-1375-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Oct  3 19:31:36.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2529 --namespace=crd-publish-openapi-2529 delete e2e-test-crd-publish-openapi-1375-crds test-cr'
Oct  3 19:31:36.464: INFO: stderr: ""
Oct  3 19:31:36.464: INFO: stdout: "e2e-test-crd-publish-openapi-1375-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 10/03/22 19:31:36.464
Oct  3 19:31:36.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2529 explain e2e-test-crd-publish-openapi-1375-crds'
Oct  3 19:31:37.172: INFO: stderr: ""
Oct  3 19:31:37.172: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1375-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 19:31:40.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2529" for this suite. 10/03/22 19:31:40.526
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":66,"skipped":1548,"failed":0}
------------------------------
• [SLOW TEST] [9.284 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:31:31.266
    Oct  3 19:31:31.266: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 19:31:31.267
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:31:31.299
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:31:31.309
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Oct  3 19:31:31.318: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 10/03/22 19:31:34.886
    Oct  3 19:31:34.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2529 --namespace=crd-publish-openapi-2529 create -f -'
    Oct  3 19:31:35.767: INFO: stderr: ""
    Oct  3 19:31:35.767: INFO: stdout: "e2e-test-crd-publish-openapi-1375-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Oct  3 19:31:35.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2529 --namespace=crd-publish-openapi-2529 delete e2e-test-crd-publish-openapi-1375-crds test-cr'
    Oct  3 19:31:35.972: INFO: stderr: ""
    Oct  3 19:31:35.972: INFO: stdout: "e2e-test-crd-publish-openapi-1375-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Oct  3 19:31:35.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2529 --namespace=crd-publish-openapi-2529 apply -f -'
    Oct  3 19:31:36.304: INFO: stderr: ""
    Oct  3 19:31:36.304: INFO: stdout: "e2e-test-crd-publish-openapi-1375-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Oct  3 19:31:36.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2529 --namespace=crd-publish-openapi-2529 delete e2e-test-crd-publish-openapi-1375-crds test-cr'
    Oct  3 19:31:36.464: INFO: stderr: ""
    Oct  3 19:31:36.464: INFO: stdout: "e2e-test-crd-publish-openapi-1375-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 10/03/22 19:31:36.464
    Oct  3 19:31:36.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2529 explain e2e-test-crd-publish-openapi-1375-crds'
    Oct  3 19:31:37.172: INFO: stderr: ""
    Oct  3 19:31:37.172: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1375-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 19:31:40.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2529" for this suite. 10/03/22 19:31:40.526
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:31:40.553
Oct  3 19:31:40.553: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-probe 10/03/22 19:31:40.554
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:31:40.597
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:31:40.607
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-3f9ebdb2-03d4-4113-812f-4bb333eb926f in namespace container-probe-2892 10/03/22 19:31:40.618
Oct  3 19:31:40.646: INFO: Waiting up to 5m0s for pod "test-webserver-3f9ebdb2-03d4-4113-812f-4bb333eb926f" in namespace "container-probe-2892" to be "not pending"
Oct  3 19:31:40.659: INFO: Pod "test-webserver-3f9ebdb2-03d4-4113-812f-4bb333eb926f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.800089ms
Oct  3 19:31:42.689: INFO: Pod "test-webserver-3f9ebdb2-03d4-4113-812f-4bb333eb926f": Phase="Running", Reason="", readiness=true. Elapsed: 2.043240359s
Oct  3 19:31:42.689: INFO: Pod "test-webserver-3f9ebdb2-03d4-4113-812f-4bb333eb926f" satisfied condition "not pending"
Oct  3 19:31:42.689: INFO: Started pod test-webserver-3f9ebdb2-03d4-4113-812f-4bb333eb926f in namespace container-probe-2892
STEP: checking the pod's current state and verifying that restartCount is present 10/03/22 19:31:42.689
Oct  3 19:31:42.704: INFO: Initial restart count of pod test-webserver-3f9ebdb2-03d4-4113-812f-4bb333eb926f is 0
STEP: deleting the pod 10/03/22 19:35:44.555
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Oct  3 19:35:44.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2892" for this suite. 10/03/22 19:35:44.616
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":67,"skipped":1568,"failed":0}
------------------------------
• [SLOW TEST] [244.087 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:31:40.553
    Oct  3 19:31:40.553: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-probe 10/03/22 19:31:40.554
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:31:40.597
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:31:40.607
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-3f9ebdb2-03d4-4113-812f-4bb333eb926f in namespace container-probe-2892 10/03/22 19:31:40.618
    Oct  3 19:31:40.646: INFO: Waiting up to 5m0s for pod "test-webserver-3f9ebdb2-03d4-4113-812f-4bb333eb926f" in namespace "container-probe-2892" to be "not pending"
    Oct  3 19:31:40.659: INFO: Pod "test-webserver-3f9ebdb2-03d4-4113-812f-4bb333eb926f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.800089ms
    Oct  3 19:31:42.689: INFO: Pod "test-webserver-3f9ebdb2-03d4-4113-812f-4bb333eb926f": Phase="Running", Reason="", readiness=true. Elapsed: 2.043240359s
    Oct  3 19:31:42.689: INFO: Pod "test-webserver-3f9ebdb2-03d4-4113-812f-4bb333eb926f" satisfied condition "not pending"
    Oct  3 19:31:42.689: INFO: Started pod test-webserver-3f9ebdb2-03d4-4113-812f-4bb333eb926f in namespace container-probe-2892
    STEP: checking the pod's current state and verifying that restartCount is present 10/03/22 19:31:42.689
    Oct  3 19:31:42.704: INFO: Initial restart count of pod test-webserver-3f9ebdb2-03d4-4113-812f-4bb333eb926f is 0
    STEP: deleting the pod 10/03/22 19:35:44.555
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Oct  3 19:35:44.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2892" for this suite. 10/03/22 19:35:44.616
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:35:44.646
Oct  3 19:35:44.647: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 19:35:44.648
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:35:44.691
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:35:44.703
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-a951e702-e725-4c1c-adf5-a98a479d8ce1 10/03/22 19:35:44.715
STEP: Creating a pod to test consume secrets 10/03/22 19:35:44.729
Oct  3 19:35:44.757: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041" in namespace "projected-3328" to be "Succeeded or Failed"
Oct  3 19:35:44.770: INFO: Pod "pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041": Phase="Pending", Reason="", readiness=false. Elapsed: 13.53596ms
Oct  3 19:35:46.787: INFO: Pod "pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041": Phase="Running", Reason="", readiness=true. Elapsed: 2.029892236s
Oct  3 19:35:48.785: INFO: Pod "pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041": Phase="Running", Reason="", readiness=false. Elapsed: 4.028002027s
Oct  3 19:35:50.786: INFO: Pod "pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029130624s
STEP: Saw pod success 10/03/22 19:35:50.786
Oct  3 19:35:50.786: INFO: Pod "pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041" satisfied condition "Succeeded or Failed"
Oct  3 19:35:50.799: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041 container secret-volume-test: <nil>
STEP: delete the pod 10/03/22 19:35:50.893
Oct  3 19:35:50.938: INFO: Waiting for pod pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041 to disappear
Oct  3 19:35:50.951: INFO: Pod pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Oct  3 19:35:50.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3328" for this suite. 10/03/22 19:35:50.968
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":68,"skipped":1617,"failed":0}
------------------------------
• [SLOW TEST] [6.345 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:35:44.646
    Oct  3 19:35:44.647: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 19:35:44.648
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:35:44.691
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:35:44.703
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-a951e702-e725-4c1c-adf5-a98a479d8ce1 10/03/22 19:35:44.715
    STEP: Creating a pod to test consume secrets 10/03/22 19:35:44.729
    Oct  3 19:35:44.757: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041" in namespace "projected-3328" to be "Succeeded or Failed"
    Oct  3 19:35:44.770: INFO: Pod "pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041": Phase="Pending", Reason="", readiness=false. Elapsed: 13.53596ms
    Oct  3 19:35:46.787: INFO: Pod "pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041": Phase="Running", Reason="", readiness=true. Elapsed: 2.029892236s
    Oct  3 19:35:48.785: INFO: Pod "pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041": Phase="Running", Reason="", readiness=false. Elapsed: 4.028002027s
    Oct  3 19:35:50.786: INFO: Pod "pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029130624s
    STEP: Saw pod success 10/03/22 19:35:50.786
    Oct  3 19:35:50.786: INFO: Pod "pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041" satisfied condition "Succeeded or Failed"
    Oct  3 19:35:50.799: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041 container secret-volume-test: <nil>
    STEP: delete the pod 10/03/22 19:35:50.893
    Oct  3 19:35:50.938: INFO: Waiting for pod pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041 to disappear
    Oct  3 19:35:50.951: INFO: Pod pod-projected-secrets-7c3f76cb-160b-4e36-96be-e878ce533041 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Oct  3 19:35:50.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3328" for this suite. 10/03/22 19:35:50.968
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:35:50.994
Oct  3 19:35:50.994: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 19:35:50.996
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:35:51.039
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:35:51.054
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 10/03/22 19:35:51.069
Oct  3 19:35:51.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-799 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Oct  3 19:35:51.195: INFO: stderr: ""
Oct  3 19:35:51.195: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 10/03/22 19:35:51.195
STEP: verifying the pod e2e-test-httpd-pod was created 10/03/22 19:35:56.247
Oct  3 19:35:56.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-799 get pod e2e-test-httpd-pod -o json'
Oct  3 19:35:56.349: INFO: stderr: ""
Oct  3 19:35:56.349: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"852b95e470df179d286bbc8e6a63b276d762321591d2bced7261960e8f8f57b9\",\n            \"cni.projectcalico.org/podIP\": \"172.30.49.22/32\",\n            \"cni.projectcalico.org/podIPs\": \"172.30.49.22/32\"\n        },\n        \"creationTimestamp\": \"2022-10-03T19:35:51Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-799\",\n        \"resourceVersion\": \"20815\",\n        \"uid\": \"60960694-f787-444b-a941-c2e293e4186e\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-879vt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.63.128.3\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-879vt\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-10-03T19:35:51Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-10-03T19:35:53Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-10-03T19:35:53Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-10-03T19:35:51Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://94568eb97016f035969dc0fc3cdfaef61ba807afc53d0df8713851005ee545d8\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-10-03T19:35:52Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.63.128.3\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.49.22\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.30.49.22\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-10-03T19:35:51Z\"\n    }\n}\n"
STEP: replace the image in the pod 10/03/22 19:35:56.349
Oct  3 19:35:56.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-799 replace -f -'
Oct  3 19:35:57.271: INFO: stderr: ""
Oct  3 19:35:57.271: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 10/03/22 19:35:57.271
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Oct  3 19:35:57.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-799 delete pods e2e-test-httpd-pod'
Oct  3 19:35:59.562: INFO: stderr: ""
Oct  3 19:35:59.562: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 19:35:59.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-799" for this suite. 10/03/22 19:35:59.582
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":69,"skipped":1631,"failed":0}
------------------------------
• [SLOW TEST] [8.611 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:35:50.994
    Oct  3 19:35:50.994: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 19:35:50.996
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:35:51.039
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:35:51.054
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 10/03/22 19:35:51.069
    Oct  3 19:35:51.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-799 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Oct  3 19:35:51.195: INFO: stderr: ""
    Oct  3 19:35:51.195: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 10/03/22 19:35:51.195
    STEP: verifying the pod e2e-test-httpd-pod was created 10/03/22 19:35:56.247
    Oct  3 19:35:56.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-799 get pod e2e-test-httpd-pod -o json'
    Oct  3 19:35:56.349: INFO: stderr: ""
    Oct  3 19:35:56.349: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"852b95e470df179d286bbc8e6a63b276d762321591d2bced7261960e8f8f57b9\",\n            \"cni.projectcalico.org/podIP\": \"172.30.49.22/32\",\n            \"cni.projectcalico.org/podIPs\": \"172.30.49.22/32\"\n        },\n        \"creationTimestamp\": \"2022-10-03T19:35:51Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-799\",\n        \"resourceVersion\": \"20815\",\n        \"uid\": \"60960694-f787-444b-a941-c2e293e4186e\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-879vt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.63.128.3\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-879vt\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-10-03T19:35:51Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-10-03T19:35:53Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-10-03T19:35:53Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-10-03T19:35:51Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://94568eb97016f035969dc0fc3cdfaef61ba807afc53d0df8713851005ee545d8\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-10-03T19:35:52Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.63.128.3\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.49.22\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.30.49.22\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-10-03T19:35:51Z\"\n    }\n}\n"
    STEP: replace the image in the pod 10/03/22 19:35:56.349
    Oct  3 19:35:56.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-799 replace -f -'
    Oct  3 19:35:57.271: INFO: stderr: ""
    Oct  3 19:35:57.271: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 10/03/22 19:35:57.271
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Oct  3 19:35:57.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-799 delete pods e2e-test-httpd-pod'
    Oct  3 19:35:59.562: INFO: stderr: ""
    Oct  3 19:35:59.562: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 19:35:59.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-799" for this suite. 10/03/22 19:35:59.582
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:35:59.605
Oct  3 19:35:59.605: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename init-container 10/03/22 19:35:59.607
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:35:59.649
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:35:59.662
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 10/03/22 19:35:59.674
Oct  3 19:35:59.675: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Oct  3 19:36:04.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8727" for this suite. 10/03/22 19:36:04.594
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":70,"skipped":1636,"failed":0}
------------------------------
• [SLOW TEST] [5.012 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:35:59.605
    Oct  3 19:35:59.605: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename init-container 10/03/22 19:35:59.607
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:35:59.649
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:35:59.662
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 10/03/22 19:35:59.674
    Oct  3 19:35:59.675: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Oct  3 19:36:04.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-8727" for this suite. 10/03/22 19:36:04.594
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:36:04.619
Oct  3 19:36:04.619: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename secrets 10/03/22 19:36:04.62
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:36:04.66
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:36:04.671
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-6c72638d-d189-4f1a-bc0b-d9d3fc217d1c 10/03/22 19:36:04.682
STEP: Creating a pod to test consume secrets 10/03/22 19:36:04.697
Oct  3 19:36:04.727: INFO: Waiting up to 5m0s for pod "pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be" in namespace "secrets-1943" to be "Succeeded or Failed"
Oct  3 19:36:04.750: INFO: Pod "pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be": Phase="Pending", Reason="", readiness=false. Elapsed: 22.946454ms
Oct  3 19:36:06.775: INFO: Pod "pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047937052s
Oct  3 19:36:08.765: INFO: Pod "pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038173042s
STEP: Saw pod success 10/03/22 19:36:08.765
Oct  3 19:36:08.766: INFO: Pod "pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be" satisfied condition "Succeeded or Failed"
Oct  3 19:36:08.778: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be container secret-volume-test: <nil>
STEP: delete the pod 10/03/22 19:36:08.81
Oct  3 19:36:08.851: INFO: Waiting for pod pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be to disappear
Oct  3 19:36:08.864: INFO: Pod pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Oct  3 19:36:08.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1943" for this suite. 10/03/22 19:36:08.882
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":71,"skipped":1638,"failed":0}
------------------------------
• [4.286 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:36:04.619
    Oct  3 19:36:04.619: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename secrets 10/03/22 19:36:04.62
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:36:04.66
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:36:04.671
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-6c72638d-d189-4f1a-bc0b-d9d3fc217d1c 10/03/22 19:36:04.682
    STEP: Creating a pod to test consume secrets 10/03/22 19:36:04.697
    Oct  3 19:36:04.727: INFO: Waiting up to 5m0s for pod "pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be" in namespace "secrets-1943" to be "Succeeded or Failed"
    Oct  3 19:36:04.750: INFO: Pod "pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be": Phase="Pending", Reason="", readiness=false. Elapsed: 22.946454ms
    Oct  3 19:36:06.775: INFO: Pod "pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047937052s
    Oct  3 19:36:08.765: INFO: Pod "pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038173042s
    STEP: Saw pod success 10/03/22 19:36:08.765
    Oct  3 19:36:08.766: INFO: Pod "pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be" satisfied condition "Succeeded or Failed"
    Oct  3 19:36:08.778: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be container secret-volume-test: <nil>
    STEP: delete the pod 10/03/22 19:36:08.81
    Oct  3 19:36:08.851: INFO: Waiting for pod pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be to disappear
    Oct  3 19:36:08.864: INFO: Pod pod-secrets-b05c76c5-3128-4cf4-b6d7-1065cc0e59be no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Oct  3 19:36:08.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1943" for this suite. 10/03/22 19:36:08.882
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:36:08.914
Oct  3 19:36:08.914: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 19:36:08.915
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:36:08.958
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:36:08.97
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 10/03/22 19:36:08.981
Oct  3 19:36:08.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 create -f -'
Oct  3 19:36:09.306: INFO: stderr: ""
Oct  3 19:36:09.306: INFO: stdout: "pod/pause created\n"
Oct  3 19:36:09.306: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct  3 19:36:09.306: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8389" to be "running and ready"
Oct  3 19:36:09.320: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 13.45115ms
Oct  3 19:36:09.320: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '10.63.128.3' to be 'Running' but was 'Pending'
Oct  3 19:36:11.334: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027554814s
Oct  3 19:36:11.334: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '10.63.128.3' to be 'Running' but was 'Pending'
Oct  3 19:36:13.335: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.028421433s
Oct  3 19:36:13.335: INFO: Pod "pause" satisfied condition "running and ready"
Oct  3 19:36:13.335: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 10/03/22 19:36:13.335
Oct  3 19:36:13.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 label pods pause testing-label=testing-label-value'
Oct  3 19:36:13.451: INFO: stderr: ""
Oct  3 19:36:13.451: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 10/03/22 19:36:13.451
Oct  3 19:36:13.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 get pod pause -L testing-label'
Oct  3 19:36:13.552: INFO: stderr: ""
Oct  3 19:36:13.552: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod 10/03/22 19:36:13.553
Oct  3 19:36:13.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 label pods pause testing-label-'
Oct  3 19:36:13.672: INFO: stderr: ""
Oct  3 19:36:13.672: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 10/03/22 19:36:13.672
Oct  3 19:36:13.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 get pod pause -L testing-label'
Oct  3 19:36:13.795: INFO: stderr: ""
Oct  3 19:36:13.795: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 10/03/22 19:36:13.795
Oct  3 19:36:13.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 delete --grace-period=0 --force -f -'
Oct  3 19:36:13.926: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  3 19:36:13.926: INFO: stdout: "pod \"pause\" force deleted\n"
Oct  3 19:36:13.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 get rc,svc -l name=pause --no-headers'
Oct  3 19:36:14.026: INFO: stderr: "No resources found in kubectl-8389 namespace.\n"
Oct  3 19:36:14.026: INFO: stdout: ""
Oct  3 19:36:14.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  3 19:36:14.122: INFO: stderr: ""
Oct  3 19:36:14.122: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 19:36:14.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8389" for this suite. 10/03/22 19:36:14.141
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":72,"skipped":1692,"failed":0}
------------------------------
• [SLOW TEST] [5.250 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:36:08.914
    Oct  3 19:36:08.914: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 19:36:08.915
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:36:08.958
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:36:08.97
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 10/03/22 19:36:08.981
    Oct  3 19:36:08.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 create -f -'
    Oct  3 19:36:09.306: INFO: stderr: ""
    Oct  3 19:36:09.306: INFO: stdout: "pod/pause created\n"
    Oct  3 19:36:09.306: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Oct  3 19:36:09.306: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8389" to be "running and ready"
    Oct  3 19:36:09.320: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 13.45115ms
    Oct  3 19:36:09.320: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '10.63.128.3' to be 'Running' but was 'Pending'
    Oct  3 19:36:11.334: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027554814s
    Oct  3 19:36:11.334: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '10.63.128.3' to be 'Running' but was 'Pending'
    Oct  3 19:36:13.335: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.028421433s
    Oct  3 19:36:13.335: INFO: Pod "pause" satisfied condition "running and ready"
    Oct  3 19:36:13.335: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 10/03/22 19:36:13.335
    Oct  3 19:36:13.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 label pods pause testing-label=testing-label-value'
    Oct  3 19:36:13.451: INFO: stderr: ""
    Oct  3 19:36:13.451: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 10/03/22 19:36:13.451
    Oct  3 19:36:13.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 get pod pause -L testing-label'
    Oct  3 19:36:13.552: INFO: stderr: ""
    Oct  3 19:36:13.552: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 10/03/22 19:36:13.553
    Oct  3 19:36:13.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 label pods pause testing-label-'
    Oct  3 19:36:13.672: INFO: stderr: ""
    Oct  3 19:36:13.672: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 10/03/22 19:36:13.672
    Oct  3 19:36:13.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 get pod pause -L testing-label'
    Oct  3 19:36:13.795: INFO: stderr: ""
    Oct  3 19:36:13.795: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 10/03/22 19:36:13.795
    Oct  3 19:36:13.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 delete --grace-period=0 --force -f -'
    Oct  3 19:36:13.926: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct  3 19:36:13.926: INFO: stdout: "pod \"pause\" force deleted\n"
    Oct  3 19:36:13.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 get rc,svc -l name=pause --no-headers'
    Oct  3 19:36:14.026: INFO: stderr: "No resources found in kubectl-8389 namespace.\n"
    Oct  3 19:36:14.026: INFO: stdout: ""
    Oct  3 19:36:14.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8389 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Oct  3 19:36:14.122: INFO: stderr: ""
    Oct  3 19:36:14.122: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 19:36:14.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8389" for this suite. 10/03/22 19:36:14.141
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:36:14.166
Oct  3 19:36:14.166: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename statefulset 10/03/22 19:36:14.167
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:36:14.213
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:36:14.225
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4085 10/03/22 19:36:14.235
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-4085 10/03/22 19:36:14.266
Oct  3 19:36:14.296: INFO: Found 0 stateful pods, waiting for 1
Oct  3 19:36:24.311: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 10/03/22 19:36:24.337
STEP: Getting /status 10/03/22 19:36:24.363
Oct  3 19:36:24.377: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 10/03/22 19:36:24.377
Oct  3 19:36:24.407: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 10/03/22 19:36:24.408
Oct  3 19:36:24.413: INFO: Observed &StatefulSet event: ADDED
Oct  3 19:36:24.413: INFO: Found Statefulset ss in namespace statefulset-4085 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Oct  3 19:36:24.413: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 10/03/22 19:36:24.413
Oct  3 19:36:24.413: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Oct  3 19:36:24.432: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 10/03/22 19:36:24.432
Oct  3 19:36:24.439: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct  3 19:36:24.439: INFO: Deleting all statefulset in ns statefulset-4085
Oct  3 19:36:24.451: INFO: Scaling statefulset ss to 0
Oct  3 19:36:34.513: INFO: Waiting for statefulset status.replicas updated to 0
Oct  3 19:36:34.526: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Oct  3 19:36:34.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4085" for this suite. 10/03/22 19:36:34.587
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":73,"skipped":1722,"failed":0}
------------------------------
• [SLOW TEST] [20.445 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:36:14.166
    Oct  3 19:36:14.166: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename statefulset 10/03/22 19:36:14.167
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:36:14.213
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:36:14.225
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4085 10/03/22 19:36:14.235
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-4085 10/03/22 19:36:14.266
    Oct  3 19:36:14.296: INFO: Found 0 stateful pods, waiting for 1
    Oct  3 19:36:24.311: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 10/03/22 19:36:24.337
    STEP: Getting /status 10/03/22 19:36:24.363
    Oct  3 19:36:24.377: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 10/03/22 19:36:24.377
    Oct  3 19:36:24.407: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 10/03/22 19:36:24.408
    Oct  3 19:36:24.413: INFO: Observed &StatefulSet event: ADDED
    Oct  3 19:36:24.413: INFO: Found Statefulset ss in namespace statefulset-4085 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Oct  3 19:36:24.413: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 10/03/22 19:36:24.413
    Oct  3 19:36:24.413: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Oct  3 19:36:24.432: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 10/03/22 19:36:24.432
    Oct  3 19:36:24.439: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Oct  3 19:36:24.439: INFO: Deleting all statefulset in ns statefulset-4085
    Oct  3 19:36:24.451: INFO: Scaling statefulset ss to 0
    Oct  3 19:36:34.513: INFO: Waiting for statefulset status.replicas updated to 0
    Oct  3 19:36:34.526: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Oct  3 19:36:34.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4085" for this suite. 10/03/22 19:36:34.587
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:36:34.613
Oct  3 19:36:34.613: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename csistoragecapacity 10/03/22 19:36:34.615
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:36:34.659
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:36:34.668
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 10/03/22 19:36:34.686
STEP: getting /apis/storage.k8s.io 10/03/22 19:36:34.696
STEP: getting /apis/storage.k8s.io/v1 10/03/22 19:36:34.702
STEP: creating 10/03/22 19:36:34.707
STEP: watching 10/03/22 19:36:34.765
Oct  3 19:36:34.765: INFO: starting watch
STEP: getting 10/03/22 19:36:34.796
STEP: listing in namespace 10/03/22 19:36:34.81
STEP: listing across namespaces 10/03/22 19:36:34.823
STEP: patching 10/03/22 19:36:34.836
STEP: updating 10/03/22 19:36:34.854
Oct  3 19:36:34.870: INFO: waiting for watch events with expected annotations in namespace
Oct  3 19:36:34.870: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 10/03/22 19:36:34.871
STEP: deleting a collection 10/03/22 19:36:34.92
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Oct  3 19:36:34.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-2968" for this suite. 10/03/22 19:36:35
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":74,"skipped":1731,"failed":0}
------------------------------
• [0.411 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:36:34.613
    Oct  3 19:36:34.613: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename csistoragecapacity 10/03/22 19:36:34.615
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:36:34.659
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:36:34.668
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 10/03/22 19:36:34.686
    STEP: getting /apis/storage.k8s.io 10/03/22 19:36:34.696
    STEP: getting /apis/storage.k8s.io/v1 10/03/22 19:36:34.702
    STEP: creating 10/03/22 19:36:34.707
    STEP: watching 10/03/22 19:36:34.765
    Oct  3 19:36:34.765: INFO: starting watch
    STEP: getting 10/03/22 19:36:34.796
    STEP: listing in namespace 10/03/22 19:36:34.81
    STEP: listing across namespaces 10/03/22 19:36:34.823
    STEP: patching 10/03/22 19:36:34.836
    STEP: updating 10/03/22 19:36:34.854
    Oct  3 19:36:34.870: INFO: waiting for watch events with expected annotations in namespace
    Oct  3 19:36:34.870: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 10/03/22 19:36:34.871
    STEP: deleting a collection 10/03/22 19:36:34.92
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Oct  3 19:36:34.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-2968" for this suite. 10/03/22 19:36:35
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:36:35.029
Oct  3 19:36:35.029: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 19:36:35.03
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:36:35.073
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:36:35.083
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 10/03/22 19:36:35.092
Oct  3 19:36:35.119: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42" in namespace "downward-api-4060" to be "Succeeded or Failed"
Oct  3 19:36:35.132: INFO: Pod "downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42": Phase="Pending", Reason="", readiness=false. Elapsed: 12.818018ms
Oct  3 19:36:37.149: INFO: Pod "downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42": Phase="Running", Reason="", readiness=true. Elapsed: 2.029589907s
Oct  3 19:36:39.148: INFO: Pod "downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42": Phase="Running", Reason="", readiness=false. Elapsed: 4.02824262s
Oct  3 19:36:41.147: INFO: Pod "downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027836533s
STEP: Saw pod success 10/03/22 19:36:41.147
Oct  3 19:36:41.148: INFO: Pod "downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42" satisfied condition "Succeeded or Failed"
Oct  3 19:36:41.162: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42 container client-container: <nil>
STEP: delete the pod 10/03/22 19:36:41.194
Oct  3 19:36:41.235: INFO: Waiting for pod downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42 to disappear
Oct  3 19:36:41.248: INFO: Pod downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Oct  3 19:36:41.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4060" for this suite. 10/03/22 19:36:41.266
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":75,"skipped":1752,"failed":0}
------------------------------
• [SLOW TEST] [6.261 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:36:35.029
    Oct  3 19:36:35.029: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 19:36:35.03
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:36:35.073
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:36:35.083
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 10/03/22 19:36:35.092
    Oct  3 19:36:35.119: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42" in namespace "downward-api-4060" to be "Succeeded or Failed"
    Oct  3 19:36:35.132: INFO: Pod "downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42": Phase="Pending", Reason="", readiness=false. Elapsed: 12.818018ms
    Oct  3 19:36:37.149: INFO: Pod "downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42": Phase="Running", Reason="", readiness=true. Elapsed: 2.029589907s
    Oct  3 19:36:39.148: INFO: Pod "downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42": Phase="Running", Reason="", readiness=false. Elapsed: 4.02824262s
    Oct  3 19:36:41.147: INFO: Pod "downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027836533s
    STEP: Saw pod success 10/03/22 19:36:41.147
    Oct  3 19:36:41.148: INFO: Pod "downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42" satisfied condition "Succeeded or Failed"
    Oct  3 19:36:41.162: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42 container client-container: <nil>
    STEP: delete the pod 10/03/22 19:36:41.194
    Oct  3 19:36:41.235: INFO: Waiting for pod downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42 to disappear
    Oct  3 19:36:41.248: INFO: Pod downwardapi-volume-a5f0dc1d-596f-44e7-80c2-799a76b4bf42 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Oct  3 19:36:41.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4060" for this suite. 10/03/22 19:36:41.266
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:36:41.29
Oct  3 19:36:41.291: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir 10/03/22 19:36:41.292
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:36:41.339
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:36:41.35
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 10/03/22 19:36:41.362
Oct  3 19:36:41.390: INFO: Waiting up to 5m0s for pod "pod-2c0a2058-1022-4e45-b227-87b183b6e82e" in namespace "emptydir-1948" to be "Succeeded or Failed"
Oct  3 19:36:41.404: INFO: Pod "pod-2c0a2058-1022-4e45-b227-87b183b6e82e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.058505ms
Oct  3 19:36:43.420: INFO: Pod "pod-2c0a2058-1022-4e45-b227-87b183b6e82e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029646582s
Oct  3 19:36:45.420: INFO: Pod "pod-2c0a2058-1022-4e45-b227-87b183b6e82e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02916214s
Oct  3 19:36:47.420: INFO: Pod "pod-2c0a2058-1022-4e45-b227-87b183b6e82e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029630565s
STEP: Saw pod success 10/03/22 19:36:47.42
Oct  3 19:36:47.420: INFO: Pod "pod-2c0a2058-1022-4e45-b227-87b183b6e82e" satisfied condition "Succeeded or Failed"
Oct  3 19:36:47.435: INFO: Trying to get logs from node 10.63.128.3 pod pod-2c0a2058-1022-4e45-b227-87b183b6e82e container test-container: <nil>
STEP: delete the pod 10/03/22 19:36:47.465
Oct  3 19:36:47.508: INFO: Waiting for pod pod-2c0a2058-1022-4e45-b227-87b183b6e82e to disappear
Oct  3 19:36:47.521: INFO: Pod pod-2c0a2058-1022-4e45-b227-87b183b6e82e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Oct  3 19:36:47.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1948" for this suite. 10/03/22 19:36:47.541
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":76,"skipped":1752,"failed":0}
------------------------------
• [SLOW TEST] [6.274 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:36:41.29
    Oct  3 19:36:41.291: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir 10/03/22 19:36:41.292
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:36:41.339
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:36:41.35
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 10/03/22 19:36:41.362
    Oct  3 19:36:41.390: INFO: Waiting up to 5m0s for pod "pod-2c0a2058-1022-4e45-b227-87b183b6e82e" in namespace "emptydir-1948" to be "Succeeded or Failed"
    Oct  3 19:36:41.404: INFO: Pod "pod-2c0a2058-1022-4e45-b227-87b183b6e82e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.058505ms
    Oct  3 19:36:43.420: INFO: Pod "pod-2c0a2058-1022-4e45-b227-87b183b6e82e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029646582s
    Oct  3 19:36:45.420: INFO: Pod "pod-2c0a2058-1022-4e45-b227-87b183b6e82e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02916214s
    Oct  3 19:36:47.420: INFO: Pod "pod-2c0a2058-1022-4e45-b227-87b183b6e82e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029630565s
    STEP: Saw pod success 10/03/22 19:36:47.42
    Oct  3 19:36:47.420: INFO: Pod "pod-2c0a2058-1022-4e45-b227-87b183b6e82e" satisfied condition "Succeeded or Failed"
    Oct  3 19:36:47.435: INFO: Trying to get logs from node 10.63.128.3 pod pod-2c0a2058-1022-4e45-b227-87b183b6e82e container test-container: <nil>
    STEP: delete the pod 10/03/22 19:36:47.465
    Oct  3 19:36:47.508: INFO: Waiting for pod pod-2c0a2058-1022-4e45-b227-87b183b6e82e to disappear
    Oct  3 19:36:47.521: INFO: Pod pod-2c0a2058-1022-4e45-b227-87b183b6e82e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Oct  3 19:36:47.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1948" for this suite. 10/03/22 19:36:47.541
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:36:47.566
Oct  3 19:36:47.566: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename statefulset 10/03/22 19:36:47.568
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:36:47.61
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:36:47.622
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3291 10/03/22 19:36:47.634
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-3291 10/03/22 19:36:47.65
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3291 10/03/22 19:36:47.666
Oct  3 19:36:47.680: INFO: Found 0 stateful pods, waiting for 1
Oct  3 19:36:57.694: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 10/03/22 19:36:57.694
Oct  3 19:36:57.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-3291 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  3 19:36:58.036: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  3 19:36:58.036: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  3 19:36:58.036: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  3 19:36:58.054: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct  3 19:37:08.070: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  3 19:37:08.070: INFO: Waiting for statefulset status.replicas updated to 0
Oct  3 19:37:08.128: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Oct  3 19:37:08.128: INFO: ss-0  10.63.128.3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:47 +0000 UTC  }]
Oct  3 19:37:08.129: INFO: 
Oct  3 19:37:08.129: INFO: StatefulSet ss has not reached scale 3, at 1
Oct  3 19:37:09.145: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985729021s
Oct  3 19:37:10.162: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.969827963s
Oct  3 19:37:11.178: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.952653438s
Oct  3 19:37:12.209: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.936448465s
Oct  3 19:37:13.225: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.906251955s
Oct  3 19:37:14.240: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.890073296s
Oct  3 19:37:15.255: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.87447564s
Oct  3 19:37:16.271: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.859538907s
Oct  3 19:37:17.303: INFO: Verifying statefulset ss doesn't scale past 3 for another 843.436205ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3291 10/03/22 19:37:18.303
Oct  3 19:37:18.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-3291 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 19:37:18.651: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  3 19:37:18.651: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  3 19:37:18.651: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  3 19:37:18.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-3291 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 19:37:18.922: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct  3 19:37:18.922: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  3 19:37:18.922: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  3 19:37:18.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-3291 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 19:37:19.202: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct  3 19:37:19.202: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  3 19:37:19.202: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  3 19:37:19.217: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  3 19:37:19.217: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  3 19:37:19.217: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 10/03/22 19:37:19.218
Oct  3 19:37:19.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-3291 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  3 19:37:19.526: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  3 19:37:19.526: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  3 19:37:19.526: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  3 19:37:19.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-3291 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  3 19:37:19.820: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  3 19:37:19.820: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  3 19:37:19.820: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  3 19:37:19.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-3291 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  3 19:37:20.152: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  3 19:37:20.152: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  3 19:37:20.152: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  3 19:37:20.152: INFO: Waiting for statefulset status.replicas updated to 0
Oct  3 19:37:20.165: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct  3 19:37:30.200: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  3 19:37:30.200: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct  3 19:37:30.200: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct  3 19:37:30.245: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Oct  3 19:37:30.245: INFO: ss-0  10.63.128.3   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:47 +0000 UTC  }]
Oct  3 19:37:30.245: INFO: ss-1  10.63.128.13  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  }]
Oct  3 19:37:30.245: INFO: ss-2  10.63.128.51  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  }]
Oct  3 19:37:30.245: INFO: 
Oct  3 19:37:30.246: INFO: StatefulSet ss has not reached scale 0, at 3
Oct  3 19:37:31.262: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Oct  3 19:37:31.262: INFO: ss-0  10.63.128.3   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:47 +0000 UTC  }]
Oct  3 19:37:31.262: INFO: ss-1  10.63.128.13  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  }]
Oct  3 19:37:31.262: INFO: ss-2  10.63.128.51  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  }]
Oct  3 19:37:31.262: INFO: 
Oct  3 19:37:31.262: INFO: StatefulSet ss has not reached scale 0, at 3
Oct  3 19:37:32.277: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.96712307s
Oct  3 19:37:33.292: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.951742102s
Oct  3 19:37:34.307: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.937015706s
Oct  3 19:37:35.322: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.921766639s
Oct  3 19:37:36.337: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.907341188s
Oct  3 19:37:37.351: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.892600495s
Oct  3 19:37:38.365: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.878239748s
Oct  3 19:37:39.381: INFO: Verifying statefulset ss doesn't scale past 0 for another 864.318667ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3291 10/03/22 19:37:40.381
Oct  3 19:37:40.397: INFO: Scaling statefulset ss to 0
Oct  3 19:37:40.433: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct  3 19:37:40.446: INFO: Deleting all statefulset in ns statefulset-3291
Oct  3 19:37:40.458: INFO: Scaling statefulset ss to 0
Oct  3 19:37:40.500: INFO: Waiting for statefulset status.replicas updated to 0
Oct  3 19:37:40.513: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Oct  3 19:37:40.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3291" for this suite. 10/03/22 19:37:40.576
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":77,"skipped":1760,"failed":0}
------------------------------
• [SLOW TEST] [53.034 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:36:47.566
    Oct  3 19:36:47.566: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename statefulset 10/03/22 19:36:47.568
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:36:47.61
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:36:47.622
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3291 10/03/22 19:36:47.634
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-3291 10/03/22 19:36:47.65
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3291 10/03/22 19:36:47.666
    Oct  3 19:36:47.680: INFO: Found 0 stateful pods, waiting for 1
    Oct  3 19:36:57.694: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 10/03/22 19:36:57.694
    Oct  3 19:36:57.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-3291 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct  3 19:36:58.036: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct  3 19:36:58.036: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct  3 19:36:58.036: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct  3 19:36:58.054: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Oct  3 19:37:08.070: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Oct  3 19:37:08.070: INFO: Waiting for statefulset status.replicas updated to 0
    Oct  3 19:37:08.128: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
    Oct  3 19:37:08.128: INFO: ss-0  10.63.128.3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:47 +0000 UTC  }]
    Oct  3 19:37:08.129: INFO: 
    Oct  3 19:37:08.129: INFO: StatefulSet ss has not reached scale 3, at 1
    Oct  3 19:37:09.145: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985729021s
    Oct  3 19:37:10.162: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.969827963s
    Oct  3 19:37:11.178: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.952653438s
    Oct  3 19:37:12.209: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.936448465s
    Oct  3 19:37:13.225: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.906251955s
    Oct  3 19:37:14.240: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.890073296s
    Oct  3 19:37:15.255: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.87447564s
    Oct  3 19:37:16.271: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.859538907s
    Oct  3 19:37:17.303: INFO: Verifying statefulset ss doesn't scale past 3 for another 843.436205ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3291 10/03/22 19:37:18.303
    Oct  3 19:37:18.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-3291 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 19:37:18.651: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Oct  3 19:37:18.651: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct  3 19:37:18.651: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Oct  3 19:37:18.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-3291 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 19:37:18.922: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Oct  3 19:37:18.922: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct  3 19:37:18.922: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Oct  3 19:37:18.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-3291 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 19:37:19.202: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Oct  3 19:37:19.202: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct  3 19:37:19.202: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Oct  3 19:37:19.217: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Oct  3 19:37:19.217: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Oct  3 19:37:19.217: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 10/03/22 19:37:19.218
    Oct  3 19:37:19.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-3291 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct  3 19:37:19.526: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct  3 19:37:19.526: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct  3 19:37:19.526: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct  3 19:37:19.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-3291 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct  3 19:37:19.820: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct  3 19:37:19.820: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct  3 19:37:19.820: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct  3 19:37:19.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-3291 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct  3 19:37:20.152: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct  3 19:37:20.152: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct  3 19:37:20.152: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct  3 19:37:20.152: INFO: Waiting for statefulset status.replicas updated to 0
    Oct  3 19:37:20.165: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Oct  3 19:37:30.200: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Oct  3 19:37:30.200: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Oct  3 19:37:30.200: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Oct  3 19:37:30.245: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
    Oct  3 19:37:30.245: INFO: ss-0  10.63.128.3   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:47 +0000 UTC  }]
    Oct  3 19:37:30.245: INFO: ss-1  10.63.128.13  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  }]
    Oct  3 19:37:30.245: INFO: ss-2  10.63.128.51  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  }]
    Oct  3 19:37:30.245: INFO: 
    Oct  3 19:37:30.246: INFO: StatefulSet ss has not reached scale 0, at 3
    Oct  3 19:37:31.262: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
    Oct  3 19:37:31.262: INFO: ss-0  10.63.128.3   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:36:47 +0000 UTC  }]
    Oct  3 19:37:31.262: INFO: ss-1  10.63.128.13  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  }]
    Oct  3 19:37:31.262: INFO: ss-2  10.63.128.51  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-03 19:37:08 +0000 UTC  }]
    Oct  3 19:37:31.262: INFO: 
    Oct  3 19:37:31.262: INFO: StatefulSet ss has not reached scale 0, at 3
    Oct  3 19:37:32.277: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.96712307s
    Oct  3 19:37:33.292: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.951742102s
    Oct  3 19:37:34.307: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.937015706s
    Oct  3 19:37:35.322: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.921766639s
    Oct  3 19:37:36.337: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.907341188s
    Oct  3 19:37:37.351: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.892600495s
    Oct  3 19:37:38.365: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.878239748s
    Oct  3 19:37:39.381: INFO: Verifying statefulset ss doesn't scale past 0 for another 864.318667ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3291 10/03/22 19:37:40.381
    Oct  3 19:37:40.397: INFO: Scaling statefulset ss to 0
    Oct  3 19:37:40.433: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Oct  3 19:37:40.446: INFO: Deleting all statefulset in ns statefulset-3291
    Oct  3 19:37:40.458: INFO: Scaling statefulset ss to 0
    Oct  3 19:37:40.500: INFO: Waiting for statefulset status.replicas updated to 0
    Oct  3 19:37:40.513: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Oct  3 19:37:40.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3291" for this suite. 10/03/22 19:37:40.576
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:37:40.603
Oct  3 19:37:40.604: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir-wrapper 10/03/22 19:37:40.605
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:37:40.654
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:37:40.665
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 10/03/22 19:37:40.676
STEP: Creating RC which spawns configmap-volume pods 10/03/22 19:37:41.379
Oct  3 19:37:41.414: INFO: Pod name wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2: Found 0 pods out of 5
Oct  3 19:37:46.442: INFO: Pod name wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2: Found 5 pods out of 5
STEP: Ensuring each pod is running 10/03/22 19:37:46.443
Oct  3 19:37:46.443: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-4f4rk" in namespace "emptydir-wrapper-7832" to be "running"
Oct  3 19:37:46.458: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-4f4rk": Phase="Running", Reason="", readiness=true. Elapsed: 15.495105ms
Oct  3 19:37:46.458: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-4f4rk" satisfied condition "running"
Oct  3 19:37:46.458: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-892zz" in namespace "emptydir-wrapper-7832" to be "running"
Oct  3 19:37:46.482: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-892zz": Phase="Running", Reason="", readiness=true. Elapsed: 23.761781ms
Oct  3 19:37:46.482: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-892zz" satisfied condition "running"
Oct  3 19:37:46.482: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-8pbf2" in namespace "emptydir-wrapper-7832" to be "running"
Oct  3 19:37:46.498: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-8pbf2": Phase="Running", Reason="", readiness=true. Elapsed: 15.66256ms
Oct  3 19:37:46.498: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-8pbf2" satisfied condition "running"
Oct  3 19:37:46.498: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-f7bmc" in namespace "emptydir-wrapper-7832" to be "running"
Oct  3 19:37:46.515: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-f7bmc": Phase="Running", Reason="", readiness=true. Elapsed: 17.136531ms
Oct  3 19:37:46.515: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-f7bmc" satisfied condition "running"
Oct  3 19:37:46.515: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-wd6dh" in namespace "emptydir-wrapper-7832" to be "running"
Oct  3 19:37:46.531: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-wd6dh": Phase="Running", Reason="", readiness=true. Elapsed: 15.725897ms
Oct  3 19:37:46.531: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-wd6dh" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2 in namespace emptydir-wrapper-7832, will wait for the garbage collector to delete the pods 10/03/22 19:37:46.531
Oct  3 19:37:46.611: INFO: Deleting ReplicationController wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2 took: 18.684882ms
Oct  3 19:37:46.713: INFO: Terminating ReplicationController wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2 pods took: 101.579717ms
STEP: Creating RC which spawns configmap-volume pods 10/03/22 19:37:49.131
Oct  3 19:37:49.167: INFO: Pod name wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc: Found 0 pods out of 5
Oct  3 19:37:54.192: INFO: Pod name wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc: Found 5 pods out of 5
STEP: Ensuring each pod is running 10/03/22 19:37:54.192
Oct  3 19:37:54.192: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-2692l" in namespace "emptydir-wrapper-7832" to be "running"
Oct  3 19:37:54.206: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-2692l": Phase="Running", Reason="", readiness=true. Elapsed: 14.587509ms
Oct  3 19:37:54.206: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-2692l" satisfied condition "running"
Oct  3 19:37:54.207: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-9jkl9" in namespace "emptydir-wrapper-7832" to be "running"
Oct  3 19:37:54.221: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-9jkl9": Phase="Running", Reason="", readiness=true. Elapsed: 14.105977ms
Oct  3 19:37:54.221: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-9jkl9" satisfied condition "running"
Oct  3 19:37:54.221: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-bb5bk" in namespace "emptydir-wrapper-7832" to be "running"
Oct  3 19:37:54.236: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-bb5bk": Phase="Running", Reason="", readiness=true. Elapsed: 14.91548ms
Oct  3 19:37:54.236: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-bb5bk" satisfied condition "running"
Oct  3 19:37:54.236: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-ftkq8" in namespace "emptydir-wrapper-7832" to be "running"
Oct  3 19:37:54.251: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-ftkq8": Phase="Running", Reason="", readiness=true. Elapsed: 14.596021ms
Oct  3 19:37:54.251: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-ftkq8" satisfied condition "running"
Oct  3 19:37:54.251: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-zrkpm" in namespace "emptydir-wrapper-7832" to be "running"
Oct  3 19:37:54.267: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-zrkpm": Phase="Running", Reason="", readiness=true. Elapsed: 16.125111ms
Oct  3 19:37:54.267: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-zrkpm" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc in namespace emptydir-wrapper-7832, will wait for the garbage collector to delete the pods 10/03/22 19:37:54.267
Oct  3 19:37:54.349: INFO: Deleting ReplicationController wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc took: 18.923515ms
Oct  3 19:37:54.450: INFO: Terminating ReplicationController wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc pods took: 100.565355ms
STEP: Creating RC which spawns configmap-volume pods 10/03/22 19:37:57.169
Oct  3 19:37:57.264: INFO: Pod name wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65: Found 4 pods out of 5
Oct  3 19:38:02.306: INFO: Pod name wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65: Found 5 pods out of 5
STEP: Ensuring each pod is running 10/03/22 19:38:02.306
Oct  3 19:38:02.307: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-c4xkh" in namespace "emptydir-wrapper-7832" to be "running"
Oct  3 19:38:02.321: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-c4xkh": Phase="Running", Reason="", readiness=true. Elapsed: 14.739356ms
Oct  3 19:38:02.322: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-c4xkh" satisfied condition "running"
Oct  3 19:38:02.322: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-ddz7s" in namespace "emptydir-wrapper-7832" to be "running"
Oct  3 19:38:02.338: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-ddz7s": Phase="Running", Reason="", readiness=true. Elapsed: 15.495425ms
Oct  3 19:38:02.338: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-ddz7s" satisfied condition "running"
Oct  3 19:38:02.338: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-hz56h" in namespace "emptydir-wrapper-7832" to be "running"
Oct  3 19:38:02.353: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-hz56h": Phase="Running", Reason="", readiness=true. Elapsed: 14.503806ms
Oct  3 19:38:02.353: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-hz56h" satisfied condition "running"
Oct  3 19:38:02.353: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-n5j6r" in namespace "emptydir-wrapper-7832" to be "running"
Oct  3 19:38:02.367: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-n5j6r": Phase="Running", Reason="", readiness=true. Elapsed: 14.20048ms
Oct  3 19:38:02.367: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-n5j6r" satisfied condition "running"
Oct  3 19:38:02.367: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-nbcr7" in namespace "emptydir-wrapper-7832" to be "running"
Oct  3 19:38:02.381: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-nbcr7": Phase="Running", Reason="", readiness=true. Elapsed: 14.336439ms
Oct  3 19:38:02.381: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-nbcr7" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65 in namespace emptydir-wrapper-7832, will wait for the garbage collector to delete the pods 10/03/22 19:38:02.382
Oct  3 19:38:02.465: INFO: Deleting ReplicationController wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65 took: 19.601499ms
Oct  3 19:38:02.566: INFO: Terminating ReplicationController wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65 pods took: 101.043329ms
STEP: Cleaning up the configMaps 10/03/22 19:38:05.266
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Oct  3 19:38:06.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7832" for this suite. 10/03/22 19:38:06.14
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":78,"skipped":1771,"failed":0}
------------------------------
• [SLOW TEST] [25.559 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:37:40.603
    Oct  3 19:37:40.604: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir-wrapper 10/03/22 19:37:40.605
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:37:40.654
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:37:40.665
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 10/03/22 19:37:40.676
    STEP: Creating RC which spawns configmap-volume pods 10/03/22 19:37:41.379
    Oct  3 19:37:41.414: INFO: Pod name wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2: Found 0 pods out of 5
    Oct  3 19:37:46.442: INFO: Pod name wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2: Found 5 pods out of 5
    STEP: Ensuring each pod is running 10/03/22 19:37:46.443
    Oct  3 19:37:46.443: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-4f4rk" in namespace "emptydir-wrapper-7832" to be "running"
    Oct  3 19:37:46.458: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-4f4rk": Phase="Running", Reason="", readiness=true. Elapsed: 15.495105ms
    Oct  3 19:37:46.458: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-4f4rk" satisfied condition "running"
    Oct  3 19:37:46.458: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-892zz" in namespace "emptydir-wrapper-7832" to be "running"
    Oct  3 19:37:46.482: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-892zz": Phase="Running", Reason="", readiness=true. Elapsed: 23.761781ms
    Oct  3 19:37:46.482: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-892zz" satisfied condition "running"
    Oct  3 19:37:46.482: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-8pbf2" in namespace "emptydir-wrapper-7832" to be "running"
    Oct  3 19:37:46.498: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-8pbf2": Phase="Running", Reason="", readiness=true. Elapsed: 15.66256ms
    Oct  3 19:37:46.498: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-8pbf2" satisfied condition "running"
    Oct  3 19:37:46.498: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-f7bmc" in namespace "emptydir-wrapper-7832" to be "running"
    Oct  3 19:37:46.515: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-f7bmc": Phase="Running", Reason="", readiness=true. Elapsed: 17.136531ms
    Oct  3 19:37:46.515: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-f7bmc" satisfied condition "running"
    Oct  3 19:37:46.515: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-wd6dh" in namespace "emptydir-wrapper-7832" to be "running"
    Oct  3 19:37:46.531: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-wd6dh": Phase="Running", Reason="", readiness=true. Elapsed: 15.725897ms
    Oct  3 19:37:46.531: INFO: Pod "wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2-wd6dh" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2 in namespace emptydir-wrapper-7832, will wait for the garbage collector to delete the pods 10/03/22 19:37:46.531
    Oct  3 19:37:46.611: INFO: Deleting ReplicationController wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2 took: 18.684882ms
    Oct  3 19:37:46.713: INFO: Terminating ReplicationController wrapped-volume-race-bafc8da7-bd46-44ba-8811-89d58e6e94a2 pods took: 101.579717ms
    STEP: Creating RC which spawns configmap-volume pods 10/03/22 19:37:49.131
    Oct  3 19:37:49.167: INFO: Pod name wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc: Found 0 pods out of 5
    Oct  3 19:37:54.192: INFO: Pod name wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc: Found 5 pods out of 5
    STEP: Ensuring each pod is running 10/03/22 19:37:54.192
    Oct  3 19:37:54.192: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-2692l" in namespace "emptydir-wrapper-7832" to be "running"
    Oct  3 19:37:54.206: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-2692l": Phase="Running", Reason="", readiness=true. Elapsed: 14.587509ms
    Oct  3 19:37:54.206: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-2692l" satisfied condition "running"
    Oct  3 19:37:54.207: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-9jkl9" in namespace "emptydir-wrapper-7832" to be "running"
    Oct  3 19:37:54.221: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-9jkl9": Phase="Running", Reason="", readiness=true. Elapsed: 14.105977ms
    Oct  3 19:37:54.221: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-9jkl9" satisfied condition "running"
    Oct  3 19:37:54.221: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-bb5bk" in namespace "emptydir-wrapper-7832" to be "running"
    Oct  3 19:37:54.236: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-bb5bk": Phase="Running", Reason="", readiness=true. Elapsed: 14.91548ms
    Oct  3 19:37:54.236: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-bb5bk" satisfied condition "running"
    Oct  3 19:37:54.236: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-ftkq8" in namespace "emptydir-wrapper-7832" to be "running"
    Oct  3 19:37:54.251: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-ftkq8": Phase="Running", Reason="", readiness=true. Elapsed: 14.596021ms
    Oct  3 19:37:54.251: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-ftkq8" satisfied condition "running"
    Oct  3 19:37:54.251: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-zrkpm" in namespace "emptydir-wrapper-7832" to be "running"
    Oct  3 19:37:54.267: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-zrkpm": Phase="Running", Reason="", readiness=true. Elapsed: 16.125111ms
    Oct  3 19:37:54.267: INFO: Pod "wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc-zrkpm" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc in namespace emptydir-wrapper-7832, will wait for the garbage collector to delete the pods 10/03/22 19:37:54.267
    Oct  3 19:37:54.349: INFO: Deleting ReplicationController wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc took: 18.923515ms
    Oct  3 19:37:54.450: INFO: Terminating ReplicationController wrapped-volume-race-f210cbd2-1f03-4059-8233-150093418edc pods took: 100.565355ms
    STEP: Creating RC which spawns configmap-volume pods 10/03/22 19:37:57.169
    Oct  3 19:37:57.264: INFO: Pod name wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65: Found 4 pods out of 5
    Oct  3 19:38:02.306: INFO: Pod name wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65: Found 5 pods out of 5
    STEP: Ensuring each pod is running 10/03/22 19:38:02.306
    Oct  3 19:38:02.307: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-c4xkh" in namespace "emptydir-wrapper-7832" to be "running"
    Oct  3 19:38:02.321: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-c4xkh": Phase="Running", Reason="", readiness=true. Elapsed: 14.739356ms
    Oct  3 19:38:02.322: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-c4xkh" satisfied condition "running"
    Oct  3 19:38:02.322: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-ddz7s" in namespace "emptydir-wrapper-7832" to be "running"
    Oct  3 19:38:02.338: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-ddz7s": Phase="Running", Reason="", readiness=true. Elapsed: 15.495425ms
    Oct  3 19:38:02.338: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-ddz7s" satisfied condition "running"
    Oct  3 19:38:02.338: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-hz56h" in namespace "emptydir-wrapper-7832" to be "running"
    Oct  3 19:38:02.353: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-hz56h": Phase="Running", Reason="", readiness=true. Elapsed: 14.503806ms
    Oct  3 19:38:02.353: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-hz56h" satisfied condition "running"
    Oct  3 19:38:02.353: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-n5j6r" in namespace "emptydir-wrapper-7832" to be "running"
    Oct  3 19:38:02.367: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-n5j6r": Phase="Running", Reason="", readiness=true. Elapsed: 14.20048ms
    Oct  3 19:38:02.367: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-n5j6r" satisfied condition "running"
    Oct  3 19:38:02.367: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-nbcr7" in namespace "emptydir-wrapper-7832" to be "running"
    Oct  3 19:38:02.381: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-nbcr7": Phase="Running", Reason="", readiness=true. Elapsed: 14.336439ms
    Oct  3 19:38:02.381: INFO: Pod "wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65-nbcr7" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65 in namespace emptydir-wrapper-7832, will wait for the garbage collector to delete the pods 10/03/22 19:38:02.382
    Oct  3 19:38:02.465: INFO: Deleting ReplicationController wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65 took: 19.601499ms
    Oct  3 19:38:02.566: INFO: Terminating ReplicationController wrapped-volume-race-1674450d-2548-42fd-bcd6-6d72e1b95e65 pods took: 101.043329ms
    STEP: Cleaning up the configMaps 10/03/22 19:38:05.266
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Oct  3 19:38:06.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-7832" for this suite. 10/03/22 19:38:06.14
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:38:06.165
Oct  3 19:38:06.165: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 19:38:06.166
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:06.225
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:06.239
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 10/03/22 19:38:06.25
Oct  3 19:38:06.277: INFO: Waiting up to 5m0s for pod "downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd" in namespace "projected-1795" to be "Succeeded or Failed"
Oct  3 19:38:06.294: INFO: Pod "downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd": Phase="Pending", Reason="", readiness=false. Elapsed: 17.001779ms
Oct  3 19:38:08.309: INFO: Pod "downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032588591s
Oct  3 19:38:10.316: INFO: Pod "downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039164054s
STEP: Saw pod success 10/03/22 19:38:10.316
Oct  3 19:38:10.317: INFO: Pod "downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd" satisfied condition "Succeeded or Failed"
Oct  3 19:38:10.331: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd container client-container: <nil>
STEP: delete the pod 10/03/22 19:38:10.36
Oct  3 19:38:10.396: INFO: Waiting for pod downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd to disappear
Oct  3 19:38:10.410: INFO: Pod downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Oct  3 19:38:10.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1795" for this suite. 10/03/22 19:38:10.426
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":79,"skipped":1775,"failed":0}
------------------------------
• [4.285 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:38:06.165
    Oct  3 19:38:06.165: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 19:38:06.166
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:06.225
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:06.239
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 10/03/22 19:38:06.25
    Oct  3 19:38:06.277: INFO: Waiting up to 5m0s for pod "downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd" in namespace "projected-1795" to be "Succeeded or Failed"
    Oct  3 19:38:06.294: INFO: Pod "downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd": Phase="Pending", Reason="", readiness=false. Elapsed: 17.001779ms
    Oct  3 19:38:08.309: INFO: Pod "downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032588591s
    Oct  3 19:38:10.316: INFO: Pod "downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039164054s
    STEP: Saw pod success 10/03/22 19:38:10.316
    Oct  3 19:38:10.317: INFO: Pod "downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd" satisfied condition "Succeeded or Failed"
    Oct  3 19:38:10.331: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd container client-container: <nil>
    STEP: delete the pod 10/03/22 19:38:10.36
    Oct  3 19:38:10.396: INFO: Waiting for pod downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd to disappear
    Oct  3 19:38:10.410: INFO: Pod downwardapi-volume-96849d78-73e0-44d9-84f6-efc76ae46cfd no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Oct  3 19:38:10.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1795" for this suite. 10/03/22 19:38:10.426
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:38:10.451
Oct  3 19:38:10.451: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename containers 10/03/22 19:38:10.453
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:10.498
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:10.51
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Oct  3 19:38:10.547: INFO: Waiting up to 5m0s for pod "client-containers-c14b89f3-5a84-41f5-814b-68f8da2f125f" in namespace "containers-1977" to be "running"
Oct  3 19:38:10.560: INFO: Pod "client-containers-c14b89f3-5a84-41f5-814b-68f8da2f125f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.674047ms
Oct  3 19:38:12.575: INFO: Pod "client-containers-c14b89f3-5a84-41f5-814b-68f8da2f125f": Phase="Running", Reason="", readiness=true. Elapsed: 2.027885945s
Oct  3 19:38:12.575: INFO: Pod "client-containers-c14b89f3-5a84-41f5-814b-68f8da2f125f" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Oct  3 19:38:12.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1977" for this suite. 10/03/22 19:38:12.626
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":80,"skipped":1781,"failed":0}
------------------------------
• [2.197 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:38:10.451
    Oct  3 19:38:10.451: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename containers 10/03/22 19:38:10.453
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:10.498
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:10.51
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Oct  3 19:38:10.547: INFO: Waiting up to 5m0s for pod "client-containers-c14b89f3-5a84-41f5-814b-68f8da2f125f" in namespace "containers-1977" to be "running"
    Oct  3 19:38:10.560: INFO: Pod "client-containers-c14b89f3-5a84-41f5-814b-68f8da2f125f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.674047ms
    Oct  3 19:38:12.575: INFO: Pod "client-containers-c14b89f3-5a84-41f5-814b-68f8da2f125f": Phase="Running", Reason="", readiness=true. Elapsed: 2.027885945s
    Oct  3 19:38:12.575: INFO: Pod "client-containers-c14b89f3-5a84-41f5-814b-68f8da2f125f" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Oct  3 19:38:12.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-1977" for this suite. 10/03/22 19:38:12.626
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:38:12.653
Oct  3 19:38:12.654: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir 10/03/22 19:38:12.655
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:12.705
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:12.717
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 10/03/22 19:38:12.728
Oct  3 19:38:12.757: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-c18b1109-c6a1-4904-bd43-332a0ed99d15" in namespace "emptydir-944" to be "running"
Oct  3 19:38:12.771: INFO: Pod "pod-sharedvolume-c18b1109-c6a1-4904-bd43-332a0ed99d15": Phase="Pending", Reason="", readiness=false. Elapsed: 13.440084ms
Oct  3 19:38:14.786: INFO: Pod "pod-sharedvolume-c18b1109-c6a1-4904-bd43-332a0ed99d15": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028684305s
Oct  3 19:38:16.786: INFO: Pod "pod-sharedvolume-c18b1109-c6a1-4904-bd43-332a0ed99d15": Phase="Running", Reason="", readiness=false. Elapsed: 4.028688843s
Oct  3 19:38:16.786: INFO: Pod "pod-sharedvolume-c18b1109-c6a1-4904-bd43-332a0ed99d15" satisfied condition "running"
STEP: Reading file content from the nginx-container 10/03/22 19:38:16.786
Oct  3 19:38:16.787: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-944 PodName:pod-sharedvolume-c18b1109-c6a1-4904-bd43-332a0ed99d15 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 19:38:16.787: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 19:38:16.788: INFO: ExecWithOptions: Clientset creation
Oct  3 19:38:16.788: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/emptydir-944/pods/pod-sharedvolume-c18b1109-c6a1-4904-bd43-332a0ed99d15/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Oct  3 19:38:16.996: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Oct  3 19:38:16.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-944" for this suite. 10/03/22 19:38:17.014
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":81,"skipped":1807,"failed":0}
------------------------------
• [4.385 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:38:12.653
    Oct  3 19:38:12.654: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir 10/03/22 19:38:12.655
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:12.705
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:12.717
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 10/03/22 19:38:12.728
    Oct  3 19:38:12.757: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-c18b1109-c6a1-4904-bd43-332a0ed99d15" in namespace "emptydir-944" to be "running"
    Oct  3 19:38:12.771: INFO: Pod "pod-sharedvolume-c18b1109-c6a1-4904-bd43-332a0ed99d15": Phase="Pending", Reason="", readiness=false. Elapsed: 13.440084ms
    Oct  3 19:38:14.786: INFO: Pod "pod-sharedvolume-c18b1109-c6a1-4904-bd43-332a0ed99d15": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028684305s
    Oct  3 19:38:16.786: INFO: Pod "pod-sharedvolume-c18b1109-c6a1-4904-bd43-332a0ed99d15": Phase="Running", Reason="", readiness=false. Elapsed: 4.028688843s
    Oct  3 19:38:16.786: INFO: Pod "pod-sharedvolume-c18b1109-c6a1-4904-bd43-332a0ed99d15" satisfied condition "running"
    STEP: Reading file content from the nginx-container 10/03/22 19:38:16.786
    Oct  3 19:38:16.787: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-944 PodName:pod-sharedvolume-c18b1109-c6a1-4904-bd43-332a0ed99d15 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 19:38:16.787: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 19:38:16.788: INFO: ExecWithOptions: Clientset creation
    Oct  3 19:38:16.788: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/emptydir-944/pods/pod-sharedvolume-c18b1109-c6a1-4904-bd43-332a0ed99d15/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Oct  3 19:38:16.996: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Oct  3 19:38:16.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-944" for this suite. 10/03/22 19:38:17.014
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:38:17.04
Oct  3 19:38:17.041: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 19:38:17.042
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:17.084
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:17.102
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-3b080b2b-9ce8-43d5-a2e1-d716d84724dd 10/03/22 19:38:17.113
STEP: Creating secret with name secret-projected-all-test-volume-1201ab0b-6883-4447-abd0-cb2955569a65 10/03/22 19:38:17.127
STEP: Creating a pod to test Check all projections for projected volume plugin 10/03/22 19:38:17.143
Oct  3 19:38:17.202: INFO: Waiting up to 5m0s for pod "projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f" in namespace "projected-2234" to be "Succeeded or Failed"
Oct  3 19:38:17.213: INFO: Pod "projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.474645ms
Oct  3 19:38:19.228: INFO: Pod "projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026120517s
Oct  3 19:38:21.228: INFO: Pod "projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026664186s
Oct  3 19:38:23.227: INFO: Pod "projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025852377s
STEP: Saw pod success 10/03/22 19:38:23.227
Oct  3 19:38:23.228: INFO: Pod "projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f" satisfied condition "Succeeded or Failed"
Oct  3 19:38:23.264: INFO: Trying to get logs from node 10.63.128.3 pod projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f container projected-all-volume-test: <nil>
STEP: delete the pod 10/03/22 19:38:23.293
Oct  3 19:38:23.357: INFO: Waiting for pod projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f to disappear
Oct  3 19:38:23.371: INFO: Pod projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Oct  3 19:38:23.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2234" for this suite. 10/03/22 19:38:23.388
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":82,"skipped":1813,"failed":0}
------------------------------
• [SLOW TEST] [6.395 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:38:17.04
    Oct  3 19:38:17.041: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 19:38:17.042
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:17.084
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:17.102
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-3b080b2b-9ce8-43d5-a2e1-d716d84724dd 10/03/22 19:38:17.113
    STEP: Creating secret with name secret-projected-all-test-volume-1201ab0b-6883-4447-abd0-cb2955569a65 10/03/22 19:38:17.127
    STEP: Creating a pod to test Check all projections for projected volume plugin 10/03/22 19:38:17.143
    Oct  3 19:38:17.202: INFO: Waiting up to 5m0s for pod "projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f" in namespace "projected-2234" to be "Succeeded or Failed"
    Oct  3 19:38:17.213: INFO: Pod "projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.474645ms
    Oct  3 19:38:19.228: INFO: Pod "projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026120517s
    Oct  3 19:38:21.228: INFO: Pod "projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026664186s
    Oct  3 19:38:23.227: INFO: Pod "projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025852377s
    STEP: Saw pod success 10/03/22 19:38:23.227
    Oct  3 19:38:23.228: INFO: Pod "projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f" satisfied condition "Succeeded or Failed"
    Oct  3 19:38:23.264: INFO: Trying to get logs from node 10.63.128.3 pod projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f container projected-all-volume-test: <nil>
    STEP: delete the pod 10/03/22 19:38:23.293
    Oct  3 19:38:23.357: INFO: Waiting for pod projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f to disappear
    Oct  3 19:38:23.371: INFO: Pod projected-volume-3dfc08fa-54d2-4c2d-90b9-35dcd72de06f no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Oct  3 19:38:23.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2234" for this suite. 10/03/22 19:38:23.388
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:38:23.448
Oct  3 19:38:23.448: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename init-container 10/03/22 19:38:23.449
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:23.497
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:23.507
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 10/03/22 19:38:23.518
Oct  3 19:38:23.518: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Oct  3 19:38:30.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8163" for this suite. 10/03/22 19:38:30.394
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":83,"skipped":1880,"failed":0}
------------------------------
• [SLOW TEST] [6.968 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:38:23.448
    Oct  3 19:38:23.448: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename init-container 10/03/22 19:38:23.449
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:23.497
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:23.507
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 10/03/22 19:38:23.518
    Oct  3 19:38:23.518: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Oct  3 19:38:30.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-8163" for this suite. 10/03/22 19:38:30.394
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:38:30.416
Oct  3 19:38:30.416: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename disruption 10/03/22 19:38:30.417
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:30.464
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:30.475
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:38:30.487
Oct  3 19:38:30.487: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename disruption-2 10/03/22 19:38:30.488
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:30.53
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:30.54
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 10/03/22 19:38:30.562
STEP: Waiting for the pdb to be processed 10/03/22 19:38:32.597
STEP: Waiting for the pdb to be processed 10/03/22 19:38:32.621
STEP: listing a collection of PDBs across all namespaces 10/03/22 19:38:32.634
STEP: listing a collection of PDBs in namespace disruption-1434 10/03/22 19:38:32.646
STEP: deleting a collection of PDBs 10/03/22 19:38:32.659
STEP: Waiting for the PDB collection to be deleted 10/03/22 19:38:32.689
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Oct  3 19:38:32.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-5073" for this suite. 10/03/22 19:38:32.773
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Oct  3 19:38:32.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1434" for this suite. 10/03/22 19:38:32.846
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":84,"skipped":1881,"failed":0}
------------------------------
• [2.453 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:38:30.416
    Oct  3 19:38:30.416: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename disruption 10/03/22 19:38:30.417
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:30.464
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:30.475
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:38:30.487
    Oct  3 19:38:30.487: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename disruption-2 10/03/22 19:38:30.488
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:30.53
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:30.54
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 10/03/22 19:38:30.562
    STEP: Waiting for the pdb to be processed 10/03/22 19:38:32.597
    STEP: Waiting for the pdb to be processed 10/03/22 19:38:32.621
    STEP: listing a collection of PDBs across all namespaces 10/03/22 19:38:32.634
    STEP: listing a collection of PDBs in namespace disruption-1434 10/03/22 19:38:32.646
    STEP: deleting a collection of PDBs 10/03/22 19:38:32.659
    STEP: Waiting for the PDB collection to be deleted 10/03/22 19:38:32.689
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Oct  3 19:38:32.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-5073" for this suite. 10/03/22 19:38:32.773
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Oct  3 19:38:32.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-1434" for this suite. 10/03/22 19:38:32.846
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:38:32.87
Oct  3 19:38:32.870: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir 10/03/22 19:38:32.871
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:32.923
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:32.933
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 10/03/22 19:38:32.941
Oct  3 19:38:32.968: INFO: Waiting up to 5m0s for pod "pod-c3c63292-bba8-43b8-b869-c7bb453e6c68" in namespace "emptydir-868" to be "Succeeded or Failed"
Oct  3 19:38:32.982: INFO: Pod "pod-c3c63292-bba8-43b8-b869-c7bb453e6c68": Phase="Pending", Reason="", readiness=false. Elapsed: 14.526636ms
Oct  3 19:38:34.999: INFO: Pod "pod-c3c63292-bba8-43b8-b869-c7bb453e6c68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031063852s
Oct  3 19:38:37.022: INFO: Pod "pod-c3c63292-bba8-43b8-b869-c7bb453e6c68": Phase="Pending", Reason="", readiness=false. Elapsed: 4.054183129s
Oct  3 19:38:38.998: INFO: Pod "pod-c3c63292-bba8-43b8-b869-c7bb453e6c68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030066077s
STEP: Saw pod success 10/03/22 19:38:38.998
Oct  3 19:38:38.998: INFO: Pod "pod-c3c63292-bba8-43b8-b869-c7bb453e6c68" satisfied condition "Succeeded or Failed"
Oct  3 19:38:39.011: INFO: Trying to get logs from node 10.63.128.3 pod pod-c3c63292-bba8-43b8-b869-c7bb453e6c68 container test-container: <nil>
STEP: delete the pod 10/03/22 19:38:39.04
Oct  3 19:38:39.074: INFO: Waiting for pod pod-c3c63292-bba8-43b8-b869-c7bb453e6c68 to disappear
Oct  3 19:38:39.087: INFO: Pod pod-c3c63292-bba8-43b8-b869-c7bb453e6c68 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Oct  3 19:38:39.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-868" for this suite. 10/03/22 19:38:39.105
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":85,"skipped":1888,"failed":0}
------------------------------
• [SLOW TEST] [6.283 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:38:32.87
    Oct  3 19:38:32.870: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir 10/03/22 19:38:32.871
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:32.923
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:32.933
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 10/03/22 19:38:32.941
    Oct  3 19:38:32.968: INFO: Waiting up to 5m0s for pod "pod-c3c63292-bba8-43b8-b869-c7bb453e6c68" in namespace "emptydir-868" to be "Succeeded or Failed"
    Oct  3 19:38:32.982: INFO: Pod "pod-c3c63292-bba8-43b8-b869-c7bb453e6c68": Phase="Pending", Reason="", readiness=false. Elapsed: 14.526636ms
    Oct  3 19:38:34.999: INFO: Pod "pod-c3c63292-bba8-43b8-b869-c7bb453e6c68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031063852s
    Oct  3 19:38:37.022: INFO: Pod "pod-c3c63292-bba8-43b8-b869-c7bb453e6c68": Phase="Pending", Reason="", readiness=false. Elapsed: 4.054183129s
    Oct  3 19:38:38.998: INFO: Pod "pod-c3c63292-bba8-43b8-b869-c7bb453e6c68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030066077s
    STEP: Saw pod success 10/03/22 19:38:38.998
    Oct  3 19:38:38.998: INFO: Pod "pod-c3c63292-bba8-43b8-b869-c7bb453e6c68" satisfied condition "Succeeded or Failed"
    Oct  3 19:38:39.011: INFO: Trying to get logs from node 10.63.128.3 pod pod-c3c63292-bba8-43b8-b869-c7bb453e6c68 container test-container: <nil>
    STEP: delete the pod 10/03/22 19:38:39.04
    Oct  3 19:38:39.074: INFO: Waiting for pod pod-c3c63292-bba8-43b8-b869-c7bb453e6c68 to disappear
    Oct  3 19:38:39.087: INFO: Pod pod-c3c63292-bba8-43b8-b869-c7bb453e6c68 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Oct  3 19:38:39.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-868" for this suite. 10/03/22 19:38:39.105
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:38:39.157
Oct  3 19:38:39.157: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename gc 10/03/22 19:38:39.158
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:39.216
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:39.233
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Oct  3 19:38:39.395: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"69938c82-1eb2-4138-96f9-549ae8725c2e", Controller:(*bool)(0xc000cd298e), BlockOwnerDeletion:(*bool)(0xc000cd298f)}}
Oct  3 19:38:39.432: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a99e8427-50ce-4e98-be6a-f573720d7762", Controller:(*bool)(0xc00307682e), BlockOwnerDeletion:(*bool)(0xc00307682f)}}
Oct  3 19:38:39.456: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"064f4b14-369c-40c1-973c-595a5af50515", Controller:(*bool)(0xc003076b4e), BlockOwnerDeletion:(*bool)(0xc003076b4f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Oct  3 19:38:44.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7334" for this suite. 10/03/22 19:38:44.535
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":86,"skipped":1890,"failed":0}
------------------------------
• [SLOW TEST] [5.402 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:38:39.157
    Oct  3 19:38:39.157: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename gc 10/03/22 19:38:39.158
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:39.216
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:39.233
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Oct  3 19:38:39.395: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"69938c82-1eb2-4138-96f9-549ae8725c2e", Controller:(*bool)(0xc000cd298e), BlockOwnerDeletion:(*bool)(0xc000cd298f)}}
    Oct  3 19:38:39.432: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a99e8427-50ce-4e98-be6a-f573720d7762", Controller:(*bool)(0xc00307682e), BlockOwnerDeletion:(*bool)(0xc00307682f)}}
    Oct  3 19:38:39.456: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"064f4b14-369c-40c1-973c-595a5af50515", Controller:(*bool)(0xc003076b4e), BlockOwnerDeletion:(*bool)(0xc003076b4f)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Oct  3 19:38:44.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7334" for this suite. 10/03/22 19:38:44.535
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:38:44.559
Oct  3 19:38:44.559: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 19:38:44.561
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:44.63
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:44.639
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 19:38:44.707
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 19:38:45.333
STEP: Deploying the webhook pod 10/03/22 19:38:45.352
STEP: Wait for the deployment to be ready 10/03/22 19:38:45.385
Oct  3 19:38:45.411: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Oct  3 19:38:47.450: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 38, 45, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 38, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 38, 45, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 38, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 10/03/22 19:38:49.466
STEP: Verifying the service has paired with the endpoint 10/03/22 19:38:49.504
Oct  3 19:38:50.505: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 10/03/22 19:38:50.515
STEP: Updating a mutating webhook configuration's rules to not include the create operation 10/03/22 19:38:50.598
STEP: Creating a configMap that should not be mutated 10/03/22 19:38:50.614
STEP: Patching a mutating webhook configuration's rules to include the create operation 10/03/22 19:38:50.641
STEP: Creating a configMap that should be mutated 10/03/22 19:38:50.656
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 19:38:50.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2303" for this suite. 10/03/22 19:38:50.774
STEP: Destroying namespace "webhook-2303-markers" for this suite. 10/03/22 19:38:50.797
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":87,"skipped":1891,"failed":0}
------------------------------
• [SLOW TEST] [6.377 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:38:44.559
    Oct  3 19:38:44.559: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 19:38:44.561
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:44.63
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:44.639
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 19:38:44.707
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 19:38:45.333
    STEP: Deploying the webhook pod 10/03/22 19:38:45.352
    STEP: Wait for the deployment to be ready 10/03/22 19:38:45.385
    Oct  3 19:38:45.411: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Oct  3 19:38:47.450: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 38, 45, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 38, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 38, 45, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 38, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 10/03/22 19:38:49.466
    STEP: Verifying the service has paired with the endpoint 10/03/22 19:38:49.504
    Oct  3 19:38:50.505: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 10/03/22 19:38:50.515
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 10/03/22 19:38:50.598
    STEP: Creating a configMap that should not be mutated 10/03/22 19:38:50.614
    STEP: Patching a mutating webhook configuration's rules to include the create operation 10/03/22 19:38:50.641
    STEP: Creating a configMap that should be mutated 10/03/22 19:38:50.656
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 19:38:50.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2303" for this suite. 10/03/22 19:38:50.774
    STEP: Destroying namespace "webhook-2303-markers" for this suite. 10/03/22 19:38:50.797
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:38:50.937
Oct  3 19:38:50.938: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename cronjob 10/03/22 19:38:50.939
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:50.981
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:50.991
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 10/03/22 19:38:51.003
STEP: Ensuring more than one job is running at a time 10/03/22 19:38:51.048
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 10/03/22 19:40:01.063
STEP: Removing cronjob 10/03/22 19:40:01.074
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Oct  3 19:40:01.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4570" for this suite. 10/03/22 19:40:01.121
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":88,"skipped":1893,"failed":0}
------------------------------
• [SLOW TEST] [70.220 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:38:50.937
    Oct  3 19:38:50.938: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename cronjob 10/03/22 19:38:50.939
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:38:50.981
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:38:50.991
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 10/03/22 19:38:51.003
    STEP: Ensuring more than one job is running at a time 10/03/22 19:38:51.048
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 10/03/22 19:40:01.063
    STEP: Removing cronjob 10/03/22 19:40:01.074
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Oct  3 19:40:01.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-4570" for this suite. 10/03/22 19:40:01.121
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:40:01.159
Oct  3 19:40:01.159: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 19:40:01.161
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:01.209
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:01.222
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 10/03/22 19:40:01.233
Oct  3 19:40:01.261: INFO: Waiting up to 5m0s for pod "downward-api-510e4e85-8607-4884-a05c-aa0514fda069" in namespace "downward-api-5055" to be "Succeeded or Failed"
Oct  3 19:40:01.276: INFO: Pod "downward-api-510e4e85-8607-4884-a05c-aa0514fda069": Phase="Pending", Reason="", readiness=false. Elapsed: 15.746994ms
Oct  3 19:40:03.293: INFO: Pod "downward-api-510e4e85-8607-4884-a05c-aa0514fda069": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03234268s
Oct  3 19:40:05.290: INFO: Pod "downward-api-510e4e85-8607-4884-a05c-aa0514fda069": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029706821s
Oct  3 19:40:07.292: INFO: Pod "downward-api-510e4e85-8607-4884-a05c-aa0514fda069": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031865766s
STEP: Saw pod success 10/03/22 19:40:07.293
Oct  3 19:40:07.293: INFO: Pod "downward-api-510e4e85-8607-4884-a05c-aa0514fda069" satisfied condition "Succeeded or Failed"
Oct  3 19:40:07.318: INFO: Trying to get logs from node 10.63.128.3 pod downward-api-510e4e85-8607-4884-a05c-aa0514fda069 container dapi-container: <nil>
STEP: delete the pod 10/03/22 19:40:07.35
Oct  3 19:40:07.391: INFO: Waiting for pod downward-api-510e4e85-8607-4884-a05c-aa0514fda069 to disappear
Oct  3 19:40:07.406: INFO: Pod downward-api-510e4e85-8607-4884-a05c-aa0514fda069 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Oct  3 19:40:07.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5055" for this suite. 10/03/22 19:40:07.424
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":89,"skipped":1910,"failed":0}
------------------------------
• [SLOW TEST] [6.287 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:40:01.159
    Oct  3 19:40:01.159: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 19:40:01.161
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:01.209
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:01.222
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 10/03/22 19:40:01.233
    Oct  3 19:40:01.261: INFO: Waiting up to 5m0s for pod "downward-api-510e4e85-8607-4884-a05c-aa0514fda069" in namespace "downward-api-5055" to be "Succeeded or Failed"
    Oct  3 19:40:01.276: INFO: Pod "downward-api-510e4e85-8607-4884-a05c-aa0514fda069": Phase="Pending", Reason="", readiness=false. Elapsed: 15.746994ms
    Oct  3 19:40:03.293: INFO: Pod "downward-api-510e4e85-8607-4884-a05c-aa0514fda069": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03234268s
    Oct  3 19:40:05.290: INFO: Pod "downward-api-510e4e85-8607-4884-a05c-aa0514fda069": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029706821s
    Oct  3 19:40:07.292: INFO: Pod "downward-api-510e4e85-8607-4884-a05c-aa0514fda069": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031865766s
    STEP: Saw pod success 10/03/22 19:40:07.293
    Oct  3 19:40:07.293: INFO: Pod "downward-api-510e4e85-8607-4884-a05c-aa0514fda069" satisfied condition "Succeeded or Failed"
    Oct  3 19:40:07.318: INFO: Trying to get logs from node 10.63.128.3 pod downward-api-510e4e85-8607-4884-a05c-aa0514fda069 container dapi-container: <nil>
    STEP: delete the pod 10/03/22 19:40:07.35
    Oct  3 19:40:07.391: INFO: Waiting for pod downward-api-510e4e85-8607-4884-a05c-aa0514fda069 to disappear
    Oct  3 19:40:07.406: INFO: Pod downward-api-510e4e85-8607-4884-a05c-aa0514fda069 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Oct  3 19:40:07.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5055" for this suite. 10/03/22 19:40:07.424
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:40:07.451
Oct  3 19:40:07.452: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename gc 10/03/22 19:40:07.454
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:07.507
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:07.516
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 10/03/22 19:40:07.526
STEP: delete the rc 10/03/22 19:40:12.561
STEP: wait for all pods to be garbage collected 10/03/22 19:40:12.577
STEP: Gathering metrics 10/03/22 19:40:17.601
W1003 19:40:17.649250      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Oct  3 19:40:17.649: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Oct  3 19:40:17.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8270" for this suite. 10/03/22 19:40:17.668
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":90,"skipped":1912,"failed":0}
------------------------------
• [SLOW TEST] [10.245 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:40:07.451
    Oct  3 19:40:07.452: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename gc 10/03/22 19:40:07.454
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:07.507
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:07.516
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 10/03/22 19:40:07.526
    STEP: delete the rc 10/03/22 19:40:12.561
    STEP: wait for all pods to be garbage collected 10/03/22 19:40:12.577
    STEP: Gathering metrics 10/03/22 19:40:17.601
    W1003 19:40:17.649250      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Oct  3 19:40:17.649: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Oct  3 19:40:17.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-8270" for this suite. 10/03/22 19:40:17.668
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:40:17.703
Oct  3 19:40:17.703: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename deployment 10/03/22 19:40:17.705
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:17.751
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:17.762
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Oct  3 19:40:17.774: INFO: Creating simple deployment test-new-deployment
Oct  3 19:40:17.817: INFO: deployment "test-new-deployment" doesn't have the required revision set
Oct  3 19:40:19.858: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 40, 17, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 40, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 40, 17, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 40, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: getting scale subresource 10/03/22 19:40:21.892
STEP: updating a scale subresource 10/03/22 19:40:21.905
STEP: verifying the deployment Spec.Replicas was modified 10/03/22 19:40:21.923
STEP: Patch a scale subresource 10/03/22 19:40:21.936
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct  3 19:40:22.013: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-8647  dfe3e3a5-7482-4763-ba15-94bff5e6c69a 22620 3 2022-10-03 19:40:17 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-10-03 19:40:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:40:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002427168 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-10-03 19:40:19 +0000 UTC,LastTransitionTime:2022-10-03 19:40:17 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-10-03 19:40:21 +0000 UTC,LastTransitionTime:2022-10-03 19:40:21 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct  3 19:40:22.026: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-8647  fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f 22621 3 2022-10-03 19:40:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment dfe3e3a5-7482-4763-ba15-94bff5e6c69a 0xc0024275d7 0xc0024275d8}] [] [{kube-controller-manager Update apps/v1 2022-10-03 19:40:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dfe3e3a5-7482-4763-ba15-94bff5e6c69a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:40:22 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002427668 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct  3 19:40:22.043: INFO: Pod "test-new-deployment-845c8977d9-4qh9s" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-4qh9s test-new-deployment-845c8977d9- deployment-8647  3732dc0f-8e6e-4bcb-acce-2c1951d88ed2 22625 0 2022-10-03 19:40:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f 0xc002427ea7 0xc002427ea8}] [] [{kube-controller-manager Update v1 2022-10-03 19:40:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2nwd9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2nwd9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:40:22.044: INFO: Pod "test-new-deployment-845c8977d9-4xbtl" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-4xbtl test-new-deployment-845c8977d9- deployment-8647  a730da96-a310-40cd-b5e6-05ea73ec9854 22602 0 2022-10-03 19:40:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:9f77aff58c4a46ba3893be95344268cebbc5926538e26ec027232abb61562f62 cni.projectcalico.org/podIP:172.30.49.39/32 cni.projectcalico.org/podIPs:172.30.49.39/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f 0xc000b04017 0xc000b04018}] [] [{kube-controller-manager Update v1 2022-10-03 19:40:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:40:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:40:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.39\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hp98f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hp98f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.39,StartTime:2022-10-03 19:40:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:40:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://9bdefcb4c96333912fece73f63362a09c14983562eb67b3f834989c86e20d2e5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.39,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:40:22.045: INFO: Pod "test-new-deployment-845c8977d9-8phl6" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-8phl6 test-new-deployment-845c8977d9- deployment-8647  a77dba24-cc64-4d86-8c36-26d9da8724d9 22622 0 2022-10-03 19:40:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f 0xc000b04267 0xc000b04268}] [] [{kube-controller-manager Update v1 2022-10-03 19:40:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-03 19:40:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hqdns,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hqdns,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:,StartTime:2022-10-03 19:40:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:40:22.045: INFO: Pod "test-new-deployment-845c8977d9-t8dc7" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-t8dc7 test-new-deployment-845c8977d9- deployment-8647  749ad083-3930-4618-830e-163a33a2684f 22627 0 2022-10-03 19:40:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f 0xc000b044b7 0xc000b044b8}] [] [{kube-controller-manager Update v1 2022-10-03 19:40:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hr4c9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hr4c9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.51,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Oct  3 19:40:22.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8647" for this suite. 10/03/22 19:40:22.067
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":91,"skipped":1952,"failed":0}
------------------------------
• [4.397 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:40:17.703
    Oct  3 19:40:17.703: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename deployment 10/03/22 19:40:17.705
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:17.751
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:17.762
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Oct  3 19:40:17.774: INFO: Creating simple deployment test-new-deployment
    Oct  3 19:40:17.817: INFO: deployment "test-new-deployment" doesn't have the required revision set
    Oct  3 19:40:19.858: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 40, 17, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 40, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 40, 17, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 40, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: getting scale subresource 10/03/22 19:40:21.892
    STEP: updating a scale subresource 10/03/22 19:40:21.905
    STEP: verifying the deployment Spec.Replicas was modified 10/03/22 19:40:21.923
    STEP: Patch a scale subresource 10/03/22 19:40:21.936
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct  3 19:40:22.013: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-8647  dfe3e3a5-7482-4763-ba15-94bff5e6c69a 22620 3 2022-10-03 19:40:17 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-10-03 19:40:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:40:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002427168 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-10-03 19:40:19 +0000 UTC,LastTransitionTime:2022-10-03 19:40:17 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-10-03 19:40:21 +0000 UTC,LastTransitionTime:2022-10-03 19:40:21 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Oct  3 19:40:22.026: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-8647  fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f 22621 3 2022-10-03 19:40:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment dfe3e3a5-7482-4763-ba15-94bff5e6c69a 0xc0024275d7 0xc0024275d8}] [] [{kube-controller-manager Update apps/v1 2022-10-03 19:40:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dfe3e3a5-7482-4763-ba15-94bff5e6c69a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:40:22 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002427668 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Oct  3 19:40:22.043: INFO: Pod "test-new-deployment-845c8977d9-4qh9s" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-4qh9s test-new-deployment-845c8977d9- deployment-8647  3732dc0f-8e6e-4bcb-acce-2c1951d88ed2 22625 0 2022-10-03 19:40:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f 0xc002427ea7 0xc002427ea8}] [] [{kube-controller-manager Update v1 2022-10-03 19:40:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2nwd9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2nwd9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:40:22.044: INFO: Pod "test-new-deployment-845c8977d9-4xbtl" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-4xbtl test-new-deployment-845c8977d9- deployment-8647  a730da96-a310-40cd-b5e6-05ea73ec9854 22602 0 2022-10-03 19:40:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:9f77aff58c4a46ba3893be95344268cebbc5926538e26ec027232abb61562f62 cni.projectcalico.org/podIP:172.30.49.39/32 cni.projectcalico.org/podIPs:172.30.49.39/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f 0xc000b04017 0xc000b04018}] [] [{kube-controller-manager Update v1 2022-10-03 19:40:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:40:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:40:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.39\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hp98f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hp98f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.39,StartTime:2022-10-03 19:40:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:40:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://9bdefcb4c96333912fece73f63362a09c14983562eb67b3f834989c86e20d2e5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.39,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:40:22.045: INFO: Pod "test-new-deployment-845c8977d9-8phl6" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-8phl6 test-new-deployment-845c8977d9- deployment-8647  a77dba24-cc64-4d86-8c36-26d9da8724d9 22622 0 2022-10-03 19:40:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f 0xc000b04267 0xc000b04268}] [] [{kube-controller-manager Update v1 2022-10-03 19:40:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-03 19:40:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hqdns,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hqdns,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:,StartTime:2022-10-03 19:40:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:40:22.045: INFO: Pod "test-new-deployment-845c8977d9-t8dc7" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-t8dc7 test-new-deployment-845c8977d9- deployment-8647  749ad083-3930-4618-830e-163a33a2684f 22627 0 2022-10-03 19:40:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f 0xc000b044b7 0xc000b044b8}] [] [{kube-controller-manager Update v1 2022-10-03 19:40:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fa95e3ef-6d64-4baa-b0b7-8a1b676efc6f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hr4c9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hr4c9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.51,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:40:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Oct  3 19:40:22.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8647" for this suite. 10/03/22 19:40:22.067
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:40:22.102
Oct  3 19:40:22.102: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 19:40:22.104
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:22.146
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:22.155
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 19:40:22.225
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 19:40:23.003
STEP: Deploying the webhook pod 10/03/22 19:40:23.031
STEP: Wait for the deployment to be ready 10/03/22 19:40:23.069
Oct  3 19:40:23.102: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/03/22 19:40:25.143
STEP: Verifying the service has paired with the endpoint 10/03/22 19:40:25.176
Oct  3 19:40:26.176: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 10/03/22 19:40:26.188
STEP: create a configmap that should be updated by the webhook 10/03/22 19:40:26.262
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 19:40:26.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9484" for this suite. 10/03/22 19:40:26.445
STEP: Destroying namespace "webhook-9484-markers" for this suite. 10/03/22 19:40:26.469
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":92,"skipped":1952,"failed":0}
------------------------------
• [4.506 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:40:22.102
    Oct  3 19:40:22.102: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 19:40:22.104
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:22.146
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:22.155
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 19:40:22.225
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 19:40:23.003
    STEP: Deploying the webhook pod 10/03/22 19:40:23.031
    STEP: Wait for the deployment to be ready 10/03/22 19:40:23.069
    Oct  3 19:40:23.102: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/03/22 19:40:25.143
    STEP: Verifying the service has paired with the endpoint 10/03/22 19:40:25.176
    Oct  3 19:40:26.176: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 10/03/22 19:40:26.188
    STEP: create a configmap that should be updated by the webhook 10/03/22 19:40:26.262
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 19:40:26.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9484" for this suite. 10/03/22 19:40:26.445
    STEP: Destroying namespace "webhook-9484-markers" for this suite. 10/03/22 19:40:26.469
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:40:26.609
Oct  3 19:40:26.609: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename secrets 10/03/22 19:40:26.611
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:26.656
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:26.668
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-bc6e9cb8-eef4-4417-8098-bb34c325a65e 10/03/22 19:40:26.679
STEP: Creating a pod to test consume secrets 10/03/22 19:40:26.695
Oct  3 19:40:26.724: INFO: Waiting up to 5m0s for pod "pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55" in namespace "secrets-8798" to be "Succeeded or Failed"
Oct  3 19:40:26.738: INFO: Pod "pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55": Phase="Pending", Reason="", readiness=false. Elapsed: 14.623151ms
Oct  3 19:40:28.758: INFO: Pod "pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033886065s
Oct  3 19:40:30.753: INFO: Pod "pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029769487s
Oct  3 19:40:32.753: INFO: Pod "pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029248444s
STEP: Saw pod success 10/03/22 19:40:32.753
Oct  3 19:40:32.753: INFO: Pod "pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55" satisfied condition "Succeeded or Failed"
Oct  3 19:40:32.768: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55 container secret-volume-test: <nil>
STEP: delete the pod 10/03/22 19:40:32.798
Oct  3 19:40:32.833: INFO: Waiting for pod pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55 to disappear
Oct  3 19:40:32.846: INFO: Pod pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Oct  3 19:40:32.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8798" for this suite. 10/03/22 19:40:32.864
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":93,"skipped":1961,"failed":0}
------------------------------
• [SLOW TEST] [6.280 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:40:26.609
    Oct  3 19:40:26.609: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename secrets 10/03/22 19:40:26.611
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:26.656
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:26.668
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-bc6e9cb8-eef4-4417-8098-bb34c325a65e 10/03/22 19:40:26.679
    STEP: Creating a pod to test consume secrets 10/03/22 19:40:26.695
    Oct  3 19:40:26.724: INFO: Waiting up to 5m0s for pod "pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55" in namespace "secrets-8798" to be "Succeeded or Failed"
    Oct  3 19:40:26.738: INFO: Pod "pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55": Phase="Pending", Reason="", readiness=false. Elapsed: 14.623151ms
    Oct  3 19:40:28.758: INFO: Pod "pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033886065s
    Oct  3 19:40:30.753: INFO: Pod "pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029769487s
    Oct  3 19:40:32.753: INFO: Pod "pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029248444s
    STEP: Saw pod success 10/03/22 19:40:32.753
    Oct  3 19:40:32.753: INFO: Pod "pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55" satisfied condition "Succeeded or Failed"
    Oct  3 19:40:32.768: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55 container secret-volume-test: <nil>
    STEP: delete the pod 10/03/22 19:40:32.798
    Oct  3 19:40:32.833: INFO: Waiting for pod pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55 to disappear
    Oct  3 19:40:32.846: INFO: Pod pod-secrets-7b44c68b-5499-4b05-a5f7-a58870c00f55 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Oct  3 19:40:32.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8798" for this suite. 10/03/22 19:40:32.864
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:40:32.89
Oct  3 19:40:32.891: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename replicaset 10/03/22 19:40:32.892
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:32.963
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:32.976
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Oct  3 19:40:32.987: INFO: Creating ReplicaSet my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4
Oct  3 19:40:33.020: INFO: Pod name my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4: Found 0 pods out of 1
Oct  3 19:40:38.038: INFO: Pod name my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4: Found 1 pods out of 1
Oct  3 19:40:38.038: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4" is running
Oct  3 19:40:38.038: INFO: Waiting up to 5m0s for pod "my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4-gglgt" in namespace "replicaset-2447" to be "running"
Oct  3 19:40:38.050: INFO: Pod "my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4-gglgt": Phase="Running", Reason="", readiness=true. Elapsed: 11.956656ms
Oct  3 19:40:38.050: INFO: Pod "my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4-gglgt" satisfied condition "running"
Oct  3 19:40:38.050: INFO: Pod "my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4-gglgt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 19:40:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 19:40:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 19:40:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 19:40:33 +0000 UTC Reason: Message:}])
Oct  3 19:40:38.050: INFO: Trying to dial the pod
Oct  3 19:40:43.130: INFO: Controller my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4: Got expected result from replica 1 [my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4-gglgt]: "my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4-gglgt", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Oct  3 19:40:43.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2447" for this suite. 10/03/22 19:40:43.15
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":94,"skipped":1971,"failed":0}
------------------------------
• [SLOW TEST] [10.282 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:40:32.89
    Oct  3 19:40:32.891: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename replicaset 10/03/22 19:40:32.892
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:32.963
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:32.976
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Oct  3 19:40:32.987: INFO: Creating ReplicaSet my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4
    Oct  3 19:40:33.020: INFO: Pod name my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4: Found 0 pods out of 1
    Oct  3 19:40:38.038: INFO: Pod name my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4: Found 1 pods out of 1
    Oct  3 19:40:38.038: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4" is running
    Oct  3 19:40:38.038: INFO: Waiting up to 5m0s for pod "my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4-gglgt" in namespace "replicaset-2447" to be "running"
    Oct  3 19:40:38.050: INFO: Pod "my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4-gglgt": Phase="Running", Reason="", readiness=true. Elapsed: 11.956656ms
    Oct  3 19:40:38.050: INFO: Pod "my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4-gglgt" satisfied condition "running"
    Oct  3 19:40:38.050: INFO: Pod "my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4-gglgt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 19:40:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 19:40:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 19:40:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 19:40:33 +0000 UTC Reason: Message:}])
    Oct  3 19:40:38.050: INFO: Trying to dial the pod
    Oct  3 19:40:43.130: INFO: Controller my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4: Got expected result from replica 1 [my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4-gglgt]: "my-hostname-basic-38d41588-4ffa-4975-8c18-b577c58e00d4-gglgt", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Oct  3 19:40:43.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-2447" for this suite. 10/03/22 19:40:43.15
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:40:43.173
Oct  3 19:40:43.174: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename disruption 10/03/22 19:40:43.175
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:43.218
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:43.228
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 10/03/22 19:40:43.253
STEP: Waiting for all pods to be running 10/03/22 19:40:45.341
Oct  3 19:40:45.354: INFO: running pods: 0 < 3
Oct  3 19:40:47.371: INFO: running pods: 1 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Oct  3 19:40:49.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2282" for this suite. 10/03/22 19:40:49.396
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":95,"skipped":1972,"failed":0}
------------------------------
• [SLOW TEST] [6.245 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:40:43.173
    Oct  3 19:40:43.174: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename disruption 10/03/22 19:40:43.175
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:43.218
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:43.228
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 10/03/22 19:40:43.253
    STEP: Waiting for all pods to be running 10/03/22 19:40:45.341
    Oct  3 19:40:45.354: INFO: running pods: 0 < 3
    Oct  3 19:40:47.371: INFO: running pods: 1 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Oct  3 19:40:49.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2282" for this suite. 10/03/22 19:40:49.396
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:40:49.425
Oct  3 19:40:49.426: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename gc 10/03/22 19:40:49.427
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:49.47
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:49.482
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 10/03/22 19:40:49.493
STEP: Wait for the Deployment to create new ReplicaSet 10/03/22 19:40:49.51
STEP: delete the deployment 10/03/22 19:40:49.522
STEP: wait for all rs to be garbage collected 10/03/22 19:40:49.576
STEP: expected 0 pods, got 2 pods 10/03/22 19:40:49.618
STEP: Gathering metrics 10/03/22 19:40:50.162
W1003 19:40:50.214408      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Oct  3 19:40:50.214: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Oct  3 19:40:50.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1033" for this suite. 10/03/22 19:40:50.232
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":96,"skipped":1998,"failed":0}
------------------------------
• [0.830 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:40:49.425
    Oct  3 19:40:49.426: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename gc 10/03/22 19:40:49.427
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:49.47
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:49.482
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 10/03/22 19:40:49.493
    STEP: Wait for the Deployment to create new ReplicaSet 10/03/22 19:40:49.51
    STEP: delete the deployment 10/03/22 19:40:49.522
    STEP: wait for all rs to be garbage collected 10/03/22 19:40:49.576
    STEP: expected 0 pods, got 2 pods 10/03/22 19:40:49.618
    STEP: Gathering metrics 10/03/22 19:40:50.162
    W1003 19:40:50.214408      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Oct  3 19:40:50.214: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Oct  3 19:40:50.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1033" for this suite. 10/03/22 19:40:50.232
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:40:50.256
Oct  3 19:40:50.256: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename cronjob 10/03/22 19:40:50.257
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:50.317
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:50.327
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 10/03/22 19:40:50.338
STEP: Ensuring no jobs are scheduled 10/03/22 19:40:50.356
STEP: Ensuring no job exists by listing jobs explicitly 10/03/22 19:45:50.382
STEP: Removing cronjob 10/03/22 19:45:50.393
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Oct  3 19:45:50.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2587" for this suite. 10/03/22 19:45:50.433
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":97,"skipped":1999,"failed":0}
------------------------------
• [SLOW TEST] [300.200 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:40:50.256
    Oct  3 19:40:50.256: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename cronjob 10/03/22 19:40:50.257
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:40:50.317
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:40:50.327
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 10/03/22 19:40:50.338
    STEP: Ensuring no jobs are scheduled 10/03/22 19:40:50.356
    STEP: Ensuring no job exists by listing jobs explicitly 10/03/22 19:45:50.382
    STEP: Removing cronjob 10/03/22 19:45:50.393
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Oct  3 19:45:50.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2587" for this suite. 10/03/22 19:45:50.433
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:45:50.463
Oct  3 19:45:50.463: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename resourcequota 10/03/22 19:45:50.464
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:45:50.529
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:45:50.54
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 10/03/22 19:46:07.564
STEP: Creating a ResourceQuota 10/03/22 19:46:12.578
STEP: Ensuring resource quota status is calculated 10/03/22 19:46:12.593
STEP: Creating a ConfigMap 10/03/22 19:46:14.61
STEP: Ensuring resource quota status captures configMap creation 10/03/22 19:46:14.641
STEP: Deleting a ConfigMap 10/03/22 19:46:16.655
STEP: Ensuring resource quota status released usage 10/03/22 19:46:16.671
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Oct  3 19:46:18.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2565" for this suite. 10/03/22 19:46:18.703
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":98,"skipped":2052,"failed":0}
------------------------------
• [SLOW TEST] [28.261 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:45:50.463
    Oct  3 19:45:50.463: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename resourcequota 10/03/22 19:45:50.464
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:45:50.529
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:45:50.54
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 10/03/22 19:46:07.564
    STEP: Creating a ResourceQuota 10/03/22 19:46:12.578
    STEP: Ensuring resource quota status is calculated 10/03/22 19:46:12.593
    STEP: Creating a ConfigMap 10/03/22 19:46:14.61
    STEP: Ensuring resource quota status captures configMap creation 10/03/22 19:46:14.641
    STEP: Deleting a ConfigMap 10/03/22 19:46:16.655
    STEP: Ensuring resource quota status released usage 10/03/22 19:46:16.671
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Oct  3 19:46:18.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2565" for this suite. 10/03/22 19:46:18.703
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:46:18.728
Oct  3 19:46:18.728: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename daemonsets 10/03/22 19:46:18.729
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:46:18.775
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:46:18.787
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 10/03/22 19:46:18.878
STEP: Check that daemon pods launch on every node of the cluster. 10/03/22 19:46:18.895
Oct  3 19:46:18.928: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:46:18.928: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:46:19.963: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:46:19.963: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:46:20.962: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct  3 19:46:20.962: INFO: Node 10.63.128.51 is running 0 daemon pod, expected 1
Oct  3 19:46:21.963: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct  3 19:46:21.963: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 10/03/22 19:46:21.976
Oct  3 19:46:22.049: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct  3 19:46:22.049: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:46:23.078: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct  3 19:46:23.078: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:46:24.082: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct  3 19:46:24.083: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:46:25.080: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct  3 19:46:25.080: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:46:26.082: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct  3 19:46:26.082: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 10/03/22 19:46:26.095
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1740, will wait for the garbage collector to delete the pods 10/03/22 19:46:26.096
Oct  3 19:46:26.179: INFO: Deleting DaemonSet.extensions daemon-set took: 20.179319ms
Oct  3 19:46:26.380: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.858054ms
Oct  3 19:46:28.793: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:46:28.793: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct  3 19:46:28.804: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23438"},"items":null}

Oct  3 19:46:28.817: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23438"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Oct  3 19:46:28.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1740" for this suite. 10/03/22 19:46:28.896
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":99,"skipped":2076,"failed":0}
------------------------------
• [SLOW TEST] [10.197 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:46:18.728
    Oct  3 19:46:18.728: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename daemonsets 10/03/22 19:46:18.729
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:46:18.775
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:46:18.787
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 10/03/22 19:46:18.878
    STEP: Check that daemon pods launch on every node of the cluster. 10/03/22 19:46:18.895
    Oct  3 19:46:18.928: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:46:18.928: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:46:19.963: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:46:19.963: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:46:20.962: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct  3 19:46:20.962: INFO: Node 10.63.128.51 is running 0 daemon pod, expected 1
    Oct  3 19:46:21.963: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct  3 19:46:21.963: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 10/03/22 19:46:21.976
    Oct  3 19:46:22.049: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct  3 19:46:22.049: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:46:23.078: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct  3 19:46:23.078: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:46:24.082: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct  3 19:46:24.083: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:46:25.080: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct  3 19:46:25.080: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:46:26.082: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct  3 19:46:26.082: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 10/03/22 19:46:26.095
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1740, will wait for the garbage collector to delete the pods 10/03/22 19:46:26.096
    Oct  3 19:46:26.179: INFO: Deleting DaemonSet.extensions daemon-set took: 20.179319ms
    Oct  3 19:46:26.380: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.858054ms
    Oct  3 19:46:28.793: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:46:28.793: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Oct  3 19:46:28.804: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23438"},"items":null}

    Oct  3 19:46:28.817: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23438"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 19:46:28.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-1740" for this suite. 10/03/22 19:46:28.896
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:46:28.928
Oct  3 19:46:28.928: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename ephemeral-containers-test 10/03/22 19:46:28.929
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:46:28.983
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:46:28.999
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 10/03/22 19:46:29.016
Oct  3 19:46:29.040: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-663" to be "running and ready"
Oct  3 19:46:29.056: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 15.124349ms
Oct  3 19:46:29.056: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:46:31.071: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031045491s
Oct  3 19:46:31.072: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:46:33.071: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.031033594s
Oct  3 19:46:33.071: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Oct  3 19:46:33.071: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 10/03/22 19:46:33.085
Oct  3 19:46:33.118: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-663" to be "container debugger running"
Oct  3 19:46:33.132: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 14.024236ms
Oct  3 19:46:35.148: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.0302265s
Oct  3 19:46:35.148: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 10/03/22 19:46:35.148
Oct  3 19:46:35.148: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-663 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 19:46:35.149: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 19:46:35.150: INFO: ExecWithOptions: Clientset creation
Oct  3 19:46:35.150: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/ephemeral-containers-test-663/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Oct  3 19:46:35.343: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Oct  3 19:46:35.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-663" for this suite. 10/03/22 19:46:35.451
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":100,"skipped":2103,"failed":0}
------------------------------
• [SLOW TEST] [6.547 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:46:28.928
    Oct  3 19:46:28.928: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename ephemeral-containers-test 10/03/22 19:46:28.929
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:46:28.983
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:46:28.999
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 10/03/22 19:46:29.016
    Oct  3 19:46:29.040: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-663" to be "running and ready"
    Oct  3 19:46:29.056: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 15.124349ms
    Oct  3 19:46:29.056: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:46:31.071: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031045491s
    Oct  3 19:46:31.072: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:46:33.071: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.031033594s
    Oct  3 19:46:33.071: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Oct  3 19:46:33.071: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 10/03/22 19:46:33.085
    Oct  3 19:46:33.118: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-663" to be "container debugger running"
    Oct  3 19:46:33.132: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 14.024236ms
    Oct  3 19:46:35.148: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.0302265s
    Oct  3 19:46:35.148: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 10/03/22 19:46:35.148
    Oct  3 19:46:35.148: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-663 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 19:46:35.149: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 19:46:35.150: INFO: ExecWithOptions: Clientset creation
    Oct  3 19:46:35.150: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/ephemeral-containers-test-663/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Oct  3 19:46:35.343: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Oct  3 19:46:35.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-663" for this suite. 10/03/22 19:46:35.451
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:46:35.476
Oct  3 19:46:35.477: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename namespaces 10/03/22 19:46:35.478
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:46:35.524
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:46:35.536
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 10/03/22 19:46:35.547
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:46:35.592
STEP: Creating a service in the namespace 10/03/22 19:46:35.603
STEP: Deleting the namespace 10/03/22 19:46:35.649
STEP: Waiting for the namespace to be removed. 10/03/22 19:46:35.677
STEP: Recreating the namespace 10/03/22 19:46:41.692
STEP: Verifying there is no service in the namespace 10/03/22 19:46:41.736
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Oct  3 19:46:41.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8679" for this suite. 10/03/22 19:46:41.763
STEP: Destroying namespace "nsdeletetest-3714" for this suite. 10/03/22 19:46:41.786
Oct  3 19:46:41.801: INFO: Namespace nsdeletetest-3714 was already deleted
STEP: Destroying namespace "nsdeletetest-1441" for this suite. 10/03/22 19:46:41.801
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":101,"skipped":2105,"failed":0}
------------------------------
• [SLOW TEST] [6.349 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:46:35.476
    Oct  3 19:46:35.477: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename namespaces 10/03/22 19:46:35.478
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:46:35.524
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:46:35.536
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 10/03/22 19:46:35.547
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:46:35.592
    STEP: Creating a service in the namespace 10/03/22 19:46:35.603
    STEP: Deleting the namespace 10/03/22 19:46:35.649
    STEP: Waiting for the namespace to be removed. 10/03/22 19:46:35.677
    STEP: Recreating the namespace 10/03/22 19:46:41.692
    STEP: Verifying there is no service in the namespace 10/03/22 19:46:41.736
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 19:46:41.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-8679" for this suite. 10/03/22 19:46:41.763
    STEP: Destroying namespace "nsdeletetest-3714" for this suite. 10/03/22 19:46:41.786
    Oct  3 19:46:41.801: INFO: Namespace nsdeletetest-3714 was already deleted
    STEP: Destroying namespace "nsdeletetest-1441" for this suite. 10/03/22 19:46:41.801
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:46:41.829
Oct  3 19:46:41.829: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename runtimeclass 10/03/22 19:46:41.83
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:46:41.874
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:46:41.885
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Oct  3 19:46:41.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-3018" for this suite. 10/03/22 19:46:41.963
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":102,"skipped":2126,"failed":0}
------------------------------
• [0.158 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:46:41.829
    Oct  3 19:46:41.829: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename runtimeclass 10/03/22 19:46:41.83
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:46:41.874
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:46:41.885
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Oct  3 19:46:41.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-3018" for this suite. 10/03/22 19:46:41.963
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:46:41.988
Oct  3 19:46:41.988: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-runtime 10/03/22 19:46:41.99
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:46:42.033
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:46:42.045
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 10/03/22 19:46:42.084
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 10/03/22 19:46:59.357
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 10/03/22 19:46:59.37
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 10/03/22 19:46:59.402
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 10/03/22 19:46:59.402
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 10/03/22 19:46:59.466
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 10/03/22 19:47:03.543
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 10/03/22 19:47:05.585
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 10/03/22 19:47:05.613
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 10/03/22 19:47:05.613
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 10/03/22 19:47:05.692
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 10/03/22 19:47:06.733
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 10/03/22 19:47:10.809
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 10/03/22 19:47:10.838
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 10/03/22 19:47:10.839
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Oct  3 19:47:10.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1968" for this suite. 10/03/22 19:47:10.954
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":103,"skipped":2128,"failed":0}
------------------------------
• [SLOW TEST] [28.989 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:46:41.988
    Oct  3 19:46:41.988: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-runtime 10/03/22 19:46:41.99
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:46:42.033
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:46:42.045
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 10/03/22 19:46:42.084
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 10/03/22 19:46:59.357
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 10/03/22 19:46:59.37
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 10/03/22 19:46:59.402
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 10/03/22 19:46:59.402
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 10/03/22 19:46:59.466
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 10/03/22 19:47:03.543
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 10/03/22 19:47:05.585
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 10/03/22 19:47:05.613
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 10/03/22 19:47:05.613
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 10/03/22 19:47:05.692
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 10/03/22 19:47:06.733
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 10/03/22 19:47:10.809
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 10/03/22 19:47:10.838
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 10/03/22 19:47:10.839
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Oct  3 19:47:10.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-1968" for this suite. 10/03/22 19:47:10.954
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:47:10.98
Oct  3 19:47:10.980: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename dns 10/03/22 19:47:10.982
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:47:11.037
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:47:11.048
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 10/03/22 19:47:11.061
Oct  3 19:47:11.089: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-8885  57328ded-43aa-4823-8d11-01ec1203e820 23654 0 2022-10-03 19:47:11 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-10-03 19:47:11 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r8xs7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r8xs7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:47:11.089: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-8885" to be "running and ready"
Oct  3 19:47:11.102: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 12.608939ms
Oct  3 19:47:11.102: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:47:13.117: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027482233s
Oct  3 19:47:13.117: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:47:15.118: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 4.028950917s
Oct  3 19:47:15.118: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Oct  3 19:47:15.118: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 10/03/22 19:47:15.118
Oct  3 19:47:15.119: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8885 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 19:47:15.119: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 19:47:15.120: INFO: ExecWithOptions: Clientset creation
Oct  3 19:47:15.120: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-8885/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 10/03/22 19:47:15.374
Oct  3 19:47:15.374: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8885 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 19:47:15.374: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 19:47:15.375: INFO: ExecWithOptions: Clientset creation
Oct  3 19:47:15.375: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-8885/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct  3 19:47:15.588: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Oct  3 19:47:15.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8885" for this suite. 10/03/22 19:47:15.649
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":104,"skipped":2132,"failed":0}
------------------------------
• [4.694 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:47:10.98
    Oct  3 19:47:10.980: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename dns 10/03/22 19:47:10.982
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:47:11.037
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:47:11.048
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 10/03/22 19:47:11.061
    Oct  3 19:47:11.089: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-8885  57328ded-43aa-4823-8d11-01ec1203e820 23654 0 2022-10-03 19:47:11 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-10-03 19:47:11 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r8xs7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r8xs7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:47:11.089: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-8885" to be "running and ready"
    Oct  3 19:47:11.102: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 12.608939ms
    Oct  3 19:47:11.102: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:47:13.117: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027482233s
    Oct  3 19:47:13.117: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:47:15.118: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 4.028950917s
    Oct  3 19:47:15.118: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Oct  3 19:47:15.118: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 10/03/22 19:47:15.118
    Oct  3 19:47:15.119: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8885 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 19:47:15.119: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 19:47:15.120: INFO: ExecWithOptions: Clientset creation
    Oct  3 19:47:15.120: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-8885/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 10/03/22 19:47:15.374
    Oct  3 19:47:15.374: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8885 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 19:47:15.374: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 19:47:15.375: INFO: ExecWithOptions: Clientset creation
    Oct  3 19:47:15.375: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-8885/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Oct  3 19:47:15.588: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Oct  3 19:47:15.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-8885" for this suite. 10/03/22 19:47:15.649
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:47:15.679
Oct  3 19:47:15.679: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 19:47:15.68
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:47:15.724
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:47:15.735
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 10/03/22 19:47:15.746
Oct  3 19:47:15.747: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 19:47:18.862: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 19:47:35.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8878" for this suite. 10/03/22 19:47:35.278
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":105,"skipped":2166,"failed":0}
------------------------------
• [SLOW TEST] [19.619 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:47:15.679
    Oct  3 19:47:15.679: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 19:47:15.68
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:47:15.724
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:47:15.735
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 10/03/22 19:47:15.746
    Oct  3 19:47:15.747: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 19:47:18.862: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 19:47:35.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8878" for this suite. 10/03/22 19:47:35.278
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:47:35.301
Oct  3 19:47:35.301: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 19:47:35.302
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:47:35.335
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:47:35.346
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 10/03/22 19:47:35.357
Oct  3 19:47:35.379: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07" in namespace "downward-api-3361" to be "Succeeded or Failed"
Oct  3 19:47:35.391: INFO: Pod "downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07": Phase="Pending", Reason="", readiness=false. Elapsed: 11.677594ms
Oct  3 19:47:37.404: INFO: Pod "downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07": Phase="Running", Reason="", readiness=true. Elapsed: 2.025250029s
Oct  3 19:47:39.404: INFO: Pod "downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07": Phase="Running", Reason="", readiness=false. Elapsed: 4.025241833s
Oct  3 19:47:41.404: INFO: Pod "downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024609742s
STEP: Saw pod success 10/03/22 19:47:41.404
Oct  3 19:47:41.404: INFO: Pod "downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07" satisfied condition "Succeeded or Failed"
Oct  3 19:47:41.415: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07 container client-container: <nil>
STEP: delete the pod 10/03/22 19:47:41.473
Oct  3 19:47:41.501: INFO: Waiting for pod downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07 to disappear
Oct  3 19:47:41.513: INFO: Pod downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Oct  3 19:47:41.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3361" for this suite. 10/03/22 19:47:41.529
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":106,"skipped":2208,"failed":0}
------------------------------
• [SLOW TEST] [6.249 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:47:35.301
    Oct  3 19:47:35.301: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 19:47:35.302
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:47:35.335
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:47:35.346
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 10/03/22 19:47:35.357
    Oct  3 19:47:35.379: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07" in namespace "downward-api-3361" to be "Succeeded or Failed"
    Oct  3 19:47:35.391: INFO: Pod "downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07": Phase="Pending", Reason="", readiness=false. Elapsed: 11.677594ms
    Oct  3 19:47:37.404: INFO: Pod "downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07": Phase="Running", Reason="", readiness=true. Elapsed: 2.025250029s
    Oct  3 19:47:39.404: INFO: Pod "downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07": Phase="Running", Reason="", readiness=false. Elapsed: 4.025241833s
    Oct  3 19:47:41.404: INFO: Pod "downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024609742s
    STEP: Saw pod success 10/03/22 19:47:41.404
    Oct  3 19:47:41.404: INFO: Pod "downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07" satisfied condition "Succeeded or Failed"
    Oct  3 19:47:41.415: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07 container client-container: <nil>
    STEP: delete the pod 10/03/22 19:47:41.473
    Oct  3 19:47:41.501: INFO: Waiting for pod downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07 to disappear
    Oct  3 19:47:41.513: INFO: Pod downwardapi-volume-1fc3b70f-9863-41a9-afdb-6198ed824d07 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Oct  3 19:47:41.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3361" for this suite. 10/03/22 19:47:41.529
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:47:41.552
Oct  3 19:47:41.552: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename secrets 10/03/22 19:47:41.553
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:47:41.61
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:47:41.647
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-63c09f33-258f-4929-8a41-bbf314f2543e 10/03/22 19:47:41.658
STEP: Creating a pod to test consume secrets 10/03/22 19:47:41.672
Oct  3 19:47:41.695: INFO: Waiting up to 5m0s for pod "pod-secrets-2880b959-4831-4843-bd9c-626bd7775697" in namespace "secrets-397" to be "Succeeded or Failed"
Oct  3 19:47:41.707: INFO: Pod "pod-secrets-2880b959-4831-4843-bd9c-626bd7775697": Phase="Pending", Reason="", readiness=false. Elapsed: 12.266516ms
Oct  3 19:47:43.719: INFO: Pod "pod-secrets-2880b959-4831-4843-bd9c-626bd7775697": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024462825s
Oct  3 19:47:45.719: INFO: Pod "pod-secrets-2880b959-4831-4843-bd9c-626bd7775697": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02374407s
Oct  3 19:47:47.721: INFO: Pod "pod-secrets-2880b959-4831-4843-bd9c-626bd7775697": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025788679s
STEP: Saw pod success 10/03/22 19:47:47.721
Oct  3 19:47:47.721: INFO: Pod "pod-secrets-2880b959-4831-4843-bd9c-626bd7775697" satisfied condition "Succeeded or Failed"
Oct  3 19:47:47.733: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-2880b959-4831-4843-bd9c-626bd7775697 container secret-volume-test: <nil>
STEP: delete the pod 10/03/22 19:47:47.76
Oct  3 19:47:47.785: INFO: Waiting for pod pod-secrets-2880b959-4831-4843-bd9c-626bd7775697 to disappear
Oct  3 19:47:47.796: INFO: Pod pod-secrets-2880b959-4831-4843-bd9c-626bd7775697 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Oct  3 19:47:47.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-397" for this suite. 10/03/22 19:47:47.811
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":107,"skipped":2222,"failed":0}
------------------------------
• [SLOW TEST] [6.279 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:47:41.552
    Oct  3 19:47:41.552: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename secrets 10/03/22 19:47:41.553
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:47:41.61
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:47:41.647
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-63c09f33-258f-4929-8a41-bbf314f2543e 10/03/22 19:47:41.658
    STEP: Creating a pod to test consume secrets 10/03/22 19:47:41.672
    Oct  3 19:47:41.695: INFO: Waiting up to 5m0s for pod "pod-secrets-2880b959-4831-4843-bd9c-626bd7775697" in namespace "secrets-397" to be "Succeeded or Failed"
    Oct  3 19:47:41.707: INFO: Pod "pod-secrets-2880b959-4831-4843-bd9c-626bd7775697": Phase="Pending", Reason="", readiness=false. Elapsed: 12.266516ms
    Oct  3 19:47:43.719: INFO: Pod "pod-secrets-2880b959-4831-4843-bd9c-626bd7775697": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024462825s
    Oct  3 19:47:45.719: INFO: Pod "pod-secrets-2880b959-4831-4843-bd9c-626bd7775697": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02374407s
    Oct  3 19:47:47.721: INFO: Pod "pod-secrets-2880b959-4831-4843-bd9c-626bd7775697": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025788679s
    STEP: Saw pod success 10/03/22 19:47:47.721
    Oct  3 19:47:47.721: INFO: Pod "pod-secrets-2880b959-4831-4843-bd9c-626bd7775697" satisfied condition "Succeeded or Failed"
    Oct  3 19:47:47.733: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-2880b959-4831-4843-bd9c-626bd7775697 container secret-volume-test: <nil>
    STEP: delete the pod 10/03/22 19:47:47.76
    Oct  3 19:47:47.785: INFO: Waiting for pod pod-secrets-2880b959-4831-4843-bd9c-626bd7775697 to disappear
    Oct  3 19:47:47.796: INFO: Pod pod-secrets-2880b959-4831-4843-bd9c-626bd7775697 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Oct  3 19:47:47.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-397" for this suite. 10/03/22 19:47:47.811
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:47:47.832
Oct  3 19:47:47.832: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 19:47:47.834
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:47:47.866
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:47:47.877
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 10/03/22 19:47:47.887
Oct  3 19:47:47.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2332 create -f -'
Oct  3 19:47:48.694: INFO: stderr: ""
Oct  3 19:47:48.694: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 10/03/22 19:47:48.694
Oct  3 19:47:49.707: INFO: Selector matched 1 pods for map[app:agnhost]
Oct  3 19:47:49.707: INFO: Found 0 / 1
Oct  3 19:47:50.707: INFO: Selector matched 1 pods for map[app:agnhost]
Oct  3 19:47:50.707: INFO: Found 0 / 1
Oct  3 19:47:51.707: INFO: Selector matched 1 pods for map[app:agnhost]
Oct  3 19:47:51.707: INFO: Found 1 / 1
Oct  3 19:47:51.707: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 10/03/22 19:47:51.708
Oct  3 19:47:51.719: INFO: Selector matched 1 pods for map[app:agnhost]
Oct  3 19:47:51.720: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct  3 19:47:51.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2332 patch pod agnhost-primary-pc495 -p {"metadata":{"annotations":{"x":"y"}}}'
Oct  3 19:47:51.834: INFO: stderr: ""
Oct  3 19:47:51.834: INFO: stdout: "pod/agnhost-primary-pc495 patched\n"
STEP: checking annotations 10/03/22 19:47:51.834
Oct  3 19:47:51.866: INFO: Selector matched 1 pods for map[app:agnhost]
Oct  3 19:47:51.866: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 19:47:51.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2332" for this suite. 10/03/22 19:47:51.882
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":108,"skipped":2233,"failed":0}
------------------------------
• [4.070 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:47:47.832
    Oct  3 19:47:47.832: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 19:47:47.834
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:47:47.866
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:47:47.877
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 10/03/22 19:47:47.887
    Oct  3 19:47:47.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2332 create -f -'
    Oct  3 19:47:48.694: INFO: stderr: ""
    Oct  3 19:47:48.694: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 10/03/22 19:47:48.694
    Oct  3 19:47:49.707: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct  3 19:47:49.707: INFO: Found 0 / 1
    Oct  3 19:47:50.707: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct  3 19:47:50.707: INFO: Found 0 / 1
    Oct  3 19:47:51.707: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct  3 19:47:51.707: INFO: Found 1 / 1
    Oct  3 19:47:51.707: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 10/03/22 19:47:51.708
    Oct  3 19:47:51.719: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct  3 19:47:51.720: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Oct  3 19:47:51.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2332 patch pod agnhost-primary-pc495 -p {"metadata":{"annotations":{"x":"y"}}}'
    Oct  3 19:47:51.834: INFO: stderr: ""
    Oct  3 19:47:51.834: INFO: stdout: "pod/agnhost-primary-pc495 patched\n"
    STEP: checking annotations 10/03/22 19:47:51.834
    Oct  3 19:47:51.866: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct  3 19:47:51.866: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 19:47:51.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2332" for this suite. 10/03/22 19:47:51.882
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:47:51.905
Oct  3 19:47:51.905: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 19:47:51.906
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:47:51.94
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:47:51.951
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-e01f431e-988d-4d32-bf22-5ea1cfa0e0fb 10/03/22 19:47:51.985
STEP: Creating the pod 10/03/22 19:47:51.999
Oct  3 19:47:52.020: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c" in namespace "projected-463" to be "running and ready"
Oct  3 19:47:52.032: INFO: Pod "pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.301912ms
Oct  3 19:47:52.032: INFO: The phase of Pod pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:47:54.044: INFO: Pod "pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023580866s
Oct  3 19:47:54.044: INFO: The phase of Pod pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:47:56.044: INFO: Pod "pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c": Phase="Running", Reason="", readiness=true. Elapsed: 4.024039288s
Oct  3 19:47:56.044: INFO: The phase of Pod pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c is Running (Ready = true)
Oct  3 19:47:56.044: INFO: Pod "pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-e01f431e-988d-4d32-bf22-5ea1cfa0e0fb 10/03/22 19:47:56.082
STEP: waiting to observe update in volume 10/03/22 19:47:56.096
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Oct  3 19:49:11.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-463" for this suite. 10/03/22 19:49:11.237
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":109,"skipped":2242,"failed":0}
------------------------------
• [SLOW TEST] [79.353 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:47:51.905
    Oct  3 19:47:51.905: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 19:47:51.906
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:47:51.94
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:47:51.951
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-e01f431e-988d-4d32-bf22-5ea1cfa0e0fb 10/03/22 19:47:51.985
    STEP: Creating the pod 10/03/22 19:47:51.999
    Oct  3 19:47:52.020: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c" in namespace "projected-463" to be "running and ready"
    Oct  3 19:47:52.032: INFO: Pod "pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.301912ms
    Oct  3 19:47:52.032: INFO: The phase of Pod pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:47:54.044: INFO: Pod "pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023580866s
    Oct  3 19:47:54.044: INFO: The phase of Pod pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:47:56.044: INFO: Pod "pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c": Phase="Running", Reason="", readiness=true. Elapsed: 4.024039288s
    Oct  3 19:47:56.044: INFO: The phase of Pod pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c is Running (Ready = true)
    Oct  3 19:47:56.044: INFO: Pod "pod-projected-configmaps-c3f95bf2-27e6-4fa9-8cc2-6e9f229aeb0c" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-e01f431e-988d-4d32-bf22-5ea1cfa0e0fb 10/03/22 19:47:56.082
    STEP: waiting to observe update in volume 10/03/22 19:47:56.096
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Oct  3 19:49:11.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-463" for this suite. 10/03/22 19:49:11.237
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:49:11.26
Oct  3 19:49:11.261: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename disruption 10/03/22 19:49:11.262
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:49:11.296
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:49:11.307
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 10/03/22 19:49:11.318
STEP: Waiting for the pdb to be processed 10/03/22 19:49:11.332
STEP: updating the pdb 10/03/22 19:49:11.345
STEP: Waiting for the pdb to be processed 10/03/22 19:49:11.371
STEP: patching the pdb 10/03/22 19:49:11.383
STEP: Waiting for the pdb to be processed 10/03/22 19:49:11.409
STEP: Waiting for the pdb to be deleted 10/03/22 19:49:11.439
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Oct  3 19:49:11.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4430" for this suite. 10/03/22 19:49:11.466
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":110,"skipped":2256,"failed":0}
------------------------------
• [0.226 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:49:11.26
    Oct  3 19:49:11.261: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename disruption 10/03/22 19:49:11.262
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:49:11.296
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:49:11.307
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 10/03/22 19:49:11.318
    STEP: Waiting for the pdb to be processed 10/03/22 19:49:11.332
    STEP: updating the pdb 10/03/22 19:49:11.345
    STEP: Waiting for the pdb to be processed 10/03/22 19:49:11.371
    STEP: patching the pdb 10/03/22 19:49:11.383
    STEP: Waiting for the pdb to be processed 10/03/22 19:49:11.409
    STEP: Waiting for the pdb to be deleted 10/03/22 19:49:11.439
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Oct  3 19:49:11.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-4430" for this suite. 10/03/22 19:49:11.466
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:49:11.487
Oct  3 19:49:11.487: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename security-context-test 10/03/22 19:49:11.489
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:49:11.525
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:49:11.536
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Oct  3 19:49:11.568: INFO: Waiting up to 5m0s for pod "busybox-user-65534-a41132d9-2993-4fa2-bbf9-875ec0d5a1e3" in namespace "security-context-test-7632" to be "Succeeded or Failed"
Oct  3 19:49:11.584: INFO: Pod "busybox-user-65534-a41132d9-2993-4fa2-bbf9-875ec0d5a1e3": Phase="Pending", Reason="", readiness=false. Elapsed: 15.548361ms
Oct  3 19:49:13.595: INFO: Pod "busybox-user-65534-a41132d9-2993-4fa2-bbf9-875ec0d5a1e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027388638s
Oct  3 19:49:15.597: INFO: Pod "busybox-user-65534-a41132d9-2993-4fa2-bbf9-875ec0d5a1e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02885104s
Oct  3 19:49:15.597: INFO: Pod "busybox-user-65534-a41132d9-2993-4fa2-bbf9-875ec0d5a1e3" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Oct  3 19:49:15.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7632" for this suite. 10/03/22 19:49:15.612
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":111,"skipped":2256,"failed":0}
------------------------------
• [4.143 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:49:11.487
    Oct  3 19:49:11.487: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename security-context-test 10/03/22 19:49:11.489
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:49:11.525
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:49:11.536
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Oct  3 19:49:11.568: INFO: Waiting up to 5m0s for pod "busybox-user-65534-a41132d9-2993-4fa2-bbf9-875ec0d5a1e3" in namespace "security-context-test-7632" to be "Succeeded or Failed"
    Oct  3 19:49:11.584: INFO: Pod "busybox-user-65534-a41132d9-2993-4fa2-bbf9-875ec0d5a1e3": Phase="Pending", Reason="", readiness=false. Elapsed: 15.548361ms
    Oct  3 19:49:13.595: INFO: Pod "busybox-user-65534-a41132d9-2993-4fa2-bbf9-875ec0d5a1e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027388638s
    Oct  3 19:49:15.597: INFO: Pod "busybox-user-65534-a41132d9-2993-4fa2-bbf9-875ec0d5a1e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02885104s
    Oct  3 19:49:15.597: INFO: Pod "busybox-user-65534-a41132d9-2993-4fa2-bbf9-875ec0d5a1e3" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Oct  3 19:49:15.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-7632" for this suite. 10/03/22 19:49:15.612
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:49:15.637
Oct  3 19:49:15.637: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubelet-test 10/03/22 19:49:15.638
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:49:15.671
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:49:15.681
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Oct  3 19:49:15.713: INFO: Waiting up to 5m0s for pod "busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5" in namespace "kubelet-test-6847" to be "running and ready"
Oct  3 19:49:15.737: INFO: Pod "busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5": Phase="Pending", Reason="", readiness=false. Elapsed: 23.915484ms
Oct  3 19:49:15.737: INFO: The phase of Pod busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:49:17.750: INFO: Pod "busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036770228s
Oct  3 19:49:17.750: INFO: The phase of Pod busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:49:19.750: INFO: Pod "busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5": Phase="Running", Reason="", readiness=true. Elapsed: 4.036684572s
Oct  3 19:49:19.750: INFO: The phase of Pod busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5 is Running (Ready = true)
Oct  3 19:49:19.750: INFO: Pod "busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Oct  3 19:49:19.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6847" for this suite. 10/03/22 19:49:19.802
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":112,"skipped":2287,"failed":0}
------------------------------
• [4.184 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:49:15.637
    Oct  3 19:49:15.637: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubelet-test 10/03/22 19:49:15.638
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:49:15.671
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:49:15.681
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Oct  3 19:49:15.713: INFO: Waiting up to 5m0s for pod "busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5" in namespace "kubelet-test-6847" to be "running and ready"
    Oct  3 19:49:15.737: INFO: Pod "busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5": Phase="Pending", Reason="", readiness=false. Elapsed: 23.915484ms
    Oct  3 19:49:15.737: INFO: The phase of Pod busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:49:17.750: INFO: Pod "busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036770228s
    Oct  3 19:49:17.750: INFO: The phase of Pod busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:49:19.750: INFO: Pod "busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5": Phase="Running", Reason="", readiness=true. Elapsed: 4.036684572s
    Oct  3 19:49:19.750: INFO: The phase of Pod busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5 is Running (Ready = true)
    Oct  3 19:49:19.750: INFO: Pod "busybox-scheduling-2d690040-ff30-4ba6-9694-cc9cde24aab5" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Oct  3 19:49:19.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-6847" for this suite. 10/03/22 19:49:19.802
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:49:19.821
Oct  3 19:49:19.821: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename subpath 10/03/22 19:49:19.823
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:49:19.854
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:49:19.864
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 10/03/22 19:49:19.875
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-mqqf 10/03/22 19:49:19.902
STEP: Creating a pod to test atomic-volume-subpath 10/03/22 19:49:19.902
Oct  3 19:49:19.923: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-mqqf" in namespace "subpath-5327" to be "Succeeded or Failed"
Oct  3 19:49:19.933: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.120567ms
Oct  3 19:49:21.946: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022577944s
Oct  3 19:49:23.945: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 4.022113297s
Oct  3 19:49:25.946: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 6.022751336s
Oct  3 19:49:27.945: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 8.022287614s
Oct  3 19:49:29.945: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 10.022386711s
Oct  3 19:49:31.945: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 12.021583133s
Oct  3 19:49:33.947: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 14.023936519s
Oct  3 19:49:35.966: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 16.042865283s
Oct  3 19:49:37.947: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 18.023758888s
Oct  3 19:49:39.946: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 20.023316116s
Oct  3 19:49:41.946: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 22.02325945s
Oct  3 19:49:43.947: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=false. Elapsed: 24.023936455s
Oct  3 19:49:45.945: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.022238397s
STEP: Saw pod success 10/03/22 19:49:45.945
Oct  3 19:49:45.945: INFO: Pod "pod-subpath-test-projected-mqqf" satisfied condition "Succeeded or Failed"
Oct  3 19:49:45.955: INFO: Trying to get logs from node 10.63.128.3 pod pod-subpath-test-projected-mqqf container test-container-subpath-projected-mqqf: <nil>
STEP: delete the pod 10/03/22 19:49:45.981
Oct  3 19:49:46.012: INFO: Waiting for pod pod-subpath-test-projected-mqqf to disappear
Oct  3 19:49:46.024: INFO: Pod pod-subpath-test-projected-mqqf no longer exists
STEP: Deleting pod pod-subpath-test-projected-mqqf 10/03/22 19:49:46.024
Oct  3 19:49:46.024: INFO: Deleting pod "pod-subpath-test-projected-mqqf" in namespace "subpath-5327"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Oct  3 19:49:46.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5327" for this suite. 10/03/22 19:49:46.051
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":113,"skipped":2289,"failed":0}
------------------------------
• [SLOW TEST] [26.249 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:49:19.821
    Oct  3 19:49:19.821: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename subpath 10/03/22 19:49:19.823
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:49:19.854
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:49:19.864
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 10/03/22 19:49:19.875
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-mqqf 10/03/22 19:49:19.902
    STEP: Creating a pod to test atomic-volume-subpath 10/03/22 19:49:19.902
    Oct  3 19:49:19.923: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-mqqf" in namespace "subpath-5327" to be "Succeeded or Failed"
    Oct  3 19:49:19.933: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.120567ms
    Oct  3 19:49:21.946: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022577944s
    Oct  3 19:49:23.945: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 4.022113297s
    Oct  3 19:49:25.946: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 6.022751336s
    Oct  3 19:49:27.945: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 8.022287614s
    Oct  3 19:49:29.945: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 10.022386711s
    Oct  3 19:49:31.945: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 12.021583133s
    Oct  3 19:49:33.947: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 14.023936519s
    Oct  3 19:49:35.966: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 16.042865283s
    Oct  3 19:49:37.947: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 18.023758888s
    Oct  3 19:49:39.946: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 20.023316116s
    Oct  3 19:49:41.946: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=true. Elapsed: 22.02325945s
    Oct  3 19:49:43.947: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Running", Reason="", readiness=false. Elapsed: 24.023936455s
    Oct  3 19:49:45.945: INFO: Pod "pod-subpath-test-projected-mqqf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.022238397s
    STEP: Saw pod success 10/03/22 19:49:45.945
    Oct  3 19:49:45.945: INFO: Pod "pod-subpath-test-projected-mqqf" satisfied condition "Succeeded or Failed"
    Oct  3 19:49:45.955: INFO: Trying to get logs from node 10.63.128.3 pod pod-subpath-test-projected-mqqf container test-container-subpath-projected-mqqf: <nil>
    STEP: delete the pod 10/03/22 19:49:45.981
    Oct  3 19:49:46.012: INFO: Waiting for pod pod-subpath-test-projected-mqqf to disappear
    Oct  3 19:49:46.024: INFO: Pod pod-subpath-test-projected-mqqf no longer exists
    STEP: Deleting pod pod-subpath-test-projected-mqqf 10/03/22 19:49:46.024
    Oct  3 19:49:46.024: INFO: Deleting pod "pod-subpath-test-projected-mqqf" in namespace "subpath-5327"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Oct  3 19:49:46.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-5327" for this suite. 10/03/22 19:49:46.051
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:49:46.076
Oct  3 19:49:46.076: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename proxy 10/03/22 19:49:46.077
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:49:46.114
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:49:46.123
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 10/03/22 19:49:46.167
STEP: creating replication controller proxy-service-5tmnz in namespace proxy-4984 10/03/22 19:49:46.167
I1003 19:49:46.182889      22 runners.go:193] Created replication controller with name: proxy-service-5tmnz, namespace: proxy-4984, replica count: 1
I1003 19:49:47.233745      22 runners.go:193] proxy-service-5tmnz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1003 19:49:48.234126      22 runners.go:193] proxy-service-5tmnz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1003 19:49:49.235345      22 runners.go:193] proxy-service-5tmnz Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  3 19:49:49.255: INFO: setup took 3.121258431s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 10/03/22 19:49:49.255
Oct  3 19:49:49.305: INFO: (0) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 49.956494ms)
Oct  3 19:49:49.306: INFO: (0) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 50.21794ms)
Oct  3 19:49:49.307: INFO: (0) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 51.564615ms)
Oct  3 19:49:49.307: INFO: (0) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 51.232019ms)
Oct  3 19:49:49.307: INFO: (0) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 51.447184ms)
Oct  3 19:49:49.311: INFO: (0) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 56.166917ms)
Oct  3 19:49:49.312: INFO: (0) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 56.361611ms)
Oct  3 19:49:49.314: INFO: (0) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 58.185929ms)
Oct  3 19:49:49.318: INFO: (0) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 62.51164ms)
Oct  3 19:49:49.318: INFO: (0) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 62.709692ms)
Oct  3 19:49:49.327: INFO: (0) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 70.833225ms)
Oct  3 19:49:49.327: INFO: (0) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 71.057142ms)
Oct  3 19:49:49.327: INFO: (0) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 71.766031ms)
Oct  3 19:49:49.329: INFO: (0) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 73.169725ms)
Oct  3 19:49:49.332: INFO: (0) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 76.314237ms)
Oct  3 19:49:49.332: INFO: (0) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 76.331795ms)
Oct  3 19:49:49.349: INFO: (1) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 16.591389ms)
Oct  3 19:49:49.352: INFO: (1) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 18.893816ms)
Oct  3 19:49:49.352: INFO: (1) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 18.275998ms)
Oct  3 19:49:49.352: INFO: (1) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 18.558158ms)
Oct  3 19:49:49.355: INFO: (1) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 21.484642ms)
Oct  3 19:49:49.355: INFO: (1) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 22.127837ms)
Oct  3 19:49:49.358: INFO: (1) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 24.341989ms)
Oct  3 19:49:49.358: INFO: (1) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 24.567582ms)
Oct  3 19:49:49.358: INFO: (1) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 24.463416ms)
Oct  3 19:49:49.358: INFO: (1) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 24.706347ms)
Oct  3 19:49:49.363: INFO: (1) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 29.386321ms)
Oct  3 19:49:49.364: INFO: (1) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 30.183601ms)
Oct  3 19:49:49.364: INFO: (1) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 30.889779ms)
Oct  3 19:49:49.370: INFO: (1) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 35.843678ms)
Oct  3 19:49:49.371: INFO: (1) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 36.963387ms)
Oct  3 19:49:49.371: INFO: (1) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 36.614731ms)
Oct  3 19:49:49.386: INFO: (2) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 15.415242ms)
Oct  3 19:49:49.391: INFO: (2) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 19.563213ms)
Oct  3 19:49:49.391: INFO: (2) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 20.317703ms)
Oct  3 19:49:49.391: INFO: (2) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.239726ms)
Oct  3 19:49:49.392: INFO: (2) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 20.630289ms)
Oct  3 19:49:49.393: INFO: (2) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 22.593006ms)
Oct  3 19:49:49.397: INFO: (2) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 26.14939ms)
Oct  3 19:49:49.397: INFO: (2) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 26.189988ms)
Oct  3 19:49:49.397: INFO: (2) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 26.609543ms)
Oct  3 19:49:49.398: INFO: (2) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 27.239867ms)
Oct  3 19:49:49.399: INFO: (2) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 27.61743ms)
Oct  3 19:49:49.404: INFO: (2) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 32.997766ms)
Oct  3 19:49:49.406: INFO: (2) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 34.674567ms)
Oct  3 19:49:49.406: INFO: (2) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 35.235521ms)
Oct  3 19:49:49.406: INFO: (2) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 35.198944ms)
Oct  3 19:49:49.406: INFO: (2) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 35.506131ms)
Oct  3 19:49:49.424: INFO: (3) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 17.922197ms)
Oct  3 19:49:49.430: INFO: (3) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 22.061055ms)
Oct  3 19:49:49.431: INFO: (3) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 23.208125ms)
Oct  3 19:49:49.431: INFO: (3) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 23.995796ms)
Oct  3 19:49:49.431: INFO: (3) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 23.733536ms)
Oct  3 19:49:49.432: INFO: (3) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 23.485787ms)
Oct  3 19:49:49.432: INFO: (3) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 24.242137ms)
Oct  3 19:49:49.432: INFO: (3) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 24.704529ms)
Oct  3 19:49:49.432: INFO: (3) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 24.072658ms)
Oct  3 19:49:49.432: INFO: (3) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 24.494893ms)
Oct  3 19:49:49.436: INFO: (3) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 29.464358ms)
Oct  3 19:49:49.443: INFO: (3) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 35.791701ms)
Oct  3 19:49:49.445: INFO: (3) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 38.229055ms)
Oct  3 19:49:49.445: INFO: (3) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 37.75041ms)
Oct  3 19:49:49.446: INFO: (3) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 39.445896ms)
Oct  3 19:49:49.447: INFO: (3) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 39.801689ms)
Oct  3 19:49:49.464: INFO: (4) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 16.982886ms)
Oct  3 19:49:49.469: INFO: (4) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 21.472372ms)
Oct  3 19:49:49.469: INFO: (4) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 21.506761ms)
Oct  3 19:49:49.469: INFO: (4) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 21.682568ms)
Oct  3 19:49:49.469: INFO: (4) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 21.640685ms)
Oct  3 19:49:49.470: INFO: (4) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 21.878493ms)
Oct  3 19:49:49.470: INFO: (4) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 22.284896ms)
Oct  3 19:49:49.470: INFO: (4) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 23.152115ms)
Oct  3 19:49:49.470: INFO: (4) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 22.711277ms)
Oct  3 19:49:49.471: INFO: (4) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 23.347162ms)
Oct  3 19:49:49.472: INFO: (4) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 24.358008ms)
Oct  3 19:49:49.477: INFO: (4) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 29.213371ms)
Oct  3 19:49:49.479: INFO: (4) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 31.358778ms)
Oct  3 19:49:49.480: INFO: (4) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 32.057071ms)
Oct  3 19:49:49.480: INFO: (4) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 32.210326ms)
Oct  3 19:49:49.480: INFO: (4) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 32.631773ms)
Oct  3 19:49:49.500: INFO: (5) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 20.272457ms)
Oct  3 19:49:49.504: INFO: (5) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 22.950864ms)
Oct  3 19:49:49.504: INFO: (5) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 23.124078ms)
Oct  3 19:49:49.505: INFO: (5) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 23.514516ms)
Oct  3 19:49:49.505: INFO: (5) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 23.904593ms)
Oct  3 19:49:49.505: INFO: (5) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 24.65057ms)
Oct  3 19:49:49.506: INFO: (5) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 24.478735ms)
Oct  3 19:49:49.506: INFO: (5) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 24.732541ms)
Oct  3 19:49:49.506: INFO: (5) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 24.68982ms)
Oct  3 19:49:49.506: INFO: (5) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 25.323292ms)
Oct  3 19:49:49.508: INFO: (5) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 26.784206ms)
Oct  3 19:49:49.513: INFO: (5) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 32.60713ms)
Oct  3 19:49:49.515: INFO: (5) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 34.496079ms)
Oct  3 19:49:49.515: INFO: (5) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 34.185651ms)
Oct  3 19:49:49.516: INFO: (5) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 35.79757ms)
Oct  3 19:49:49.516: INFO: (5) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 34.883955ms)
Oct  3 19:49:49.533: INFO: (6) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 16.440479ms)
Oct  3 19:49:49.535: INFO: (6) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 18.133599ms)
Oct  3 19:49:49.536: INFO: (6) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 18.949366ms)
Oct  3 19:49:49.536: INFO: (6) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 19.919794ms)
Oct  3 19:49:49.537: INFO: (6) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 20.034507ms)
Oct  3 19:49:49.537: INFO: (6) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 20.006604ms)
Oct  3 19:49:49.537: INFO: (6) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 20.774312ms)
Oct  3 19:49:49.537: INFO: (6) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 21.055391ms)
Oct  3 19:49:49.538: INFO: (6) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 20.905222ms)
Oct  3 19:49:49.538: INFO: (6) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 21.75328ms)
Oct  3 19:49:49.542: INFO: (6) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 25.558874ms)
Oct  3 19:49:49.545: INFO: (6) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 28.102594ms)
Oct  3 19:49:49.546: INFO: (6) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 29.587806ms)
Oct  3 19:49:49.548: INFO: (6) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 31.607942ms)
Oct  3 19:49:49.548: INFO: (6) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 31.370218ms)
Oct  3 19:49:49.549: INFO: (6) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 32.213618ms)
Oct  3 19:49:49.567: INFO: (7) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 18.029944ms)
Oct  3 19:49:49.569: INFO: (7) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 18.43333ms)
Oct  3 19:49:49.570: INFO: (7) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 18.974461ms)
Oct  3 19:49:49.570: INFO: (7) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 19.423445ms)
Oct  3 19:49:49.570: INFO: (7) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 19.795722ms)
Oct  3 19:49:49.571: INFO: (7) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 21.485531ms)
Oct  3 19:49:49.571: INFO: (7) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 20.861921ms)
Oct  3 19:49:49.572: INFO: (7) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 20.589549ms)
Oct  3 19:49:49.572: INFO: (7) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 21.989479ms)
Oct  3 19:49:49.572: INFO: (7) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 21.311865ms)
Oct  3 19:49:49.574: INFO: (7) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 24.848566ms)
Oct  3 19:49:49.578: INFO: (7) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 28.199477ms)
Oct  3 19:49:49.581: INFO: (7) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 30.661528ms)
Oct  3 19:49:49.582: INFO: (7) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 32.8909ms)
Oct  3 19:49:49.582: INFO: (7) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 31.371626ms)
Oct  3 19:49:49.582: INFO: (7) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 32.377834ms)
Oct  3 19:49:49.599: INFO: (8) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 16.23119ms)
Oct  3 19:49:49.603: INFO: (8) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 19.58365ms)
Oct  3 19:49:49.604: INFO: (8) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.254804ms)
Oct  3 19:49:49.604: INFO: (8) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 20.603701ms)
Oct  3 19:49:49.604: INFO: (8) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 21.041448ms)
Oct  3 19:49:49.604: INFO: (8) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 20.601675ms)
Oct  3 19:49:49.604: INFO: (8) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 20.652911ms)
Oct  3 19:49:49.605: INFO: (8) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 21.614665ms)
Oct  3 19:49:49.605: INFO: (8) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 21.856529ms)
Oct  3 19:49:49.605: INFO: (8) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 22.667663ms)
Oct  3 19:49:49.608: INFO: (8) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 25.48465ms)
Oct  3 19:49:49.612: INFO: (8) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 29.335365ms)
Oct  3 19:49:49.615: INFO: (8) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 31.596966ms)
Oct  3 19:49:49.616: INFO: (8) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 32.191004ms)
Oct  3 19:49:49.616: INFO: (8) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 32.414694ms)
Oct  3 19:49:49.618: INFO: (8) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 34.221222ms)
Oct  3 19:49:49.637: INFO: (9) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 18.191646ms)
Oct  3 19:49:49.637: INFO: (9) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 18.17822ms)
Oct  3 19:49:49.638: INFO: (9) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 19.186464ms)
Oct  3 19:49:49.638: INFO: (9) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 19.300607ms)
Oct  3 19:49:49.639: INFO: (9) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 20.140739ms)
Oct  3 19:49:49.639: INFO: (9) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 21.339077ms)
Oct  3 19:49:49.639: INFO: (9) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 20.257414ms)
Oct  3 19:49:49.640: INFO: (9) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 21.887848ms)
Oct  3 19:49:49.641: INFO: (9) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 23.538928ms)
Oct  3 19:49:49.641: INFO: (9) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 23.108415ms)
Oct  3 19:49:49.643: INFO: (9) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 25.517525ms)
Oct  3 19:49:49.644: INFO: (9) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 26.008541ms)
Oct  3 19:49:49.647: INFO: (9) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 28.429739ms)
Oct  3 19:49:49.650: INFO: (9) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 32.14526ms)
Oct  3 19:49:49.650: INFO: (9) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 31.286429ms)
Oct  3 19:49:49.651: INFO: (9) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 32.595903ms)
Oct  3 19:49:49.669: INFO: (10) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 17.725399ms)
Oct  3 19:49:49.669: INFO: (10) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 17.183197ms)
Oct  3 19:49:49.670: INFO: (10) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 17.944896ms)
Oct  3 19:49:49.671: INFO: (10) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 18.807597ms)
Oct  3 19:49:49.672: INFO: (10) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 19.96081ms)
Oct  3 19:49:49.672: INFO: (10) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 20.136281ms)
Oct  3 19:49:49.672: INFO: (10) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 19.553793ms)
Oct  3 19:49:49.673: INFO: (10) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.104452ms)
Oct  3 19:49:49.673: INFO: (10) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.572835ms)
Oct  3 19:49:49.673: INFO: (10) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 20.519553ms)
Oct  3 19:49:49.681: INFO: (10) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 29.210314ms)
Oct  3 19:49:49.682: INFO: (10) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 29.535548ms)
Oct  3 19:49:49.683: INFO: (10) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 30.39947ms)
Oct  3 19:49:49.683: INFO: (10) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 31.465717ms)
Oct  3 19:49:49.683: INFO: (10) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 31.686528ms)
Oct  3 19:49:49.684: INFO: (10) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 31.156842ms)
Oct  3 19:49:49.699: INFO: (11) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 15.422386ms)
Oct  3 19:49:49.706: INFO: (11) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 21.927987ms)
Oct  3 19:49:49.706: INFO: (11) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 21.944309ms)
Oct  3 19:49:49.707: INFO: (11) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 22.647764ms)
Oct  3 19:49:49.707: INFO: (11) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 23.042989ms)
Oct  3 19:49:49.708: INFO: (11) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 23.491448ms)
Oct  3 19:49:49.708: INFO: (11) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 23.1248ms)
Oct  3 19:49:49.708: INFO: (11) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 23.416035ms)
Oct  3 19:49:49.708: INFO: (11) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 22.852457ms)
Oct  3 19:49:49.708: INFO: (11) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 22.967753ms)
Oct  3 19:49:49.708: INFO: (11) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 23.621971ms)
Oct  3 19:49:49.713: INFO: (11) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 28.540549ms)
Oct  3 19:49:49.716: INFO: (11) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 32.017178ms)
Oct  3 19:49:49.716: INFO: (11) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 31.849506ms)
Oct  3 19:49:49.716: INFO: (11) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 31.793815ms)
Oct  3 19:49:49.716: INFO: (11) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 32.066076ms)
Oct  3 19:49:49.733: INFO: (12) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 16.650773ms)
Oct  3 19:49:49.736: INFO: (12) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 19.19362ms)
Oct  3 19:49:49.737: INFO: (12) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 19.638634ms)
Oct  3 19:49:49.738: INFO: (12) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 20.887688ms)
Oct  3 19:49:49.738: INFO: (12) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 21.019114ms)
Oct  3 19:49:49.739: INFO: (12) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 21.487164ms)
Oct  3 19:49:49.739: INFO: (12) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 21.449802ms)
Oct  3 19:49:49.739: INFO: (12) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 21.878447ms)
Oct  3 19:49:49.739: INFO: (12) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 22.012825ms)
Oct  3 19:49:49.739: INFO: (12) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 22.504334ms)
Oct  3 19:49:49.741: INFO: (12) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 24.243938ms)
Oct  3 19:49:49.745: INFO: (12) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 28.28422ms)
Oct  3 19:49:49.748: INFO: (12) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 31.018672ms)
Oct  3 19:49:49.750: INFO: (12) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 32.698332ms)
Oct  3 19:49:49.750: INFO: (12) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 33.02788ms)
Oct  3 19:49:49.750: INFO: (12) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 33.057975ms)
Oct  3 19:49:49.767: INFO: (13) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 17.211736ms)
Oct  3 19:49:49.770: INFO: (13) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 19.328904ms)
Oct  3 19:49:49.771: INFO: (13) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 20.226299ms)
Oct  3 19:49:49.771: INFO: (13) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 20.588294ms)
Oct  3 19:49:49.772: INFO: (13) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 21.453986ms)
Oct  3 19:49:49.772: INFO: (13) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 21.468309ms)
Oct  3 19:49:49.772: INFO: (13) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 21.76089ms)
Oct  3 19:49:49.772: INFO: (13) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 21.705393ms)
Oct  3 19:49:49.773: INFO: (13) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 22.977513ms)
Oct  3 19:49:49.773: INFO: (13) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 22.718081ms)
Oct  3 19:49:49.775: INFO: (13) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 24.560468ms)
Oct  3 19:49:49.780: INFO: (13) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 29.702197ms)
Oct  3 19:49:49.782: INFO: (13) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 31.43017ms)
Oct  3 19:49:49.782: INFO: (13) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 31.80447ms)
Oct  3 19:49:49.782: INFO: (13) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 32.17276ms)
Oct  3 19:49:49.787: INFO: (13) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 36.426163ms)
Oct  3 19:49:49.805: INFO: (14) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 18.241435ms)
Oct  3 19:49:49.807: INFO: (14) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 19.185659ms)
Oct  3 19:49:49.807: INFO: (14) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 19.775174ms)
Oct  3 19:49:49.808: INFO: (14) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 20.828765ms)
Oct  3 19:49:49.809: INFO: (14) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 21.398568ms)
Oct  3 19:49:49.809: INFO: (14) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 21.945399ms)
Oct  3 19:49:49.810: INFO: (14) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 22.692274ms)
Oct  3 19:49:49.810: INFO: (14) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 22.472752ms)
Oct  3 19:49:49.810: INFO: (14) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 22.133474ms)
Oct  3 19:49:49.810: INFO: (14) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 23.149223ms)
Oct  3 19:49:49.811: INFO: (14) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 23.642648ms)
Oct  3 19:49:49.820: INFO: (14) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 32.85065ms)
Oct  3 19:49:49.820: INFO: (14) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 32.667579ms)
Oct  3 19:49:49.820: INFO: (14) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 32.951398ms)
Oct  3 19:49:49.820: INFO: (14) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 32.847717ms)
Oct  3 19:49:49.820: INFO: (14) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 33.204653ms)
Oct  3 19:49:49.838: INFO: (15) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 17.86939ms)
Oct  3 19:49:49.839: INFO: (15) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 18.965921ms)
Oct  3 19:49:49.841: INFO: (15) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 20.747ms)
Oct  3 19:49:49.842: INFO: (15) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 20.748385ms)
Oct  3 19:49:49.842: INFO: (15) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.733461ms)
Oct  3 19:49:49.842: INFO: (15) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.882716ms)
Oct  3 19:49:49.843: INFO: (15) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 21.765076ms)
Oct  3 19:49:49.843: INFO: (15) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 21.872559ms)
Oct  3 19:49:49.843: INFO: (15) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 22.094062ms)
Oct  3 19:49:49.843: INFO: (15) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 22.630828ms)
Oct  3 19:49:49.846: INFO: (15) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 25.604006ms)
Oct  3 19:49:49.850: INFO: (15) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 28.868466ms)
Oct  3 19:49:49.855: INFO: (15) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 33.627942ms)
Oct  3 19:49:49.855: INFO: (15) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 33.904498ms)
Oct  3 19:49:49.855: INFO: (15) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 34.042924ms)
Oct  3 19:49:49.855: INFO: (15) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 33.894595ms)
Oct  3 19:49:49.872: INFO: (16) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 16.703732ms)
Oct  3 19:49:49.876: INFO: (16) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.458211ms)
Oct  3 19:49:49.876: INFO: (16) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 21.055571ms)
Oct  3 19:49:49.876: INFO: (16) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 21.213577ms)
Oct  3 19:49:49.876: INFO: (16) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 21.11209ms)
Oct  3 19:49:49.876: INFO: (16) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 21.273241ms)
Oct  3 19:49:49.877: INFO: (16) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 21.87591ms)
Oct  3 19:49:49.879: INFO: (16) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 23.434155ms)
Oct  3 19:49:49.879: INFO: (16) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 24.025705ms)
Oct  3 19:49:49.880: INFO: (16) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 24.820788ms)
Oct  3 19:49:49.882: INFO: (16) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 27.501003ms)
Oct  3 19:49:49.884: INFO: (16) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 28.290567ms)
Oct  3 19:49:49.885: INFO: (16) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 30.14764ms)
Oct  3 19:49:49.885: INFO: (16) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 30.274381ms)
Oct  3 19:49:49.903: INFO: (16) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 47.739615ms)
Oct  3 19:49:49.903: INFO: (16) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 47.668923ms)
Oct  3 19:49:49.920: INFO: (17) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 16.628092ms)
Oct  3 19:49:49.923: INFO: (17) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 19.111589ms)
Oct  3 19:49:49.924: INFO: (17) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 20.065833ms)
Oct  3 19:49:49.924: INFO: (17) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.218912ms)
Oct  3 19:49:49.925: INFO: (17) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 20.797878ms)
Oct  3 19:49:49.925: INFO: (17) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 21.319411ms)
Oct  3 19:49:49.925: INFO: (17) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 21.764561ms)
Oct  3 19:49:49.925: INFO: (17) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 21.376701ms)
Oct  3 19:49:49.928: INFO: (17) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 25.026708ms)
Oct  3 19:49:49.932: INFO: (17) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 28.716571ms)
Oct  3 19:49:49.934: INFO: (17) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 30.245431ms)
Oct  3 19:49:49.935: INFO: (17) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 31.446424ms)
Oct  3 19:49:49.935: INFO: (17) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 31.293071ms)
Oct  3 19:49:49.942: INFO: (17) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 38.525852ms)
Oct  3 19:49:49.942: INFO: (17) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 38.541798ms)
Oct  3 19:49:49.942: INFO: (17) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 38.130275ms)
Oct  3 19:49:49.960: INFO: (18) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 17.904055ms)
Oct  3 19:49:49.964: INFO: (18) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.986878ms)
Oct  3 19:49:49.965: INFO: (18) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 22.549092ms)
Oct  3 19:49:49.965: INFO: (18) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 22.63491ms)
Oct  3 19:49:49.965: INFO: (18) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 22.769785ms)
Oct  3 19:49:49.966: INFO: (18) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 22.840707ms)
Oct  3 19:49:49.967: INFO: (18) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 23.983433ms)
Oct  3 19:49:49.967: INFO: (18) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 24.267648ms)
Oct  3 19:49:49.967: INFO: (18) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 24.381228ms)
Oct  3 19:49:49.967: INFO: (18) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 24.402357ms)
Oct  3 19:49:49.969: INFO: (18) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 26.473409ms)
Oct  3 19:49:49.972: INFO: (18) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 29.419209ms)
Oct  3 19:49:49.975: INFO: (18) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 32.766732ms)
Oct  3 19:49:49.975: INFO: (18) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 32.320064ms)
Oct  3 19:49:49.976: INFO: (18) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 33.088947ms)
Oct  3 19:49:49.976: INFO: (18) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 33.245461ms)
Oct  3 19:49:49.997: INFO: (19) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 20.907069ms)
Oct  3 19:49:50.000: INFO: (19) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 22.121807ms)
Oct  3 19:49:50.000: INFO: (19) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 23.655459ms)
Oct  3 19:49:50.000: INFO: (19) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 22.696883ms)
Oct  3 19:49:50.001: INFO: (19) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 24.763254ms)
Oct  3 19:49:50.001: INFO: (19) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 24.216134ms)
Oct  3 19:49:50.002: INFO: (19) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 25.023109ms)
Oct  3 19:49:50.002: INFO: (19) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 25.335556ms)
Oct  3 19:49:50.002: INFO: (19) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 24.987997ms)
Oct  3 19:49:50.002: INFO: (19) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 25.222248ms)
Oct  3 19:49:50.007: INFO: (19) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 30.052163ms)
Oct  3 19:49:50.009: INFO: (19) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 32.396635ms)
Oct  3 19:49:50.010: INFO: (19) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 32.885451ms)
Oct  3 19:49:50.011: INFO: (19) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 33.312765ms)
Oct  3 19:49:50.011: INFO: (19) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 34.759266ms)
Oct  3 19:49:50.011: INFO: (19) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 34.659181ms)
STEP: deleting ReplicationController proxy-service-5tmnz in namespace proxy-4984, will wait for the garbage collector to delete the pods 10/03/22 19:49:50.012
Oct  3 19:49:50.097: INFO: Deleting ReplicationController proxy-service-5tmnz took: 22.3187ms
Oct  3 19:49:50.198: INFO: Terminating ReplicationController proxy-service-5tmnz pods took: 101.280865ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Oct  3 19:49:52.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4984" for this suite. 10/03/22 19:49:52.815
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":114,"skipped":2300,"failed":0}
------------------------------
• [SLOW TEST] [6.785 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:49:46.076
    Oct  3 19:49:46.076: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename proxy 10/03/22 19:49:46.077
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:49:46.114
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:49:46.123
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 10/03/22 19:49:46.167
    STEP: creating replication controller proxy-service-5tmnz in namespace proxy-4984 10/03/22 19:49:46.167
    I1003 19:49:46.182889      22 runners.go:193] Created replication controller with name: proxy-service-5tmnz, namespace: proxy-4984, replica count: 1
    I1003 19:49:47.233745      22 runners.go:193] proxy-service-5tmnz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1003 19:49:48.234126      22 runners.go:193] proxy-service-5tmnz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1003 19:49:49.235345      22 runners.go:193] proxy-service-5tmnz Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct  3 19:49:49.255: INFO: setup took 3.121258431s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 10/03/22 19:49:49.255
    Oct  3 19:49:49.305: INFO: (0) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 49.956494ms)
    Oct  3 19:49:49.306: INFO: (0) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 50.21794ms)
    Oct  3 19:49:49.307: INFO: (0) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 51.564615ms)
    Oct  3 19:49:49.307: INFO: (0) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 51.232019ms)
    Oct  3 19:49:49.307: INFO: (0) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 51.447184ms)
    Oct  3 19:49:49.311: INFO: (0) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 56.166917ms)
    Oct  3 19:49:49.312: INFO: (0) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 56.361611ms)
    Oct  3 19:49:49.314: INFO: (0) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 58.185929ms)
    Oct  3 19:49:49.318: INFO: (0) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 62.51164ms)
    Oct  3 19:49:49.318: INFO: (0) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 62.709692ms)
    Oct  3 19:49:49.327: INFO: (0) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 70.833225ms)
    Oct  3 19:49:49.327: INFO: (0) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 71.057142ms)
    Oct  3 19:49:49.327: INFO: (0) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 71.766031ms)
    Oct  3 19:49:49.329: INFO: (0) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 73.169725ms)
    Oct  3 19:49:49.332: INFO: (0) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 76.314237ms)
    Oct  3 19:49:49.332: INFO: (0) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 76.331795ms)
    Oct  3 19:49:49.349: INFO: (1) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 16.591389ms)
    Oct  3 19:49:49.352: INFO: (1) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 18.893816ms)
    Oct  3 19:49:49.352: INFO: (1) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 18.275998ms)
    Oct  3 19:49:49.352: INFO: (1) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 18.558158ms)
    Oct  3 19:49:49.355: INFO: (1) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 21.484642ms)
    Oct  3 19:49:49.355: INFO: (1) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 22.127837ms)
    Oct  3 19:49:49.358: INFO: (1) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 24.341989ms)
    Oct  3 19:49:49.358: INFO: (1) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 24.567582ms)
    Oct  3 19:49:49.358: INFO: (1) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 24.463416ms)
    Oct  3 19:49:49.358: INFO: (1) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 24.706347ms)
    Oct  3 19:49:49.363: INFO: (1) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 29.386321ms)
    Oct  3 19:49:49.364: INFO: (1) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 30.183601ms)
    Oct  3 19:49:49.364: INFO: (1) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 30.889779ms)
    Oct  3 19:49:49.370: INFO: (1) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 35.843678ms)
    Oct  3 19:49:49.371: INFO: (1) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 36.963387ms)
    Oct  3 19:49:49.371: INFO: (1) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 36.614731ms)
    Oct  3 19:49:49.386: INFO: (2) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 15.415242ms)
    Oct  3 19:49:49.391: INFO: (2) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 19.563213ms)
    Oct  3 19:49:49.391: INFO: (2) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 20.317703ms)
    Oct  3 19:49:49.391: INFO: (2) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.239726ms)
    Oct  3 19:49:49.392: INFO: (2) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 20.630289ms)
    Oct  3 19:49:49.393: INFO: (2) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 22.593006ms)
    Oct  3 19:49:49.397: INFO: (2) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 26.14939ms)
    Oct  3 19:49:49.397: INFO: (2) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 26.189988ms)
    Oct  3 19:49:49.397: INFO: (2) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 26.609543ms)
    Oct  3 19:49:49.398: INFO: (2) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 27.239867ms)
    Oct  3 19:49:49.399: INFO: (2) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 27.61743ms)
    Oct  3 19:49:49.404: INFO: (2) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 32.997766ms)
    Oct  3 19:49:49.406: INFO: (2) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 34.674567ms)
    Oct  3 19:49:49.406: INFO: (2) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 35.235521ms)
    Oct  3 19:49:49.406: INFO: (2) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 35.198944ms)
    Oct  3 19:49:49.406: INFO: (2) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 35.506131ms)
    Oct  3 19:49:49.424: INFO: (3) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 17.922197ms)
    Oct  3 19:49:49.430: INFO: (3) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 22.061055ms)
    Oct  3 19:49:49.431: INFO: (3) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 23.208125ms)
    Oct  3 19:49:49.431: INFO: (3) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 23.995796ms)
    Oct  3 19:49:49.431: INFO: (3) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 23.733536ms)
    Oct  3 19:49:49.432: INFO: (3) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 23.485787ms)
    Oct  3 19:49:49.432: INFO: (3) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 24.242137ms)
    Oct  3 19:49:49.432: INFO: (3) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 24.704529ms)
    Oct  3 19:49:49.432: INFO: (3) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 24.072658ms)
    Oct  3 19:49:49.432: INFO: (3) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 24.494893ms)
    Oct  3 19:49:49.436: INFO: (3) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 29.464358ms)
    Oct  3 19:49:49.443: INFO: (3) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 35.791701ms)
    Oct  3 19:49:49.445: INFO: (3) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 38.229055ms)
    Oct  3 19:49:49.445: INFO: (3) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 37.75041ms)
    Oct  3 19:49:49.446: INFO: (3) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 39.445896ms)
    Oct  3 19:49:49.447: INFO: (3) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 39.801689ms)
    Oct  3 19:49:49.464: INFO: (4) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 16.982886ms)
    Oct  3 19:49:49.469: INFO: (4) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 21.472372ms)
    Oct  3 19:49:49.469: INFO: (4) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 21.506761ms)
    Oct  3 19:49:49.469: INFO: (4) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 21.682568ms)
    Oct  3 19:49:49.469: INFO: (4) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 21.640685ms)
    Oct  3 19:49:49.470: INFO: (4) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 21.878493ms)
    Oct  3 19:49:49.470: INFO: (4) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 22.284896ms)
    Oct  3 19:49:49.470: INFO: (4) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 23.152115ms)
    Oct  3 19:49:49.470: INFO: (4) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 22.711277ms)
    Oct  3 19:49:49.471: INFO: (4) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 23.347162ms)
    Oct  3 19:49:49.472: INFO: (4) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 24.358008ms)
    Oct  3 19:49:49.477: INFO: (4) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 29.213371ms)
    Oct  3 19:49:49.479: INFO: (4) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 31.358778ms)
    Oct  3 19:49:49.480: INFO: (4) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 32.057071ms)
    Oct  3 19:49:49.480: INFO: (4) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 32.210326ms)
    Oct  3 19:49:49.480: INFO: (4) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 32.631773ms)
    Oct  3 19:49:49.500: INFO: (5) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 20.272457ms)
    Oct  3 19:49:49.504: INFO: (5) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 22.950864ms)
    Oct  3 19:49:49.504: INFO: (5) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 23.124078ms)
    Oct  3 19:49:49.505: INFO: (5) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 23.514516ms)
    Oct  3 19:49:49.505: INFO: (5) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 23.904593ms)
    Oct  3 19:49:49.505: INFO: (5) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 24.65057ms)
    Oct  3 19:49:49.506: INFO: (5) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 24.478735ms)
    Oct  3 19:49:49.506: INFO: (5) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 24.732541ms)
    Oct  3 19:49:49.506: INFO: (5) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 24.68982ms)
    Oct  3 19:49:49.506: INFO: (5) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 25.323292ms)
    Oct  3 19:49:49.508: INFO: (5) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 26.784206ms)
    Oct  3 19:49:49.513: INFO: (5) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 32.60713ms)
    Oct  3 19:49:49.515: INFO: (5) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 34.496079ms)
    Oct  3 19:49:49.515: INFO: (5) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 34.185651ms)
    Oct  3 19:49:49.516: INFO: (5) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 35.79757ms)
    Oct  3 19:49:49.516: INFO: (5) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 34.883955ms)
    Oct  3 19:49:49.533: INFO: (6) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 16.440479ms)
    Oct  3 19:49:49.535: INFO: (6) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 18.133599ms)
    Oct  3 19:49:49.536: INFO: (6) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 18.949366ms)
    Oct  3 19:49:49.536: INFO: (6) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 19.919794ms)
    Oct  3 19:49:49.537: INFO: (6) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 20.034507ms)
    Oct  3 19:49:49.537: INFO: (6) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 20.006604ms)
    Oct  3 19:49:49.537: INFO: (6) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 20.774312ms)
    Oct  3 19:49:49.537: INFO: (6) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 21.055391ms)
    Oct  3 19:49:49.538: INFO: (6) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 20.905222ms)
    Oct  3 19:49:49.538: INFO: (6) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 21.75328ms)
    Oct  3 19:49:49.542: INFO: (6) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 25.558874ms)
    Oct  3 19:49:49.545: INFO: (6) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 28.102594ms)
    Oct  3 19:49:49.546: INFO: (6) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 29.587806ms)
    Oct  3 19:49:49.548: INFO: (6) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 31.607942ms)
    Oct  3 19:49:49.548: INFO: (6) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 31.370218ms)
    Oct  3 19:49:49.549: INFO: (6) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 32.213618ms)
    Oct  3 19:49:49.567: INFO: (7) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 18.029944ms)
    Oct  3 19:49:49.569: INFO: (7) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 18.43333ms)
    Oct  3 19:49:49.570: INFO: (7) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 18.974461ms)
    Oct  3 19:49:49.570: INFO: (7) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 19.423445ms)
    Oct  3 19:49:49.570: INFO: (7) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 19.795722ms)
    Oct  3 19:49:49.571: INFO: (7) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 21.485531ms)
    Oct  3 19:49:49.571: INFO: (7) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 20.861921ms)
    Oct  3 19:49:49.572: INFO: (7) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 20.589549ms)
    Oct  3 19:49:49.572: INFO: (7) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 21.989479ms)
    Oct  3 19:49:49.572: INFO: (7) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 21.311865ms)
    Oct  3 19:49:49.574: INFO: (7) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 24.848566ms)
    Oct  3 19:49:49.578: INFO: (7) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 28.199477ms)
    Oct  3 19:49:49.581: INFO: (7) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 30.661528ms)
    Oct  3 19:49:49.582: INFO: (7) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 32.8909ms)
    Oct  3 19:49:49.582: INFO: (7) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 31.371626ms)
    Oct  3 19:49:49.582: INFO: (7) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 32.377834ms)
    Oct  3 19:49:49.599: INFO: (8) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 16.23119ms)
    Oct  3 19:49:49.603: INFO: (8) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 19.58365ms)
    Oct  3 19:49:49.604: INFO: (8) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.254804ms)
    Oct  3 19:49:49.604: INFO: (8) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 20.603701ms)
    Oct  3 19:49:49.604: INFO: (8) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 21.041448ms)
    Oct  3 19:49:49.604: INFO: (8) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 20.601675ms)
    Oct  3 19:49:49.604: INFO: (8) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 20.652911ms)
    Oct  3 19:49:49.605: INFO: (8) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 21.614665ms)
    Oct  3 19:49:49.605: INFO: (8) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 21.856529ms)
    Oct  3 19:49:49.605: INFO: (8) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 22.667663ms)
    Oct  3 19:49:49.608: INFO: (8) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 25.48465ms)
    Oct  3 19:49:49.612: INFO: (8) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 29.335365ms)
    Oct  3 19:49:49.615: INFO: (8) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 31.596966ms)
    Oct  3 19:49:49.616: INFO: (8) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 32.191004ms)
    Oct  3 19:49:49.616: INFO: (8) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 32.414694ms)
    Oct  3 19:49:49.618: INFO: (8) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 34.221222ms)
    Oct  3 19:49:49.637: INFO: (9) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 18.191646ms)
    Oct  3 19:49:49.637: INFO: (9) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 18.17822ms)
    Oct  3 19:49:49.638: INFO: (9) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 19.186464ms)
    Oct  3 19:49:49.638: INFO: (9) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 19.300607ms)
    Oct  3 19:49:49.639: INFO: (9) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 20.140739ms)
    Oct  3 19:49:49.639: INFO: (9) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 21.339077ms)
    Oct  3 19:49:49.639: INFO: (9) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 20.257414ms)
    Oct  3 19:49:49.640: INFO: (9) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 21.887848ms)
    Oct  3 19:49:49.641: INFO: (9) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 23.538928ms)
    Oct  3 19:49:49.641: INFO: (9) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 23.108415ms)
    Oct  3 19:49:49.643: INFO: (9) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 25.517525ms)
    Oct  3 19:49:49.644: INFO: (9) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 26.008541ms)
    Oct  3 19:49:49.647: INFO: (9) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 28.429739ms)
    Oct  3 19:49:49.650: INFO: (9) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 32.14526ms)
    Oct  3 19:49:49.650: INFO: (9) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 31.286429ms)
    Oct  3 19:49:49.651: INFO: (9) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 32.595903ms)
    Oct  3 19:49:49.669: INFO: (10) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 17.725399ms)
    Oct  3 19:49:49.669: INFO: (10) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 17.183197ms)
    Oct  3 19:49:49.670: INFO: (10) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 17.944896ms)
    Oct  3 19:49:49.671: INFO: (10) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 18.807597ms)
    Oct  3 19:49:49.672: INFO: (10) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 19.96081ms)
    Oct  3 19:49:49.672: INFO: (10) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 20.136281ms)
    Oct  3 19:49:49.672: INFO: (10) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 19.553793ms)
    Oct  3 19:49:49.673: INFO: (10) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.104452ms)
    Oct  3 19:49:49.673: INFO: (10) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.572835ms)
    Oct  3 19:49:49.673: INFO: (10) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 20.519553ms)
    Oct  3 19:49:49.681: INFO: (10) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 29.210314ms)
    Oct  3 19:49:49.682: INFO: (10) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 29.535548ms)
    Oct  3 19:49:49.683: INFO: (10) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 30.39947ms)
    Oct  3 19:49:49.683: INFO: (10) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 31.465717ms)
    Oct  3 19:49:49.683: INFO: (10) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 31.686528ms)
    Oct  3 19:49:49.684: INFO: (10) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 31.156842ms)
    Oct  3 19:49:49.699: INFO: (11) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 15.422386ms)
    Oct  3 19:49:49.706: INFO: (11) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 21.927987ms)
    Oct  3 19:49:49.706: INFO: (11) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 21.944309ms)
    Oct  3 19:49:49.707: INFO: (11) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 22.647764ms)
    Oct  3 19:49:49.707: INFO: (11) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 23.042989ms)
    Oct  3 19:49:49.708: INFO: (11) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 23.491448ms)
    Oct  3 19:49:49.708: INFO: (11) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 23.1248ms)
    Oct  3 19:49:49.708: INFO: (11) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 23.416035ms)
    Oct  3 19:49:49.708: INFO: (11) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 22.852457ms)
    Oct  3 19:49:49.708: INFO: (11) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 22.967753ms)
    Oct  3 19:49:49.708: INFO: (11) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 23.621971ms)
    Oct  3 19:49:49.713: INFO: (11) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 28.540549ms)
    Oct  3 19:49:49.716: INFO: (11) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 32.017178ms)
    Oct  3 19:49:49.716: INFO: (11) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 31.849506ms)
    Oct  3 19:49:49.716: INFO: (11) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 31.793815ms)
    Oct  3 19:49:49.716: INFO: (11) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 32.066076ms)
    Oct  3 19:49:49.733: INFO: (12) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 16.650773ms)
    Oct  3 19:49:49.736: INFO: (12) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 19.19362ms)
    Oct  3 19:49:49.737: INFO: (12) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 19.638634ms)
    Oct  3 19:49:49.738: INFO: (12) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 20.887688ms)
    Oct  3 19:49:49.738: INFO: (12) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 21.019114ms)
    Oct  3 19:49:49.739: INFO: (12) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 21.487164ms)
    Oct  3 19:49:49.739: INFO: (12) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 21.449802ms)
    Oct  3 19:49:49.739: INFO: (12) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 21.878447ms)
    Oct  3 19:49:49.739: INFO: (12) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 22.012825ms)
    Oct  3 19:49:49.739: INFO: (12) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 22.504334ms)
    Oct  3 19:49:49.741: INFO: (12) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 24.243938ms)
    Oct  3 19:49:49.745: INFO: (12) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 28.28422ms)
    Oct  3 19:49:49.748: INFO: (12) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 31.018672ms)
    Oct  3 19:49:49.750: INFO: (12) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 32.698332ms)
    Oct  3 19:49:49.750: INFO: (12) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 33.02788ms)
    Oct  3 19:49:49.750: INFO: (12) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 33.057975ms)
    Oct  3 19:49:49.767: INFO: (13) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 17.211736ms)
    Oct  3 19:49:49.770: INFO: (13) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 19.328904ms)
    Oct  3 19:49:49.771: INFO: (13) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 20.226299ms)
    Oct  3 19:49:49.771: INFO: (13) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 20.588294ms)
    Oct  3 19:49:49.772: INFO: (13) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 21.453986ms)
    Oct  3 19:49:49.772: INFO: (13) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 21.468309ms)
    Oct  3 19:49:49.772: INFO: (13) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 21.76089ms)
    Oct  3 19:49:49.772: INFO: (13) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 21.705393ms)
    Oct  3 19:49:49.773: INFO: (13) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 22.977513ms)
    Oct  3 19:49:49.773: INFO: (13) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 22.718081ms)
    Oct  3 19:49:49.775: INFO: (13) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 24.560468ms)
    Oct  3 19:49:49.780: INFO: (13) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 29.702197ms)
    Oct  3 19:49:49.782: INFO: (13) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 31.43017ms)
    Oct  3 19:49:49.782: INFO: (13) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 31.80447ms)
    Oct  3 19:49:49.782: INFO: (13) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 32.17276ms)
    Oct  3 19:49:49.787: INFO: (13) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 36.426163ms)
    Oct  3 19:49:49.805: INFO: (14) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 18.241435ms)
    Oct  3 19:49:49.807: INFO: (14) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 19.185659ms)
    Oct  3 19:49:49.807: INFO: (14) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 19.775174ms)
    Oct  3 19:49:49.808: INFO: (14) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 20.828765ms)
    Oct  3 19:49:49.809: INFO: (14) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 21.398568ms)
    Oct  3 19:49:49.809: INFO: (14) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 21.945399ms)
    Oct  3 19:49:49.810: INFO: (14) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 22.692274ms)
    Oct  3 19:49:49.810: INFO: (14) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 22.472752ms)
    Oct  3 19:49:49.810: INFO: (14) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 22.133474ms)
    Oct  3 19:49:49.810: INFO: (14) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 23.149223ms)
    Oct  3 19:49:49.811: INFO: (14) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 23.642648ms)
    Oct  3 19:49:49.820: INFO: (14) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 32.85065ms)
    Oct  3 19:49:49.820: INFO: (14) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 32.667579ms)
    Oct  3 19:49:49.820: INFO: (14) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 32.951398ms)
    Oct  3 19:49:49.820: INFO: (14) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 32.847717ms)
    Oct  3 19:49:49.820: INFO: (14) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 33.204653ms)
    Oct  3 19:49:49.838: INFO: (15) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 17.86939ms)
    Oct  3 19:49:49.839: INFO: (15) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 18.965921ms)
    Oct  3 19:49:49.841: INFO: (15) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 20.747ms)
    Oct  3 19:49:49.842: INFO: (15) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 20.748385ms)
    Oct  3 19:49:49.842: INFO: (15) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.733461ms)
    Oct  3 19:49:49.842: INFO: (15) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.882716ms)
    Oct  3 19:49:49.843: INFO: (15) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 21.765076ms)
    Oct  3 19:49:49.843: INFO: (15) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 21.872559ms)
    Oct  3 19:49:49.843: INFO: (15) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 22.094062ms)
    Oct  3 19:49:49.843: INFO: (15) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 22.630828ms)
    Oct  3 19:49:49.846: INFO: (15) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 25.604006ms)
    Oct  3 19:49:49.850: INFO: (15) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 28.868466ms)
    Oct  3 19:49:49.855: INFO: (15) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 33.627942ms)
    Oct  3 19:49:49.855: INFO: (15) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 33.904498ms)
    Oct  3 19:49:49.855: INFO: (15) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 34.042924ms)
    Oct  3 19:49:49.855: INFO: (15) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 33.894595ms)
    Oct  3 19:49:49.872: INFO: (16) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 16.703732ms)
    Oct  3 19:49:49.876: INFO: (16) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.458211ms)
    Oct  3 19:49:49.876: INFO: (16) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 21.055571ms)
    Oct  3 19:49:49.876: INFO: (16) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 21.213577ms)
    Oct  3 19:49:49.876: INFO: (16) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 21.11209ms)
    Oct  3 19:49:49.876: INFO: (16) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 21.273241ms)
    Oct  3 19:49:49.877: INFO: (16) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 21.87591ms)
    Oct  3 19:49:49.879: INFO: (16) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 23.434155ms)
    Oct  3 19:49:49.879: INFO: (16) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 24.025705ms)
    Oct  3 19:49:49.880: INFO: (16) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 24.820788ms)
    Oct  3 19:49:49.882: INFO: (16) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 27.501003ms)
    Oct  3 19:49:49.884: INFO: (16) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 28.290567ms)
    Oct  3 19:49:49.885: INFO: (16) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 30.14764ms)
    Oct  3 19:49:49.885: INFO: (16) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 30.274381ms)
    Oct  3 19:49:49.903: INFO: (16) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 47.739615ms)
    Oct  3 19:49:49.903: INFO: (16) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 47.668923ms)
    Oct  3 19:49:49.920: INFO: (17) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 16.628092ms)
    Oct  3 19:49:49.923: INFO: (17) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 19.111589ms)
    Oct  3 19:49:49.924: INFO: (17) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 20.065833ms)
    Oct  3 19:49:49.924: INFO: (17) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.218912ms)
    Oct  3 19:49:49.925: INFO: (17) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 20.797878ms)
    Oct  3 19:49:49.925: INFO: (17) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 21.319411ms)
    Oct  3 19:49:49.925: INFO: (17) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 21.764561ms)
    Oct  3 19:49:49.925: INFO: (17) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 21.376701ms)
    Oct  3 19:49:49.928: INFO: (17) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 25.026708ms)
    Oct  3 19:49:49.932: INFO: (17) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 28.716571ms)
    Oct  3 19:49:49.934: INFO: (17) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 30.245431ms)
    Oct  3 19:49:49.935: INFO: (17) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 31.446424ms)
    Oct  3 19:49:49.935: INFO: (17) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 31.293071ms)
    Oct  3 19:49:49.942: INFO: (17) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 38.525852ms)
    Oct  3 19:49:49.942: INFO: (17) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 38.541798ms)
    Oct  3 19:49:49.942: INFO: (17) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 38.130275ms)
    Oct  3 19:49:49.960: INFO: (18) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 17.904055ms)
    Oct  3 19:49:49.964: INFO: (18) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 20.986878ms)
    Oct  3 19:49:49.965: INFO: (18) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 22.549092ms)
    Oct  3 19:49:49.965: INFO: (18) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 22.63491ms)
    Oct  3 19:49:49.965: INFO: (18) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 22.769785ms)
    Oct  3 19:49:49.966: INFO: (18) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 22.840707ms)
    Oct  3 19:49:49.967: INFO: (18) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 23.983433ms)
    Oct  3 19:49:49.967: INFO: (18) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 24.267648ms)
    Oct  3 19:49:49.967: INFO: (18) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 24.381228ms)
    Oct  3 19:49:49.967: INFO: (18) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 24.402357ms)
    Oct  3 19:49:49.969: INFO: (18) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 26.473409ms)
    Oct  3 19:49:49.972: INFO: (18) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 29.419209ms)
    Oct  3 19:49:49.975: INFO: (18) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 32.766732ms)
    Oct  3 19:49:49.975: INFO: (18) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 32.320064ms)
    Oct  3 19:49:49.976: INFO: (18) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 33.088947ms)
    Oct  3 19:49:49.976: INFO: (18) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 33.245461ms)
    Oct  3 19:49:49.997: INFO: (19) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:462/proxy/: tls qux (200; 20.907069ms)
    Oct  3 19:49:50.000: INFO: (19) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 22.121807ms)
    Oct  3 19:49:50.000: INFO: (19) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 23.655459ms)
    Oct  3 19:49:50.000: INFO: (19) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:162/proxy/: bar (200; 22.696883ms)
    Oct  3 19:49:50.001: INFO: (19) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">test<... (200; 24.763254ms)
    Oct  3 19:49:50.001: INFO: (19) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg/proxy/rewriteme">test</a> (200; 24.216134ms)
    Oct  3 19:49:50.002: INFO: (19) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:460/proxy/: tls baz (200; 25.023109ms)
    Oct  3 19:49:50.002: INFO: (19) /api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/http:proxy-service-5tmnz-4xslg:1080/proxy/rewriteme">... (200; 25.335556ms)
    Oct  3 19:49:50.002: INFO: (19) /api/v1/namespaces/proxy-4984/pods/proxy-service-5tmnz-4xslg:160/proxy/: foo (200; 24.987997ms)
    Oct  3 19:49:50.002: INFO: (19) /api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/: <a href="/api/v1/namespaces/proxy-4984/pods/https:proxy-service-5tmnz-4xslg:443/proxy/tlsrewritem... (200; 25.222248ms)
    Oct  3 19:49:50.007: INFO: (19) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname1/proxy/: foo (200; 30.052163ms)
    Oct  3 19:49:50.009: INFO: (19) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname2/proxy/: tls qux (200; 32.396635ms)
    Oct  3 19:49:50.010: INFO: (19) /api/v1/namespaces/proxy-4984/services/proxy-service-5tmnz:portname2/proxy/: bar (200; 32.885451ms)
    Oct  3 19:49:50.011: INFO: (19) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname1/proxy/: foo (200; 33.312765ms)
    Oct  3 19:49:50.011: INFO: (19) /api/v1/namespaces/proxy-4984/services/http:proxy-service-5tmnz:portname2/proxy/: bar (200; 34.759266ms)
    Oct  3 19:49:50.011: INFO: (19) /api/v1/namespaces/proxy-4984/services/https:proxy-service-5tmnz:tlsportname1/proxy/: tls baz (200; 34.659181ms)
    STEP: deleting ReplicationController proxy-service-5tmnz in namespace proxy-4984, will wait for the garbage collector to delete the pods 10/03/22 19:49:50.012
    Oct  3 19:49:50.097: INFO: Deleting ReplicationController proxy-service-5tmnz took: 22.3187ms
    Oct  3 19:49:50.198: INFO: Terminating ReplicationController proxy-service-5tmnz pods took: 101.280865ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Oct  3 19:49:52.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-4984" for this suite. 10/03/22 19:49:52.815
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:49:52.863
Oct  3 19:49:52.863: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir 10/03/22 19:49:52.865
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:49:52.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:49:52.909
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 10/03/22 19:49:52.92
Oct  3 19:49:52.941: INFO: Waiting up to 5m0s for pod "pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff" in namespace "emptydir-7774" to be "Succeeded or Failed"
Oct  3 19:49:52.953: INFO: Pod "pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff": Phase="Pending", Reason="", readiness=false. Elapsed: 12.082794ms
Oct  3 19:49:54.966: INFO: Pod "pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff": Phase="Running", Reason="", readiness=true. Elapsed: 2.024534915s
Oct  3 19:49:56.965: INFO: Pod "pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff": Phase="Running", Reason="", readiness=false. Elapsed: 4.024274357s
Oct  3 19:49:58.970: INFO: Pod "pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029144957s
STEP: Saw pod success 10/03/22 19:49:58.97
Oct  3 19:49:58.971: INFO: Pod "pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff" satisfied condition "Succeeded or Failed"
Oct  3 19:49:58.996: INFO: Trying to get logs from node 10.63.128.3 pod pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff container test-container: <nil>
STEP: delete the pod 10/03/22 19:49:59.022
Oct  3 19:49:59.049: INFO: Waiting for pod pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff to disappear
Oct  3 19:49:59.059: INFO: Pod pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Oct  3 19:49:59.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7774" for this suite. 10/03/22 19:49:59.074
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":115,"skipped":2329,"failed":0}
------------------------------
• [SLOW TEST] [6.229 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:49:52.863
    Oct  3 19:49:52.863: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir 10/03/22 19:49:52.865
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:49:52.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:49:52.909
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 10/03/22 19:49:52.92
    Oct  3 19:49:52.941: INFO: Waiting up to 5m0s for pod "pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff" in namespace "emptydir-7774" to be "Succeeded or Failed"
    Oct  3 19:49:52.953: INFO: Pod "pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff": Phase="Pending", Reason="", readiness=false. Elapsed: 12.082794ms
    Oct  3 19:49:54.966: INFO: Pod "pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff": Phase="Running", Reason="", readiness=true. Elapsed: 2.024534915s
    Oct  3 19:49:56.965: INFO: Pod "pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff": Phase="Running", Reason="", readiness=false. Elapsed: 4.024274357s
    Oct  3 19:49:58.970: INFO: Pod "pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029144957s
    STEP: Saw pod success 10/03/22 19:49:58.97
    Oct  3 19:49:58.971: INFO: Pod "pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff" satisfied condition "Succeeded or Failed"
    Oct  3 19:49:58.996: INFO: Trying to get logs from node 10.63.128.3 pod pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff container test-container: <nil>
    STEP: delete the pod 10/03/22 19:49:59.022
    Oct  3 19:49:59.049: INFO: Waiting for pod pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff to disappear
    Oct  3 19:49:59.059: INFO: Pod pod-3e7396c6-5c87-4cc8-b44f-b11f83f179ff no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Oct  3 19:49:59.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7774" for this suite. 10/03/22 19:49:59.074
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:49:59.098
Oct  3 19:49:59.099: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename svc-latency 10/03/22 19:49:59.1
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:49:59.135
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:49:59.145
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Oct  3 19:49:59.155: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: creating replication controller svc-latency-rc in namespace svc-latency-4943 10/03/22 19:49:59.156
I1003 19:49:59.173493      22 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4943, replica count: 1
I1003 19:50:00.224584      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1003 19:50:01.224859      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1003 19:50:02.225514      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  3 19:50:02.375: INFO: Created: latency-svc-kwtsr
Oct  3 19:50:02.385: INFO: Got endpoints: latency-svc-kwtsr [58.828098ms]
Oct  3 19:50:02.415: INFO: Created: latency-svc-gs744
Oct  3 19:50:02.427: INFO: Got endpoints: latency-svc-gs744 [42.135193ms]
Oct  3 19:50:02.438: INFO: Created: latency-svc-thzw7
Oct  3 19:50:02.446: INFO: Got endpoints: latency-svc-thzw7 [60.990458ms]
Oct  3 19:50:02.453: INFO: Created: latency-svc-bmphs
Oct  3 19:50:02.466: INFO: Got endpoints: latency-svc-bmphs [80.636945ms]
Oct  3 19:50:02.470: INFO: Created: latency-svc-2jkmn
Oct  3 19:50:02.481: INFO: Got endpoints: latency-svc-2jkmn [95.536333ms]
Oct  3 19:50:02.487: INFO: Created: latency-svc-8758p
Oct  3 19:50:02.498: INFO: Got endpoints: latency-svc-8758p [112.721915ms]
Oct  3 19:50:02.504: INFO: Created: latency-svc-78ln2
Oct  3 19:50:02.516: INFO: Got endpoints: latency-svc-78ln2 [131.044718ms]
Oct  3 19:50:02.521: INFO: Created: latency-svc-7k62s
Oct  3 19:50:02.538: INFO: Got endpoints: latency-svc-7k62s [151.904228ms]
Oct  3 19:50:02.577: INFO: Created: latency-svc-mkq5t
Oct  3 19:50:02.577: INFO: Created: latency-svc-mljjz
Oct  3 19:50:02.589: INFO: Got endpoints: latency-svc-mljjz [202.725998ms]
Oct  3 19:50:02.589: INFO: Created: latency-svc-cgq7h
Oct  3 19:50:02.590: INFO: Got endpoints: latency-svc-mkq5t [203.736158ms]
Oct  3 19:50:02.598: INFO: Got endpoints: latency-svc-cgq7h [211.519548ms]
Oct  3 19:50:02.598: INFO: Created: latency-svc-tdx2r
Oct  3 19:50:02.625: INFO: Got endpoints: latency-svc-tdx2r [239.770908ms]
Oct  3 19:50:02.632: INFO: Created: latency-svc-nq5pf
Oct  3 19:50:02.640: INFO: Got endpoints: latency-svc-nq5pf [253.889519ms]
Oct  3 19:50:02.648: INFO: Created: latency-svc-wxstv
Oct  3 19:50:02.658: INFO: Got endpoints: latency-svc-wxstv [272.351624ms]
Oct  3 19:50:02.665: INFO: Created: latency-svc-f8r7v
Oct  3 19:50:02.675: INFO: Got endpoints: latency-svc-f8r7v [289.11785ms]
Oct  3 19:50:02.684: INFO: Created: latency-svc-87ssr
Oct  3 19:50:02.699: INFO: Got endpoints: latency-svc-87ssr [313.734134ms]
Oct  3 19:50:02.701: INFO: Created: latency-svc-mg9jk
Oct  3 19:50:02.707: INFO: Got endpoints: latency-svc-mg9jk [279.624348ms]
Oct  3 19:50:02.713: INFO: Created: latency-svc-ptp2q
Oct  3 19:50:02.724: INFO: Got endpoints: latency-svc-ptp2q [277.618828ms]
Oct  3 19:50:02.730: INFO: Created: latency-svc-c9vqw
Oct  3 19:50:02.741: INFO: Got endpoints: latency-svc-c9vqw [275.556269ms]
Oct  3 19:50:02.748: INFO: Created: latency-svc-dv2t4
Oct  3 19:50:02.759: INFO: Got endpoints: latency-svc-dv2t4 [278.537345ms]
Oct  3 19:50:02.766: INFO: Created: latency-svc-2nw64
Oct  3 19:50:02.787: INFO: Got endpoints: latency-svc-2nw64 [288.999298ms]
Oct  3 19:50:02.794: INFO: Created: latency-svc-jzwbx
Oct  3 19:50:02.805: INFO: Got endpoints: latency-svc-jzwbx [288.124998ms]
Oct  3 19:50:02.810: INFO: Created: latency-svc-jq27j
Oct  3 19:50:02.825: INFO: Got endpoints: latency-svc-jq27j [286.864574ms]
Oct  3 19:50:02.830: INFO: Created: latency-svc-gv9nc
Oct  3 19:50:02.842: INFO: Got endpoints: latency-svc-gv9nc [252.845729ms]
Oct  3 19:50:02.850: INFO: Created: latency-svc-thmq5
Oct  3 19:50:02.861: INFO: Got endpoints: latency-svc-thmq5 [271.461946ms]
Oct  3 19:50:02.870: INFO: Created: latency-svc-5j7bp
Oct  3 19:50:02.883: INFO: Got endpoints: latency-svc-5j7bp [285.271406ms]
Oct  3 19:50:02.888: INFO: Created: latency-svc-bjh5v
Oct  3 19:50:02.899: INFO: Got endpoints: latency-svc-bjh5v [273.327846ms]
Oct  3 19:50:02.904: INFO: Created: latency-svc-6jvxk
Oct  3 19:50:02.923: INFO: Got endpoints: latency-svc-6jvxk [282.14681ms]
Oct  3 19:50:02.930: INFO: Created: latency-svc-r6pcj
Oct  3 19:50:02.942: INFO: Got endpoints: latency-svc-r6pcj [284.051051ms]
Oct  3 19:50:02.948: INFO: Created: latency-svc-n865f
Oct  3 19:50:02.959: INFO: Got endpoints: latency-svc-n865f [283.40485ms]
Oct  3 19:50:02.965: INFO: Created: latency-svc-fc9wh
Oct  3 19:50:02.983: INFO: Got endpoints: latency-svc-fc9wh [284.605564ms]
Oct  3 19:50:03.003: INFO: Created: latency-svc-qpdp5
Oct  3 19:50:03.007: INFO: Created: latency-svc-nmtcr
Oct  3 19:50:03.032: INFO: Got endpoints: latency-svc-qpdp5 [325.42234ms]
Oct  3 19:50:03.032: INFO: Got endpoints: latency-svc-nmtcr [308.30377ms]
Oct  3 19:50:03.037: INFO: Created: latency-svc-dmk6f
Oct  3 19:50:03.046: INFO: Got endpoints: latency-svc-dmk6f [304.582291ms]
Oct  3 19:50:03.050: INFO: Created: latency-svc-nlfxs
Oct  3 19:50:03.061: INFO: Got endpoints: latency-svc-nlfxs [301.007333ms]
Oct  3 19:50:03.065: INFO: Created: latency-svc-5vnqx
Oct  3 19:50:03.076: INFO: Got endpoints: latency-svc-5vnqx [289.044294ms]
Oct  3 19:50:03.082: INFO: Created: latency-svc-vtct7
Oct  3 19:50:03.092: INFO: Got endpoints: latency-svc-vtct7 [287.641764ms]
Oct  3 19:50:03.096: INFO: Created: latency-svc-vc2pj
Oct  3 19:50:03.111: INFO: Got endpoints: latency-svc-vc2pj [286.517941ms]
Oct  3 19:50:03.117: INFO: Created: latency-svc-8rkwx
Oct  3 19:50:03.126: INFO: Got endpoints: latency-svc-8rkwx [283.375653ms]
Oct  3 19:50:03.136: INFO: Created: latency-svc-4qh5b
Oct  3 19:50:03.148: INFO: Got endpoints: latency-svc-4qh5b [286.498783ms]
Oct  3 19:50:03.152: INFO: Created: latency-svc-jxgjz
Oct  3 19:50:03.163: INFO: Got endpoints: latency-svc-jxgjz [279.468379ms]
Oct  3 19:50:03.173: INFO: Created: latency-svc-8ct47
Oct  3 19:50:03.181: INFO: Got endpoints: latency-svc-8ct47 [281.798629ms]
Oct  3 19:50:03.186: INFO: Created: latency-svc-5xqvr
Oct  3 19:50:03.196: INFO: Got endpoints: latency-svc-5xqvr [272.959163ms]
Oct  3 19:50:03.203: INFO: Created: latency-svc-pchqp
Oct  3 19:50:03.234: INFO: Got endpoints: latency-svc-pchqp [291.826371ms]
Oct  3 19:50:03.242: INFO: Created: latency-svc-rhlfb
Oct  3 19:50:03.252: INFO: Got endpoints: latency-svc-rhlfb [293.517797ms]
Oct  3 19:50:03.258: INFO: Created: latency-svc-sll6p
Oct  3 19:50:03.267: INFO: Got endpoints: latency-svc-sll6p [283.852689ms]
Oct  3 19:50:03.274: INFO: Created: latency-svc-lpn2q
Oct  3 19:50:03.284: INFO: Got endpoints: latency-svc-lpn2q [251.852715ms]
Oct  3 19:50:03.289: INFO: Created: latency-svc-7zxzn
Oct  3 19:50:03.311: INFO: Got endpoints: latency-svc-7zxzn [278.603032ms]
Oct  3 19:50:03.311: INFO: Created: latency-svc-wptzm
Oct  3 19:50:03.320: INFO: Got endpoints: latency-svc-wptzm [274.664091ms]
Oct  3 19:50:03.327: INFO: Created: latency-svc-rmk5t
Oct  3 19:50:03.336: INFO: Got endpoints: latency-svc-rmk5t [274.904688ms]
Oct  3 19:50:03.343: INFO: Created: latency-svc-kxb76
Oct  3 19:50:03.364: INFO: Got endpoints: latency-svc-kxb76 [287.121923ms]
Oct  3 19:50:03.371: INFO: Created: latency-svc-97hnp
Oct  3 19:50:03.382: INFO: Got endpoints: latency-svc-97hnp [289.762014ms]
Oct  3 19:50:03.388: INFO: Created: latency-svc-h7645
Oct  3 19:50:03.399: INFO: Got endpoints: latency-svc-h7645 [287.318491ms]
Oct  3 19:50:03.403: INFO: Created: latency-svc-mcj8b
Oct  3 19:50:03.414: INFO: Got endpoints: latency-svc-mcj8b [288.323363ms]
Oct  3 19:50:03.420: INFO: Created: latency-svc-rtn9w
Oct  3 19:50:03.431: INFO: Got endpoints: latency-svc-rtn9w [283.651008ms]
Oct  3 19:50:03.440: INFO: Created: latency-svc-ncrjq
Oct  3 19:50:03.467: INFO: Got endpoints: latency-svc-ncrjq [304.203795ms]
Oct  3 19:50:03.483: INFO: Created: latency-svc-rxqbd
Oct  3 19:50:03.506: INFO: Got endpoints: latency-svc-rxqbd [324.467536ms]
Oct  3 19:50:03.506: INFO: Created: latency-svc-52ktx
Oct  3 19:50:03.513: INFO: Got endpoints: latency-svc-52ktx [317.247689ms]
Oct  3 19:50:03.517: INFO: Created: latency-svc-b4v54
Oct  3 19:50:03.527: INFO: Got endpoints: latency-svc-b4v54 [292.475386ms]
Oct  3 19:50:03.532: INFO: Created: latency-svc-8z27k
Oct  3 19:50:03.543: INFO: Got endpoints: latency-svc-8z27k [290.946997ms]
Oct  3 19:50:03.549: INFO: Created: latency-svc-7tl4d
Oct  3 19:50:03.558: INFO: Got endpoints: latency-svc-7tl4d [290.525663ms]
Oct  3 19:50:03.565: INFO: Created: latency-svc-frmbz
Oct  3 19:50:03.573: INFO: Got endpoints: latency-svc-frmbz [288.552205ms]
Oct  3 19:50:03.581: INFO: Created: latency-svc-mpj7t
Oct  3 19:50:03.591: INFO: Got endpoints: latency-svc-mpj7t [279.473672ms]
Oct  3 19:50:03.595: INFO: Created: latency-svc-qr229
Oct  3 19:50:03.603: INFO: Got endpoints: latency-svc-qr229 [282.922977ms]
Oct  3 19:50:03.610: INFO: Created: latency-svc-gl645
Oct  3 19:50:03.620: INFO: Got endpoints: latency-svc-gl645 [284.549958ms]
Oct  3 19:50:03.627: INFO: Created: latency-svc-b4nsq
Oct  3 19:50:03.637: INFO: Got endpoints: latency-svc-b4nsq [272.744268ms]
Oct  3 19:50:03.639: INFO: Created: latency-svc-lghx8
Oct  3 19:50:03.650: INFO: Got endpoints: latency-svc-lghx8 [267.458148ms]
Oct  3 19:50:03.653: INFO: Created: latency-svc-wdlkj
Oct  3 19:50:03.672: INFO: Got endpoints: latency-svc-wdlkj [273.28506ms]
Oct  3 19:50:03.673: INFO: Created: latency-svc-wtpq8
Oct  3 19:50:03.683: INFO: Got endpoints: latency-svc-wtpq8 [269.055945ms]
Oct  3 19:50:03.687: INFO: Created: latency-svc-8f7fg
Oct  3 19:50:03.697: INFO: Got endpoints: latency-svc-8f7fg [265.736957ms]
Oct  3 19:50:03.700: INFO: Created: latency-svc-7g2xl
Oct  3 19:50:03.711: INFO: Got endpoints: latency-svc-7g2xl [244.184653ms]
Oct  3 19:50:03.717: INFO: Created: latency-svc-dl697
Oct  3 19:50:03.724: INFO: Got endpoints: latency-svc-dl697 [218.120087ms]
Oct  3 19:50:03.732: INFO: Created: latency-svc-hrdlp
Oct  3 19:50:03.742: INFO: Got endpoints: latency-svc-hrdlp [228.596121ms]
Oct  3 19:50:03.952: INFO: Created: latency-svc-5q67z
Oct  3 19:50:03.952: INFO: Created: latency-svc-g5q46
Oct  3 19:50:03.961: INFO: Created: latency-svc-6wb77
Oct  3 19:50:03.961: INFO: Created: latency-svc-jqgzg
Oct  3 19:50:03.961: INFO: Created: latency-svc-ssn25
Oct  3 19:50:03.962: INFO: Created: latency-svc-snbfh
Oct  3 19:50:03.962: INFO: Created: latency-svc-gg78w
Oct  3 19:50:03.962: INFO: Created: latency-svc-j4xsg
Oct  3 19:50:03.962: INFO: Created: latency-svc-wngfw
Oct  3 19:50:03.962: INFO: Created: latency-svc-nvcv9
Oct  3 19:50:03.963: INFO: Created: latency-svc-g29xc
Oct  3 19:50:03.963: INFO: Created: latency-svc-62fcc
Oct  3 19:50:03.963: INFO: Created: latency-svc-rdkhd
Oct  3 19:50:03.963: INFO: Created: latency-svc-mswph
Oct  3 19:50:03.964: INFO: Created: latency-svc-nbltp
Oct  3 19:50:03.975: INFO: Got endpoints: latency-svc-g5q46 [371.381786ms]
Oct  3 19:50:03.975: INFO: Got endpoints: latency-svc-rdkhd [302.739514ms]
Oct  3 19:50:03.975: INFO: Got endpoints: latency-svc-5q67z [431.531159ms]
Oct  3 19:50:03.978: INFO: Got endpoints: latency-svc-snbfh [294.241826ms]
Oct  3 19:50:03.978: INFO: Got endpoints: latency-svc-wngfw [261.708364ms]
Oct  3 19:50:03.992: INFO: Got endpoints: latency-svc-jqgzg [355.719267ms]
Oct  3 19:50:03.993: INFO: Got endpoints: latency-svc-nvcv9 [295.372904ms]
Oct  3 19:50:03.995: INFO: Got endpoints: latency-svc-ssn25 [345.292075ms]
Oct  3 19:50:03.995: INFO: Got endpoints: latency-svc-62fcc [468.177969ms]
Oct  3 19:50:03.995: INFO: Got endpoints: latency-svc-gg78w [421.670054ms]
Oct  3 19:50:04.004: INFO: Got endpoints: latency-svc-6wb77 [413.257449ms]
Oct  3 19:50:04.007: INFO: Got endpoints: latency-svc-nbltp [282.955788ms]
Oct  3 19:50:04.009: INFO: Created: latency-svc-p45c2
Oct  3 19:50:04.010: INFO: Got endpoints: latency-svc-j4xsg [451.647721ms]
Oct  3 19:50:04.016: INFO: Got endpoints: latency-svc-mswph [273.815937ms]
Oct  3 19:50:04.016: INFO: Got endpoints: latency-svc-g29xc [395.484989ms]
Oct  3 19:50:04.022: INFO: Got endpoints: latency-svc-p45c2 [46.95785ms]
Oct  3 19:50:04.030: INFO: Created: latency-svc-2vl57
Oct  3 19:50:04.041: INFO: Got endpoints: latency-svc-2vl57 [66.523457ms]
Oct  3 19:50:04.051: INFO: Created: latency-svc-9mj55
Oct  3 19:50:04.061: INFO: Got endpoints: latency-svc-9mj55 [85.561616ms]
Oct  3 19:50:04.066: INFO: Created: latency-svc-9nr87
Oct  3 19:50:04.076: INFO: Got endpoints: latency-svc-9nr87 [97.858992ms]
Oct  3 19:50:04.083: INFO: Created: latency-svc-87t8r
Oct  3 19:50:04.092: INFO: Got endpoints: latency-svc-87t8r [114.035364ms]
Oct  3 19:50:04.144: INFO: Created: latency-svc-cq5g9
Oct  3 19:50:04.154: INFO: Got endpoints: latency-svc-cq5g9 [161.293212ms]
Oct  3 19:50:04.158: INFO: Created: latency-svc-4phk9
Oct  3 19:50:04.169: INFO: Got endpoints: latency-svc-4phk9 [176.254947ms]
Oct  3 19:50:04.175: INFO: Created: latency-svc-7t5gt
Oct  3 19:50:04.187: INFO: Got endpoints: latency-svc-7t5gt [191.807241ms]
Oct  3 19:50:04.189: INFO: Created: latency-svc-fm4x4
Oct  3 19:50:04.197: INFO: Got endpoints: latency-svc-fm4x4 [201.644647ms]
Oct  3 19:50:04.203: INFO: Created: latency-svc-7zjk2
Oct  3 19:50:04.214: INFO: Got endpoints: latency-svc-7zjk2 [217.747519ms]
Oct  3 19:50:04.218: INFO: Created: latency-svc-428xt
Oct  3 19:50:04.228: INFO: Got endpoints: latency-svc-428xt [224.050633ms]
Oct  3 19:50:04.233: INFO: Created: latency-svc-vr9tf
Oct  3 19:50:04.242: INFO: Got endpoints: latency-svc-vr9tf [234.903738ms]
Oct  3 19:50:04.251: INFO: Created: latency-svc-rhq4h
Oct  3 19:50:04.262: INFO: Got endpoints: latency-svc-rhq4h [251.723533ms]
Oct  3 19:50:04.266: INFO: Created: latency-svc-qfjf8
Oct  3 19:50:04.276: INFO: Got endpoints: latency-svc-qfjf8 [260.695083ms]
Oct  3 19:50:04.284: INFO: Created: latency-svc-fhzs7
Oct  3 19:50:04.295: INFO: Got endpoints: latency-svc-fhzs7 [279.266505ms]
Oct  3 19:50:04.296: INFO: Created: latency-svc-r6vgv
Oct  3 19:50:04.312: INFO: Got endpoints: latency-svc-r6vgv [289.659355ms]
Oct  3 19:50:04.316: INFO: Created: latency-svc-jkfjm
Oct  3 19:50:04.330: INFO: Got endpoints: latency-svc-jkfjm [288.257076ms]
Oct  3 19:50:04.336: INFO: Created: latency-svc-j74bg
Oct  3 19:50:04.346: INFO: Got endpoints: latency-svc-j74bg [285.193497ms]
Oct  3 19:50:04.353: INFO: Created: latency-svc-dtgcw
Oct  3 19:50:04.364: INFO: Got endpoints: latency-svc-dtgcw [288.197813ms]
Oct  3 19:50:04.367: INFO: Created: latency-svc-6dfk8
Oct  3 19:50:04.378: INFO: Got endpoints: latency-svc-6dfk8 [286.063169ms]
Oct  3 19:50:04.388: INFO: Created: latency-svc-gqftp
Oct  3 19:50:04.402: INFO: Got endpoints: latency-svc-gqftp [248.166761ms]
Oct  3 19:50:04.408: INFO: Created: latency-svc-c794h
Oct  3 19:50:04.418: INFO: Got endpoints: latency-svc-c794h [249.142529ms]
Oct  3 19:50:04.423: INFO: Created: latency-svc-f4jfv
Oct  3 19:50:04.434: INFO: Got endpoints: latency-svc-f4jfv [246.757876ms]
Oct  3 19:50:04.441: INFO: Created: latency-svc-8j5p8
Oct  3 19:50:04.458: INFO: Got endpoints: latency-svc-8j5p8 [260.708444ms]
Oct  3 19:50:04.466: INFO: Created: latency-svc-mw9f5
Oct  3 19:50:04.476: INFO: Got endpoints: latency-svc-mw9f5 [262.504364ms]
Oct  3 19:50:04.483: INFO: Created: latency-svc-2kq9z
Oct  3 19:50:04.497: INFO: Got endpoints: latency-svc-2kq9z [268.36774ms]
Oct  3 19:50:04.504: INFO: Created: latency-svc-6dnpl
Oct  3 19:50:04.514: INFO: Got endpoints: latency-svc-6dnpl [272.248631ms]
Oct  3 19:50:04.521: INFO: Created: latency-svc-x6c9q
Oct  3 19:50:04.529: INFO: Got endpoints: latency-svc-x6c9q [267.599079ms]
Oct  3 19:50:04.534: INFO: Created: latency-svc-vh8mc
Oct  3 19:50:04.544: INFO: Got endpoints: latency-svc-vh8mc [267.945453ms]
Oct  3 19:50:04.551: INFO: Created: latency-svc-m428s
Oct  3 19:50:04.562: INFO: Got endpoints: latency-svc-m428s [266.786297ms]
Oct  3 19:50:04.567: INFO: Created: latency-svc-ss67q
Oct  3 19:50:04.578: INFO: Got endpoints: latency-svc-ss67q [266.446729ms]
Oct  3 19:50:04.586: INFO: Created: latency-svc-lqrt6
Oct  3 19:50:04.598: INFO: Got endpoints: latency-svc-lqrt6 [267.688858ms]
Oct  3 19:50:04.603: INFO: Created: latency-svc-vmdqz
Oct  3 19:50:04.614: INFO: Got endpoints: latency-svc-vmdqz [267.290407ms]
Oct  3 19:50:04.621: INFO: Created: latency-svc-whlsq
Oct  3 19:50:04.632: INFO: Got endpoints: latency-svc-whlsq [267.836549ms]
Oct  3 19:50:04.638: INFO: Created: latency-svc-znmf7
Oct  3 19:50:04.649: INFO: Got endpoints: latency-svc-znmf7 [271.050069ms]
Oct  3 19:50:04.655: INFO: Created: latency-svc-84fx6
Oct  3 19:50:04.665: INFO: Got endpoints: latency-svc-84fx6 [262.259779ms]
Oct  3 19:50:04.672: INFO: Created: latency-svc-p8kfc
Oct  3 19:50:04.682: INFO: Got endpoints: latency-svc-p8kfc [263.593674ms]
Oct  3 19:50:04.686: INFO: Created: latency-svc-gz6s8
Oct  3 19:50:04.698: INFO: Got endpoints: latency-svc-gz6s8 [263.510999ms]
Oct  3 19:50:04.702: INFO: Created: latency-svc-nhbzg
Oct  3 19:50:04.712: INFO: Got endpoints: latency-svc-nhbzg [253.79392ms]
Oct  3 19:50:04.719: INFO: Created: latency-svc-48nxl
Oct  3 19:50:04.728: INFO: Got endpoints: latency-svc-48nxl [251.521727ms]
Oct  3 19:50:04.740: INFO: Created: latency-svc-sjxsh
Oct  3 19:50:04.751: INFO: Got endpoints: latency-svc-sjxsh [254.654584ms]
Oct  3 19:50:04.757: INFO: Created: latency-svc-zn6ft
Oct  3 19:50:04.767: INFO: Got endpoints: latency-svc-zn6ft [253.070839ms]
Oct  3 19:50:04.772: INFO: Created: latency-svc-k8h7s
Oct  3 19:50:04.782: INFO: Got endpoints: latency-svc-k8h7s [252.692292ms]
Oct  3 19:50:04.786: INFO: Created: latency-svc-wgz9w
Oct  3 19:50:04.795: INFO: Got endpoints: latency-svc-wgz9w [251.001644ms]
Oct  3 19:50:04.800: INFO: Created: latency-svc-vm48z
Oct  3 19:50:04.809: INFO: Got endpoints: latency-svc-vm48z [246.959655ms]
Oct  3 19:50:04.816: INFO: Created: latency-svc-6d92q
Oct  3 19:50:04.827: INFO: Got endpoints: latency-svc-6d92q [247.894034ms]
Oct  3 19:50:04.833: INFO: Created: latency-svc-rl47q
Oct  3 19:50:04.844: INFO: Got endpoints: latency-svc-rl47q [246.002194ms]
Oct  3 19:50:04.853: INFO: Created: latency-svc-hw5jk
Oct  3 19:50:04.861: INFO: Got endpoints: latency-svc-hw5jk [246.234193ms]
Oct  3 19:50:04.865: INFO: Created: latency-svc-j4h86
Oct  3 19:50:04.876: INFO: Got endpoints: latency-svc-j4h86 [243.412817ms]
Oct  3 19:50:04.882: INFO: Created: latency-svc-qts76
Oct  3 19:50:04.894: INFO: Got endpoints: latency-svc-qts76 [244.072893ms]
Oct  3 19:50:04.908: INFO: Created: latency-svc-nwg7v
Oct  3 19:50:04.923: INFO: Created: latency-svc-xt4qg
Oct  3 19:50:04.923: INFO: Got endpoints: latency-svc-nwg7v [258.293075ms]
Oct  3 19:50:04.933: INFO: Got endpoints: latency-svc-xt4qg [250.851799ms]
Oct  3 19:50:04.933: INFO: Created: latency-svc-j76dm
Oct  3 19:50:04.945: INFO: Got endpoints: latency-svc-j76dm [246.740416ms]
Oct  3 19:50:04.951: INFO: Created: latency-svc-66g2v
Oct  3 19:50:04.963: INFO: Got endpoints: latency-svc-66g2v [250.973422ms]
Oct  3 19:50:04.966: INFO: Created: latency-svc-r8f5g
Oct  3 19:50:04.975: INFO: Got endpoints: latency-svc-r8f5g [247.294915ms]
Oct  3 19:50:04.981: INFO: Created: latency-svc-rrbgj
Oct  3 19:50:04.992: INFO: Got endpoints: latency-svc-rrbgj [240.881658ms]
Oct  3 19:50:04.997: INFO: Created: latency-svc-dggj2
Oct  3 19:50:05.009: INFO: Got endpoints: latency-svc-dggj2 [242.13057ms]
Oct  3 19:50:05.016: INFO: Created: latency-svc-wfwpb
Oct  3 19:50:05.026: INFO: Got endpoints: latency-svc-wfwpb [243.620221ms]
Oct  3 19:50:05.032: INFO: Created: latency-svc-lrw76
Oct  3 19:50:05.040: INFO: Got endpoints: latency-svc-lrw76 [244.715422ms]
Oct  3 19:50:05.048: INFO: Created: latency-svc-h6h5q
Oct  3 19:50:05.058: INFO: Got endpoints: latency-svc-h6h5q [249.01184ms]
Oct  3 19:50:05.062: INFO: Created: latency-svc-cz5mx
Oct  3 19:50:05.073: INFO: Got endpoints: latency-svc-cz5mx [245.521858ms]
Oct  3 19:50:05.080: INFO: Created: latency-svc-2vrmf
Oct  3 19:50:05.090: INFO: Got endpoints: latency-svc-2vrmf [245.756789ms]
Oct  3 19:50:05.096: INFO: Created: latency-svc-tcc5v
Oct  3 19:50:05.106: INFO: Got endpoints: latency-svc-tcc5v [245.136845ms]
Oct  3 19:50:05.127: INFO: Created: latency-svc-b2hn9
Oct  3 19:50:05.135: INFO: Got endpoints: latency-svc-b2hn9 [259.62366ms]
Oct  3 19:50:05.142: INFO: Created: latency-svc-t848d
Oct  3 19:50:05.151: INFO: Got endpoints: latency-svc-t848d [257.439121ms]
Oct  3 19:50:05.157: INFO: Created: latency-svc-f79f8
Oct  3 19:50:05.166: INFO: Got endpoints: latency-svc-f79f8 [242.572321ms]
Oct  3 19:50:05.172: INFO: Created: latency-svc-c7kmd
Oct  3 19:50:05.183: INFO: Got endpoints: latency-svc-c7kmd [249.910574ms]
Oct  3 19:50:05.186: INFO: Created: latency-svc-qzrlm
Oct  3 19:50:05.197: INFO: Got endpoints: latency-svc-qzrlm [252.052372ms]
Oct  3 19:50:05.204: INFO: Created: latency-svc-chzg6
Oct  3 19:50:05.214: INFO: Got endpoints: latency-svc-chzg6 [251.574019ms]
Oct  3 19:50:05.223: INFO: Created: latency-svc-qfz9x
Oct  3 19:50:05.235: INFO: Got endpoints: latency-svc-qfz9x [259.587698ms]
Oct  3 19:50:05.241: INFO: Created: latency-svc-drmsg
Oct  3 19:50:05.276: INFO: Got endpoints: latency-svc-drmsg [283.21398ms]
Oct  3 19:50:05.282: INFO: Created: latency-svc-b2zmt
Oct  3 19:50:05.324: INFO: Created: latency-svc-25pn5
Oct  3 19:50:05.385: INFO: Got endpoints: latency-svc-25pn5 [359.109628ms]
Oct  3 19:50:05.385: INFO: Got endpoints: latency-svc-b2zmt [375.602569ms]
Oct  3 19:50:05.402: INFO: Created: latency-svc-b8gv8
Oct  3 19:50:05.413: INFO: Got endpoints: latency-svc-b8gv8 [372.569098ms]
Oct  3 19:50:05.418: INFO: Created: latency-svc-698z5
Oct  3 19:50:05.429: INFO: Got endpoints: latency-svc-698z5 [370.342306ms]
Oct  3 19:50:05.436: INFO: Created: latency-svc-c95w8
Oct  3 19:50:05.445: INFO: Got endpoints: latency-svc-c95w8 [372.513773ms]
Oct  3 19:50:05.456: INFO: Created: latency-svc-5c8vx
Oct  3 19:50:05.463: INFO: Got endpoints: latency-svc-5c8vx [373.113995ms]
Oct  3 19:50:05.478: INFO: Created: latency-svc-lccmc
Oct  3 19:50:05.488: INFO: Created: latency-svc-l6j57
Oct  3 19:50:05.489: INFO: Got endpoints: latency-svc-lccmc [382.841648ms]
Oct  3 19:50:05.496: INFO: Got endpoints: latency-svc-l6j57 [360.435805ms]
Oct  3 19:50:05.503: INFO: Created: latency-svc-hmqsh
Oct  3 19:50:05.513: INFO: Got endpoints: latency-svc-hmqsh [362.329509ms]
Oct  3 19:50:05.534: INFO: Created: latency-svc-9v7xt
Oct  3 19:50:05.555: INFO: Got endpoints: latency-svc-9v7xt [389.54456ms]
Oct  3 19:50:05.562: INFO: Created: latency-svc-f4xnh
Oct  3 19:50:05.571: INFO: Got endpoints: latency-svc-f4xnh [387.883857ms]
Oct  3 19:50:05.575: INFO: Created: latency-svc-xgngj
Oct  3 19:50:05.589: INFO: Got endpoints: latency-svc-xgngj [392.221605ms]
Oct  3 19:50:05.597: INFO: Created: latency-svc-84tjk
Oct  3 19:50:05.606: INFO: Got endpoints: latency-svc-84tjk [391.354266ms]
Oct  3 19:50:05.614: INFO: Created: latency-svc-whwxn
Oct  3 19:50:05.624: INFO: Got endpoints: latency-svc-whwxn [389.010392ms]
Oct  3 19:50:05.631: INFO: Created: latency-svc-mkj9d
Oct  3 19:50:05.643: INFO: Got endpoints: latency-svc-mkj9d [367.21392ms]
Oct  3 19:50:05.647: INFO: Created: latency-svc-cs6h8
Oct  3 19:50:05.660: INFO: Got endpoints: latency-svc-cs6h8 [275.152886ms]
Oct  3 19:50:05.666: INFO: Created: latency-svc-8nprs
Oct  3 19:50:05.678: INFO: Got endpoints: latency-svc-8nprs [293.122978ms]
Oct  3 19:50:05.683: INFO: Created: latency-svc-kgr2c
Oct  3 19:50:05.699: INFO: Got endpoints: latency-svc-kgr2c [286.081393ms]
Oct  3 19:50:05.723: INFO: Created: latency-svc-8ktnv
Oct  3 19:50:05.737: INFO: Got endpoints: latency-svc-8ktnv [308.688301ms]
Oct  3 19:50:05.747: INFO: Created: latency-svc-rnn5s
Oct  3 19:50:05.757: INFO: Got endpoints: latency-svc-rnn5s [311.549396ms]
Oct  3 19:50:05.759: INFO: Created: latency-svc-gtbpq
Oct  3 19:50:05.769: INFO: Got endpoints: latency-svc-gtbpq [306.539579ms]
Oct  3 19:50:05.777: INFO: Created: latency-svc-kblzj
Oct  3 19:50:05.788: INFO: Got endpoints: latency-svc-kblzj [298.743136ms]
Oct  3 19:50:05.794: INFO: Created: latency-svc-mkbt2
Oct  3 19:50:05.810: INFO: Got endpoints: latency-svc-mkbt2 [313.977633ms]
Oct  3 19:50:05.817: INFO: Created: latency-svc-cxv88
Oct  3 19:50:05.839: INFO: Got endpoints: latency-svc-cxv88 [325.605652ms]
Oct  3 19:50:05.874: INFO: Created: latency-svc-brmqk
Oct  3 19:50:05.884: INFO: Got endpoints: latency-svc-brmqk [328.549796ms]
Oct  3 19:50:05.895: INFO: Created: latency-svc-rsqzv
Oct  3 19:50:05.910: INFO: Got endpoints: latency-svc-rsqzv [338.547149ms]
Oct  3 19:50:05.913: INFO: Created: latency-svc-n77rx
Oct  3 19:50:05.924: INFO: Got endpoints: latency-svc-n77rx [334.779987ms]
Oct  3 19:50:05.931: INFO: Created: latency-svc-z5t89
Oct  3 19:50:05.941: INFO: Got endpoints: latency-svc-z5t89 [335.134393ms]
Oct  3 19:50:05.950: INFO: Created: latency-svc-wntxm
Oct  3 19:50:05.991: INFO: Created: latency-svc-qrjzh
Oct  3 19:50:05.991: INFO: Got endpoints: latency-svc-qrjzh [348.164972ms]
Oct  3 19:50:05.991: INFO: Got endpoints: latency-svc-wntxm [367.074802ms]
Oct  3 19:50:05.991: INFO: Created: latency-svc-zhmms
Oct  3 19:50:05.996: INFO: Got endpoints: latency-svc-zhmms [335.654571ms]
Oct  3 19:50:06.003: INFO: Created: latency-svc-swmlb
Oct  3 19:50:06.015: INFO: Got endpoints: latency-svc-swmlb [336.730202ms]
Oct  3 19:50:06.021: INFO: Created: latency-svc-5gfwf
Oct  3 19:50:06.031: INFO: Got endpoints: latency-svc-5gfwf [332.13078ms]
Oct  3 19:50:06.065: INFO: Created: latency-svc-ghrw4
Oct  3 19:50:06.065: INFO: Got endpoints: latency-svc-ghrw4 [327.378465ms]
Oct  3 19:50:06.065: INFO: Created: latency-svc-ghttj
Oct  3 19:50:06.094: INFO: Created: latency-svc-mxbhm
Oct  3 19:50:06.094: INFO: Got endpoints: latency-svc-mxbhm [324.666746ms]
Oct  3 19:50:06.094: INFO: Created: latency-svc-qnrgn
Oct  3 19:50:06.094: INFO: Got endpoints: latency-svc-ghttj [337.246243ms]
Oct  3 19:50:06.131: INFO: Got endpoints: latency-svc-qnrgn [343.189742ms]
Oct  3 19:50:06.131: INFO: Created: latency-svc-fnd79
Oct  3 19:50:06.131: INFO: Got endpoints: latency-svc-fnd79 [320.825833ms]
Oct  3 19:50:06.131: INFO: Created: latency-svc-jmpbd
Oct  3 19:50:06.133: INFO: Got endpoints: latency-svc-jmpbd [294.085976ms]
Oct  3 19:50:06.155: INFO: Created: latency-svc-4j7jf
Oct  3 19:50:06.175: INFO: Got endpoints: latency-svc-4j7jf [291.19593ms]
Oct  3 19:50:06.194: INFO: Created: latency-svc-26svs
Oct  3 19:50:06.206: INFO: Created: latency-svc-n6hls
Oct  3 19:50:06.206: INFO: Got endpoints: latency-svc-26svs [295.842643ms]
Oct  3 19:50:06.223: INFO: Got endpoints: latency-svc-n6hls [299.238287ms]
Oct  3 19:50:06.224: INFO: Latencies: [42.135193ms 46.95785ms 60.990458ms 66.523457ms 80.636945ms 85.561616ms 95.536333ms 97.858992ms 112.721915ms 114.035364ms 131.044718ms 151.904228ms 161.293212ms 176.254947ms 191.807241ms 201.644647ms 202.725998ms 203.736158ms 211.519548ms 217.747519ms 218.120087ms 224.050633ms 228.596121ms 234.903738ms 239.770908ms 240.881658ms 242.13057ms 242.572321ms 243.412817ms 243.620221ms 244.072893ms 244.184653ms 244.715422ms 245.136845ms 245.521858ms 245.756789ms 246.002194ms 246.234193ms 246.740416ms 246.757876ms 246.959655ms 247.294915ms 247.894034ms 248.166761ms 249.01184ms 249.142529ms 249.910574ms 250.851799ms 250.973422ms 251.001644ms 251.521727ms 251.574019ms 251.723533ms 251.852715ms 252.052372ms 252.692292ms 252.845729ms 253.070839ms 253.79392ms 253.889519ms 254.654584ms 257.439121ms 258.293075ms 259.587698ms 259.62366ms 260.695083ms 260.708444ms 261.708364ms 262.259779ms 262.504364ms 263.510999ms 263.593674ms 265.736957ms 266.446729ms 266.786297ms 267.290407ms 267.458148ms 267.599079ms 267.688858ms 267.836549ms 267.945453ms 268.36774ms 269.055945ms 271.050069ms 271.461946ms 272.248631ms 272.351624ms 272.744268ms 272.959163ms 273.28506ms 273.327846ms 273.815937ms 274.664091ms 274.904688ms 275.152886ms 275.556269ms 277.618828ms 278.537345ms 278.603032ms 279.266505ms 279.468379ms 279.473672ms 279.624348ms 281.798629ms 282.14681ms 282.922977ms 282.955788ms 283.21398ms 283.375653ms 283.40485ms 283.651008ms 283.852689ms 284.051051ms 284.549958ms 284.605564ms 285.193497ms 285.271406ms 286.063169ms 286.081393ms 286.498783ms 286.517941ms 286.864574ms 287.121923ms 287.318491ms 287.641764ms 288.124998ms 288.197813ms 288.257076ms 288.323363ms 288.552205ms 288.999298ms 289.044294ms 289.11785ms 289.659355ms 289.762014ms 290.525663ms 290.946997ms 291.19593ms 291.826371ms 292.475386ms 293.122978ms 293.517797ms 294.085976ms 294.241826ms 295.372904ms 295.842643ms 298.743136ms 299.238287ms 301.007333ms 302.739514ms 304.203795ms 304.582291ms 306.539579ms 308.30377ms 308.688301ms 311.549396ms 313.734134ms 313.977633ms 317.247689ms 320.825833ms 324.467536ms 324.666746ms 325.42234ms 325.605652ms 327.378465ms 328.549796ms 332.13078ms 334.779987ms 335.134393ms 335.654571ms 336.730202ms 337.246243ms 338.547149ms 343.189742ms 345.292075ms 348.164972ms 355.719267ms 359.109628ms 360.435805ms 362.329509ms 367.074802ms 367.21392ms 370.342306ms 371.381786ms 372.513773ms 372.569098ms 373.113995ms 375.602569ms 382.841648ms 387.883857ms 389.010392ms 389.54456ms 391.354266ms 392.221605ms 395.484989ms 413.257449ms 421.670054ms 431.531159ms 451.647721ms 468.177969ms]
Oct  3 19:50:06.224: INFO: 50 %ile: 279.468379ms
Oct  3 19:50:06.224: INFO: 90 %ile: 367.074802ms
Oct  3 19:50:06.224: INFO: 99 %ile: 451.647721ms
Oct  3 19:50:06.224: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Oct  3 19:50:06.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-4943" for this suite. 10/03/22 19:50:06.274
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":116,"skipped":2368,"failed":0}
------------------------------
• [SLOW TEST] [7.197 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:49:59.098
    Oct  3 19:49:59.099: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename svc-latency 10/03/22 19:49:59.1
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:49:59.135
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:49:59.145
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Oct  3 19:49:59.155: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-4943 10/03/22 19:49:59.156
    I1003 19:49:59.173493      22 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4943, replica count: 1
    I1003 19:50:00.224584      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1003 19:50:01.224859      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1003 19:50:02.225514      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct  3 19:50:02.375: INFO: Created: latency-svc-kwtsr
    Oct  3 19:50:02.385: INFO: Got endpoints: latency-svc-kwtsr [58.828098ms]
    Oct  3 19:50:02.415: INFO: Created: latency-svc-gs744
    Oct  3 19:50:02.427: INFO: Got endpoints: latency-svc-gs744 [42.135193ms]
    Oct  3 19:50:02.438: INFO: Created: latency-svc-thzw7
    Oct  3 19:50:02.446: INFO: Got endpoints: latency-svc-thzw7 [60.990458ms]
    Oct  3 19:50:02.453: INFO: Created: latency-svc-bmphs
    Oct  3 19:50:02.466: INFO: Got endpoints: latency-svc-bmphs [80.636945ms]
    Oct  3 19:50:02.470: INFO: Created: latency-svc-2jkmn
    Oct  3 19:50:02.481: INFO: Got endpoints: latency-svc-2jkmn [95.536333ms]
    Oct  3 19:50:02.487: INFO: Created: latency-svc-8758p
    Oct  3 19:50:02.498: INFO: Got endpoints: latency-svc-8758p [112.721915ms]
    Oct  3 19:50:02.504: INFO: Created: latency-svc-78ln2
    Oct  3 19:50:02.516: INFO: Got endpoints: latency-svc-78ln2 [131.044718ms]
    Oct  3 19:50:02.521: INFO: Created: latency-svc-7k62s
    Oct  3 19:50:02.538: INFO: Got endpoints: latency-svc-7k62s [151.904228ms]
    Oct  3 19:50:02.577: INFO: Created: latency-svc-mkq5t
    Oct  3 19:50:02.577: INFO: Created: latency-svc-mljjz
    Oct  3 19:50:02.589: INFO: Got endpoints: latency-svc-mljjz [202.725998ms]
    Oct  3 19:50:02.589: INFO: Created: latency-svc-cgq7h
    Oct  3 19:50:02.590: INFO: Got endpoints: latency-svc-mkq5t [203.736158ms]
    Oct  3 19:50:02.598: INFO: Got endpoints: latency-svc-cgq7h [211.519548ms]
    Oct  3 19:50:02.598: INFO: Created: latency-svc-tdx2r
    Oct  3 19:50:02.625: INFO: Got endpoints: latency-svc-tdx2r [239.770908ms]
    Oct  3 19:50:02.632: INFO: Created: latency-svc-nq5pf
    Oct  3 19:50:02.640: INFO: Got endpoints: latency-svc-nq5pf [253.889519ms]
    Oct  3 19:50:02.648: INFO: Created: latency-svc-wxstv
    Oct  3 19:50:02.658: INFO: Got endpoints: latency-svc-wxstv [272.351624ms]
    Oct  3 19:50:02.665: INFO: Created: latency-svc-f8r7v
    Oct  3 19:50:02.675: INFO: Got endpoints: latency-svc-f8r7v [289.11785ms]
    Oct  3 19:50:02.684: INFO: Created: latency-svc-87ssr
    Oct  3 19:50:02.699: INFO: Got endpoints: latency-svc-87ssr [313.734134ms]
    Oct  3 19:50:02.701: INFO: Created: latency-svc-mg9jk
    Oct  3 19:50:02.707: INFO: Got endpoints: latency-svc-mg9jk [279.624348ms]
    Oct  3 19:50:02.713: INFO: Created: latency-svc-ptp2q
    Oct  3 19:50:02.724: INFO: Got endpoints: latency-svc-ptp2q [277.618828ms]
    Oct  3 19:50:02.730: INFO: Created: latency-svc-c9vqw
    Oct  3 19:50:02.741: INFO: Got endpoints: latency-svc-c9vqw [275.556269ms]
    Oct  3 19:50:02.748: INFO: Created: latency-svc-dv2t4
    Oct  3 19:50:02.759: INFO: Got endpoints: latency-svc-dv2t4 [278.537345ms]
    Oct  3 19:50:02.766: INFO: Created: latency-svc-2nw64
    Oct  3 19:50:02.787: INFO: Got endpoints: latency-svc-2nw64 [288.999298ms]
    Oct  3 19:50:02.794: INFO: Created: latency-svc-jzwbx
    Oct  3 19:50:02.805: INFO: Got endpoints: latency-svc-jzwbx [288.124998ms]
    Oct  3 19:50:02.810: INFO: Created: latency-svc-jq27j
    Oct  3 19:50:02.825: INFO: Got endpoints: latency-svc-jq27j [286.864574ms]
    Oct  3 19:50:02.830: INFO: Created: latency-svc-gv9nc
    Oct  3 19:50:02.842: INFO: Got endpoints: latency-svc-gv9nc [252.845729ms]
    Oct  3 19:50:02.850: INFO: Created: latency-svc-thmq5
    Oct  3 19:50:02.861: INFO: Got endpoints: latency-svc-thmq5 [271.461946ms]
    Oct  3 19:50:02.870: INFO: Created: latency-svc-5j7bp
    Oct  3 19:50:02.883: INFO: Got endpoints: latency-svc-5j7bp [285.271406ms]
    Oct  3 19:50:02.888: INFO: Created: latency-svc-bjh5v
    Oct  3 19:50:02.899: INFO: Got endpoints: latency-svc-bjh5v [273.327846ms]
    Oct  3 19:50:02.904: INFO: Created: latency-svc-6jvxk
    Oct  3 19:50:02.923: INFO: Got endpoints: latency-svc-6jvxk [282.14681ms]
    Oct  3 19:50:02.930: INFO: Created: latency-svc-r6pcj
    Oct  3 19:50:02.942: INFO: Got endpoints: latency-svc-r6pcj [284.051051ms]
    Oct  3 19:50:02.948: INFO: Created: latency-svc-n865f
    Oct  3 19:50:02.959: INFO: Got endpoints: latency-svc-n865f [283.40485ms]
    Oct  3 19:50:02.965: INFO: Created: latency-svc-fc9wh
    Oct  3 19:50:02.983: INFO: Got endpoints: latency-svc-fc9wh [284.605564ms]
    Oct  3 19:50:03.003: INFO: Created: latency-svc-qpdp5
    Oct  3 19:50:03.007: INFO: Created: latency-svc-nmtcr
    Oct  3 19:50:03.032: INFO: Got endpoints: latency-svc-qpdp5 [325.42234ms]
    Oct  3 19:50:03.032: INFO: Got endpoints: latency-svc-nmtcr [308.30377ms]
    Oct  3 19:50:03.037: INFO: Created: latency-svc-dmk6f
    Oct  3 19:50:03.046: INFO: Got endpoints: latency-svc-dmk6f [304.582291ms]
    Oct  3 19:50:03.050: INFO: Created: latency-svc-nlfxs
    Oct  3 19:50:03.061: INFO: Got endpoints: latency-svc-nlfxs [301.007333ms]
    Oct  3 19:50:03.065: INFO: Created: latency-svc-5vnqx
    Oct  3 19:50:03.076: INFO: Got endpoints: latency-svc-5vnqx [289.044294ms]
    Oct  3 19:50:03.082: INFO: Created: latency-svc-vtct7
    Oct  3 19:50:03.092: INFO: Got endpoints: latency-svc-vtct7 [287.641764ms]
    Oct  3 19:50:03.096: INFO: Created: latency-svc-vc2pj
    Oct  3 19:50:03.111: INFO: Got endpoints: latency-svc-vc2pj [286.517941ms]
    Oct  3 19:50:03.117: INFO: Created: latency-svc-8rkwx
    Oct  3 19:50:03.126: INFO: Got endpoints: latency-svc-8rkwx [283.375653ms]
    Oct  3 19:50:03.136: INFO: Created: latency-svc-4qh5b
    Oct  3 19:50:03.148: INFO: Got endpoints: latency-svc-4qh5b [286.498783ms]
    Oct  3 19:50:03.152: INFO: Created: latency-svc-jxgjz
    Oct  3 19:50:03.163: INFO: Got endpoints: latency-svc-jxgjz [279.468379ms]
    Oct  3 19:50:03.173: INFO: Created: latency-svc-8ct47
    Oct  3 19:50:03.181: INFO: Got endpoints: latency-svc-8ct47 [281.798629ms]
    Oct  3 19:50:03.186: INFO: Created: latency-svc-5xqvr
    Oct  3 19:50:03.196: INFO: Got endpoints: latency-svc-5xqvr [272.959163ms]
    Oct  3 19:50:03.203: INFO: Created: latency-svc-pchqp
    Oct  3 19:50:03.234: INFO: Got endpoints: latency-svc-pchqp [291.826371ms]
    Oct  3 19:50:03.242: INFO: Created: latency-svc-rhlfb
    Oct  3 19:50:03.252: INFO: Got endpoints: latency-svc-rhlfb [293.517797ms]
    Oct  3 19:50:03.258: INFO: Created: latency-svc-sll6p
    Oct  3 19:50:03.267: INFO: Got endpoints: latency-svc-sll6p [283.852689ms]
    Oct  3 19:50:03.274: INFO: Created: latency-svc-lpn2q
    Oct  3 19:50:03.284: INFO: Got endpoints: latency-svc-lpn2q [251.852715ms]
    Oct  3 19:50:03.289: INFO: Created: latency-svc-7zxzn
    Oct  3 19:50:03.311: INFO: Got endpoints: latency-svc-7zxzn [278.603032ms]
    Oct  3 19:50:03.311: INFO: Created: latency-svc-wptzm
    Oct  3 19:50:03.320: INFO: Got endpoints: latency-svc-wptzm [274.664091ms]
    Oct  3 19:50:03.327: INFO: Created: latency-svc-rmk5t
    Oct  3 19:50:03.336: INFO: Got endpoints: latency-svc-rmk5t [274.904688ms]
    Oct  3 19:50:03.343: INFO: Created: latency-svc-kxb76
    Oct  3 19:50:03.364: INFO: Got endpoints: latency-svc-kxb76 [287.121923ms]
    Oct  3 19:50:03.371: INFO: Created: latency-svc-97hnp
    Oct  3 19:50:03.382: INFO: Got endpoints: latency-svc-97hnp [289.762014ms]
    Oct  3 19:50:03.388: INFO: Created: latency-svc-h7645
    Oct  3 19:50:03.399: INFO: Got endpoints: latency-svc-h7645 [287.318491ms]
    Oct  3 19:50:03.403: INFO: Created: latency-svc-mcj8b
    Oct  3 19:50:03.414: INFO: Got endpoints: latency-svc-mcj8b [288.323363ms]
    Oct  3 19:50:03.420: INFO: Created: latency-svc-rtn9w
    Oct  3 19:50:03.431: INFO: Got endpoints: latency-svc-rtn9w [283.651008ms]
    Oct  3 19:50:03.440: INFO: Created: latency-svc-ncrjq
    Oct  3 19:50:03.467: INFO: Got endpoints: latency-svc-ncrjq [304.203795ms]
    Oct  3 19:50:03.483: INFO: Created: latency-svc-rxqbd
    Oct  3 19:50:03.506: INFO: Got endpoints: latency-svc-rxqbd [324.467536ms]
    Oct  3 19:50:03.506: INFO: Created: latency-svc-52ktx
    Oct  3 19:50:03.513: INFO: Got endpoints: latency-svc-52ktx [317.247689ms]
    Oct  3 19:50:03.517: INFO: Created: latency-svc-b4v54
    Oct  3 19:50:03.527: INFO: Got endpoints: latency-svc-b4v54 [292.475386ms]
    Oct  3 19:50:03.532: INFO: Created: latency-svc-8z27k
    Oct  3 19:50:03.543: INFO: Got endpoints: latency-svc-8z27k [290.946997ms]
    Oct  3 19:50:03.549: INFO: Created: latency-svc-7tl4d
    Oct  3 19:50:03.558: INFO: Got endpoints: latency-svc-7tl4d [290.525663ms]
    Oct  3 19:50:03.565: INFO: Created: latency-svc-frmbz
    Oct  3 19:50:03.573: INFO: Got endpoints: latency-svc-frmbz [288.552205ms]
    Oct  3 19:50:03.581: INFO: Created: latency-svc-mpj7t
    Oct  3 19:50:03.591: INFO: Got endpoints: latency-svc-mpj7t [279.473672ms]
    Oct  3 19:50:03.595: INFO: Created: latency-svc-qr229
    Oct  3 19:50:03.603: INFO: Got endpoints: latency-svc-qr229 [282.922977ms]
    Oct  3 19:50:03.610: INFO: Created: latency-svc-gl645
    Oct  3 19:50:03.620: INFO: Got endpoints: latency-svc-gl645 [284.549958ms]
    Oct  3 19:50:03.627: INFO: Created: latency-svc-b4nsq
    Oct  3 19:50:03.637: INFO: Got endpoints: latency-svc-b4nsq [272.744268ms]
    Oct  3 19:50:03.639: INFO: Created: latency-svc-lghx8
    Oct  3 19:50:03.650: INFO: Got endpoints: latency-svc-lghx8 [267.458148ms]
    Oct  3 19:50:03.653: INFO: Created: latency-svc-wdlkj
    Oct  3 19:50:03.672: INFO: Got endpoints: latency-svc-wdlkj [273.28506ms]
    Oct  3 19:50:03.673: INFO: Created: latency-svc-wtpq8
    Oct  3 19:50:03.683: INFO: Got endpoints: latency-svc-wtpq8 [269.055945ms]
    Oct  3 19:50:03.687: INFO: Created: latency-svc-8f7fg
    Oct  3 19:50:03.697: INFO: Got endpoints: latency-svc-8f7fg [265.736957ms]
    Oct  3 19:50:03.700: INFO: Created: latency-svc-7g2xl
    Oct  3 19:50:03.711: INFO: Got endpoints: latency-svc-7g2xl [244.184653ms]
    Oct  3 19:50:03.717: INFO: Created: latency-svc-dl697
    Oct  3 19:50:03.724: INFO: Got endpoints: latency-svc-dl697 [218.120087ms]
    Oct  3 19:50:03.732: INFO: Created: latency-svc-hrdlp
    Oct  3 19:50:03.742: INFO: Got endpoints: latency-svc-hrdlp [228.596121ms]
    Oct  3 19:50:03.952: INFO: Created: latency-svc-5q67z
    Oct  3 19:50:03.952: INFO: Created: latency-svc-g5q46
    Oct  3 19:50:03.961: INFO: Created: latency-svc-6wb77
    Oct  3 19:50:03.961: INFO: Created: latency-svc-jqgzg
    Oct  3 19:50:03.961: INFO: Created: latency-svc-ssn25
    Oct  3 19:50:03.962: INFO: Created: latency-svc-snbfh
    Oct  3 19:50:03.962: INFO: Created: latency-svc-gg78w
    Oct  3 19:50:03.962: INFO: Created: latency-svc-j4xsg
    Oct  3 19:50:03.962: INFO: Created: latency-svc-wngfw
    Oct  3 19:50:03.962: INFO: Created: latency-svc-nvcv9
    Oct  3 19:50:03.963: INFO: Created: latency-svc-g29xc
    Oct  3 19:50:03.963: INFO: Created: latency-svc-62fcc
    Oct  3 19:50:03.963: INFO: Created: latency-svc-rdkhd
    Oct  3 19:50:03.963: INFO: Created: latency-svc-mswph
    Oct  3 19:50:03.964: INFO: Created: latency-svc-nbltp
    Oct  3 19:50:03.975: INFO: Got endpoints: latency-svc-g5q46 [371.381786ms]
    Oct  3 19:50:03.975: INFO: Got endpoints: latency-svc-rdkhd [302.739514ms]
    Oct  3 19:50:03.975: INFO: Got endpoints: latency-svc-5q67z [431.531159ms]
    Oct  3 19:50:03.978: INFO: Got endpoints: latency-svc-snbfh [294.241826ms]
    Oct  3 19:50:03.978: INFO: Got endpoints: latency-svc-wngfw [261.708364ms]
    Oct  3 19:50:03.992: INFO: Got endpoints: latency-svc-jqgzg [355.719267ms]
    Oct  3 19:50:03.993: INFO: Got endpoints: latency-svc-nvcv9 [295.372904ms]
    Oct  3 19:50:03.995: INFO: Got endpoints: latency-svc-ssn25 [345.292075ms]
    Oct  3 19:50:03.995: INFO: Got endpoints: latency-svc-62fcc [468.177969ms]
    Oct  3 19:50:03.995: INFO: Got endpoints: latency-svc-gg78w [421.670054ms]
    Oct  3 19:50:04.004: INFO: Got endpoints: latency-svc-6wb77 [413.257449ms]
    Oct  3 19:50:04.007: INFO: Got endpoints: latency-svc-nbltp [282.955788ms]
    Oct  3 19:50:04.009: INFO: Created: latency-svc-p45c2
    Oct  3 19:50:04.010: INFO: Got endpoints: latency-svc-j4xsg [451.647721ms]
    Oct  3 19:50:04.016: INFO: Got endpoints: latency-svc-mswph [273.815937ms]
    Oct  3 19:50:04.016: INFO: Got endpoints: latency-svc-g29xc [395.484989ms]
    Oct  3 19:50:04.022: INFO: Got endpoints: latency-svc-p45c2 [46.95785ms]
    Oct  3 19:50:04.030: INFO: Created: latency-svc-2vl57
    Oct  3 19:50:04.041: INFO: Got endpoints: latency-svc-2vl57 [66.523457ms]
    Oct  3 19:50:04.051: INFO: Created: latency-svc-9mj55
    Oct  3 19:50:04.061: INFO: Got endpoints: latency-svc-9mj55 [85.561616ms]
    Oct  3 19:50:04.066: INFO: Created: latency-svc-9nr87
    Oct  3 19:50:04.076: INFO: Got endpoints: latency-svc-9nr87 [97.858992ms]
    Oct  3 19:50:04.083: INFO: Created: latency-svc-87t8r
    Oct  3 19:50:04.092: INFO: Got endpoints: latency-svc-87t8r [114.035364ms]
    Oct  3 19:50:04.144: INFO: Created: latency-svc-cq5g9
    Oct  3 19:50:04.154: INFO: Got endpoints: latency-svc-cq5g9 [161.293212ms]
    Oct  3 19:50:04.158: INFO: Created: latency-svc-4phk9
    Oct  3 19:50:04.169: INFO: Got endpoints: latency-svc-4phk9 [176.254947ms]
    Oct  3 19:50:04.175: INFO: Created: latency-svc-7t5gt
    Oct  3 19:50:04.187: INFO: Got endpoints: latency-svc-7t5gt [191.807241ms]
    Oct  3 19:50:04.189: INFO: Created: latency-svc-fm4x4
    Oct  3 19:50:04.197: INFO: Got endpoints: latency-svc-fm4x4 [201.644647ms]
    Oct  3 19:50:04.203: INFO: Created: latency-svc-7zjk2
    Oct  3 19:50:04.214: INFO: Got endpoints: latency-svc-7zjk2 [217.747519ms]
    Oct  3 19:50:04.218: INFO: Created: latency-svc-428xt
    Oct  3 19:50:04.228: INFO: Got endpoints: latency-svc-428xt [224.050633ms]
    Oct  3 19:50:04.233: INFO: Created: latency-svc-vr9tf
    Oct  3 19:50:04.242: INFO: Got endpoints: latency-svc-vr9tf [234.903738ms]
    Oct  3 19:50:04.251: INFO: Created: latency-svc-rhq4h
    Oct  3 19:50:04.262: INFO: Got endpoints: latency-svc-rhq4h [251.723533ms]
    Oct  3 19:50:04.266: INFO: Created: latency-svc-qfjf8
    Oct  3 19:50:04.276: INFO: Got endpoints: latency-svc-qfjf8 [260.695083ms]
    Oct  3 19:50:04.284: INFO: Created: latency-svc-fhzs7
    Oct  3 19:50:04.295: INFO: Got endpoints: latency-svc-fhzs7 [279.266505ms]
    Oct  3 19:50:04.296: INFO: Created: latency-svc-r6vgv
    Oct  3 19:50:04.312: INFO: Got endpoints: latency-svc-r6vgv [289.659355ms]
    Oct  3 19:50:04.316: INFO: Created: latency-svc-jkfjm
    Oct  3 19:50:04.330: INFO: Got endpoints: latency-svc-jkfjm [288.257076ms]
    Oct  3 19:50:04.336: INFO: Created: latency-svc-j74bg
    Oct  3 19:50:04.346: INFO: Got endpoints: latency-svc-j74bg [285.193497ms]
    Oct  3 19:50:04.353: INFO: Created: latency-svc-dtgcw
    Oct  3 19:50:04.364: INFO: Got endpoints: latency-svc-dtgcw [288.197813ms]
    Oct  3 19:50:04.367: INFO: Created: latency-svc-6dfk8
    Oct  3 19:50:04.378: INFO: Got endpoints: latency-svc-6dfk8 [286.063169ms]
    Oct  3 19:50:04.388: INFO: Created: latency-svc-gqftp
    Oct  3 19:50:04.402: INFO: Got endpoints: latency-svc-gqftp [248.166761ms]
    Oct  3 19:50:04.408: INFO: Created: latency-svc-c794h
    Oct  3 19:50:04.418: INFO: Got endpoints: latency-svc-c794h [249.142529ms]
    Oct  3 19:50:04.423: INFO: Created: latency-svc-f4jfv
    Oct  3 19:50:04.434: INFO: Got endpoints: latency-svc-f4jfv [246.757876ms]
    Oct  3 19:50:04.441: INFO: Created: latency-svc-8j5p8
    Oct  3 19:50:04.458: INFO: Got endpoints: latency-svc-8j5p8 [260.708444ms]
    Oct  3 19:50:04.466: INFO: Created: latency-svc-mw9f5
    Oct  3 19:50:04.476: INFO: Got endpoints: latency-svc-mw9f5 [262.504364ms]
    Oct  3 19:50:04.483: INFO: Created: latency-svc-2kq9z
    Oct  3 19:50:04.497: INFO: Got endpoints: latency-svc-2kq9z [268.36774ms]
    Oct  3 19:50:04.504: INFO: Created: latency-svc-6dnpl
    Oct  3 19:50:04.514: INFO: Got endpoints: latency-svc-6dnpl [272.248631ms]
    Oct  3 19:50:04.521: INFO: Created: latency-svc-x6c9q
    Oct  3 19:50:04.529: INFO: Got endpoints: latency-svc-x6c9q [267.599079ms]
    Oct  3 19:50:04.534: INFO: Created: latency-svc-vh8mc
    Oct  3 19:50:04.544: INFO: Got endpoints: latency-svc-vh8mc [267.945453ms]
    Oct  3 19:50:04.551: INFO: Created: latency-svc-m428s
    Oct  3 19:50:04.562: INFO: Got endpoints: latency-svc-m428s [266.786297ms]
    Oct  3 19:50:04.567: INFO: Created: latency-svc-ss67q
    Oct  3 19:50:04.578: INFO: Got endpoints: latency-svc-ss67q [266.446729ms]
    Oct  3 19:50:04.586: INFO: Created: latency-svc-lqrt6
    Oct  3 19:50:04.598: INFO: Got endpoints: latency-svc-lqrt6 [267.688858ms]
    Oct  3 19:50:04.603: INFO: Created: latency-svc-vmdqz
    Oct  3 19:50:04.614: INFO: Got endpoints: latency-svc-vmdqz [267.290407ms]
    Oct  3 19:50:04.621: INFO: Created: latency-svc-whlsq
    Oct  3 19:50:04.632: INFO: Got endpoints: latency-svc-whlsq [267.836549ms]
    Oct  3 19:50:04.638: INFO: Created: latency-svc-znmf7
    Oct  3 19:50:04.649: INFO: Got endpoints: latency-svc-znmf7 [271.050069ms]
    Oct  3 19:50:04.655: INFO: Created: latency-svc-84fx6
    Oct  3 19:50:04.665: INFO: Got endpoints: latency-svc-84fx6 [262.259779ms]
    Oct  3 19:50:04.672: INFO: Created: latency-svc-p8kfc
    Oct  3 19:50:04.682: INFO: Got endpoints: latency-svc-p8kfc [263.593674ms]
    Oct  3 19:50:04.686: INFO: Created: latency-svc-gz6s8
    Oct  3 19:50:04.698: INFO: Got endpoints: latency-svc-gz6s8 [263.510999ms]
    Oct  3 19:50:04.702: INFO: Created: latency-svc-nhbzg
    Oct  3 19:50:04.712: INFO: Got endpoints: latency-svc-nhbzg [253.79392ms]
    Oct  3 19:50:04.719: INFO: Created: latency-svc-48nxl
    Oct  3 19:50:04.728: INFO: Got endpoints: latency-svc-48nxl [251.521727ms]
    Oct  3 19:50:04.740: INFO: Created: latency-svc-sjxsh
    Oct  3 19:50:04.751: INFO: Got endpoints: latency-svc-sjxsh [254.654584ms]
    Oct  3 19:50:04.757: INFO: Created: latency-svc-zn6ft
    Oct  3 19:50:04.767: INFO: Got endpoints: latency-svc-zn6ft [253.070839ms]
    Oct  3 19:50:04.772: INFO: Created: latency-svc-k8h7s
    Oct  3 19:50:04.782: INFO: Got endpoints: latency-svc-k8h7s [252.692292ms]
    Oct  3 19:50:04.786: INFO: Created: latency-svc-wgz9w
    Oct  3 19:50:04.795: INFO: Got endpoints: latency-svc-wgz9w [251.001644ms]
    Oct  3 19:50:04.800: INFO: Created: latency-svc-vm48z
    Oct  3 19:50:04.809: INFO: Got endpoints: latency-svc-vm48z [246.959655ms]
    Oct  3 19:50:04.816: INFO: Created: latency-svc-6d92q
    Oct  3 19:50:04.827: INFO: Got endpoints: latency-svc-6d92q [247.894034ms]
    Oct  3 19:50:04.833: INFO: Created: latency-svc-rl47q
    Oct  3 19:50:04.844: INFO: Got endpoints: latency-svc-rl47q [246.002194ms]
    Oct  3 19:50:04.853: INFO: Created: latency-svc-hw5jk
    Oct  3 19:50:04.861: INFO: Got endpoints: latency-svc-hw5jk [246.234193ms]
    Oct  3 19:50:04.865: INFO: Created: latency-svc-j4h86
    Oct  3 19:50:04.876: INFO: Got endpoints: latency-svc-j4h86 [243.412817ms]
    Oct  3 19:50:04.882: INFO: Created: latency-svc-qts76
    Oct  3 19:50:04.894: INFO: Got endpoints: latency-svc-qts76 [244.072893ms]
    Oct  3 19:50:04.908: INFO: Created: latency-svc-nwg7v
    Oct  3 19:50:04.923: INFO: Created: latency-svc-xt4qg
    Oct  3 19:50:04.923: INFO: Got endpoints: latency-svc-nwg7v [258.293075ms]
    Oct  3 19:50:04.933: INFO: Got endpoints: latency-svc-xt4qg [250.851799ms]
    Oct  3 19:50:04.933: INFO: Created: latency-svc-j76dm
    Oct  3 19:50:04.945: INFO: Got endpoints: latency-svc-j76dm [246.740416ms]
    Oct  3 19:50:04.951: INFO: Created: latency-svc-66g2v
    Oct  3 19:50:04.963: INFO: Got endpoints: latency-svc-66g2v [250.973422ms]
    Oct  3 19:50:04.966: INFO: Created: latency-svc-r8f5g
    Oct  3 19:50:04.975: INFO: Got endpoints: latency-svc-r8f5g [247.294915ms]
    Oct  3 19:50:04.981: INFO: Created: latency-svc-rrbgj
    Oct  3 19:50:04.992: INFO: Got endpoints: latency-svc-rrbgj [240.881658ms]
    Oct  3 19:50:04.997: INFO: Created: latency-svc-dggj2
    Oct  3 19:50:05.009: INFO: Got endpoints: latency-svc-dggj2 [242.13057ms]
    Oct  3 19:50:05.016: INFO: Created: latency-svc-wfwpb
    Oct  3 19:50:05.026: INFO: Got endpoints: latency-svc-wfwpb [243.620221ms]
    Oct  3 19:50:05.032: INFO: Created: latency-svc-lrw76
    Oct  3 19:50:05.040: INFO: Got endpoints: latency-svc-lrw76 [244.715422ms]
    Oct  3 19:50:05.048: INFO: Created: latency-svc-h6h5q
    Oct  3 19:50:05.058: INFO: Got endpoints: latency-svc-h6h5q [249.01184ms]
    Oct  3 19:50:05.062: INFO: Created: latency-svc-cz5mx
    Oct  3 19:50:05.073: INFO: Got endpoints: latency-svc-cz5mx [245.521858ms]
    Oct  3 19:50:05.080: INFO: Created: latency-svc-2vrmf
    Oct  3 19:50:05.090: INFO: Got endpoints: latency-svc-2vrmf [245.756789ms]
    Oct  3 19:50:05.096: INFO: Created: latency-svc-tcc5v
    Oct  3 19:50:05.106: INFO: Got endpoints: latency-svc-tcc5v [245.136845ms]
    Oct  3 19:50:05.127: INFO: Created: latency-svc-b2hn9
    Oct  3 19:50:05.135: INFO: Got endpoints: latency-svc-b2hn9 [259.62366ms]
    Oct  3 19:50:05.142: INFO: Created: latency-svc-t848d
    Oct  3 19:50:05.151: INFO: Got endpoints: latency-svc-t848d [257.439121ms]
    Oct  3 19:50:05.157: INFO: Created: latency-svc-f79f8
    Oct  3 19:50:05.166: INFO: Got endpoints: latency-svc-f79f8 [242.572321ms]
    Oct  3 19:50:05.172: INFO: Created: latency-svc-c7kmd
    Oct  3 19:50:05.183: INFO: Got endpoints: latency-svc-c7kmd [249.910574ms]
    Oct  3 19:50:05.186: INFO: Created: latency-svc-qzrlm
    Oct  3 19:50:05.197: INFO: Got endpoints: latency-svc-qzrlm [252.052372ms]
    Oct  3 19:50:05.204: INFO: Created: latency-svc-chzg6
    Oct  3 19:50:05.214: INFO: Got endpoints: latency-svc-chzg6 [251.574019ms]
    Oct  3 19:50:05.223: INFO: Created: latency-svc-qfz9x
    Oct  3 19:50:05.235: INFO: Got endpoints: latency-svc-qfz9x [259.587698ms]
    Oct  3 19:50:05.241: INFO: Created: latency-svc-drmsg
    Oct  3 19:50:05.276: INFO: Got endpoints: latency-svc-drmsg [283.21398ms]
    Oct  3 19:50:05.282: INFO: Created: latency-svc-b2zmt
    Oct  3 19:50:05.324: INFO: Created: latency-svc-25pn5
    Oct  3 19:50:05.385: INFO: Got endpoints: latency-svc-25pn5 [359.109628ms]
    Oct  3 19:50:05.385: INFO: Got endpoints: latency-svc-b2zmt [375.602569ms]
    Oct  3 19:50:05.402: INFO: Created: latency-svc-b8gv8
    Oct  3 19:50:05.413: INFO: Got endpoints: latency-svc-b8gv8 [372.569098ms]
    Oct  3 19:50:05.418: INFO: Created: latency-svc-698z5
    Oct  3 19:50:05.429: INFO: Got endpoints: latency-svc-698z5 [370.342306ms]
    Oct  3 19:50:05.436: INFO: Created: latency-svc-c95w8
    Oct  3 19:50:05.445: INFO: Got endpoints: latency-svc-c95w8 [372.513773ms]
    Oct  3 19:50:05.456: INFO: Created: latency-svc-5c8vx
    Oct  3 19:50:05.463: INFO: Got endpoints: latency-svc-5c8vx [373.113995ms]
    Oct  3 19:50:05.478: INFO: Created: latency-svc-lccmc
    Oct  3 19:50:05.488: INFO: Created: latency-svc-l6j57
    Oct  3 19:50:05.489: INFO: Got endpoints: latency-svc-lccmc [382.841648ms]
    Oct  3 19:50:05.496: INFO: Got endpoints: latency-svc-l6j57 [360.435805ms]
    Oct  3 19:50:05.503: INFO: Created: latency-svc-hmqsh
    Oct  3 19:50:05.513: INFO: Got endpoints: latency-svc-hmqsh [362.329509ms]
    Oct  3 19:50:05.534: INFO: Created: latency-svc-9v7xt
    Oct  3 19:50:05.555: INFO: Got endpoints: latency-svc-9v7xt [389.54456ms]
    Oct  3 19:50:05.562: INFO: Created: latency-svc-f4xnh
    Oct  3 19:50:05.571: INFO: Got endpoints: latency-svc-f4xnh [387.883857ms]
    Oct  3 19:50:05.575: INFO: Created: latency-svc-xgngj
    Oct  3 19:50:05.589: INFO: Got endpoints: latency-svc-xgngj [392.221605ms]
    Oct  3 19:50:05.597: INFO: Created: latency-svc-84tjk
    Oct  3 19:50:05.606: INFO: Got endpoints: latency-svc-84tjk [391.354266ms]
    Oct  3 19:50:05.614: INFO: Created: latency-svc-whwxn
    Oct  3 19:50:05.624: INFO: Got endpoints: latency-svc-whwxn [389.010392ms]
    Oct  3 19:50:05.631: INFO: Created: latency-svc-mkj9d
    Oct  3 19:50:05.643: INFO: Got endpoints: latency-svc-mkj9d [367.21392ms]
    Oct  3 19:50:05.647: INFO: Created: latency-svc-cs6h8
    Oct  3 19:50:05.660: INFO: Got endpoints: latency-svc-cs6h8 [275.152886ms]
    Oct  3 19:50:05.666: INFO: Created: latency-svc-8nprs
    Oct  3 19:50:05.678: INFO: Got endpoints: latency-svc-8nprs [293.122978ms]
    Oct  3 19:50:05.683: INFO: Created: latency-svc-kgr2c
    Oct  3 19:50:05.699: INFO: Got endpoints: latency-svc-kgr2c [286.081393ms]
    Oct  3 19:50:05.723: INFO: Created: latency-svc-8ktnv
    Oct  3 19:50:05.737: INFO: Got endpoints: latency-svc-8ktnv [308.688301ms]
    Oct  3 19:50:05.747: INFO: Created: latency-svc-rnn5s
    Oct  3 19:50:05.757: INFO: Got endpoints: latency-svc-rnn5s [311.549396ms]
    Oct  3 19:50:05.759: INFO: Created: latency-svc-gtbpq
    Oct  3 19:50:05.769: INFO: Got endpoints: latency-svc-gtbpq [306.539579ms]
    Oct  3 19:50:05.777: INFO: Created: latency-svc-kblzj
    Oct  3 19:50:05.788: INFO: Got endpoints: latency-svc-kblzj [298.743136ms]
    Oct  3 19:50:05.794: INFO: Created: latency-svc-mkbt2
    Oct  3 19:50:05.810: INFO: Got endpoints: latency-svc-mkbt2 [313.977633ms]
    Oct  3 19:50:05.817: INFO: Created: latency-svc-cxv88
    Oct  3 19:50:05.839: INFO: Got endpoints: latency-svc-cxv88 [325.605652ms]
    Oct  3 19:50:05.874: INFO: Created: latency-svc-brmqk
    Oct  3 19:50:05.884: INFO: Got endpoints: latency-svc-brmqk [328.549796ms]
    Oct  3 19:50:05.895: INFO: Created: latency-svc-rsqzv
    Oct  3 19:50:05.910: INFO: Got endpoints: latency-svc-rsqzv [338.547149ms]
    Oct  3 19:50:05.913: INFO: Created: latency-svc-n77rx
    Oct  3 19:50:05.924: INFO: Got endpoints: latency-svc-n77rx [334.779987ms]
    Oct  3 19:50:05.931: INFO: Created: latency-svc-z5t89
    Oct  3 19:50:05.941: INFO: Got endpoints: latency-svc-z5t89 [335.134393ms]
    Oct  3 19:50:05.950: INFO: Created: latency-svc-wntxm
    Oct  3 19:50:05.991: INFO: Created: latency-svc-qrjzh
    Oct  3 19:50:05.991: INFO: Got endpoints: latency-svc-qrjzh [348.164972ms]
    Oct  3 19:50:05.991: INFO: Got endpoints: latency-svc-wntxm [367.074802ms]
    Oct  3 19:50:05.991: INFO: Created: latency-svc-zhmms
    Oct  3 19:50:05.996: INFO: Got endpoints: latency-svc-zhmms [335.654571ms]
    Oct  3 19:50:06.003: INFO: Created: latency-svc-swmlb
    Oct  3 19:50:06.015: INFO: Got endpoints: latency-svc-swmlb [336.730202ms]
    Oct  3 19:50:06.021: INFO: Created: latency-svc-5gfwf
    Oct  3 19:50:06.031: INFO: Got endpoints: latency-svc-5gfwf [332.13078ms]
    Oct  3 19:50:06.065: INFO: Created: latency-svc-ghrw4
    Oct  3 19:50:06.065: INFO: Got endpoints: latency-svc-ghrw4 [327.378465ms]
    Oct  3 19:50:06.065: INFO: Created: latency-svc-ghttj
    Oct  3 19:50:06.094: INFO: Created: latency-svc-mxbhm
    Oct  3 19:50:06.094: INFO: Got endpoints: latency-svc-mxbhm [324.666746ms]
    Oct  3 19:50:06.094: INFO: Created: latency-svc-qnrgn
    Oct  3 19:50:06.094: INFO: Got endpoints: latency-svc-ghttj [337.246243ms]
    Oct  3 19:50:06.131: INFO: Got endpoints: latency-svc-qnrgn [343.189742ms]
    Oct  3 19:50:06.131: INFO: Created: latency-svc-fnd79
    Oct  3 19:50:06.131: INFO: Got endpoints: latency-svc-fnd79 [320.825833ms]
    Oct  3 19:50:06.131: INFO: Created: latency-svc-jmpbd
    Oct  3 19:50:06.133: INFO: Got endpoints: latency-svc-jmpbd [294.085976ms]
    Oct  3 19:50:06.155: INFO: Created: latency-svc-4j7jf
    Oct  3 19:50:06.175: INFO: Got endpoints: latency-svc-4j7jf [291.19593ms]
    Oct  3 19:50:06.194: INFO: Created: latency-svc-26svs
    Oct  3 19:50:06.206: INFO: Created: latency-svc-n6hls
    Oct  3 19:50:06.206: INFO: Got endpoints: latency-svc-26svs [295.842643ms]
    Oct  3 19:50:06.223: INFO: Got endpoints: latency-svc-n6hls [299.238287ms]
    Oct  3 19:50:06.224: INFO: Latencies: [42.135193ms 46.95785ms 60.990458ms 66.523457ms 80.636945ms 85.561616ms 95.536333ms 97.858992ms 112.721915ms 114.035364ms 131.044718ms 151.904228ms 161.293212ms 176.254947ms 191.807241ms 201.644647ms 202.725998ms 203.736158ms 211.519548ms 217.747519ms 218.120087ms 224.050633ms 228.596121ms 234.903738ms 239.770908ms 240.881658ms 242.13057ms 242.572321ms 243.412817ms 243.620221ms 244.072893ms 244.184653ms 244.715422ms 245.136845ms 245.521858ms 245.756789ms 246.002194ms 246.234193ms 246.740416ms 246.757876ms 246.959655ms 247.294915ms 247.894034ms 248.166761ms 249.01184ms 249.142529ms 249.910574ms 250.851799ms 250.973422ms 251.001644ms 251.521727ms 251.574019ms 251.723533ms 251.852715ms 252.052372ms 252.692292ms 252.845729ms 253.070839ms 253.79392ms 253.889519ms 254.654584ms 257.439121ms 258.293075ms 259.587698ms 259.62366ms 260.695083ms 260.708444ms 261.708364ms 262.259779ms 262.504364ms 263.510999ms 263.593674ms 265.736957ms 266.446729ms 266.786297ms 267.290407ms 267.458148ms 267.599079ms 267.688858ms 267.836549ms 267.945453ms 268.36774ms 269.055945ms 271.050069ms 271.461946ms 272.248631ms 272.351624ms 272.744268ms 272.959163ms 273.28506ms 273.327846ms 273.815937ms 274.664091ms 274.904688ms 275.152886ms 275.556269ms 277.618828ms 278.537345ms 278.603032ms 279.266505ms 279.468379ms 279.473672ms 279.624348ms 281.798629ms 282.14681ms 282.922977ms 282.955788ms 283.21398ms 283.375653ms 283.40485ms 283.651008ms 283.852689ms 284.051051ms 284.549958ms 284.605564ms 285.193497ms 285.271406ms 286.063169ms 286.081393ms 286.498783ms 286.517941ms 286.864574ms 287.121923ms 287.318491ms 287.641764ms 288.124998ms 288.197813ms 288.257076ms 288.323363ms 288.552205ms 288.999298ms 289.044294ms 289.11785ms 289.659355ms 289.762014ms 290.525663ms 290.946997ms 291.19593ms 291.826371ms 292.475386ms 293.122978ms 293.517797ms 294.085976ms 294.241826ms 295.372904ms 295.842643ms 298.743136ms 299.238287ms 301.007333ms 302.739514ms 304.203795ms 304.582291ms 306.539579ms 308.30377ms 308.688301ms 311.549396ms 313.734134ms 313.977633ms 317.247689ms 320.825833ms 324.467536ms 324.666746ms 325.42234ms 325.605652ms 327.378465ms 328.549796ms 332.13078ms 334.779987ms 335.134393ms 335.654571ms 336.730202ms 337.246243ms 338.547149ms 343.189742ms 345.292075ms 348.164972ms 355.719267ms 359.109628ms 360.435805ms 362.329509ms 367.074802ms 367.21392ms 370.342306ms 371.381786ms 372.513773ms 372.569098ms 373.113995ms 375.602569ms 382.841648ms 387.883857ms 389.010392ms 389.54456ms 391.354266ms 392.221605ms 395.484989ms 413.257449ms 421.670054ms 431.531159ms 451.647721ms 468.177969ms]
    Oct  3 19:50:06.224: INFO: 50 %ile: 279.468379ms
    Oct  3 19:50:06.224: INFO: 90 %ile: 367.074802ms
    Oct  3 19:50:06.224: INFO: 99 %ile: 451.647721ms
    Oct  3 19:50:06.224: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Oct  3 19:50:06.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-4943" for this suite. 10/03/22 19:50:06.274
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:50:06.297
Oct  3 19:50:06.297: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename proxy 10/03/22 19:50:06.298
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:50:06.333
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:50:06.343
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Oct  3 19:50:06.353: INFO: Creating pod...
Oct  3 19:50:06.374: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-247" to be "running"
Oct  3 19:50:06.384: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 10.381337ms
Oct  3 19:50:08.398: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024205498s
Oct  3 19:50:10.398: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.024118601s
Oct  3 19:50:10.398: INFO: Pod "agnhost" satisfied condition "running"
Oct  3 19:50:10.398: INFO: Creating service...
Oct  3 19:50:10.428: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/pods/agnhost/proxy/some/path/with/DELETE
Oct  3 19:50:10.470: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Oct  3 19:50:10.470: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/pods/agnhost/proxy/some/path/with/GET
Oct  3 19:50:10.486: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Oct  3 19:50:10.486: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/pods/agnhost/proxy/some/path/with/HEAD
Oct  3 19:50:10.503: INFO: http.Client request:HEAD | StatusCode:200
Oct  3 19:50:10.503: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/pods/agnhost/proxy/some/path/with/OPTIONS
Oct  3 19:50:10.519: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Oct  3 19:50:10.519: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/pods/agnhost/proxy/some/path/with/PATCH
Oct  3 19:50:10.538: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Oct  3 19:50:10.538: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/pods/agnhost/proxy/some/path/with/POST
Oct  3 19:50:10.568: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Oct  3 19:50:10.568: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/pods/agnhost/proxy/some/path/with/PUT
Oct  3 19:50:10.587: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Oct  3 19:50:10.587: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/services/test-service/proxy/some/path/with/DELETE
Oct  3 19:50:10.635: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Oct  3 19:50:10.635: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/services/test-service/proxy/some/path/with/GET
Oct  3 19:50:10.660: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Oct  3 19:50:10.660: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/services/test-service/proxy/some/path/with/HEAD
Oct  3 19:50:10.686: INFO: http.Client request:HEAD | StatusCode:200
Oct  3 19:50:10.686: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/services/test-service/proxy/some/path/with/OPTIONS
Oct  3 19:50:10.717: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Oct  3 19:50:10.717: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/services/test-service/proxy/some/path/with/PATCH
Oct  3 19:50:10.742: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Oct  3 19:50:10.742: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/services/test-service/proxy/some/path/with/POST
Oct  3 19:50:10.768: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Oct  3 19:50:10.768: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/services/test-service/proxy/some/path/with/PUT
Oct  3 19:50:10.792: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Oct  3 19:50:10.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-247" for this suite. 10/03/22 19:50:10.81
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":117,"skipped":2373,"failed":0}
------------------------------
• [4.534 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:50:06.297
    Oct  3 19:50:06.297: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename proxy 10/03/22 19:50:06.298
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:50:06.333
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:50:06.343
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Oct  3 19:50:06.353: INFO: Creating pod...
    Oct  3 19:50:06.374: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-247" to be "running"
    Oct  3 19:50:06.384: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 10.381337ms
    Oct  3 19:50:08.398: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024205498s
    Oct  3 19:50:10.398: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.024118601s
    Oct  3 19:50:10.398: INFO: Pod "agnhost" satisfied condition "running"
    Oct  3 19:50:10.398: INFO: Creating service...
    Oct  3 19:50:10.428: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/pods/agnhost/proxy/some/path/with/DELETE
    Oct  3 19:50:10.470: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Oct  3 19:50:10.470: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/pods/agnhost/proxy/some/path/with/GET
    Oct  3 19:50:10.486: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Oct  3 19:50:10.486: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/pods/agnhost/proxy/some/path/with/HEAD
    Oct  3 19:50:10.503: INFO: http.Client request:HEAD | StatusCode:200
    Oct  3 19:50:10.503: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/pods/agnhost/proxy/some/path/with/OPTIONS
    Oct  3 19:50:10.519: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Oct  3 19:50:10.519: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/pods/agnhost/proxy/some/path/with/PATCH
    Oct  3 19:50:10.538: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Oct  3 19:50:10.538: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/pods/agnhost/proxy/some/path/with/POST
    Oct  3 19:50:10.568: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Oct  3 19:50:10.568: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/pods/agnhost/proxy/some/path/with/PUT
    Oct  3 19:50:10.587: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Oct  3 19:50:10.587: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/services/test-service/proxy/some/path/with/DELETE
    Oct  3 19:50:10.635: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Oct  3 19:50:10.635: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/services/test-service/proxy/some/path/with/GET
    Oct  3 19:50:10.660: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Oct  3 19:50:10.660: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/services/test-service/proxy/some/path/with/HEAD
    Oct  3 19:50:10.686: INFO: http.Client request:HEAD | StatusCode:200
    Oct  3 19:50:10.686: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/services/test-service/proxy/some/path/with/OPTIONS
    Oct  3 19:50:10.717: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Oct  3 19:50:10.717: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/services/test-service/proxy/some/path/with/PATCH
    Oct  3 19:50:10.742: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Oct  3 19:50:10.742: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/services/test-service/proxy/some/path/with/POST
    Oct  3 19:50:10.768: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Oct  3 19:50:10.768: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-247/services/test-service/proxy/some/path/with/PUT
    Oct  3 19:50:10.792: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Oct  3 19:50:10.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-247" for this suite. 10/03/22 19:50:10.81
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:50:10.836
Oct  3 19:50:10.836: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-lifecycle-hook 10/03/22 19:50:10.838
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:50:10.875
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:50:10.885
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 10/03/22 19:50:10.913
Oct  3 19:50:10.934: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9640" to be "running and ready"
Oct  3 19:50:10.946: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 12.392499ms
Oct  3 19:50:10.946: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:50:12.959: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.025157004s
Oct  3 19:50:12.959: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Oct  3 19:50:12.959: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 10/03/22 19:50:12.97
Oct  3 19:50:12.984: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-9640" to be "running and ready"
Oct  3 19:50:12.999: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 14.678839ms
Oct  3 19:50:12.999: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:50:15.012: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.02798219s
Oct  3 19:50:15.012: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Oct  3 19:50:15.012: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 10/03/22 19:50:15.023
Oct  3 19:50:15.043: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  3 19:50:15.057: INFO: Pod pod-with-prestop-http-hook still exists
Oct  3 19:50:17.058: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  3 19:50:17.070: INFO: Pod pod-with-prestop-http-hook still exists
Oct  3 19:50:19.057: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  3 19:50:19.069: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 10/03/22 19:50:19.069
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Oct  3 19:50:19.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9640" for this suite. 10/03/22 19:50:19.114
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":118,"skipped":2384,"failed":0}
------------------------------
• [SLOW TEST] [8.299 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:50:10.836
    Oct  3 19:50:10.836: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-lifecycle-hook 10/03/22 19:50:10.838
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:50:10.875
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:50:10.885
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 10/03/22 19:50:10.913
    Oct  3 19:50:10.934: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9640" to be "running and ready"
    Oct  3 19:50:10.946: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 12.392499ms
    Oct  3 19:50:10.946: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:50:12.959: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.025157004s
    Oct  3 19:50:12.959: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Oct  3 19:50:12.959: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 10/03/22 19:50:12.97
    Oct  3 19:50:12.984: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-9640" to be "running and ready"
    Oct  3 19:50:12.999: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 14.678839ms
    Oct  3 19:50:12.999: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:50:15.012: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.02798219s
    Oct  3 19:50:15.012: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Oct  3 19:50:15.012: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 10/03/22 19:50:15.023
    Oct  3 19:50:15.043: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Oct  3 19:50:15.057: INFO: Pod pod-with-prestop-http-hook still exists
    Oct  3 19:50:17.058: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Oct  3 19:50:17.070: INFO: Pod pod-with-prestop-http-hook still exists
    Oct  3 19:50:19.057: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Oct  3 19:50:19.069: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 10/03/22 19:50:19.069
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Oct  3 19:50:19.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-9640" for this suite. 10/03/22 19:50:19.114
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:50:19.138
Oct  3 19:50:19.139: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename aggregator 10/03/22 19:50:19.144
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:50:19.174
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:50:19.184
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Oct  3 19:50:19.194: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 10/03/22 19:50:19.196
Oct  3 19:50:19.891: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct  3 19:50:22.022: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:50:24.035: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:50:26.034: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:50:28.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:50:30.035: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:50:32.035: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:50:34.036: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:50:36.035: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:50:38.037: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:50:40.036: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:50:42.036: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:50:44.036: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:50:46.036: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 19:50:48.252: INFO: Waited 197.775769ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 10/03/22 19:50:48.451
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 10/03/22 19:50:48.463
STEP: List APIServices 10/03/22 19:50:48.48
Oct  3 19:50:48.504: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Oct  3 19:50:48.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-2818" for this suite. 10/03/22 19:50:48.934
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":119,"skipped":2391,"failed":0}
------------------------------
• [SLOW TEST] [29.817 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:50:19.138
    Oct  3 19:50:19.139: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename aggregator 10/03/22 19:50:19.144
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:50:19.174
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:50:19.184
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Oct  3 19:50:19.194: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 10/03/22 19:50:19.196
    Oct  3 19:50:19.891: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Oct  3 19:50:22.022: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:50:24.035: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:50:26.034: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:50:28.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:50:30.035: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:50:32.035: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:50:34.036: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:50:36.035: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:50:38.037: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:50:40.036: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:50:42.036: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:50:44.036: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:50:46.036: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 50, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 19:50:48.252: INFO: Waited 197.775769ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 10/03/22 19:50:48.451
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 10/03/22 19:50:48.463
    STEP: List APIServices 10/03/22 19:50:48.48
    Oct  3 19:50:48.504: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Oct  3 19:50:48.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-2818" for this suite. 10/03/22 19:50:48.934
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:50:48.958
Oct  3 19:50:48.958: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename dns 10/03/22 19:50:48.959
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:50:48.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:50:49.009
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 10/03/22 19:50:49.019
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local;sleep 1; done
 10/03/22 19:50:49.033
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local;sleep 1; done
 10/03/22 19:50:49.033
STEP: creating a pod to probe DNS 10/03/22 19:50:49.033
STEP: submitting the pod to kubernetes 10/03/22 19:50:49.033
Oct  3 19:50:49.080: INFO: Waiting up to 15m0s for pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99" in namespace "dns-1926" to be "running"
Oct  3 19:50:49.112: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Pending", Reason="", readiness=false. Elapsed: 31.405218ms
Oct  3 19:50:51.124: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043592908s
Oct  3 19:50:53.125: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044527941s
Oct  3 19:50:55.123: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Pending", Reason="", readiness=false. Elapsed: 6.04312494s
Oct  3 19:50:57.136: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Pending", Reason="", readiness=false. Elapsed: 8.055965798s
Oct  3 19:50:59.124: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Pending", Reason="", readiness=false. Elapsed: 10.044104332s
Oct  3 19:51:01.131: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Pending", Reason="", readiness=false. Elapsed: 12.050319817s
Oct  3 19:51:03.124: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Running", Reason="", readiness=true. Elapsed: 14.043756328s
Oct  3 19:51:03.124: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99" satisfied condition "running"
STEP: retrieving the pod 10/03/22 19:51:03.124
STEP: looking for the results for each expected name from probers 10/03/22 19:51:03.135
Oct  3 19:51:03.180: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:03.198: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:03.215: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:03.234: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:03.250: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:03.267: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:03.314: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:03.332: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:03.332: INFO: Lookups using dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local]

Oct  3 19:51:08.395: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:08.414: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:08.447: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:08.464: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:08.478: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:08.492: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:08.506: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:08.520: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:08.521: INFO: Lookups using dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local]

Oct  3 19:51:13.348: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:13.363: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:13.377: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:13.392: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:13.407: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:13.421: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:13.436: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:13.450: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:13.450: INFO: Lookups using dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local]

Oct  3 19:51:18.350: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:18.364: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:18.378: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:18.392: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:18.405: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:18.420: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:18.435: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:18.450: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:18.450: INFO: Lookups using dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local]

Oct  3 19:51:23.363: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:23.421: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
Oct  3 19:51:23.451: INFO: Lookups using dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99 failed for: [wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local]

Oct  3 19:51:28.446: INFO: DNS probes using dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99 succeeded

STEP: deleting the pod 10/03/22 19:51:28.446
STEP: deleting the test headless service 10/03/22 19:51:28.498
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Oct  3 19:51:28.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1926" for this suite. 10/03/22 19:51:28.591
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":120,"skipped":2422,"failed":0}
------------------------------
• [SLOW TEST] [39.654 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:50:48.958
    Oct  3 19:50:48.958: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename dns 10/03/22 19:50:48.959
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:50:48.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:50:49.009
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 10/03/22 19:50:49.019
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local;sleep 1; done
     10/03/22 19:50:49.033
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1926.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local;sleep 1; done
     10/03/22 19:50:49.033
    STEP: creating a pod to probe DNS 10/03/22 19:50:49.033
    STEP: submitting the pod to kubernetes 10/03/22 19:50:49.033
    Oct  3 19:50:49.080: INFO: Waiting up to 15m0s for pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99" in namespace "dns-1926" to be "running"
    Oct  3 19:50:49.112: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Pending", Reason="", readiness=false. Elapsed: 31.405218ms
    Oct  3 19:50:51.124: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043592908s
    Oct  3 19:50:53.125: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044527941s
    Oct  3 19:50:55.123: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Pending", Reason="", readiness=false. Elapsed: 6.04312494s
    Oct  3 19:50:57.136: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Pending", Reason="", readiness=false. Elapsed: 8.055965798s
    Oct  3 19:50:59.124: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Pending", Reason="", readiness=false. Elapsed: 10.044104332s
    Oct  3 19:51:01.131: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Pending", Reason="", readiness=false. Elapsed: 12.050319817s
    Oct  3 19:51:03.124: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99": Phase="Running", Reason="", readiness=true. Elapsed: 14.043756328s
    Oct  3 19:51:03.124: INFO: Pod "dns-test-9a23d802-4130-4ea3-b029-161e756f4d99" satisfied condition "running"
    STEP: retrieving the pod 10/03/22 19:51:03.124
    STEP: looking for the results for each expected name from probers 10/03/22 19:51:03.135
    Oct  3 19:51:03.180: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:03.198: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:03.215: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:03.234: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:03.250: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:03.267: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:03.314: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:03.332: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:03.332: INFO: Lookups using dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local]

    Oct  3 19:51:08.395: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:08.414: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:08.447: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:08.464: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:08.478: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:08.492: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:08.506: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:08.520: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:08.521: INFO: Lookups using dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local]

    Oct  3 19:51:13.348: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:13.363: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:13.377: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:13.392: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:13.407: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:13.421: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:13.436: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:13.450: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:13.450: INFO: Lookups using dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local]

    Oct  3 19:51:18.350: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:18.364: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:18.378: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:18.392: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:18.405: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:18.420: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:18.435: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:18.450: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:18.450: INFO: Lookups using dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1926.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_udp@dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1926.svc.cluster.local]

    Oct  3 19:51:23.363: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:23.421: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local from pod dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99: the server could not find the requested resource (get pods dns-test-9a23d802-4130-4ea3-b029-161e756f4d99)
    Oct  3 19:51:23.451: INFO: Lookups using dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99 failed for: [wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1926.svc.cluster.local]

    Oct  3 19:51:28.446: INFO: DNS probes using dns-1926/dns-test-9a23d802-4130-4ea3-b029-161e756f4d99 succeeded

    STEP: deleting the pod 10/03/22 19:51:28.446
    STEP: deleting the test headless service 10/03/22 19:51:28.498
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Oct  3 19:51:28.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1926" for this suite. 10/03/22 19:51:28.591
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:51:28.614
Oct  3 19:51:28.614: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename var-expansion 10/03/22 19:51:28.617
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:51:28.662
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:51:28.67
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 10/03/22 19:51:28.679
Oct  3 19:51:28.699: INFO: Waiting up to 5m0s for pod "var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea" in namespace "var-expansion-4623" to be "Succeeded or Failed"
Oct  3 19:51:28.712: INFO: Pod "var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea": Phase="Pending", Reason="", readiness=false. Elapsed: 13.025178ms
Oct  3 19:51:30.723: INFO: Pod "var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024270868s
Oct  3 19:51:32.725: INFO: Pod "var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026517424s
Oct  3 19:51:34.724: INFO: Pod "var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024920394s
STEP: Saw pod success 10/03/22 19:51:34.724
Oct  3 19:51:34.724: INFO: Pod "var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea" satisfied condition "Succeeded or Failed"
Oct  3 19:51:34.736: INFO: Trying to get logs from node 10.63.128.3 pod var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea container dapi-container: <nil>
STEP: delete the pod 10/03/22 19:51:34.792
Oct  3 19:51:34.819: INFO: Waiting for pod var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea to disappear
Oct  3 19:51:34.830: INFO: Pod var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Oct  3 19:51:34.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4623" for this suite. 10/03/22 19:51:34.844
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":121,"skipped":2429,"failed":0}
------------------------------
• [SLOW TEST] [6.249 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:51:28.614
    Oct  3 19:51:28.614: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename var-expansion 10/03/22 19:51:28.617
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:51:28.662
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:51:28.67
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 10/03/22 19:51:28.679
    Oct  3 19:51:28.699: INFO: Waiting up to 5m0s for pod "var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea" in namespace "var-expansion-4623" to be "Succeeded or Failed"
    Oct  3 19:51:28.712: INFO: Pod "var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea": Phase="Pending", Reason="", readiness=false. Elapsed: 13.025178ms
    Oct  3 19:51:30.723: INFO: Pod "var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024270868s
    Oct  3 19:51:32.725: INFO: Pod "var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026517424s
    Oct  3 19:51:34.724: INFO: Pod "var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024920394s
    STEP: Saw pod success 10/03/22 19:51:34.724
    Oct  3 19:51:34.724: INFO: Pod "var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea" satisfied condition "Succeeded or Failed"
    Oct  3 19:51:34.736: INFO: Trying to get logs from node 10.63.128.3 pod var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea container dapi-container: <nil>
    STEP: delete the pod 10/03/22 19:51:34.792
    Oct  3 19:51:34.819: INFO: Waiting for pod var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea to disappear
    Oct  3 19:51:34.830: INFO: Pod var-expansion-9e080ee6-3dcd-480e-8017-ea835b7d71ea no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Oct  3 19:51:34.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4623" for this suite. 10/03/22 19:51:34.844
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:51:34.863
Oct  3 19:51:34.864: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename configmap 10/03/22 19:51:34.865
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:51:34.903
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:51:34.91
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-00edc026-da3a-4b07-b746-80e26f9a7d79 10/03/22 19:51:34.931
STEP: Creating the pod 10/03/22 19:51:34.942
Oct  3 19:51:34.962: INFO: Waiting up to 5m0s for pod "pod-configmaps-8f7c871d-a317-46c7-899f-d0e0b17e7a5d" in namespace "configmap-813" to be "running"
Oct  3 19:51:34.973: INFO: Pod "pod-configmaps-8f7c871d-a317-46c7-899f-d0e0b17e7a5d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.889428ms
Oct  3 19:51:36.985: INFO: Pod "pod-configmaps-8f7c871d-a317-46c7-899f-d0e0b17e7a5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02295288s
Oct  3 19:51:38.985: INFO: Pod "pod-configmaps-8f7c871d-a317-46c7-899f-d0e0b17e7a5d": Phase="Running", Reason="", readiness=false. Elapsed: 4.023146747s
Oct  3 19:51:38.985: INFO: Pod "pod-configmaps-8f7c871d-a317-46c7-899f-d0e0b17e7a5d" satisfied condition "running"
STEP: Waiting for pod with text data 10/03/22 19:51:38.985
STEP: Waiting for pod with binary data 10/03/22 19:51:39.018
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Oct  3 19:51:39.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-813" for this suite. 10/03/22 19:51:39.06
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":122,"skipped":2432,"failed":0}
------------------------------
• [4.215 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:51:34.863
    Oct  3 19:51:34.864: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename configmap 10/03/22 19:51:34.865
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:51:34.903
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:51:34.91
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-00edc026-da3a-4b07-b746-80e26f9a7d79 10/03/22 19:51:34.931
    STEP: Creating the pod 10/03/22 19:51:34.942
    Oct  3 19:51:34.962: INFO: Waiting up to 5m0s for pod "pod-configmaps-8f7c871d-a317-46c7-899f-d0e0b17e7a5d" in namespace "configmap-813" to be "running"
    Oct  3 19:51:34.973: INFO: Pod "pod-configmaps-8f7c871d-a317-46c7-899f-d0e0b17e7a5d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.889428ms
    Oct  3 19:51:36.985: INFO: Pod "pod-configmaps-8f7c871d-a317-46c7-899f-d0e0b17e7a5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02295288s
    Oct  3 19:51:38.985: INFO: Pod "pod-configmaps-8f7c871d-a317-46c7-899f-d0e0b17e7a5d": Phase="Running", Reason="", readiness=false. Elapsed: 4.023146747s
    Oct  3 19:51:38.985: INFO: Pod "pod-configmaps-8f7c871d-a317-46c7-899f-d0e0b17e7a5d" satisfied condition "running"
    STEP: Waiting for pod with text data 10/03/22 19:51:38.985
    STEP: Waiting for pod with binary data 10/03/22 19:51:39.018
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Oct  3 19:51:39.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-813" for this suite. 10/03/22 19:51:39.06
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:51:39.088
Oct  3 19:51:39.088: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename daemonsets 10/03/22 19:51:39.089
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:51:39.125
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:51:39.133
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 10/03/22 19:51:39.203
STEP: Check that daemon pods launch on every node of the cluster. 10/03/22 19:51:39.215
Oct  3 19:51:39.239: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:51:39.240: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:51:40.270: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 19:51:40.270: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:51:41.268: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Oct  3 19:51:41.268: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 19:51:42.266: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct  3 19:51:42.266: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 10/03/22 19:51:42.275
STEP: DeleteCollection of the DaemonSets 10/03/22 19:51:42.285
STEP: Verify that ReplicaSets have been deleted 10/03/22 19:51:42.315
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Oct  3 19:51:42.342: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26319"},"items":null}

Oct  3 19:51:42.353: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26319"},"items":[{"metadata":{"name":"daemon-set-dbtsq","generateName":"daemon-set-","namespace":"daemonsets-315","uid":"83c57069-3ad7-4433-9696-a055ad02eacd","resourceVersion":"26316","creationTimestamp":"2022-10-03T19:51:39Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"0bfdada1605f29475277504abc3c945ebb9d21696d09205ff770c56e14d24317","cni.projectcalico.org/podIP":"172.30.35.205/32","cni.projectcalico.org/podIPs":"172.30.35.205/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"607a4b1f-cd7b-4765-ace3-73c8feb05bcf","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:39Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"607a4b1f-cd7b-4765-ace3-73c8feb05bcf\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:40Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:41Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.35.205\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-tm88c","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-tm88c","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.63.128.13","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.63.128.13"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:39Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:41Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:41Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:39Z"}],"hostIP":"10.63.128.13","podIP":"172.30.35.205","podIPs":[{"ip":"172.30.35.205"}],"startTime":"2022-10-03T19:51:39Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-10-03T19:51:41Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://421b58c566748ac1e1166993585305402a67340967e9044c6c12bab3bf7560bc","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-s76tc","generateName":"daemon-set-","namespace":"daemonsets-315","uid":"3947932b-0e78-4289-9eb2-7e189e357d5c","resourceVersion":"26314","creationTimestamp":"2022-10-03T19:51:39Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"398886034731b6650f6c15ba0d33cf29fe96c82987d9e034204fdb404bc21c34","cni.projectcalico.org/podIP":"172.30.49.10/32","cni.projectcalico.org/podIPs":"172.30.49.10/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"607a4b1f-cd7b-4765-ace3-73c8feb05bcf","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:39Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"607a4b1f-cd7b-4765-ace3-73c8feb05bcf\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:40Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:41Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.10\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-nxgjn","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-nxgjn","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.63.128.3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.63.128.3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:39Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:41Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:41Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:39Z"}],"hostIP":"10.63.128.3","podIP":"172.30.49.10","podIPs":[{"ip":"172.30.49.10"}],"startTime":"2022-10-03T19:51:39Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-10-03T19:51:40Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://1b2f5b09d6c442ed7869da3f204cb4da52368765572f8b11cfb7b5c72d466f69","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-tgvqw","generateName":"daemon-set-","namespace":"daemonsets-315","uid":"0f380d20-e4ba-4433-9cb4-4ad10ba53be9","resourceVersion":"26311","creationTimestamp":"2022-10-03T19:51:39Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"d62a716fa7286dd9aca1e72b8268101934f2e5eacef664ec7d240b2f597b87e4","cni.projectcalico.org/podIP":"172.30.174.201/32","cni.projectcalico.org/podIPs":"172.30.174.201/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"607a4b1f-cd7b-4765-ace3-73c8feb05bcf","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:39Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"607a4b1f-cd7b-4765-ace3-73c8feb05bcf\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:40Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:41Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.174.201\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-bjpmz","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-bjpmz","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.63.128.51","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.63.128.51"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:39Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:41Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:41Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:39Z"}],"hostIP":"10.63.128.51","podIP":"172.30.174.201","podIPs":[{"ip":"172.30.174.201"}],"startTime":"2022-10-03T19:51:39Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-10-03T19:51:40Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://48e1b657c53de528127f304865d47a721baacfc9140b5cbeca52675bacdcc5b4","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Oct  3 19:51:42.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-315" for this suite. 10/03/22 19:51:42.413
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":123,"skipped":2480,"failed":0}
------------------------------
• [3.347 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:51:39.088
    Oct  3 19:51:39.088: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename daemonsets 10/03/22 19:51:39.089
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:51:39.125
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:51:39.133
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 10/03/22 19:51:39.203
    STEP: Check that daemon pods launch on every node of the cluster. 10/03/22 19:51:39.215
    Oct  3 19:51:39.239: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:51:39.240: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:51:40.270: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 19:51:40.270: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:51:41.268: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Oct  3 19:51:41.268: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 19:51:42.266: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct  3 19:51:42.266: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 10/03/22 19:51:42.275
    STEP: DeleteCollection of the DaemonSets 10/03/22 19:51:42.285
    STEP: Verify that ReplicaSets have been deleted 10/03/22 19:51:42.315
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Oct  3 19:51:42.342: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26319"},"items":null}

    Oct  3 19:51:42.353: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26319"},"items":[{"metadata":{"name":"daemon-set-dbtsq","generateName":"daemon-set-","namespace":"daemonsets-315","uid":"83c57069-3ad7-4433-9696-a055ad02eacd","resourceVersion":"26316","creationTimestamp":"2022-10-03T19:51:39Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"0bfdada1605f29475277504abc3c945ebb9d21696d09205ff770c56e14d24317","cni.projectcalico.org/podIP":"172.30.35.205/32","cni.projectcalico.org/podIPs":"172.30.35.205/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"607a4b1f-cd7b-4765-ace3-73c8feb05bcf","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:39Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"607a4b1f-cd7b-4765-ace3-73c8feb05bcf\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:40Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:41Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.35.205\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-tm88c","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-tm88c","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.63.128.13","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.63.128.13"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:39Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:41Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:41Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:39Z"}],"hostIP":"10.63.128.13","podIP":"172.30.35.205","podIPs":[{"ip":"172.30.35.205"}],"startTime":"2022-10-03T19:51:39Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-10-03T19:51:41Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://421b58c566748ac1e1166993585305402a67340967e9044c6c12bab3bf7560bc","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-s76tc","generateName":"daemon-set-","namespace":"daemonsets-315","uid":"3947932b-0e78-4289-9eb2-7e189e357d5c","resourceVersion":"26314","creationTimestamp":"2022-10-03T19:51:39Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"398886034731b6650f6c15ba0d33cf29fe96c82987d9e034204fdb404bc21c34","cni.projectcalico.org/podIP":"172.30.49.10/32","cni.projectcalico.org/podIPs":"172.30.49.10/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"607a4b1f-cd7b-4765-ace3-73c8feb05bcf","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:39Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"607a4b1f-cd7b-4765-ace3-73c8feb05bcf\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:40Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:41Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.10\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-nxgjn","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-nxgjn","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.63.128.3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.63.128.3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:39Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:41Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:41Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:39Z"}],"hostIP":"10.63.128.3","podIP":"172.30.49.10","podIPs":[{"ip":"172.30.49.10"}],"startTime":"2022-10-03T19:51:39Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-10-03T19:51:40Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://1b2f5b09d6c442ed7869da3f204cb4da52368765572f8b11cfb7b5c72d466f69","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-tgvqw","generateName":"daemon-set-","namespace":"daemonsets-315","uid":"0f380d20-e4ba-4433-9cb4-4ad10ba53be9","resourceVersion":"26311","creationTimestamp":"2022-10-03T19:51:39Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"d62a716fa7286dd9aca1e72b8268101934f2e5eacef664ec7d240b2f597b87e4","cni.projectcalico.org/podIP":"172.30.174.201/32","cni.projectcalico.org/podIPs":"172.30.174.201/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"607a4b1f-cd7b-4765-ace3-73c8feb05bcf","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:39Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"607a4b1f-cd7b-4765-ace3-73c8feb05bcf\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:40Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-10-03T19:51:41Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.174.201\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-bjpmz","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-bjpmz","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.63.128.51","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.63.128.51"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:39Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:41Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:41Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-03T19:51:39Z"}],"hostIP":"10.63.128.51","podIP":"172.30.174.201","podIPs":[{"ip":"172.30.174.201"}],"startTime":"2022-10-03T19:51:39Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-10-03T19:51:40Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://48e1b657c53de528127f304865d47a721baacfc9140b5cbeca52675bacdcc5b4","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 19:51:42.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-315" for this suite. 10/03/22 19:51:42.413
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:51:42.436
Oct  3 19:51:42.436: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir 10/03/22 19:51:42.438
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:51:42.486
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:51:42.494
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 10/03/22 19:51:42.501
Oct  3 19:51:42.525: INFO: Waiting up to 5m0s for pod "pod-3f1f812f-6081-4487-85cd-864443ee6197" in namespace "emptydir-8803" to be "Succeeded or Failed"
Oct  3 19:51:42.535: INFO: Pod "pod-3f1f812f-6081-4487-85cd-864443ee6197": Phase="Pending", Reason="", readiness=false. Elapsed: 10.782269ms
Oct  3 19:51:44.547: INFO: Pod "pod-3f1f812f-6081-4487-85cd-864443ee6197": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022854427s
Oct  3 19:51:46.548: INFO: Pod "pod-3f1f812f-6081-4487-85cd-864443ee6197": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022982117s
STEP: Saw pod success 10/03/22 19:51:46.548
Oct  3 19:51:46.548: INFO: Pod "pod-3f1f812f-6081-4487-85cd-864443ee6197" satisfied condition "Succeeded or Failed"
Oct  3 19:51:46.560: INFO: Trying to get logs from node 10.63.128.3 pod pod-3f1f812f-6081-4487-85cd-864443ee6197 container test-container: <nil>
STEP: delete the pod 10/03/22 19:51:46.586
Oct  3 19:51:46.622: INFO: Waiting for pod pod-3f1f812f-6081-4487-85cd-864443ee6197 to disappear
Oct  3 19:51:46.632: INFO: Pod pod-3f1f812f-6081-4487-85cd-864443ee6197 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Oct  3 19:51:46.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8803" for this suite. 10/03/22 19:51:46.646
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":124,"skipped":2493,"failed":0}
------------------------------
• [4.229 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:51:42.436
    Oct  3 19:51:42.436: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir 10/03/22 19:51:42.438
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:51:42.486
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:51:42.494
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 10/03/22 19:51:42.501
    Oct  3 19:51:42.525: INFO: Waiting up to 5m0s for pod "pod-3f1f812f-6081-4487-85cd-864443ee6197" in namespace "emptydir-8803" to be "Succeeded or Failed"
    Oct  3 19:51:42.535: INFO: Pod "pod-3f1f812f-6081-4487-85cd-864443ee6197": Phase="Pending", Reason="", readiness=false. Elapsed: 10.782269ms
    Oct  3 19:51:44.547: INFO: Pod "pod-3f1f812f-6081-4487-85cd-864443ee6197": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022854427s
    Oct  3 19:51:46.548: INFO: Pod "pod-3f1f812f-6081-4487-85cd-864443ee6197": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022982117s
    STEP: Saw pod success 10/03/22 19:51:46.548
    Oct  3 19:51:46.548: INFO: Pod "pod-3f1f812f-6081-4487-85cd-864443ee6197" satisfied condition "Succeeded or Failed"
    Oct  3 19:51:46.560: INFO: Trying to get logs from node 10.63.128.3 pod pod-3f1f812f-6081-4487-85cd-864443ee6197 container test-container: <nil>
    STEP: delete the pod 10/03/22 19:51:46.586
    Oct  3 19:51:46.622: INFO: Waiting for pod pod-3f1f812f-6081-4487-85cd-864443ee6197 to disappear
    Oct  3 19:51:46.632: INFO: Pod pod-3f1f812f-6081-4487-85cd-864443ee6197 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Oct  3 19:51:46.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8803" for this suite. 10/03/22 19:51:46.646
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:51:46.666
Oct  3 19:51:46.667: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename deployment 10/03/22 19:51:46.668
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:51:46.705
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:51:46.712
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Oct  3 19:51:46.720: INFO: Creating deployment "webserver-deployment"
Oct  3 19:51:46.733: INFO: Waiting for observed generation 1
Oct  3 19:51:48.758: INFO: Waiting for all required pods to come up
Oct  3 19:51:48.772: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 10/03/22 19:51:48.772
Oct  3 19:51:48.772: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-7f8ms" in namespace "deployment-6348" to be "running"
Oct  3 19:51:48.773: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-822kx" in namespace "deployment-6348" to be "running"
Oct  3 19:51:48.773: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-866lx" in namespace "deployment-6348" to be "running"
Oct  3 19:51:48.773: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-zfhhr" in namespace "deployment-6348" to be "running"
Oct  3 19:51:48.773: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-f2785" in namespace "deployment-6348" to be "running"
Oct  3 19:51:48.773: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-mldb9" in namespace "deployment-6348" to be "running"
Oct  3 19:51:48.773: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-7v9nj" in namespace "deployment-6348" to be "running"
Oct  3 19:51:48.773: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-wfdxx" in namespace "deployment-6348" to be "running"
Oct  3 19:51:48.784: INFO: Pod "webserver-deployment-845c8977d9-zfhhr": Phase="Pending", Reason="", readiness=false. Elapsed: 10.671546ms
Oct  3 19:51:48.788: INFO: Pod "webserver-deployment-845c8977d9-7v9nj": Phase="Pending", Reason="", readiness=false. Elapsed: 15.271229ms
Oct  3 19:51:48.788: INFO: Pod "webserver-deployment-845c8977d9-f2785": Phase="Pending", Reason="", readiness=false. Elapsed: 15.424425ms
Oct  3 19:51:48.789: INFO: Pod "webserver-deployment-845c8977d9-wfdxx": Phase="Pending", Reason="", readiness=false. Elapsed: 15.696235ms
Oct  3 19:51:48.789: INFO: Pod "webserver-deployment-845c8977d9-7f8ms": Phase="Pending", Reason="", readiness=false. Elapsed: 16.574186ms
Oct  3 19:51:48.789: INFO: Pod "webserver-deployment-845c8977d9-mldb9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.279939ms
Oct  3 19:51:48.790: INFO: Pod "webserver-deployment-845c8977d9-822kx": Phase="Running", Reason="", readiness=true. Elapsed: 17.118116ms
Oct  3 19:51:48.790: INFO: Pod "webserver-deployment-845c8977d9-822kx" satisfied condition "running"
Oct  3 19:51:48.790: INFO: Pod "webserver-deployment-845c8977d9-866lx": Phase="Pending", Reason="", readiness=false. Elapsed: 17.545356ms
Oct  3 19:51:50.796: INFO: Pod "webserver-deployment-845c8977d9-zfhhr": Phase="Running", Reason="", readiness=true. Elapsed: 2.023586753s
Oct  3 19:51:50.797: INFO: Pod "webserver-deployment-845c8977d9-zfhhr" satisfied condition "running"
Oct  3 19:51:50.801: INFO: Pod "webserver-deployment-845c8977d9-f2785": Phase="Running", Reason="", readiness=true. Elapsed: 2.027952123s
Oct  3 19:51:50.801: INFO: Pod "webserver-deployment-845c8977d9-f2785" satisfied condition "running"
Oct  3 19:51:50.801: INFO: Pod "webserver-deployment-845c8977d9-7v9nj": Phase="Running", Reason="", readiness=true. Elapsed: 2.027853036s
Oct  3 19:51:50.801: INFO: Pod "webserver-deployment-845c8977d9-7v9nj" satisfied condition "running"
Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-mldb9": Phase="Running", Reason="", readiness=true. Elapsed: 2.032467014s
Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-mldb9" satisfied condition "running"
Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-7f8ms": Phase="Running", Reason="", readiness=true. Elapsed: 2.032991626s
Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-7f8ms" satisfied condition "running"
Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-wfdxx": Phase="Running", Reason="", readiness=true. Elapsed: 2.032724487s
Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-wfdxx" satisfied condition "running"
Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-866lx": Phase="Running", Reason="", readiness=true. Elapsed: 2.033513667s
Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-866lx" satisfied condition "running"
Oct  3 19:51:50.806: INFO: Waiting for deployment "webserver-deployment" to complete
Oct  3 19:51:50.826: INFO: Updating deployment "webserver-deployment" with a non-existent image
Oct  3 19:51:50.850: INFO: Updating deployment webserver-deployment
Oct  3 19:51:50.850: INFO: Waiting for observed generation 2
Oct  3 19:51:52.868: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct  3 19:51:52.877: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct  3 19:51:52.886: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Oct  3 19:51:52.912: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct  3 19:51:52.912: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct  3 19:51:52.922: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Oct  3 19:51:52.939: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Oct  3 19:51:52.939: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Oct  3 19:51:52.961: INFO: Updating deployment webserver-deployment
Oct  3 19:51:52.961: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Oct  3 19:51:52.980: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct  3 19:51:52.987: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct  3 19:51:53.018: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-6348  a4b5a373-d055-4e3d-bc8a-0f8330c9b48a 26660 3 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003cfb488 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-10-03 19:51:50 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-10-03 19:51:52 +0000 UTC,LastTransitionTime:2022-10-03 19:51:52 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Oct  3 19:51:53.028: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-6348  9d85fa38-9e22-483d-824f-56cf6e08ea1d 26657 3 2022-10-03 19:51:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment a4b5a373-d055-4e3d-bc8a-0f8330c9b48a 0xc003cfb8c7 0xc003cfb8c8}] [] [{kube-controller-manager Update apps/v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a4b5a373-d055-4e3d-bc8a-0f8330c9b48a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003cfb968 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  3 19:51:53.028: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Oct  3 19:51:53.028: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-6348  d5762740-0319-4411-a46a-1b4382f8b2ea 26654 3 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment a4b5a373-d055-4e3d-bc8a-0f8330c9b48a 0xc003cfb9c7 0xc003cfb9c8}] [] [{kube-controller-manager Update apps/v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a4b5a373-d055-4e3d-bc8a-0f8330c9b48a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003cfba68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Oct  3 19:51:53.070: INFO: Pod "webserver-deployment-69b7448995-28qrb" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-28qrb webserver-deployment-69b7448995- deployment-6348  e5e2085d-7ac4-4fef-9ac2-f2e74130fe05 26622 0 2022-10-03 19:51:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:d9ee5fb5b36467c39a6d3a7baaeac4950daa6949afff0b123b918958328ce41e cni.projectcalico.org/podIP:172.30.174.207/32 cni.projectcalico.org/podIPs:172.30.174.207/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc003cfbfc7 0xc003cfbfc8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-10-03 19:51:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p4lr8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p4lr8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.51,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.51,PodIP:,StartTime:2022-10-03 19:51:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.070: INFO: Pod "webserver-deployment-69b7448995-2t8gj" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-2t8gj webserver-deployment-69b7448995- deployment-6348  5d6baee8-caad-45d6-a435-8a0f1e4ed261 26681 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312a1e7 0xc00312a1e8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m5479,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m5479,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.071: INFO: Pod "webserver-deployment-69b7448995-66d5s" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-66d5s webserver-deployment-69b7448995- deployment-6348  3713f0af-d959-4af8-ba6c-23e6dba367bd 26626 0 2022-10-03 19:51:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:2b6cb7bbb0cbb78c7a6b3c2511e773ce520bdb4da2570bdcb0c6bbac4fb908af cni.projectcalico.org/podIP:172.30.49.17/32 cni.projectcalico.org/podIPs:172.30.49.17/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312a357 0xc00312a358}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-10-03 19:51:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rd2wp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rd2wp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:,StartTime:2022-10-03 19:51:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.071: INFO: Pod "webserver-deployment-69b7448995-dbgvb" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-dbgvb webserver-deployment-69b7448995- deployment-6348  03ef3dcf-53db-418d-835b-904c4da8b71e 26679 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312a590 0xc00312a591}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rhw9g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rhw9g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.071: INFO: Pod "webserver-deployment-69b7448995-fzxpn" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-fzxpn webserver-deployment-69b7448995- deployment-6348  d5065cfd-b1a1-428a-9339-2189dbb4f3de 26665 0 2022-10-03 19:51:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312a6d7 0xc00312a6d8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4b5hb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4b5hb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.51,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.071: INFO: Pod "webserver-deployment-69b7448995-h962q" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-h962q webserver-deployment-69b7448995- deployment-6348  c9328e91-d7d3-4bf3-9242-fa8372efd965 26676 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312a850 0xc00312a851}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5xd25,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5xd25,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.072: INFO: Pod "webserver-deployment-69b7448995-jq952" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-jq952 webserver-deployment-69b7448995- deployment-6348  da15f8dd-04df-4b94-85f9-168fef3c28ae 26641 0 2022-10-03 19:51:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:45e60d7c2377cdb40867419562dc0d73220c3129e75e983206bd225a11d6bcea cni.projectcalico.org/podIP:172.30.35.211/32 cni.projectcalico.org/podIPs:172.30.35.211/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312a9b7 0xc00312a9b8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dd4bw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dd4bw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:,StartTime:2022-10-03 19:51:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.072: INFO: Pod "webserver-deployment-69b7448995-jrpmp" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-jrpmp webserver-deployment-69b7448995- deployment-6348  681cd99b-c68e-42f1-af24-6e4d84178645 26677 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312abc7 0xc00312abc8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fv2nh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fv2nh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.072: INFO: Pod "webserver-deployment-69b7448995-k69qm" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-k69qm webserver-deployment-69b7448995- deployment-6348  c5afba64-9656-43a6-ab65-0b808bfc83d5 26678 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312ad50 0xc00312ad51}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wj4gw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wj4gw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.073: INFO: Pod "webserver-deployment-69b7448995-lwjfc" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-lwjfc webserver-deployment-69b7448995- deployment-6348  ba18b699-2dc2-4291-8fa2-8371e3a445df 26624 0 2022-10-03 19:51:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:ed3e5c55bc44e9251ee08fa701582c4d171ce463150e876482213629be352549 cni.projectcalico.org/podIP:172.30.35.208/32 cni.projectcalico.org/podIPs:172.30.35.208/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312b080 0xc00312b081}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dfnz8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dfnz8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:,StartTime:2022-10-03 19:51:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.073: INFO: Pod "webserver-deployment-69b7448995-ns4vt" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-ns4vt webserver-deployment-69b7448995- deployment-6348  62ce3cf0-7955-4414-8943-ab04bab7e066 26637 0 2022-10-03 19:51:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:d2ebd06c05031176111942bced83d61462b052196be1c827d36d1e961fe6e67f cni.projectcalico.org/podIP:172.30.49.15/32 cni.projectcalico.org/podIPs:172.30.49.15/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312b2a7 0xc00312b2a8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-llgq6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-llgq6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:,StartTime:2022-10-03 19:51:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.073: INFO: Pod "webserver-deployment-69b7448995-r527l" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-r527l webserver-deployment-69b7448995- deployment-6348  8a6fc31c-1546-4655-b7b4-1a6f933391a5 26680 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312b4b0 0xc00312b4b1}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qvccl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qvccl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.074: INFO: Pod "webserver-deployment-845c8977d9-2sm4n" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-2sm4n webserver-deployment-845c8977d9- deployment-6348  613f4e31-739b-4469-ac79-c005d3ff09fc 26689 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc00312b5f7 0xc00312b5f8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8wrht,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8wrht,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.074: INFO: Pod "webserver-deployment-845c8977d9-46jwm" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-46jwm webserver-deployment-845c8977d9- deployment-6348  4232aed9-cd25-42d2-a3f7-77a866685328 26685 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc00312b737 0xc00312b738}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4rzlx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4rzlx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.075: INFO: Pod "webserver-deployment-845c8977d9-7f8ms" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-7f8ms webserver-deployment-845c8977d9- deployment-6348  7ddc6efe-3f6f-47d2-9059-c81d5cf446af 26548 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:4f58bbdc6354198a8ba4da7e02a8f99358e9c78ad91c05da992e1ee7af3f6d0e cni.projectcalico.org/podIP:172.30.174.198/32 cni.projectcalico.org/podIPs:172.30.174.198/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc00312b877 0xc00312b878}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.174.198\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-55cw9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-55cw9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.51,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.51,PodIP:172.30.174.198,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://79e5dfc29aeb93cc0946d14623119e11862fc4b34bc873e44f143f4229997349,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.174.198,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.075: INFO: Pod "webserver-deployment-845c8977d9-7v9nj" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-7v9nj webserver-deployment-845c8977d9- deployment-6348  1d4f2fc3-6508-419c-ae7b-001d734dafae 26544 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:af56e0eee9c21b9a562a0338cfdb6fa532ab2aba4fdee18b5c447d0b86e5bf9b cni.projectcalico.org/podIP:172.30.174.210/32 cni.projectcalico.org/podIPs:172.30.174.210/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc00312ba87 0xc00312ba88}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.174.210\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-99q8z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-99q8z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.51,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.51,PodIP:172.30.174.210,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c17c0221512319683a51e303eb46ca8aba6929cdb787187a85a0da1dec7fb059,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.174.210,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.076: INFO: Pod "webserver-deployment-845c8977d9-822kx" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-822kx webserver-deployment-845c8977d9- deployment-6348  2d5ea8c0-9523-4392-b43b-7b2c22fdceed 26531 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:3ff2b02d67842e228723825fe8be84f3e965e470ce62b0d986b99ec454d6a37c cni.projectcalico.org/podIP:172.30.35.207/32 cni.projectcalico.org/podIPs:172.30.35.207/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc00312bcb7 0xc00312bcb8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.35.207\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w8cch,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w8cch,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:172.30.35.207,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://aa9ecbf9bbecac2b4075cbf9be4c1e011e76c647d0f20b0166841c5a6a091de4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.35.207,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.077: INFO: Pod "webserver-deployment-845c8977d9-866lx" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-866lx webserver-deployment-845c8977d9- deployment-6348  50f74bff-5300-4274-9c67-d1c9d9aa1d81 26562 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6a3d7ff318cc7b4b733f296c30d20460243411e7199af4622fa0009eaf3e05e3 cni.projectcalico.org/podIP:172.30.35.210/32 cni.projectcalico.org/podIPs:172.30.35.210/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc00312bee7 0xc00312bee8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.35.210\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wdnpg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wdnpg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:172.30.35.210,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://fdf2a86e903c4ebcdea842ccab284fc7fc41995681223ded1945bd73f77b57f1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.35.210,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.077: INFO: Pod "webserver-deployment-845c8977d9-dmcxx" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-dmcxx webserver-deployment-845c8977d9- deployment-6348  724e51a1-a38a-43a7-bd4b-8d5f632f6a61 26688 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426107 0xc002426108}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7zz2c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7zz2c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.077: INFO: Pod "webserver-deployment-845c8977d9-f97j6" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-f97j6 webserver-deployment-845c8977d9- deployment-6348  8326807c-d314-499c-bc72-5cf512220625 26508 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:5917c0586139f108aeda71b95a350cdf9687942b7e6ed5596fdc15beacca6934 cni.projectcalico.org/podIP:172.30.49.12/32 cni.projectcalico.org/podIPs:172.30.49.12/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426290 0xc002426291}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.12\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9n78d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9n78d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.12,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://87b70d69ffe93c509a34225efe5721471dec2fb385fc31f09a25cccc4cf80877,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.12,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.078: INFO: Pod "webserver-deployment-845c8977d9-gckqs" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gckqs webserver-deployment-845c8977d9- deployment-6348  7b0e4bab-eeca-4cdd-889c-114a8d63158d 26674 0 2022-10-03 19:51:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426497 0xc002426498}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hrmsn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hrmsn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.078: INFO: Pod "webserver-deployment-845c8977d9-hrmpj" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-hrmpj webserver-deployment-845c8977d9- deployment-6348  e43c8e2c-846d-442e-849e-b57adb19916e 26526 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:a21fbb0b89c15dab066e579a6c6fd16e0bdc0a52571c66702b08b878562fdc83 cni.projectcalico.org/podIP:172.30.35.206/32 cni.projectcalico.org/podIPs:172.30.35.206/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426620 0xc002426621}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.35.206\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j7mx6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j7mx6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:172.30.35.206,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7688a446e0ede38ac77c321a4be501dbb79928231ba8f40f0aa5eea3945afa12,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.35.206,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.079: INFO: Pod "webserver-deployment-845c8977d9-lrq5g" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-lrq5g webserver-deployment-845c8977d9- deployment-6348  cc6c2a9c-5310-4594-8b8d-1f121f3a863b 26683 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426827 0xc002426828}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dgzcn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dgzcn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.079: INFO: Pod "webserver-deployment-845c8977d9-mldb9" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-mldb9 webserver-deployment-845c8977d9- deployment-6348  7036a7f4-90f4-41a9-8276-8787023db9ba 26541 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:45f4ead2d553824e5144ab4fa0343c5b5017f899a2732d22b6c6de501c9c00a6 cni.projectcalico.org/podIP:172.30.174.199/32 cni.projectcalico.org/podIPs:172.30.174.199/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426990 0xc002426991}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.174.199\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qj7c5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qj7c5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.51,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.51,PodIP:172.30.174.199,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://fd9ae9645720f2626b182d8efe59eddd63d75d61fa939d7b25f0ace8d9d844f8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.174.199,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.079: INFO: Pod "webserver-deployment-845c8977d9-p2mfw" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-p2mfw webserver-deployment-845c8977d9- deployment-6348  f674fb25-5a7f-4fe8-989c-988c58ecc73c 26684 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426b97 0xc002426b98}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mm7hd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mm7hd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.080: INFO: Pod "webserver-deployment-845c8977d9-p98p7" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-p98p7 webserver-deployment-845c8977d9- deployment-6348  a961c7fb-b6f4-4f68-98db-d8787709d206 26682 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426d00 0xc002426d01}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-28hzz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-28hzz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.51,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.080: INFO: Pod "webserver-deployment-845c8977d9-qd2tc" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-qd2tc webserver-deployment-845c8977d9- deployment-6348  f4eec246-4067-4379-a435-6db4b0d95889 26687 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426e60 0xc002426e61}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5pqc2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5pqc2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.080: INFO: Pod "webserver-deployment-845c8977d9-qzg4w" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-qzg4w webserver-deployment-845c8977d9- deployment-6348  2332c6fc-30af-4a30-a1cc-80804f8ee3b1 26690 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426f97 0xc002426f98}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sgm4p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sgm4p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.081: INFO: Pod "webserver-deployment-845c8977d9-ssfsc" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ssfsc webserver-deployment-845c8977d9- deployment-6348  4a9cedfa-96e8-4032-a6fd-9426fded9c55 26672 0 2022-10-03 19:51:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc0024270f7 0xc0024270f8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tl6tv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tl6tv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.081: INFO: Pod "webserver-deployment-845c8977d9-vx998" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-vx998 webserver-deployment-845c8977d9- deployment-6348  54f8d2eb-c52b-4a2b-8116-0880e51f6640 26691 0 2022-10-03 19:51:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002427260 0xc002427261}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lgsv5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lgsv5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:,StartTime:2022-10-03 19:51:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.081: INFO: Pod "webserver-deployment-845c8977d9-wfdxx" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-wfdxx webserver-deployment-845c8977d9- deployment-6348  9f16a513-67f2-4108-ab75-ae9be5cce5b7 26551 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d0b76e5f9822727565fae4f9375a0a5fdf0ac03ba47071c2fff8991362223317 cni.projectcalico.org/podIP:172.30.49.18/32 cni.projectcalico.org/podIPs:172.30.49.18/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002427457 0xc002427458}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-898cl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-898cl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.18,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7de6ae26e8bb75adecf85ff17dcf6e7a9a706e0d42e6d52207a7225ff74baff9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  3 19:51:53.084: INFO: Pod "webserver-deployment-845c8977d9-zbmxf" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-zbmxf webserver-deployment-845c8977d9- deployment-6348  08a9d88e-2b48-4887-9b35-fe881633536a 26686 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002427687 0xc002427688}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jm8xr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jm8xr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Oct  3 19:51:53.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6348" for this suite. 10/03/22 19:51:53.111
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":125,"skipped":2495,"failed":0}
------------------------------
• [SLOW TEST] [6.467 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:51:46.666
    Oct  3 19:51:46.667: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename deployment 10/03/22 19:51:46.668
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:51:46.705
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:51:46.712
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Oct  3 19:51:46.720: INFO: Creating deployment "webserver-deployment"
    Oct  3 19:51:46.733: INFO: Waiting for observed generation 1
    Oct  3 19:51:48.758: INFO: Waiting for all required pods to come up
    Oct  3 19:51:48.772: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 10/03/22 19:51:48.772
    Oct  3 19:51:48.772: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-7f8ms" in namespace "deployment-6348" to be "running"
    Oct  3 19:51:48.773: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-822kx" in namespace "deployment-6348" to be "running"
    Oct  3 19:51:48.773: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-866lx" in namespace "deployment-6348" to be "running"
    Oct  3 19:51:48.773: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-zfhhr" in namespace "deployment-6348" to be "running"
    Oct  3 19:51:48.773: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-f2785" in namespace "deployment-6348" to be "running"
    Oct  3 19:51:48.773: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-mldb9" in namespace "deployment-6348" to be "running"
    Oct  3 19:51:48.773: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-7v9nj" in namespace "deployment-6348" to be "running"
    Oct  3 19:51:48.773: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-wfdxx" in namespace "deployment-6348" to be "running"
    Oct  3 19:51:48.784: INFO: Pod "webserver-deployment-845c8977d9-zfhhr": Phase="Pending", Reason="", readiness=false. Elapsed: 10.671546ms
    Oct  3 19:51:48.788: INFO: Pod "webserver-deployment-845c8977d9-7v9nj": Phase="Pending", Reason="", readiness=false. Elapsed: 15.271229ms
    Oct  3 19:51:48.788: INFO: Pod "webserver-deployment-845c8977d9-f2785": Phase="Pending", Reason="", readiness=false. Elapsed: 15.424425ms
    Oct  3 19:51:48.789: INFO: Pod "webserver-deployment-845c8977d9-wfdxx": Phase="Pending", Reason="", readiness=false. Elapsed: 15.696235ms
    Oct  3 19:51:48.789: INFO: Pod "webserver-deployment-845c8977d9-7f8ms": Phase="Pending", Reason="", readiness=false. Elapsed: 16.574186ms
    Oct  3 19:51:48.789: INFO: Pod "webserver-deployment-845c8977d9-mldb9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.279939ms
    Oct  3 19:51:48.790: INFO: Pod "webserver-deployment-845c8977d9-822kx": Phase="Running", Reason="", readiness=true. Elapsed: 17.118116ms
    Oct  3 19:51:48.790: INFO: Pod "webserver-deployment-845c8977d9-822kx" satisfied condition "running"
    Oct  3 19:51:48.790: INFO: Pod "webserver-deployment-845c8977d9-866lx": Phase="Pending", Reason="", readiness=false. Elapsed: 17.545356ms
    Oct  3 19:51:50.796: INFO: Pod "webserver-deployment-845c8977d9-zfhhr": Phase="Running", Reason="", readiness=true. Elapsed: 2.023586753s
    Oct  3 19:51:50.797: INFO: Pod "webserver-deployment-845c8977d9-zfhhr" satisfied condition "running"
    Oct  3 19:51:50.801: INFO: Pod "webserver-deployment-845c8977d9-f2785": Phase="Running", Reason="", readiness=true. Elapsed: 2.027952123s
    Oct  3 19:51:50.801: INFO: Pod "webserver-deployment-845c8977d9-f2785" satisfied condition "running"
    Oct  3 19:51:50.801: INFO: Pod "webserver-deployment-845c8977d9-7v9nj": Phase="Running", Reason="", readiness=true. Elapsed: 2.027853036s
    Oct  3 19:51:50.801: INFO: Pod "webserver-deployment-845c8977d9-7v9nj" satisfied condition "running"
    Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-mldb9": Phase="Running", Reason="", readiness=true. Elapsed: 2.032467014s
    Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-mldb9" satisfied condition "running"
    Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-7f8ms": Phase="Running", Reason="", readiness=true. Elapsed: 2.032991626s
    Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-7f8ms" satisfied condition "running"
    Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-wfdxx": Phase="Running", Reason="", readiness=true. Elapsed: 2.032724487s
    Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-wfdxx" satisfied condition "running"
    Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-866lx": Phase="Running", Reason="", readiness=true. Elapsed: 2.033513667s
    Oct  3 19:51:50.806: INFO: Pod "webserver-deployment-845c8977d9-866lx" satisfied condition "running"
    Oct  3 19:51:50.806: INFO: Waiting for deployment "webserver-deployment" to complete
    Oct  3 19:51:50.826: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Oct  3 19:51:50.850: INFO: Updating deployment webserver-deployment
    Oct  3 19:51:50.850: INFO: Waiting for observed generation 2
    Oct  3 19:51:52.868: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Oct  3 19:51:52.877: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Oct  3 19:51:52.886: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Oct  3 19:51:52.912: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Oct  3 19:51:52.912: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Oct  3 19:51:52.922: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Oct  3 19:51:52.939: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Oct  3 19:51:52.939: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Oct  3 19:51:52.961: INFO: Updating deployment webserver-deployment
    Oct  3 19:51:52.961: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Oct  3 19:51:52.980: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Oct  3 19:51:52.987: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct  3 19:51:53.018: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-6348  a4b5a373-d055-4e3d-bc8a-0f8330c9b48a 26660 3 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003cfb488 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-10-03 19:51:50 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-10-03 19:51:52 +0000 UTC,LastTransitionTime:2022-10-03 19:51:52 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Oct  3 19:51:53.028: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-6348  9d85fa38-9e22-483d-824f-56cf6e08ea1d 26657 3 2022-10-03 19:51:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment a4b5a373-d055-4e3d-bc8a-0f8330c9b48a 0xc003cfb8c7 0xc003cfb8c8}] [] [{kube-controller-manager Update apps/v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a4b5a373-d055-4e3d-bc8a-0f8330c9b48a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003cfb968 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Oct  3 19:51:53.028: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Oct  3 19:51:53.028: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-6348  d5762740-0319-4411-a46a-1b4382f8b2ea 26654 3 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment a4b5a373-d055-4e3d-bc8a-0f8330c9b48a 0xc003cfb9c7 0xc003cfb9c8}] [] [{kube-controller-manager Update apps/v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a4b5a373-d055-4e3d-bc8a-0f8330c9b48a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003cfba68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Oct  3 19:51:53.070: INFO: Pod "webserver-deployment-69b7448995-28qrb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-28qrb webserver-deployment-69b7448995- deployment-6348  e5e2085d-7ac4-4fef-9ac2-f2e74130fe05 26622 0 2022-10-03 19:51:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:d9ee5fb5b36467c39a6d3a7baaeac4950daa6949afff0b123b918958328ce41e cni.projectcalico.org/podIP:172.30.174.207/32 cni.projectcalico.org/podIPs:172.30.174.207/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc003cfbfc7 0xc003cfbfc8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-10-03 19:51:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p4lr8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p4lr8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.51,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.51,PodIP:,StartTime:2022-10-03 19:51:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.070: INFO: Pod "webserver-deployment-69b7448995-2t8gj" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-2t8gj webserver-deployment-69b7448995- deployment-6348  5d6baee8-caad-45d6-a435-8a0f1e4ed261 26681 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312a1e7 0xc00312a1e8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m5479,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m5479,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.071: INFO: Pod "webserver-deployment-69b7448995-66d5s" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-66d5s webserver-deployment-69b7448995- deployment-6348  3713f0af-d959-4af8-ba6c-23e6dba367bd 26626 0 2022-10-03 19:51:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:2b6cb7bbb0cbb78c7a6b3c2511e773ce520bdb4da2570bdcb0c6bbac4fb908af cni.projectcalico.org/podIP:172.30.49.17/32 cni.projectcalico.org/podIPs:172.30.49.17/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312a357 0xc00312a358}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-10-03 19:51:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rd2wp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rd2wp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:,StartTime:2022-10-03 19:51:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.071: INFO: Pod "webserver-deployment-69b7448995-dbgvb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-dbgvb webserver-deployment-69b7448995- deployment-6348  03ef3dcf-53db-418d-835b-904c4da8b71e 26679 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312a590 0xc00312a591}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rhw9g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rhw9g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.071: INFO: Pod "webserver-deployment-69b7448995-fzxpn" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-fzxpn webserver-deployment-69b7448995- deployment-6348  d5065cfd-b1a1-428a-9339-2189dbb4f3de 26665 0 2022-10-03 19:51:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312a6d7 0xc00312a6d8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4b5hb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4b5hb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.51,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.071: INFO: Pod "webserver-deployment-69b7448995-h962q" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-h962q webserver-deployment-69b7448995- deployment-6348  c9328e91-d7d3-4bf3-9242-fa8372efd965 26676 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312a850 0xc00312a851}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5xd25,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5xd25,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.072: INFO: Pod "webserver-deployment-69b7448995-jq952" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-jq952 webserver-deployment-69b7448995- deployment-6348  da15f8dd-04df-4b94-85f9-168fef3c28ae 26641 0 2022-10-03 19:51:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:45e60d7c2377cdb40867419562dc0d73220c3129e75e983206bd225a11d6bcea cni.projectcalico.org/podIP:172.30.35.211/32 cni.projectcalico.org/podIPs:172.30.35.211/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312a9b7 0xc00312a9b8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dd4bw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dd4bw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:,StartTime:2022-10-03 19:51:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.072: INFO: Pod "webserver-deployment-69b7448995-jrpmp" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-jrpmp webserver-deployment-69b7448995- deployment-6348  681cd99b-c68e-42f1-af24-6e4d84178645 26677 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312abc7 0xc00312abc8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fv2nh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fv2nh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.072: INFO: Pod "webserver-deployment-69b7448995-k69qm" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-k69qm webserver-deployment-69b7448995- deployment-6348  c5afba64-9656-43a6-ab65-0b808bfc83d5 26678 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312ad50 0xc00312ad51}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wj4gw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wj4gw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.073: INFO: Pod "webserver-deployment-69b7448995-lwjfc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-lwjfc webserver-deployment-69b7448995- deployment-6348  ba18b699-2dc2-4291-8fa2-8371e3a445df 26624 0 2022-10-03 19:51:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:ed3e5c55bc44e9251ee08fa701582c4d171ce463150e876482213629be352549 cni.projectcalico.org/podIP:172.30.35.208/32 cni.projectcalico.org/podIPs:172.30.35.208/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312b080 0xc00312b081}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dfnz8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dfnz8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:,StartTime:2022-10-03 19:51:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.073: INFO: Pod "webserver-deployment-69b7448995-ns4vt" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-ns4vt webserver-deployment-69b7448995- deployment-6348  62ce3cf0-7955-4414-8943-ab04bab7e066 26637 0 2022-10-03 19:51:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:d2ebd06c05031176111942bced83d61462b052196be1c827d36d1e961fe6e67f cni.projectcalico.org/podIP:172.30.49.15/32 cni.projectcalico.org/podIPs:172.30.49.15/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312b2a7 0xc00312b2a8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-03 19:51:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-llgq6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-llgq6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:,StartTime:2022-10-03 19:51:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.073: INFO: Pod "webserver-deployment-69b7448995-r527l" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-r527l webserver-deployment-69b7448995- deployment-6348  8a6fc31c-1546-4655-b7b4-1a6f933391a5 26680 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 9d85fa38-9e22-483d-824f-56cf6e08ea1d 0xc00312b4b0 0xc00312b4b1}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d85fa38-9e22-483d-824f-56cf6e08ea1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qvccl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qvccl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.074: INFO: Pod "webserver-deployment-845c8977d9-2sm4n" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-2sm4n webserver-deployment-845c8977d9- deployment-6348  613f4e31-739b-4469-ac79-c005d3ff09fc 26689 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc00312b5f7 0xc00312b5f8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8wrht,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8wrht,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.074: INFO: Pod "webserver-deployment-845c8977d9-46jwm" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-46jwm webserver-deployment-845c8977d9- deployment-6348  4232aed9-cd25-42d2-a3f7-77a866685328 26685 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc00312b737 0xc00312b738}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4rzlx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4rzlx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.075: INFO: Pod "webserver-deployment-845c8977d9-7f8ms" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-7f8ms webserver-deployment-845c8977d9- deployment-6348  7ddc6efe-3f6f-47d2-9059-c81d5cf446af 26548 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:4f58bbdc6354198a8ba4da7e02a8f99358e9c78ad91c05da992e1ee7af3f6d0e cni.projectcalico.org/podIP:172.30.174.198/32 cni.projectcalico.org/podIPs:172.30.174.198/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc00312b877 0xc00312b878}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.174.198\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-55cw9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-55cw9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.51,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.51,PodIP:172.30.174.198,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://79e5dfc29aeb93cc0946d14623119e11862fc4b34bc873e44f143f4229997349,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.174.198,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.075: INFO: Pod "webserver-deployment-845c8977d9-7v9nj" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-7v9nj webserver-deployment-845c8977d9- deployment-6348  1d4f2fc3-6508-419c-ae7b-001d734dafae 26544 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:af56e0eee9c21b9a562a0338cfdb6fa532ab2aba4fdee18b5c447d0b86e5bf9b cni.projectcalico.org/podIP:172.30.174.210/32 cni.projectcalico.org/podIPs:172.30.174.210/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc00312ba87 0xc00312ba88}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.174.210\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-99q8z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-99q8z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.51,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.51,PodIP:172.30.174.210,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c17c0221512319683a51e303eb46ca8aba6929cdb787187a85a0da1dec7fb059,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.174.210,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.076: INFO: Pod "webserver-deployment-845c8977d9-822kx" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-822kx webserver-deployment-845c8977d9- deployment-6348  2d5ea8c0-9523-4392-b43b-7b2c22fdceed 26531 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:3ff2b02d67842e228723825fe8be84f3e965e470ce62b0d986b99ec454d6a37c cni.projectcalico.org/podIP:172.30.35.207/32 cni.projectcalico.org/podIPs:172.30.35.207/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc00312bcb7 0xc00312bcb8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.35.207\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w8cch,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w8cch,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:172.30.35.207,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://aa9ecbf9bbecac2b4075cbf9be4c1e011e76c647d0f20b0166841c5a6a091de4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.35.207,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.077: INFO: Pod "webserver-deployment-845c8977d9-866lx" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-866lx webserver-deployment-845c8977d9- deployment-6348  50f74bff-5300-4274-9c67-d1c9d9aa1d81 26562 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6a3d7ff318cc7b4b733f296c30d20460243411e7199af4622fa0009eaf3e05e3 cni.projectcalico.org/podIP:172.30.35.210/32 cni.projectcalico.org/podIPs:172.30.35.210/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc00312bee7 0xc00312bee8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.35.210\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wdnpg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wdnpg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:172.30.35.210,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://fdf2a86e903c4ebcdea842ccab284fc7fc41995681223ded1945bd73f77b57f1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.35.210,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.077: INFO: Pod "webserver-deployment-845c8977d9-dmcxx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-dmcxx webserver-deployment-845c8977d9- deployment-6348  724e51a1-a38a-43a7-bd4b-8d5f632f6a61 26688 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426107 0xc002426108}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7zz2c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7zz2c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.077: INFO: Pod "webserver-deployment-845c8977d9-f97j6" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-f97j6 webserver-deployment-845c8977d9- deployment-6348  8326807c-d314-499c-bc72-5cf512220625 26508 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:5917c0586139f108aeda71b95a350cdf9687942b7e6ed5596fdc15beacca6934 cni.projectcalico.org/podIP:172.30.49.12/32 cni.projectcalico.org/podIPs:172.30.49.12/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426290 0xc002426291}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.12\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9n78d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9n78d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.12,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://87b70d69ffe93c509a34225efe5721471dec2fb385fc31f09a25cccc4cf80877,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.12,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.078: INFO: Pod "webserver-deployment-845c8977d9-gckqs" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gckqs webserver-deployment-845c8977d9- deployment-6348  7b0e4bab-eeca-4cdd-889c-114a8d63158d 26674 0 2022-10-03 19:51:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426497 0xc002426498}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hrmsn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hrmsn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.078: INFO: Pod "webserver-deployment-845c8977d9-hrmpj" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-hrmpj webserver-deployment-845c8977d9- deployment-6348  e43c8e2c-846d-442e-849e-b57adb19916e 26526 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:a21fbb0b89c15dab066e579a6c6fd16e0bdc0a52571c66702b08b878562fdc83 cni.projectcalico.org/podIP:172.30.35.206/32 cni.projectcalico.org/podIPs:172.30.35.206/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426620 0xc002426621}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.35.206\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j7mx6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j7mx6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:172.30.35.206,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7688a446e0ede38ac77c321a4be501dbb79928231ba8f40f0aa5eea3945afa12,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.35.206,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.079: INFO: Pod "webserver-deployment-845c8977d9-lrq5g" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-lrq5g webserver-deployment-845c8977d9- deployment-6348  cc6c2a9c-5310-4594-8b8d-1f121f3a863b 26683 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426827 0xc002426828}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dgzcn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dgzcn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.079: INFO: Pod "webserver-deployment-845c8977d9-mldb9" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-mldb9 webserver-deployment-845c8977d9- deployment-6348  7036a7f4-90f4-41a9-8276-8787023db9ba 26541 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:45f4ead2d553824e5144ab4fa0343c5b5017f899a2732d22b6c6de501c9c00a6 cni.projectcalico.org/podIP:172.30.174.199/32 cni.projectcalico.org/podIPs:172.30.174.199/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426990 0xc002426991}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.174.199\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qj7c5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qj7c5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.51,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.51,PodIP:172.30.174.199,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://fd9ae9645720f2626b182d8efe59eddd63d75d61fa939d7b25f0ace8d9d844f8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.174.199,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.079: INFO: Pod "webserver-deployment-845c8977d9-p2mfw" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-p2mfw webserver-deployment-845c8977d9- deployment-6348  f674fb25-5a7f-4fe8-989c-988c58ecc73c 26684 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426b97 0xc002426b98}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mm7hd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mm7hd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.080: INFO: Pod "webserver-deployment-845c8977d9-p98p7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-p98p7 webserver-deployment-845c8977d9- deployment-6348  a961c7fb-b6f4-4f68-98db-d8787709d206 26682 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426d00 0xc002426d01}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-28hzz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-28hzz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.51,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.080: INFO: Pod "webserver-deployment-845c8977d9-qd2tc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-qd2tc webserver-deployment-845c8977d9- deployment-6348  f4eec246-4067-4379-a435-6db4b0d95889 26687 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426e60 0xc002426e61}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5pqc2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5pqc2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.080: INFO: Pod "webserver-deployment-845c8977d9-qzg4w" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-qzg4w webserver-deployment-845c8977d9- deployment-6348  2332c6fc-30af-4a30-a1cc-80804f8ee3b1 26690 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002426f97 0xc002426f98}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sgm4p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sgm4p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.081: INFO: Pod "webserver-deployment-845c8977d9-ssfsc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ssfsc webserver-deployment-845c8977d9- deployment-6348  4a9cedfa-96e8-4032-a6fd-9426fded9c55 26672 0 2022-10-03 19:51:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc0024270f7 0xc0024270f8}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tl6tv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tl6tv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.081: INFO: Pod "webserver-deployment-845c8977d9-vx998" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-vx998 webserver-deployment-845c8977d9- deployment-6348  54f8d2eb-c52b-4a2b-8116-0880e51f6640 26691 0 2022-10-03 19:51:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002427260 0xc002427261}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lgsv5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lgsv5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:,StartTime:2022-10-03 19:51:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.081: INFO: Pod "webserver-deployment-845c8977d9-wfdxx" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-wfdxx webserver-deployment-845c8977d9- deployment-6348  9f16a513-67f2-4108-ab75-ae9be5cce5b7 26551 0 2022-10-03 19:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d0b76e5f9822727565fae4f9375a0a5fdf0ac03ba47071c2fff8991362223317 cni.projectcalico.org/podIP:172.30.49.18/32 cni.projectcalico.org/podIPs:172.30.49.18/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002427457 0xc002427458}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 19:51:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 19:51:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-898cl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-898cl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 19:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.18,StartTime:2022-10-03 19:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 19:51:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7de6ae26e8bb75adecf85ff17dcf6e7a9a706e0d42e6d52207a7225ff74baff9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct  3 19:51:53.084: INFO: Pod "webserver-deployment-845c8977d9-zbmxf" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-zbmxf webserver-deployment-845c8977d9- deployment-6348  08a9d88e-2b48-4887-9b35-fe881633536a 26686 0 2022-10-03 19:51:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d5762740-0319-4411-a46a-1b4382f8b2ea 0xc002427687 0xc002427688}] [] [{kube-controller-manager Update v1 2022-10-03 19:51:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d5762740-0319-4411-a46a-1b4382f8b2ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jm8xr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jm8xr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Oct  3 19:51:53.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-6348" for this suite. 10/03/22 19:51:53.111
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:51:53.136
Oct  3 19:51:53.136: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename events 10/03/22 19:51:53.138
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:51:53.192
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:51:53.206
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 10/03/22 19:51:53.244
STEP: get a list of Events with a label in the current namespace 10/03/22 19:51:53.291
STEP: delete a list of events 10/03/22 19:51:53.3
Oct  3 19:51:53.300: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 10/03/22 19:51:53.361
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Oct  3 19:51:53.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-85" for this suite. 10/03/22 19:51:53.383
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":126,"skipped":2498,"failed":0}
------------------------------
• [0.266 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:51:53.136
    Oct  3 19:51:53.136: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename events 10/03/22 19:51:53.138
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:51:53.192
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:51:53.206
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 10/03/22 19:51:53.244
    STEP: get a list of Events with a label in the current namespace 10/03/22 19:51:53.291
    STEP: delete a list of events 10/03/22 19:51:53.3
    Oct  3 19:51:53.300: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 10/03/22 19:51:53.361
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Oct  3 19:51:53.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-85" for this suite. 10/03/22 19:51:53.383
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:51:53.403
Oct  3 19:51:53.403: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename var-expansion 10/03/22 19:51:53.404
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:51:53.444
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:51:53.452
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 10/03/22 19:51:53.46
STEP: waiting for pod running 10/03/22 19:51:53.481
Oct  3 19:51:53.481: INFO: Waiting up to 2m0s for pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e" in namespace "var-expansion-3751" to be "running"
Oct  3 19:51:53.494: INFO: Pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.270167ms
Oct  3 19:51:55.506: INFO: Pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024529541s
Oct  3 19:51:57.505: INFO: Pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e": Phase="Running", Reason="", readiness=true. Elapsed: 4.023708158s
Oct  3 19:51:57.505: INFO: Pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e" satisfied condition "running"
STEP: creating a file in subpath 10/03/22 19:51:57.505
Oct  3 19:51:57.516: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3751 PodName:var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 19:51:57.516: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 19:51:57.517: INFO: ExecWithOptions: Clientset creation
Oct  3 19:51:57.517: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-3751/pods/var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 10/03/22 19:51:57.721
Oct  3 19:51:57.733: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3751 PodName:var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 19:51:57.733: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 19:51:57.734: INFO: ExecWithOptions: Clientset creation
Oct  3 19:51:57.734: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-3751/pods/var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 10/03/22 19:51:57.926
Oct  3 19:51:58.472: INFO: Successfully updated pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e"
STEP: waiting for annotated pod running 10/03/22 19:51:58.472
Oct  3 19:51:58.473: INFO: Waiting up to 2m0s for pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e" in namespace "var-expansion-3751" to be "running"
Oct  3 19:51:58.484: INFO: Pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e": Phase="Running", Reason="", readiness=true. Elapsed: 11.651802ms
Oct  3 19:51:58.484: INFO: Pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e" satisfied condition "running"
STEP: deleting the pod gracefully 10/03/22 19:51:58.484
Oct  3 19:51:58.485: INFO: Deleting pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e" in namespace "var-expansion-3751"
Oct  3 19:51:58.514: INFO: Wait up to 5m0s for pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Oct  3 19:52:32.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3751" for this suite. 10/03/22 19:52:32.559
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":127,"skipped":2503,"failed":0}
------------------------------
• [SLOW TEST] [39.177 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:51:53.403
    Oct  3 19:51:53.403: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename var-expansion 10/03/22 19:51:53.404
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:51:53.444
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:51:53.452
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 10/03/22 19:51:53.46
    STEP: waiting for pod running 10/03/22 19:51:53.481
    Oct  3 19:51:53.481: INFO: Waiting up to 2m0s for pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e" in namespace "var-expansion-3751" to be "running"
    Oct  3 19:51:53.494: INFO: Pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.270167ms
    Oct  3 19:51:55.506: INFO: Pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024529541s
    Oct  3 19:51:57.505: INFO: Pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e": Phase="Running", Reason="", readiness=true. Elapsed: 4.023708158s
    Oct  3 19:51:57.505: INFO: Pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e" satisfied condition "running"
    STEP: creating a file in subpath 10/03/22 19:51:57.505
    Oct  3 19:51:57.516: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3751 PodName:var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 19:51:57.516: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 19:51:57.517: INFO: ExecWithOptions: Clientset creation
    Oct  3 19:51:57.517: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-3751/pods/var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 10/03/22 19:51:57.721
    Oct  3 19:51:57.733: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3751 PodName:var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 19:51:57.733: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 19:51:57.734: INFO: ExecWithOptions: Clientset creation
    Oct  3 19:51:57.734: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-3751/pods/var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 10/03/22 19:51:57.926
    Oct  3 19:51:58.472: INFO: Successfully updated pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e"
    STEP: waiting for annotated pod running 10/03/22 19:51:58.472
    Oct  3 19:51:58.473: INFO: Waiting up to 2m0s for pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e" in namespace "var-expansion-3751" to be "running"
    Oct  3 19:51:58.484: INFO: Pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e": Phase="Running", Reason="", readiness=true. Elapsed: 11.651802ms
    Oct  3 19:51:58.484: INFO: Pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e" satisfied condition "running"
    STEP: deleting the pod gracefully 10/03/22 19:51:58.484
    Oct  3 19:51:58.485: INFO: Deleting pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e" in namespace "var-expansion-3751"
    Oct  3 19:51:58.514: INFO: Wait up to 5m0s for pod "var-expansion-fd9ddbf2-c32d-464e-8239-64eff1defe9e" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Oct  3 19:52:32.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3751" for this suite. 10/03/22 19:52:32.559
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:52:32.584
Oct  3 19:52:32.585: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 19:52:32.586
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:52:32.624
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:52:32.632
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 10/03/22 19:52:32.64
Oct  3 19:52:32.663: INFO: Waiting up to 5m0s for pod "downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185" in namespace "downward-api-6385" to be "Succeeded or Failed"
Oct  3 19:52:32.676: INFO: Pod "downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185": Phase="Pending", Reason="", readiness=false. Elapsed: 12.976995ms
Oct  3 19:52:34.689: INFO: Pod "downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025714004s
Oct  3 19:52:36.688: INFO: Pod "downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185": Phase="Running", Reason="", readiness=false. Elapsed: 4.025577636s
Oct  3 19:52:38.688: INFO: Pod "downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025022231s
STEP: Saw pod success 10/03/22 19:52:38.688
Oct  3 19:52:38.688: INFO: Pod "downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185" satisfied condition "Succeeded or Failed"
Oct  3 19:52:38.699: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185 container client-container: <nil>
STEP: delete the pod 10/03/22 19:52:38.726
Oct  3 19:52:38.766: INFO: Waiting for pod downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185 to disappear
Oct  3 19:52:38.777: INFO: Pod downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Oct  3 19:52:38.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6385" for this suite. 10/03/22 19:52:38.791
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":128,"skipped":2523,"failed":0}
------------------------------
• [SLOW TEST] [6.226 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:52:32.584
    Oct  3 19:52:32.585: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 19:52:32.586
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:52:32.624
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:52:32.632
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 10/03/22 19:52:32.64
    Oct  3 19:52:32.663: INFO: Waiting up to 5m0s for pod "downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185" in namespace "downward-api-6385" to be "Succeeded or Failed"
    Oct  3 19:52:32.676: INFO: Pod "downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185": Phase="Pending", Reason="", readiness=false. Elapsed: 12.976995ms
    Oct  3 19:52:34.689: INFO: Pod "downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025714004s
    Oct  3 19:52:36.688: INFO: Pod "downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185": Phase="Running", Reason="", readiness=false. Elapsed: 4.025577636s
    Oct  3 19:52:38.688: INFO: Pod "downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025022231s
    STEP: Saw pod success 10/03/22 19:52:38.688
    Oct  3 19:52:38.688: INFO: Pod "downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185" satisfied condition "Succeeded or Failed"
    Oct  3 19:52:38.699: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185 container client-container: <nil>
    STEP: delete the pod 10/03/22 19:52:38.726
    Oct  3 19:52:38.766: INFO: Waiting for pod downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185 to disappear
    Oct  3 19:52:38.777: INFO: Pod downwardapi-volume-58675e13-7c45-4244-9516-c82400c54185 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Oct  3 19:52:38.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6385" for this suite. 10/03/22 19:52:38.791
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:52:38.814
Oct  3 19:52:38.814: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename endpointslice 10/03/22 19:52:38.815
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:52:38.854
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:52:38.863
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Oct  3 19:52:38.901: INFO: Endpoints addresses: [172.20.0.1] , ports: [2040]
Oct  3 19:52:38.901: INFO: EndpointSlices addresses: [172.20.0.1] , ports: [2040]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Oct  3 19:52:38.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-2877" for this suite. 10/03/22 19:52:38.915
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":129,"skipped":2590,"failed":0}
------------------------------
• [0.122 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:52:38.814
    Oct  3 19:52:38.814: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename endpointslice 10/03/22 19:52:38.815
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:52:38.854
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:52:38.863
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Oct  3 19:52:38.901: INFO: Endpoints addresses: [172.20.0.1] , ports: [2040]
    Oct  3 19:52:38.901: INFO: EndpointSlices addresses: [172.20.0.1] , ports: [2040]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Oct  3 19:52:38.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-2877" for this suite. 10/03/22 19:52:38.915
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:52:38.938
Oct  3 19:52:38.938: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename svcaccounts 10/03/22 19:52:38.939
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:52:38.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:52:38.984
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Oct  3 19:52:39.022: INFO: Waiting up to 5m0s for pod "pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466" in namespace "svcaccounts-4499" to be "running"
Oct  3 19:52:39.033: INFO: Pod "pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466": Phase="Pending", Reason="", readiness=false. Elapsed: 11.162961ms
Oct  3 19:52:41.046: INFO: Pod "pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023435978s
Oct  3 19:52:43.046: INFO: Pod "pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466": Phase="Running", Reason="", readiness=true. Elapsed: 4.024243139s
Oct  3 19:52:43.047: INFO: Pod "pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466" satisfied condition "running"
STEP: reading a file in the container 10/03/22 19:52:43.047
Oct  3 19:52:43.047: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4499 pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 10/03/22 19:52:43.333
Oct  3 19:52:43.334: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4499 pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 10/03/22 19:52:43.643
Oct  3 19:52:43.643: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4499 pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Oct  3 19:52:44.051: INFO: Got root ca configmap in namespace "svcaccounts-4499"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Oct  3 19:52:44.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4499" for this suite. 10/03/22 19:52:44.07
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":130,"skipped":2600,"failed":0}
------------------------------
• [SLOW TEST] [5.151 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:52:38.938
    Oct  3 19:52:38.938: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename svcaccounts 10/03/22 19:52:38.939
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:52:38.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:52:38.984
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Oct  3 19:52:39.022: INFO: Waiting up to 5m0s for pod "pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466" in namespace "svcaccounts-4499" to be "running"
    Oct  3 19:52:39.033: INFO: Pod "pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466": Phase="Pending", Reason="", readiness=false. Elapsed: 11.162961ms
    Oct  3 19:52:41.046: INFO: Pod "pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023435978s
    Oct  3 19:52:43.046: INFO: Pod "pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466": Phase="Running", Reason="", readiness=true. Elapsed: 4.024243139s
    Oct  3 19:52:43.047: INFO: Pod "pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466" satisfied condition "running"
    STEP: reading a file in the container 10/03/22 19:52:43.047
    Oct  3 19:52:43.047: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4499 pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 10/03/22 19:52:43.333
    Oct  3 19:52:43.334: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4499 pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 10/03/22 19:52:43.643
    Oct  3 19:52:43.643: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4499 pod-service-account-2586689a-b6d2-4d5f-a228-3474cb9ff466 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Oct  3 19:52:44.051: INFO: Got root ca configmap in namespace "svcaccounts-4499"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Oct  3 19:52:44.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4499" for this suite. 10/03/22 19:52:44.07
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:52:44.092
Oct  3 19:52:44.092: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename pods 10/03/22 19:52:44.093
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:52:44.134
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:52:44.145
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 10/03/22 19:52:44.156
STEP: submitting the pod to kubernetes 10/03/22 19:52:44.157
Oct  3 19:52:44.180: INFO: Waiting up to 5m0s for pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1" in namespace "pods-5172" to be "running and ready"
Oct  3 19:52:44.193: INFO: Pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1": Phase="Pending", Reason="", readiness=false. Elapsed: 13.202084ms
Oct  3 19:52:44.193: INFO: The phase of Pod pod-update-2639ff8b-033e-4f76-97b8-5247204319d1 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:52:46.205: INFO: Pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02528486s
Oct  3 19:52:46.205: INFO: The phase of Pod pod-update-2639ff8b-033e-4f76-97b8-5247204319d1 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:52:48.206: INFO: Pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1": Phase="Running", Reason="", readiness=true. Elapsed: 4.026146103s
Oct  3 19:52:48.206: INFO: The phase of Pod pod-update-2639ff8b-033e-4f76-97b8-5247204319d1 is Running (Ready = true)
Oct  3 19:52:48.206: INFO: Pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 10/03/22 19:52:48.217
STEP: updating the pod 10/03/22 19:52:48.229
Oct  3 19:52:48.757: INFO: Successfully updated pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1"
Oct  3 19:52:48.757: INFO: Waiting up to 5m0s for pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1" in namespace "pods-5172" to be "running"
Oct  3 19:52:48.769: INFO: Pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1": Phase="Running", Reason="", readiness=true. Elapsed: 11.500864ms
Oct  3 19:52:48.769: INFO: Pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 10/03/22 19:52:48.769
Oct  3 19:52:48.781: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Oct  3 19:52:48.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5172" for this suite. 10/03/22 19:52:48.794
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":131,"skipped":2627,"failed":0}
------------------------------
• [4.722 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:52:44.092
    Oct  3 19:52:44.092: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename pods 10/03/22 19:52:44.093
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:52:44.134
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:52:44.145
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 10/03/22 19:52:44.156
    STEP: submitting the pod to kubernetes 10/03/22 19:52:44.157
    Oct  3 19:52:44.180: INFO: Waiting up to 5m0s for pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1" in namespace "pods-5172" to be "running and ready"
    Oct  3 19:52:44.193: INFO: Pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1": Phase="Pending", Reason="", readiness=false. Elapsed: 13.202084ms
    Oct  3 19:52:44.193: INFO: The phase of Pod pod-update-2639ff8b-033e-4f76-97b8-5247204319d1 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:52:46.205: INFO: Pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02528486s
    Oct  3 19:52:46.205: INFO: The phase of Pod pod-update-2639ff8b-033e-4f76-97b8-5247204319d1 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:52:48.206: INFO: Pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1": Phase="Running", Reason="", readiness=true. Elapsed: 4.026146103s
    Oct  3 19:52:48.206: INFO: The phase of Pod pod-update-2639ff8b-033e-4f76-97b8-5247204319d1 is Running (Ready = true)
    Oct  3 19:52:48.206: INFO: Pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 10/03/22 19:52:48.217
    STEP: updating the pod 10/03/22 19:52:48.229
    Oct  3 19:52:48.757: INFO: Successfully updated pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1"
    Oct  3 19:52:48.757: INFO: Waiting up to 5m0s for pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1" in namespace "pods-5172" to be "running"
    Oct  3 19:52:48.769: INFO: Pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1": Phase="Running", Reason="", readiness=true. Elapsed: 11.500864ms
    Oct  3 19:52:48.769: INFO: Pod "pod-update-2639ff8b-033e-4f76-97b8-5247204319d1" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 10/03/22 19:52:48.769
    Oct  3 19:52:48.781: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Oct  3 19:52:48.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5172" for this suite. 10/03/22 19:52:48.794
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:52:48.814
Oct  3 19:52:48.815: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-probe 10/03/22 19:52:48.815
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:52:48.855
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:52:48.863
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Oct  3 19:53:48.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1922" for this suite. 10/03/22 19:53:48.92
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":132,"skipped":2634,"failed":0}
------------------------------
• [SLOW TEST] [60.126 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:52:48.814
    Oct  3 19:52:48.815: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-probe 10/03/22 19:52:48.815
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:52:48.855
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:52:48.863
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Oct  3 19:53:48.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-1922" for this suite. 10/03/22 19:53:48.92
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:53:48.947
Oct  3 19:53:48.948: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename cronjob 10/03/22 19:53:48.949
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:53:48.992
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:53:49
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 10/03/22 19:53:49.009
STEP: Ensuring a job is scheduled 10/03/22 19:53:49.028
STEP: Ensuring exactly one is scheduled 10/03/22 19:54:01.038
STEP: Ensuring exactly one running job exists by listing jobs explicitly 10/03/22 19:54:01.049
STEP: Ensuring no more jobs are scheduled 10/03/22 19:54:01.063
STEP: Removing cronjob 10/03/22 19:59:01.087
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Oct  3 19:59:01.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2215" for this suite. 10/03/22 19:59:01.147
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":133,"skipped":2647,"failed":0}
------------------------------
• [SLOW TEST] [312.234 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:53:48.947
    Oct  3 19:53:48.948: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename cronjob 10/03/22 19:53:48.949
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:53:48.992
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:53:49
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 10/03/22 19:53:49.009
    STEP: Ensuring a job is scheduled 10/03/22 19:53:49.028
    STEP: Ensuring exactly one is scheduled 10/03/22 19:54:01.038
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 10/03/22 19:54:01.049
    STEP: Ensuring no more jobs are scheduled 10/03/22 19:54:01.063
    STEP: Removing cronjob 10/03/22 19:59:01.087
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Oct  3 19:59:01.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2215" for this suite. 10/03/22 19:59:01.147
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:59:01.188
Oct  3 19:59:01.188: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 19:59:01.189
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:59:01.224
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:59:01.234
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 19:59:01.294
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 19:59:01.686
STEP: Deploying the webhook pod 10/03/22 19:59:01.7
STEP: Wait for the deployment to be ready 10/03/22 19:59:01.73
Oct  3 19:59:01.756: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  3 19:59:03.792: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 59, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 59, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 10/03/22 19:59:05.805
STEP: Verifying the service has paired with the endpoint 10/03/22 19:59:05.85
Oct  3 19:59:06.851: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 10/03/22 19:59:06.863
STEP: create a pod that should be updated by the webhook 10/03/22 19:59:06.931
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 19:59:07.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2334" for this suite. 10/03/22 19:59:07.052
STEP: Destroying namespace "webhook-2334-markers" for this suite. 10/03/22 19:59:07.072
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":134,"skipped":2686,"failed":0}
------------------------------
• [SLOW TEST] [6.082 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:59:01.188
    Oct  3 19:59:01.188: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 19:59:01.189
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:59:01.224
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:59:01.234
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 19:59:01.294
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 19:59:01.686
    STEP: Deploying the webhook pod 10/03/22 19:59:01.7
    STEP: Wait for the deployment to be ready 10/03/22 19:59:01.73
    Oct  3 19:59:01.756: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Oct  3 19:59:03.792: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 19, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 59, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 19, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 19, 59, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 10/03/22 19:59:05.805
    STEP: Verifying the service has paired with the endpoint 10/03/22 19:59:05.85
    Oct  3 19:59:06.851: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 10/03/22 19:59:06.863
    STEP: create a pod that should be updated by the webhook 10/03/22 19:59:06.931
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 19:59:07.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2334" for this suite. 10/03/22 19:59:07.052
    STEP: Destroying namespace "webhook-2334-markers" for this suite. 10/03/22 19:59:07.072
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:59:07.271
Oct  3 19:59:07.271: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 19:59:07.273
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:59:07.317
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:59:07.328
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 10/03/22 19:59:07.338
Oct  3 19:59:07.360: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2" in namespace "downward-api-986" to be "Succeeded or Failed"
Oct  3 19:59:07.371: INFO: Pod "downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.016648ms
Oct  3 19:59:09.384: INFO: Pod "downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023970212s
Oct  3 19:59:11.385: INFO: Pod "downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024403293s
Oct  3 19:59:13.385: INFO: Pod "downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024470915s
STEP: Saw pod success 10/03/22 19:59:13.385
Oct  3 19:59:13.385: INFO: Pod "downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2" satisfied condition "Succeeded or Failed"
Oct  3 19:59:13.397: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2 container client-container: <nil>
STEP: delete the pod 10/03/22 19:59:13.476
Oct  3 19:59:13.508: INFO: Waiting for pod downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2 to disappear
Oct  3 19:59:13.519: INFO: Pod downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Oct  3 19:59:13.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-986" for this suite. 10/03/22 19:59:13.535
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":135,"skipped":2698,"failed":0}
------------------------------
• [SLOW TEST] [6.284 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:59:07.271
    Oct  3 19:59:07.271: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 19:59:07.273
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:59:07.317
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:59:07.328
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 10/03/22 19:59:07.338
    Oct  3 19:59:07.360: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2" in namespace "downward-api-986" to be "Succeeded or Failed"
    Oct  3 19:59:07.371: INFO: Pod "downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.016648ms
    Oct  3 19:59:09.384: INFO: Pod "downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023970212s
    Oct  3 19:59:11.385: INFO: Pod "downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024403293s
    Oct  3 19:59:13.385: INFO: Pod "downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024470915s
    STEP: Saw pod success 10/03/22 19:59:13.385
    Oct  3 19:59:13.385: INFO: Pod "downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2" satisfied condition "Succeeded or Failed"
    Oct  3 19:59:13.397: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2 container client-container: <nil>
    STEP: delete the pod 10/03/22 19:59:13.476
    Oct  3 19:59:13.508: INFO: Waiting for pod downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2 to disappear
    Oct  3 19:59:13.519: INFO: Pod downwardapi-volume-4e45720b-021f-4a24-b76b-61c67b188ba2 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Oct  3 19:59:13.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-986" for this suite. 10/03/22 19:59:13.535
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:59:13.558
Oct  3 19:59:13.559: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename cronjob 10/03/22 19:59:13.56
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:59:13.592
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:59:13.601
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 10/03/22 19:59:13.611
STEP: creating 10/03/22 19:59:13.611
STEP: getting 10/03/22 19:59:13.625
STEP: listing 10/03/22 19:59:13.635
STEP: watching 10/03/22 19:59:13.646
Oct  3 19:59:13.646: INFO: starting watch
STEP: cluster-wide listing 10/03/22 19:59:13.651
STEP: cluster-wide watching 10/03/22 19:59:13.661
Oct  3 19:59:13.661: INFO: starting watch
STEP: patching 10/03/22 19:59:13.666
STEP: updating 10/03/22 19:59:13.68
Oct  3 19:59:13.704: INFO: waiting for watch events with expected annotations
Oct  3 19:59:13.704: INFO: saw patched and updated annotations
STEP: patching /status 10/03/22 19:59:13.704
STEP: updating /status 10/03/22 19:59:13.718
STEP: get /status 10/03/22 19:59:13.743
STEP: deleting 10/03/22 19:59:13.754
STEP: deleting a collection 10/03/22 19:59:13.795
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Oct  3 19:59:13.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9786" for this suite. 10/03/22 19:59:13.848
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":136,"skipped":2698,"failed":0}
------------------------------
• [0.309 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:59:13.558
    Oct  3 19:59:13.559: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename cronjob 10/03/22 19:59:13.56
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:59:13.592
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:59:13.601
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 10/03/22 19:59:13.611
    STEP: creating 10/03/22 19:59:13.611
    STEP: getting 10/03/22 19:59:13.625
    STEP: listing 10/03/22 19:59:13.635
    STEP: watching 10/03/22 19:59:13.646
    Oct  3 19:59:13.646: INFO: starting watch
    STEP: cluster-wide listing 10/03/22 19:59:13.651
    STEP: cluster-wide watching 10/03/22 19:59:13.661
    Oct  3 19:59:13.661: INFO: starting watch
    STEP: patching 10/03/22 19:59:13.666
    STEP: updating 10/03/22 19:59:13.68
    Oct  3 19:59:13.704: INFO: waiting for watch events with expected annotations
    Oct  3 19:59:13.704: INFO: saw patched and updated annotations
    STEP: patching /status 10/03/22 19:59:13.704
    STEP: updating /status 10/03/22 19:59:13.718
    STEP: get /status 10/03/22 19:59:13.743
    STEP: deleting 10/03/22 19:59:13.754
    STEP: deleting a collection 10/03/22 19:59:13.795
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Oct  3 19:59:13.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9786" for this suite. 10/03/22 19:59:13.848
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:59:13.87
Oct  3 19:59:13.871: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 19:59:13.872
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:59:13.905
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:59:13.915
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-fe62a71a-1837-46a3-acaf-bc64b7045175 10/03/22 19:59:13.924
STEP: Creating a pod to test consume configMaps 10/03/22 19:59:13.947
Oct  3 19:59:13.969: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93" in namespace "projected-3522" to be "Succeeded or Failed"
Oct  3 19:59:13.982: INFO: Pod "pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93": Phase="Pending", Reason="", readiness=false. Elapsed: 12.230539ms
Oct  3 19:59:15.995: INFO: Pod "pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93": Phase="Running", Reason="", readiness=true. Elapsed: 2.025775887s
Oct  3 19:59:17.992: INFO: Pod "pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93": Phase="Running", Reason="", readiness=false. Elapsed: 4.02284132s
Oct  3 19:59:19.994: INFO: Pod "pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024696832s
STEP: Saw pod success 10/03/22 19:59:19.994
Oct  3 19:59:19.995: INFO: Pod "pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93" satisfied condition "Succeeded or Failed"
Oct  3 19:59:20.005: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93 container agnhost-container: <nil>
STEP: delete the pod 10/03/22 19:59:20.032
Oct  3 19:59:20.057: INFO: Waiting for pod pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93 to disappear
Oct  3 19:59:20.067: INFO: Pod pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Oct  3 19:59:20.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3522" for this suite. 10/03/22 19:59:20.081
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":137,"skipped":2705,"failed":0}
------------------------------
• [SLOW TEST] [6.230 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:59:13.87
    Oct  3 19:59:13.871: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 19:59:13.872
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:59:13.905
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:59:13.915
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-fe62a71a-1837-46a3-acaf-bc64b7045175 10/03/22 19:59:13.924
    STEP: Creating a pod to test consume configMaps 10/03/22 19:59:13.947
    Oct  3 19:59:13.969: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93" in namespace "projected-3522" to be "Succeeded or Failed"
    Oct  3 19:59:13.982: INFO: Pod "pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93": Phase="Pending", Reason="", readiness=false. Elapsed: 12.230539ms
    Oct  3 19:59:15.995: INFO: Pod "pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93": Phase="Running", Reason="", readiness=true. Elapsed: 2.025775887s
    Oct  3 19:59:17.992: INFO: Pod "pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93": Phase="Running", Reason="", readiness=false. Elapsed: 4.02284132s
    Oct  3 19:59:19.994: INFO: Pod "pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024696832s
    STEP: Saw pod success 10/03/22 19:59:19.994
    Oct  3 19:59:19.995: INFO: Pod "pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93" satisfied condition "Succeeded or Failed"
    Oct  3 19:59:20.005: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93 container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 19:59:20.032
    Oct  3 19:59:20.057: INFO: Waiting for pod pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93 to disappear
    Oct  3 19:59:20.067: INFO: Pod pod-projected-configmaps-bfebc2c1-3c7a-4af5-910e-1872b3642f93 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Oct  3 19:59:20.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3522" for this suite. 10/03/22 19:59:20.081
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:59:20.107
Oct  3 19:59:20.107: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 19:59:20.108
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:59:20.141
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:59:20.149
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 10/03/22 19:59:20.172
STEP: waiting for available Endpoint 10/03/22 19:59:20.188
STEP: listing all Endpoints 10/03/22 19:59:20.192
STEP: updating the Endpoint 10/03/22 19:59:20.206
STEP: fetching the Endpoint 10/03/22 19:59:20.224
STEP: patching the Endpoint 10/03/22 19:59:20.234
STEP: fetching the Endpoint 10/03/22 19:59:20.253
STEP: deleting the Endpoint by Collection 10/03/22 19:59:20.264
STEP: waiting for Endpoint deletion 10/03/22 19:59:20.287
STEP: fetching the Endpoint 10/03/22 19:59:20.292
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 19:59:20.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5164" for this suite. 10/03/22 19:59:20.317
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":138,"skipped":2710,"failed":0}
------------------------------
• [0.228 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:59:20.107
    Oct  3 19:59:20.107: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 19:59:20.108
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:59:20.141
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:59:20.149
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 10/03/22 19:59:20.172
    STEP: waiting for available Endpoint 10/03/22 19:59:20.188
    STEP: listing all Endpoints 10/03/22 19:59:20.192
    STEP: updating the Endpoint 10/03/22 19:59:20.206
    STEP: fetching the Endpoint 10/03/22 19:59:20.224
    STEP: patching the Endpoint 10/03/22 19:59:20.234
    STEP: fetching the Endpoint 10/03/22 19:59:20.253
    STEP: deleting the Endpoint by Collection 10/03/22 19:59:20.264
    STEP: waiting for Endpoint deletion 10/03/22 19:59:20.287
    STEP: fetching the Endpoint 10/03/22 19:59:20.292
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 19:59:20.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5164" for this suite. 10/03/22 19:59:20.317
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:59:20.336
Oct  3 19:59:20.336: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename configmap 10/03/22 19:59:20.337
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:59:20.381
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:59:20.39
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-caff660d-6f26-49d8-9bcf-f5985f8d7757 10/03/22 19:59:20.443
STEP: Creating configMap with name cm-test-opt-upd-2763ecf6-4c2e-412e-8de1-bfd01f302da9 10/03/22 19:59:20.455
STEP: Creating the pod 10/03/22 19:59:20.482
Oct  3 19:59:20.505: INFO: Waiting up to 5m0s for pod "pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38" in namespace "configmap-583" to be "running and ready"
Oct  3 19:59:20.517: INFO: Pod "pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38": Phase="Pending", Reason="", readiness=false. Elapsed: 12.204023ms
Oct  3 19:59:20.517: INFO: The phase of Pod pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:59:22.530: INFO: Pod "pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024910154s
Oct  3 19:59:22.530: INFO: The phase of Pod pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 19:59:24.530: INFO: Pod "pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38": Phase="Running", Reason="", readiness=true. Elapsed: 4.024907176s
Oct  3 19:59:24.530: INFO: The phase of Pod pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38 is Running (Ready = true)
Oct  3 19:59:24.530: INFO: Pod "pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-caff660d-6f26-49d8-9bcf-f5985f8d7757 10/03/22 19:59:24.627
STEP: Updating configmap cm-test-opt-upd-2763ecf6-4c2e-412e-8de1-bfd01f302da9 10/03/22 19:59:24.646
STEP: Creating configMap with name cm-test-opt-create-cbcf279f-3be7-424e-aa88-cb07cee385d7 10/03/22 19:59:24.659
STEP: waiting to observe update in volume 10/03/22 19:59:24.673
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Oct  3 19:59:26.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-583" for this suite. 10/03/22 19:59:26.793
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":139,"skipped":2717,"failed":0}
------------------------------
• [SLOW TEST] [6.475 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:59:20.336
    Oct  3 19:59:20.336: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename configmap 10/03/22 19:59:20.337
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:59:20.381
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:59:20.39
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-caff660d-6f26-49d8-9bcf-f5985f8d7757 10/03/22 19:59:20.443
    STEP: Creating configMap with name cm-test-opt-upd-2763ecf6-4c2e-412e-8de1-bfd01f302da9 10/03/22 19:59:20.455
    STEP: Creating the pod 10/03/22 19:59:20.482
    Oct  3 19:59:20.505: INFO: Waiting up to 5m0s for pod "pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38" in namespace "configmap-583" to be "running and ready"
    Oct  3 19:59:20.517: INFO: Pod "pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38": Phase="Pending", Reason="", readiness=false. Elapsed: 12.204023ms
    Oct  3 19:59:20.517: INFO: The phase of Pod pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:59:22.530: INFO: Pod "pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024910154s
    Oct  3 19:59:22.530: INFO: The phase of Pod pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 19:59:24.530: INFO: Pod "pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38": Phase="Running", Reason="", readiness=true. Elapsed: 4.024907176s
    Oct  3 19:59:24.530: INFO: The phase of Pod pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38 is Running (Ready = true)
    Oct  3 19:59:24.530: INFO: Pod "pod-configmaps-1f2626e0-cf7d-4737-b990-c3488a131a38" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-caff660d-6f26-49d8-9bcf-f5985f8d7757 10/03/22 19:59:24.627
    STEP: Updating configmap cm-test-opt-upd-2763ecf6-4c2e-412e-8de1-bfd01f302da9 10/03/22 19:59:24.646
    STEP: Creating configMap with name cm-test-opt-create-cbcf279f-3be7-424e-aa88-cb07cee385d7 10/03/22 19:59:24.659
    STEP: waiting to observe update in volume 10/03/22 19:59:24.673
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Oct  3 19:59:26.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-583" for this suite. 10/03/22 19:59:26.793
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 19:59:26.812
Oct  3 19:59:26.812: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename sched-preemption 10/03/22 19:59:26.813
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:59:26.844
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:59:26.853
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Oct  3 19:59:26.917: INFO: Waiting up to 1m0s for all nodes to be ready
Oct  3 20:00:27.000: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:00:27.015
Oct  3 20:00:27.015: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename sched-preemption-path 10/03/22 20:00:27.016
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:00:27.05
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:00:27.06
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Oct  3 20:00:27.109: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Oct  3 20:00:27.120: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Oct  3 20:00:27.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-7347" for this suite. 10/03/22 20:00:27.196
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Oct  3 20:00:27.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-1371" for this suite. 10/03/22 20:00:27.267
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":140,"skipped":2722,"failed":0}
------------------------------
• [SLOW TEST] [60.589 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 19:59:26.812
    Oct  3 19:59:26.812: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename sched-preemption 10/03/22 19:59:26.813
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 19:59:26.844
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 19:59:26.853
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Oct  3 19:59:26.917: INFO: Waiting up to 1m0s for all nodes to be ready
    Oct  3 20:00:27.000: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:00:27.015
    Oct  3 20:00:27.015: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename sched-preemption-path 10/03/22 20:00:27.016
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:00:27.05
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:00:27.06
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Oct  3 20:00:27.109: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Oct  3 20:00:27.120: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Oct  3 20:00:27.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-7347" for this suite. 10/03/22 20:00:27.196
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 20:00:27.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-1371" for this suite. 10/03/22 20:00:27.267
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:00:27.404
Oct  3 20:00:27.405: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename daemonsets 10/03/22 20:00:27.405
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:00:27.436
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:00:27.445
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Oct  3 20:00:27.528: INFO: Create a RollingUpdate DaemonSet
Oct  3 20:00:27.541: INFO: Check that daemon pods launch on every node of the cluster
Oct  3 20:00:27.570: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 20:00:27.570: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 20:00:28.596: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 20:00:28.596: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 20:00:29.600: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Oct  3 20:00:29.600: INFO: Node 10.63.128.3 is running 0 daemon pod, expected 1
Oct  3 20:00:30.600: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct  3 20:00:30.600: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Oct  3 20:00:30.600: INFO: Update the DaemonSet to trigger a rollout
Oct  3 20:00:30.629: INFO: Updating DaemonSet daemon-set
Oct  3 20:00:32.678: INFO: Roll back the DaemonSet before rollout is complete
Oct  3 20:00:32.701: INFO: Updating DaemonSet daemon-set
Oct  3 20:00:32.701: INFO: Make sure DaemonSet rollback is complete
Oct  3 20:00:32.714: INFO: Wrong image for pod: daemon-set-4h6vv. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Oct  3 20:00:32.714: INFO: Pod daemon-set-4h6vv is not available
Oct  3 20:00:39.740: INFO: Pod daemon-set-j8td7 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 10/03/22 20:00:39.791
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4449, will wait for the garbage collector to delete the pods 10/03/22 20:00:39.791
Oct  3 20:00:39.871: INFO: Deleting DaemonSet.extensions daemon-set took: 18.728328ms
Oct  3 20:00:40.072: INFO: Terminating DaemonSet.extensions daemon-set pods took: 201.133945ms
Oct  3 20:00:42.584: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 20:00:42.584: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct  3 20:00:42.594: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"28197"},"items":null}

Oct  3 20:00:42.604: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"28197"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Oct  3 20:00:42.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4449" for this suite. 10/03/22 20:00:42.674
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":141,"skipped":2779,"failed":0}
------------------------------
• [SLOW TEST] [15.289 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:00:27.404
    Oct  3 20:00:27.405: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename daemonsets 10/03/22 20:00:27.405
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:00:27.436
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:00:27.445
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Oct  3 20:00:27.528: INFO: Create a RollingUpdate DaemonSet
    Oct  3 20:00:27.541: INFO: Check that daemon pods launch on every node of the cluster
    Oct  3 20:00:27.570: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 20:00:27.570: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 20:00:28.596: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 20:00:28.596: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 20:00:29.600: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Oct  3 20:00:29.600: INFO: Node 10.63.128.3 is running 0 daemon pod, expected 1
    Oct  3 20:00:30.600: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct  3 20:00:30.600: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Oct  3 20:00:30.600: INFO: Update the DaemonSet to trigger a rollout
    Oct  3 20:00:30.629: INFO: Updating DaemonSet daemon-set
    Oct  3 20:00:32.678: INFO: Roll back the DaemonSet before rollout is complete
    Oct  3 20:00:32.701: INFO: Updating DaemonSet daemon-set
    Oct  3 20:00:32.701: INFO: Make sure DaemonSet rollback is complete
    Oct  3 20:00:32.714: INFO: Wrong image for pod: daemon-set-4h6vv. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Oct  3 20:00:32.714: INFO: Pod daemon-set-4h6vv is not available
    Oct  3 20:00:39.740: INFO: Pod daemon-set-j8td7 is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 10/03/22 20:00:39.791
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4449, will wait for the garbage collector to delete the pods 10/03/22 20:00:39.791
    Oct  3 20:00:39.871: INFO: Deleting DaemonSet.extensions daemon-set took: 18.728328ms
    Oct  3 20:00:40.072: INFO: Terminating DaemonSet.extensions daemon-set pods took: 201.133945ms
    Oct  3 20:00:42.584: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 20:00:42.584: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Oct  3 20:00:42.594: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"28197"},"items":null}

    Oct  3 20:00:42.604: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"28197"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 20:00:42.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4449" for this suite. 10/03/22 20:00:42.674
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:00:42.696
Oct  3 20:00:42.696: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename discovery 10/03/22 20:00:42.697
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:00:42.728
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:00:42.747
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 10/03/22 20:00:42.761
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Oct  3 20:00:43.300: INFO: Checking APIGroup: apiregistration.k8s.io
Oct  3 20:00:43.305: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Oct  3 20:00:43.305: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Oct  3 20:00:43.305: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Oct  3 20:00:43.305: INFO: Checking APIGroup: apps
Oct  3 20:00:43.309: INFO: PreferredVersion.GroupVersion: apps/v1
Oct  3 20:00:43.309: INFO: Versions found [{apps/v1 v1}]
Oct  3 20:00:43.309: INFO: apps/v1 matches apps/v1
Oct  3 20:00:43.309: INFO: Checking APIGroup: events.k8s.io
Oct  3 20:00:43.314: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Oct  3 20:00:43.314: INFO: Versions found [{events.k8s.io/v1 v1}]
Oct  3 20:00:43.314: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Oct  3 20:00:43.314: INFO: Checking APIGroup: authentication.k8s.io
Oct  3 20:00:43.318: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Oct  3 20:00:43.318: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Oct  3 20:00:43.318: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Oct  3 20:00:43.318: INFO: Checking APIGroup: authorization.k8s.io
Oct  3 20:00:43.322: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Oct  3 20:00:43.322: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Oct  3 20:00:43.322: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Oct  3 20:00:43.322: INFO: Checking APIGroup: autoscaling
Oct  3 20:00:43.327: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Oct  3 20:00:43.327: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Oct  3 20:00:43.327: INFO: autoscaling/v2 matches autoscaling/v2
Oct  3 20:00:43.327: INFO: Checking APIGroup: batch
Oct  3 20:00:43.331: INFO: PreferredVersion.GroupVersion: batch/v1
Oct  3 20:00:43.331: INFO: Versions found [{batch/v1 v1}]
Oct  3 20:00:43.331: INFO: batch/v1 matches batch/v1
Oct  3 20:00:43.331: INFO: Checking APIGroup: certificates.k8s.io
Oct  3 20:00:43.335: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Oct  3 20:00:43.335: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Oct  3 20:00:43.335: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Oct  3 20:00:43.335: INFO: Checking APIGroup: networking.k8s.io
Oct  3 20:00:43.340: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Oct  3 20:00:43.340: INFO: Versions found [{networking.k8s.io/v1 v1}]
Oct  3 20:00:43.340: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Oct  3 20:00:43.340: INFO: Checking APIGroup: policy
Oct  3 20:00:43.344: INFO: PreferredVersion.GroupVersion: policy/v1
Oct  3 20:00:43.344: INFO: Versions found [{policy/v1 v1}]
Oct  3 20:00:43.344: INFO: policy/v1 matches policy/v1
Oct  3 20:00:43.344: INFO: Checking APIGroup: rbac.authorization.k8s.io
Oct  3 20:00:43.349: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Oct  3 20:00:43.349: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Oct  3 20:00:43.349: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Oct  3 20:00:43.349: INFO: Checking APIGroup: storage.k8s.io
Oct  3 20:00:43.353: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Oct  3 20:00:43.353: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Oct  3 20:00:43.353: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Oct  3 20:00:43.353: INFO: Checking APIGroup: admissionregistration.k8s.io
Oct  3 20:00:43.358: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Oct  3 20:00:43.358: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Oct  3 20:00:43.358: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Oct  3 20:00:43.358: INFO: Checking APIGroup: apiextensions.k8s.io
Oct  3 20:00:43.362: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Oct  3 20:00:43.362: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Oct  3 20:00:43.362: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Oct  3 20:00:43.362: INFO: Checking APIGroup: scheduling.k8s.io
Oct  3 20:00:43.366: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Oct  3 20:00:43.366: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Oct  3 20:00:43.366: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Oct  3 20:00:43.366: INFO: Checking APIGroup: coordination.k8s.io
Oct  3 20:00:43.371: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Oct  3 20:00:43.371: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Oct  3 20:00:43.371: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Oct  3 20:00:43.371: INFO: Checking APIGroup: node.k8s.io
Oct  3 20:00:43.376: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Oct  3 20:00:43.376: INFO: Versions found [{node.k8s.io/v1 v1}]
Oct  3 20:00:43.376: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Oct  3 20:00:43.376: INFO: Checking APIGroup: discovery.k8s.io
Oct  3 20:00:43.380: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Oct  3 20:00:43.380: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Oct  3 20:00:43.380: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Oct  3 20:00:43.381: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Oct  3 20:00:43.385: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Oct  3 20:00:43.385: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Oct  3 20:00:43.385: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Oct  3 20:00:43.385: INFO: Checking APIGroup: crd.projectcalico.org
Oct  3 20:00:43.390: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Oct  3 20:00:43.390: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Oct  3 20:00:43.390: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
Oct  3 20:00:43.390: INFO: Checking APIGroup: snapshot.storage.k8s.io
Oct  3 20:00:43.394: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
Oct  3 20:00:43.394: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1}]
Oct  3 20:00:43.394: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
Oct  3 20:00:43.394: INFO: Checking APIGroup: ibm.com
Oct  3 20:00:43.398: INFO: PreferredVersion.GroupVersion: ibm.com/v1alpha1
Oct  3 20:00:43.399: INFO: Versions found [{ibm.com/v1alpha1 v1alpha1}]
Oct  3 20:00:43.399: INFO: ibm.com/v1alpha1 matches ibm.com/v1alpha1
Oct  3 20:00:43.399: INFO: Checking APIGroup: metrics.k8s.io
Oct  3 20:00:43.403: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Oct  3 20:00:43.403: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Oct  3 20:00:43.403: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Oct  3 20:00:43.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-3924" for this suite. 10/03/22 20:00:43.419
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":142,"skipped":2799,"failed":0}
------------------------------
• [0.743 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:00:42.696
    Oct  3 20:00:42.696: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename discovery 10/03/22 20:00:42.697
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:00:42.728
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:00:42.747
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 10/03/22 20:00:42.761
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Oct  3 20:00:43.300: INFO: Checking APIGroup: apiregistration.k8s.io
    Oct  3 20:00:43.305: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Oct  3 20:00:43.305: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Oct  3 20:00:43.305: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Oct  3 20:00:43.305: INFO: Checking APIGroup: apps
    Oct  3 20:00:43.309: INFO: PreferredVersion.GroupVersion: apps/v1
    Oct  3 20:00:43.309: INFO: Versions found [{apps/v1 v1}]
    Oct  3 20:00:43.309: INFO: apps/v1 matches apps/v1
    Oct  3 20:00:43.309: INFO: Checking APIGroup: events.k8s.io
    Oct  3 20:00:43.314: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Oct  3 20:00:43.314: INFO: Versions found [{events.k8s.io/v1 v1}]
    Oct  3 20:00:43.314: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Oct  3 20:00:43.314: INFO: Checking APIGroup: authentication.k8s.io
    Oct  3 20:00:43.318: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Oct  3 20:00:43.318: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Oct  3 20:00:43.318: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Oct  3 20:00:43.318: INFO: Checking APIGroup: authorization.k8s.io
    Oct  3 20:00:43.322: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Oct  3 20:00:43.322: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Oct  3 20:00:43.322: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Oct  3 20:00:43.322: INFO: Checking APIGroup: autoscaling
    Oct  3 20:00:43.327: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Oct  3 20:00:43.327: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Oct  3 20:00:43.327: INFO: autoscaling/v2 matches autoscaling/v2
    Oct  3 20:00:43.327: INFO: Checking APIGroup: batch
    Oct  3 20:00:43.331: INFO: PreferredVersion.GroupVersion: batch/v1
    Oct  3 20:00:43.331: INFO: Versions found [{batch/v1 v1}]
    Oct  3 20:00:43.331: INFO: batch/v1 matches batch/v1
    Oct  3 20:00:43.331: INFO: Checking APIGroup: certificates.k8s.io
    Oct  3 20:00:43.335: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Oct  3 20:00:43.335: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Oct  3 20:00:43.335: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Oct  3 20:00:43.335: INFO: Checking APIGroup: networking.k8s.io
    Oct  3 20:00:43.340: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Oct  3 20:00:43.340: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Oct  3 20:00:43.340: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Oct  3 20:00:43.340: INFO: Checking APIGroup: policy
    Oct  3 20:00:43.344: INFO: PreferredVersion.GroupVersion: policy/v1
    Oct  3 20:00:43.344: INFO: Versions found [{policy/v1 v1}]
    Oct  3 20:00:43.344: INFO: policy/v1 matches policy/v1
    Oct  3 20:00:43.344: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Oct  3 20:00:43.349: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Oct  3 20:00:43.349: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Oct  3 20:00:43.349: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Oct  3 20:00:43.349: INFO: Checking APIGroup: storage.k8s.io
    Oct  3 20:00:43.353: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Oct  3 20:00:43.353: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Oct  3 20:00:43.353: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Oct  3 20:00:43.353: INFO: Checking APIGroup: admissionregistration.k8s.io
    Oct  3 20:00:43.358: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Oct  3 20:00:43.358: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Oct  3 20:00:43.358: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Oct  3 20:00:43.358: INFO: Checking APIGroup: apiextensions.k8s.io
    Oct  3 20:00:43.362: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Oct  3 20:00:43.362: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Oct  3 20:00:43.362: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Oct  3 20:00:43.362: INFO: Checking APIGroup: scheduling.k8s.io
    Oct  3 20:00:43.366: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Oct  3 20:00:43.366: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Oct  3 20:00:43.366: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Oct  3 20:00:43.366: INFO: Checking APIGroup: coordination.k8s.io
    Oct  3 20:00:43.371: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Oct  3 20:00:43.371: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Oct  3 20:00:43.371: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Oct  3 20:00:43.371: INFO: Checking APIGroup: node.k8s.io
    Oct  3 20:00:43.376: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Oct  3 20:00:43.376: INFO: Versions found [{node.k8s.io/v1 v1}]
    Oct  3 20:00:43.376: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Oct  3 20:00:43.376: INFO: Checking APIGroup: discovery.k8s.io
    Oct  3 20:00:43.380: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Oct  3 20:00:43.380: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Oct  3 20:00:43.380: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Oct  3 20:00:43.381: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Oct  3 20:00:43.385: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Oct  3 20:00:43.385: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Oct  3 20:00:43.385: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Oct  3 20:00:43.385: INFO: Checking APIGroup: crd.projectcalico.org
    Oct  3 20:00:43.390: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
    Oct  3 20:00:43.390: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
    Oct  3 20:00:43.390: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
    Oct  3 20:00:43.390: INFO: Checking APIGroup: snapshot.storage.k8s.io
    Oct  3 20:00:43.394: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
    Oct  3 20:00:43.394: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1}]
    Oct  3 20:00:43.394: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
    Oct  3 20:00:43.394: INFO: Checking APIGroup: ibm.com
    Oct  3 20:00:43.398: INFO: PreferredVersion.GroupVersion: ibm.com/v1alpha1
    Oct  3 20:00:43.399: INFO: Versions found [{ibm.com/v1alpha1 v1alpha1}]
    Oct  3 20:00:43.399: INFO: ibm.com/v1alpha1 matches ibm.com/v1alpha1
    Oct  3 20:00:43.399: INFO: Checking APIGroup: metrics.k8s.io
    Oct  3 20:00:43.403: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Oct  3 20:00:43.403: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Oct  3 20:00:43.403: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Oct  3 20:00:43.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-3924" for this suite. 10/03/22 20:00:43.419
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:00:43.44
Oct  3 20:00:43.440: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubelet-test 10/03/22 20:00:43.442
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:00:43.473
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:00:43.485
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Oct  3 20:00:43.515: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65" in namespace "kubelet-test-39" to be "running and ready"
Oct  3 20:00:43.526: INFO: Pod "busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65": Phase="Pending", Reason="", readiness=false. Elapsed: 10.964356ms
Oct  3 20:00:43.526: INFO: The phase of Pod busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:00:45.538: INFO: Pod "busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022701089s
Oct  3 20:00:45.538: INFO: The phase of Pod busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:00:47.538: INFO: Pod "busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65": Phase="Running", Reason="", readiness=true. Elapsed: 4.022732425s
Oct  3 20:00:47.538: INFO: The phase of Pod busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65 is Running (Ready = true)
Oct  3 20:00:47.538: INFO: Pod "busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Oct  3 20:00:47.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-39" for this suite. 10/03/22 20:00:47.593
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":143,"skipped":2801,"failed":0}
------------------------------
• [4.173 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:00:43.44
    Oct  3 20:00:43.440: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubelet-test 10/03/22 20:00:43.442
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:00:43.473
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:00:43.485
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Oct  3 20:00:43.515: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65" in namespace "kubelet-test-39" to be "running and ready"
    Oct  3 20:00:43.526: INFO: Pod "busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65": Phase="Pending", Reason="", readiness=false. Elapsed: 10.964356ms
    Oct  3 20:00:43.526: INFO: The phase of Pod busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:00:45.538: INFO: Pod "busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022701089s
    Oct  3 20:00:45.538: INFO: The phase of Pod busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:00:47.538: INFO: Pod "busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65": Phase="Running", Reason="", readiness=true. Elapsed: 4.022732425s
    Oct  3 20:00:47.538: INFO: The phase of Pod busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65 is Running (Ready = true)
    Oct  3 20:00:47.538: INFO: Pod "busybox-readonly-fs1e66b99c-ffd6-48c3-90de-78a7d746cf65" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Oct  3 20:00:47.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-39" for this suite. 10/03/22 20:00:47.593
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:00:47.617
Oct  3 20:00:47.617: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename var-expansion 10/03/22 20:00:47.618
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:00:47.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:00:47.666
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 10/03/22 20:00:47.677
Oct  3 20:00:47.699: INFO: Waiting up to 5m0s for pod "var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d" in namespace "var-expansion-3931" to be "Succeeded or Failed"
Oct  3 20:00:47.710: INFO: Pod "var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.980211ms
Oct  3 20:00:49.723: INFO: Pod "var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024080403s
Oct  3 20:00:51.723: INFO: Pod "var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024296518s
Oct  3 20:00:53.722: INFO: Pod "var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023074417s
STEP: Saw pod success 10/03/22 20:00:53.722
Oct  3 20:00:53.723: INFO: Pod "var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d" satisfied condition "Succeeded or Failed"
Oct  3 20:00:53.738: INFO: Trying to get logs from node 10.63.128.3 pod var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d container dapi-container: <nil>
STEP: delete the pod 10/03/22 20:00:53.773
Oct  3 20:00:53.799: INFO: Waiting for pod var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d to disappear
Oct  3 20:00:53.809: INFO: Pod var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Oct  3 20:00:53.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3931" for this suite. 10/03/22 20:00:53.826
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":144,"skipped":2806,"failed":0}
------------------------------
• [SLOW TEST] [6.230 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:00:47.617
    Oct  3 20:00:47.617: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename var-expansion 10/03/22 20:00:47.618
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:00:47.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:00:47.666
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 10/03/22 20:00:47.677
    Oct  3 20:00:47.699: INFO: Waiting up to 5m0s for pod "var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d" in namespace "var-expansion-3931" to be "Succeeded or Failed"
    Oct  3 20:00:47.710: INFO: Pod "var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.980211ms
    Oct  3 20:00:49.723: INFO: Pod "var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024080403s
    Oct  3 20:00:51.723: INFO: Pod "var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024296518s
    Oct  3 20:00:53.722: INFO: Pod "var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023074417s
    STEP: Saw pod success 10/03/22 20:00:53.722
    Oct  3 20:00:53.723: INFO: Pod "var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d" satisfied condition "Succeeded or Failed"
    Oct  3 20:00:53.738: INFO: Trying to get logs from node 10.63.128.3 pod var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d container dapi-container: <nil>
    STEP: delete the pod 10/03/22 20:00:53.773
    Oct  3 20:00:53.799: INFO: Waiting for pod var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d to disappear
    Oct  3 20:00:53.809: INFO: Pod var-expansion-5c5a79a7-95d7-4e4e-9948-8b399c9c2b5d no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Oct  3 20:00:53.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3931" for this suite. 10/03/22 20:00:53.826
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:00:53.857
Oct  3 20:00:53.857: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename resourcequota 10/03/22 20:00:53.858
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:00:53.891
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:00:53.901
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 10/03/22 20:00:53.911
STEP: Counting existing ResourceQuota 10/03/22 20:00:58.925
STEP: Creating a ResourceQuota 10/03/22 20:01:03.939
STEP: Ensuring resource quota status is calculated 10/03/22 20:01:03.952
STEP: Creating a Secret 10/03/22 20:01:05.965
STEP: Ensuring resource quota status captures secret creation 10/03/22 20:01:05.992
STEP: Deleting a secret 10/03/22 20:01:08.004
STEP: Ensuring resource quota status released usage 10/03/22 20:01:08.022
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Oct  3 20:01:10.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6257" for this suite. 10/03/22 20:01:10.053
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":145,"skipped":2872,"failed":0}
------------------------------
• [SLOW TEST] [16.214 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:00:53.857
    Oct  3 20:00:53.857: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename resourcequota 10/03/22 20:00:53.858
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:00:53.891
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:00:53.901
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 10/03/22 20:00:53.911
    STEP: Counting existing ResourceQuota 10/03/22 20:00:58.925
    STEP: Creating a ResourceQuota 10/03/22 20:01:03.939
    STEP: Ensuring resource quota status is calculated 10/03/22 20:01:03.952
    STEP: Creating a Secret 10/03/22 20:01:05.965
    STEP: Ensuring resource quota status captures secret creation 10/03/22 20:01:05.992
    STEP: Deleting a secret 10/03/22 20:01:08.004
    STEP: Ensuring resource quota status released usage 10/03/22 20:01:08.022
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Oct  3 20:01:10.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6257" for this suite. 10/03/22 20:01:10.053
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:01:10.074
Oct  3 20:01:10.074: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 20:01:10.075
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:10.11
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:10.12
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 10/03/22 20:01:10.13
Oct  3 20:01:10.130: INFO: Creating e2e-svc-a-ttjp2
Oct  3 20:01:10.162: INFO: Creating e2e-svc-b-2ggjv
Oct  3 20:01:10.207: INFO: Creating e2e-svc-c-tgvk5
STEP: deleting service collection 10/03/22 20:01:10.264
Oct  3 20:01:10.360: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 20:01:10.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8418" for this suite. 10/03/22 20:01:10.374
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":146,"skipped":2880,"failed":0}
------------------------------
• [0.319 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:01:10.074
    Oct  3 20:01:10.074: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 20:01:10.075
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:10.11
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:10.12
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 10/03/22 20:01:10.13
    Oct  3 20:01:10.130: INFO: Creating e2e-svc-a-ttjp2
    Oct  3 20:01:10.162: INFO: Creating e2e-svc-b-2ggjv
    Oct  3 20:01:10.207: INFO: Creating e2e-svc-c-tgvk5
    STEP: deleting service collection 10/03/22 20:01:10.264
    Oct  3 20:01:10.360: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 20:01:10.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8418" for this suite. 10/03/22 20:01:10.374
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:01:10.394
Oct  3 20:01:10.394: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 20:01:10.395
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:10.43
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:10.439
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 10/03/22 20:01:10.449
Oct  3 20:01:10.483: INFO: Waiting up to 5m0s for pod "annotationupdate58a3a21d-93a9-4085-ade7-84ee918563c8" in namespace "downward-api-5852" to be "running and ready"
Oct  3 20:01:10.494: INFO: Pod "annotationupdate58a3a21d-93a9-4085-ade7-84ee918563c8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.840645ms
Oct  3 20:01:10.494: INFO: The phase of Pod annotationupdate58a3a21d-93a9-4085-ade7-84ee918563c8 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:01:12.507: INFO: Pod "annotationupdate58a3a21d-93a9-4085-ade7-84ee918563c8": Phase="Running", Reason="", readiness=true. Elapsed: 2.023388974s
Oct  3 20:01:12.507: INFO: The phase of Pod annotationupdate58a3a21d-93a9-4085-ade7-84ee918563c8 is Running (Ready = true)
Oct  3 20:01:12.507: INFO: Pod "annotationupdate58a3a21d-93a9-4085-ade7-84ee918563c8" satisfied condition "running and ready"
Oct  3 20:01:13.080: INFO: Successfully updated pod "annotationupdate58a3a21d-93a9-4085-ade7-84ee918563c8"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Oct  3 20:01:15.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5852" for this suite. 10/03/22 20:01:15.17
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":147,"skipped":2894,"failed":0}
------------------------------
• [4.800 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:01:10.394
    Oct  3 20:01:10.394: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 20:01:10.395
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:10.43
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:10.439
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 10/03/22 20:01:10.449
    Oct  3 20:01:10.483: INFO: Waiting up to 5m0s for pod "annotationupdate58a3a21d-93a9-4085-ade7-84ee918563c8" in namespace "downward-api-5852" to be "running and ready"
    Oct  3 20:01:10.494: INFO: Pod "annotationupdate58a3a21d-93a9-4085-ade7-84ee918563c8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.840645ms
    Oct  3 20:01:10.494: INFO: The phase of Pod annotationupdate58a3a21d-93a9-4085-ade7-84ee918563c8 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:01:12.507: INFO: Pod "annotationupdate58a3a21d-93a9-4085-ade7-84ee918563c8": Phase="Running", Reason="", readiness=true. Elapsed: 2.023388974s
    Oct  3 20:01:12.507: INFO: The phase of Pod annotationupdate58a3a21d-93a9-4085-ade7-84ee918563c8 is Running (Ready = true)
    Oct  3 20:01:12.507: INFO: Pod "annotationupdate58a3a21d-93a9-4085-ade7-84ee918563c8" satisfied condition "running and ready"
    Oct  3 20:01:13.080: INFO: Successfully updated pod "annotationupdate58a3a21d-93a9-4085-ade7-84ee918563c8"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Oct  3 20:01:15.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5852" for this suite. 10/03/22 20:01:15.17
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:01:15.201
Oct  3 20:01:15.201: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename dns 10/03/22 20:01:15.202
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:15.232
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:15.241
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 10/03/22 20:01:15.251
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3353.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-3353.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 10/03/22 20:01:15.266
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3353.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-3353.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 10/03/22 20:01:15.266
STEP: creating a pod to probe DNS 10/03/22 20:01:15.266
STEP: submitting the pod to kubernetes 10/03/22 20:01:15.266
Oct  3 20:01:15.285: INFO: Waiting up to 15m0s for pod "dns-test-b50a0698-dc40-498d-94e4-fa11d746c0d6" in namespace "dns-3353" to be "running"
Oct  3 20:01:15.295: INFO: Pod "dns-test-b50a0698-dc40-498d-94e4-fa11d746c0d6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.006339ms
Oct  3 20:01:17.308: INFO: Pod "dns-test-b50a0698-dc40-498d-94e4-fa11d746c0d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023158206s
Oct  3 20:01:19.306: INFO: Pod "dns-test-b50a0698-dc40-498d-94e4-fa11d746c0d6": Phase="Running", Reason="", readiness=true. Elapsed: 4.021747475s
Oct  3 20:01:19.307: INFO: Pod "dns-test-b50a0698-dc40-498d-94e4-fa11d746c0d6" satisfied condition "running"
STEP: retrieving the pod 10/03/22 20:01:19.307
STEP: looking for the results for each expected name from probers 10/03/22 20:01:19.317
Oct  3 20:01:19.406: INFO: DNS probes using dns-3353/dns-test-b50a0698-dc40-498d-94e4-fa11d746c0d6 succeeded

STEP: deleting the pod 10/03/22 20:01:19.407
STEP: deleting the test headless service 10/03/22 20:01:19.44
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Oct  3 20:01:19.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3353" for this suite. 10/03/22 20:01:19.486
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":148,"skipped":2915,"failed":0}
------------------------------
• [4.304 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:01:15.201
    Oct  3 20:01:15.201: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename dns 10/03/22 20:01:15.202
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:15.232
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:15.241
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 10/03/22 20:01:15.251
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3353.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-3353.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     10/03/22 20:01:15.266
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3353.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-3353.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     10/03/22 20:01:15.266
    STEP: creating a pod to probe DNS 10/03/22 20:01:15.266
    STEP: submitting the pod to kubernetes 10/03/22 20:01:15.266
    Oct  3 20:01:15.285: INFO: Waiting up to 15m0s for pod "dns-test-b50a0698-dc40-498d-94e4-fa11d746c0d6" in namespace "dns-3353" to be "running"
    Oct  3 20:01:15.295: INFO: Pod "dns-test-b50a0698-dc40-498d-94e4-fa11d746c0d6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.006339ms
    Oct  3 20:01:17.308: INFO: Pod "dns-test-b50a0698-dc40-498d-94e4-fa11d746c0d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023158206s
    Oct  3 20:01:19.306: INFO: Pod "dns-test-b50a0698-dc40-498d-94e4-fa11d746c0d6": Phase="Running", Reason="", readiness=true. Elapsed: 4.021747475s
    Oct  3 20:01:19.307: INFO: Pod "dns-test-b50a0698-dc40-498d-94e4-fa11d746c0d6" satisfied condition "running"
    STEP: retrieving the pod 10/03/22 20:01:19.307
    STEP: looking for the results for each expected name from probers 10/03/22 20:01:19.317
    Oct  3 20:01:19.406: INFO: DNS probes using dns-3353/dns-test-b50a0698-dc40-498d-94e4-fa11d746c0d6 succeeded

    STEP: deleting the pod 10/03/22 20:01:19.407
    STEP: deleting the test headless service 10/03/22 20:01:19.44
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Oct  3 20:01:19.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3353" for this suite. 10/03/22 20:01:19.486
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:01:19.506
Oct  3 20:01:19.506: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename containers 10/03/22 20:01:19.507
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:19.538
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:19.548
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 10/03/22 20:01:19.557
Oct  3 20:01:19.577: INFO: Waiting up to 5m0s for pod "client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a" in namespace "containers-7980" to be "Succeeded or Failed"
Oct  3 20:01:19.588: INFO: Pod "client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.643083ms
Oct  3 20:01:21.600: INFO: Pod "client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a": Phase="Running", Reason="", readiness=true. Elapsed: 2.022573605s
Oct  3 20:01:23.601: INFO: Pod "client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a": Phase="Running", Reason="", readiness=false. Elapsed: 4.023863336s
Oct  3 20:01:25.599: INFO: Pod "client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022101709s
STEP: Saw pod success 10/03/22 20:01:25.599
Oct  3 20:01:25.599: INFO: Pod "client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a" satisfied condition "Succeeded or Failed"
Oct  3 20:01:25.610: INFO: Trying to get logs from node 10.63.128.3 pod client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a container agnhost-container: <nil>
STEP: delete the pod 10/03/22 20:01:25.636
Oct  3 20:01:25.661: INFO: Waiting for pod client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a to disappear
Oct  3 20:01:25.672: INFO: Pod client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Oct  3 20:01:25.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7980" for this suite. 10/03/22 20:01:25.689
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":149,"skipped":2924,"failed":0}
------------------------------
• [SLOW TEST] [6.202 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:01:19.506
    Oct  3 20:01:19.506: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename containers 10/03/22 20:01:19.507
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:19.538
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:19.548
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 10/03/22 20:01:19.557
    Oct  3 20:01:19.577: INFO: Waiting up to 5m0s for pod "client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a" in namespace "containers-7980" to be "Succeeded or Failed"
    Oct  3 20:01:19.588: INFO: Pod "client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.643083ms
    Oct  3 20:01:21.600: INFO: Pod "client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a": Phase="Running", Reason="", readiness=true. Elapsed: 2.022573605s
    Oct  3 20:01:23.601: INFO: Pod "client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a": Phase="Running", Reason="", readiness=false. Elapsed: 4.023863336s
    Oct  3 20:01:25.599: INFO: Pod "client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022101709s
    STEP: Saw pod success 10/03/22 20:01:25.599
    Oct  3 20:01:25.599: INFO: Pod "client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a" satisfied condition "Succeeded or Failed"
    Oct  3 20:01:25.610: INFO: Trying to get logs from node 10.63.128.3 pod client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 20:01:25.636
    Oct  3 20:01:25.661: INFO: Waiting for pod client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a to disappear
    Oct  3 20:01:25.672: INFO: Pod client-containers-43a8ca0a-fae9-4b65-99f4-9c802797e35a no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Oct  3 20:01:25.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-7980" for this suite. 10/03/22 20:01:25.689
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:01:25.711
Oct  3 20:01:25.711: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 20:01:25.712
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:25.757
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:25.766
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 20:01:25.809
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:01:26.92
STEP: Deploying the webhook pod 10/03/22 20:01:26.941
STEP: Wait for the deployment to be ready 10/03/22 20:01:26.971
Oct  3 20:01:27.002: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  3 20:01:29.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 20, 1, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 1, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 20, 1, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 1, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 10/03/22 20:01:31.055
STEP: Verifying the service has paired with the endpoint 10/03/22 20:01:31.095
Oct  3 20:01:32.095: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 10/03/22 20:01:32.31
STEP: Creating a configMap that does not comply to the validation webhook rules 10/03/22 20:01:32.421
STEP: Deleting the collection of validation webhooks 10/03/22 20:01:32.495
STEP: Creating a configMap that does not comply to the validation webhook rules 10/03/22 20:01:32.642
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:01:32.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8568" for this suite. 10/03/22 20:01:32.692
STEP: Destroying namespace "webhook-8568-markers" for this suite. 10/03/22 20:01:32.713
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":150,"skipped":2934,"failed":0}
------------------------------
• [SLOW TEST] [7.140 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:01:25.711
    Oct  3 20:01:25.711: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 20:01:25.712
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:25.757
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:25.766
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 20:01:25.809
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:01:26.92
    STEP: Deploying the webhook pod 10/03/22 20:01:26.941
    STEP: Wait for the deployment to be ready 10/03/22 20:01:26.971
    Oct  3 20:01:27.002: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Oct  3 20:01:29.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 20, 1, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 1, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 20, 1, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 1, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 10/03/22 20:01:31.055
    STEP: Verifying the service has paired with the endpoint 10/03/22 20:01:31.095
    Oct  3 20:01:32.095: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 10/03/22 20:01:32.31
    STEP: Creating a configMap that does not comply to the validation webhook rules 10/03/22 20:01:32.421
    STEP: Deleting the collection of validation webhooks 10/03/22 20:01:32.495
    STEP: Creating a configMap that does not comply to the validation webhook rules 10/03/22 20:01:32.642
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:01:32.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8568" for this suite. 10/03/22 20:01:32.692
    STEP: Destroying namespace "webhook-8568-markers" for this suite. 10/03/22 20:01:32.713
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:01:32.86
Oct  3 20:01:32.860: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename configmap 10/03/22 20:01:32.861
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:32.908
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:32.918
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-0b65ffe4-bf85-45ca-b6a8-05f9d8eaa43d 10/03/22 20:01:32.928
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Oct  3 20:01:32.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5336" for this suite. 10/03/22 20:01:32.95
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":151,"skipped":2984,"failed":0}
------------------------------
• [0.112 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:01:32.86
    Oct  3 20:01:32.860: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename configmap 10/03/22 20:01:32.861
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:32.908
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:32.918
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-0b65ffe4-bf85-45ca-b6a8-05f9d8eaa43d 10/03/22 20:01:32.928
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Oct  3 20:01:32.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5336" for this suite. 10/03/22 20:01:32.95
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:01:32.973
Oct  3 20:01:32.973: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename replication-controller 10/03/22 20:01:32.974
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:33.006
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:33.016
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Oct  3 20:01:33.026: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 10/03/22 20:01:33.054
STEP: Checking rc "condition-test" has the desired failure condition set 10/03/22 20:01:33.068
STEP: Scaling down rc "condition-test" to satisfy pod quota 10/03/22 20:01:34.101
Oct  3 20:01:34.139: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 10/03/22 20:01:34.139
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Oct  3 20:01:34.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7310" for this suite. 10/03/22 20:01:34.169
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":152,"skipped":2990,"failed":0}
------------------------------
• [1.219 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:01:32.973
    Oct  3 20:01:32.973: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename replication-controller 10/03/22 20:01:32.974
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:33.006
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:33.016
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Oct  3 20:01:33.026: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 10/03/22 20:01:33.054
    STEP: Checking rc "condition-test" has the desired failure condition set 10/03/22 20:01:33.068
    STEP: Scaling down rc "condition-test" to satisfy pod quota 10/03/22 20:01:34.101
    Oct  3 20:01:34.139: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 10/03/22 20:01:34.139
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Oct  3 20:01:34.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-7310" for this suite. 10/03/22 20:01:34.169
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:01:34.193
Oct  3 20:01:34.193: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir 10/03/22 20:01:34.194
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:34.227
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:34.236
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 10/03/22 20:01:34.246
Oct  3 20:01:34.268: INFO: Waiting up to 5m0s for pod "pod-15b3966d-3913-4eb5-adfa-15743f1e0b44" in namespace "emptydir-8914" to be "Succeeded or Failed"
Oct  3 20:01:34.279: INFO: Pod "pod-15b3966d-3913-4eb5-adfa-15743f1e0b44": Phase="Pending", Reason="", readiness=false. Elapsed: 10.61998ms
Oct  3 20:01:36.291: INFO: Pod "pod-15b3966d-3913-4eb5-adfa-15743f1e0b44": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022828624s
Oct  3 20:01:38.290: INFO: Pod "pod-15b3966d-3913-4eb5-adfa-15743f1e0b44": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02210419s
Oct  3 20:01:40.292: INFO: Pod "pod-15b3966d-3913-4eb5-adfa-15743f1e0b44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02324731s
STEP: Saw pod success 10/03/22 20:01:40.292
Oct  3 20:01:40.292: INFO: Pod "pod-15b3966d-3913-4eb5-adfa-15743f1e0b44" satisfied condition "Succeeded or Failed"
Oct  3 20:01:40.304: INFO: Trying to get logs from node 10.63.128.3 pod pod-15b3966d-3913-4eb5-adfa-15743f1e0b44 container test-container: <nil>
STEP: delete the pod 10/03/22 20:01:40.33
Oct  3 20:01:40.354: INFO: Waiting for pod pod-15b3966d-3913-4eb5-adfa-15743f1e0b44 to disappear
Oct  3 20:01:40.365: INFO: Pod pod-15b3966d-3913-4eb5-adfa-15743f1e0b44 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Oct  3 20:01:40.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8914" for this suite. 10/03/22 20:01:40.381
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":153,"skipped":2998,"failed":0}
------------------------------
• [SLOW TEST] [6.206 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:01:34.193
    Oct  3 20:01:34.193: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir 10/03/22 20:01:34.194
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:34.227
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:34.236
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 10/03/22 20:01:34.246
    Oct  3 20:01:34.268: INFO: Waiting up to 5m0s for pod "pod-15b3966d-3913-4eb5-adfa-15743f1e0b44" in namespace "emptydir-8914" to be "Succeeded or Failed"
    Oct  3 20:01:34.279: INFO: Pod "pod-15b3966d-3913-4eb5-adfa-15743f1e0b44": Phase="Pending", Reason="", readiness=false. Elapsed: 10.61998ms
    Oct  3 20:01:36.291: INFO: Pod "pod-15b3966d-3913-4eb5-adfa-15743f1e0b44": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022828624s
    Oct  3 20:01:38.290: INFO: Pod "pod-15b3966d-3913-4eb5-adfa-15743f1e0b44": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02210419s
    Oct  3 20:01:40.292: INFO: Pod "pod-15b3966d-3913-4eb5-adfa-15743f1e0b44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02324731s
    STEP: Saw pod success 10/03/22 20:01:40.292
    Oct  3 20:01:40.292: INFO: Pod "pod-15b3966d-3913-4eb5-adfa-15743f1e0b44" satisfied condition "Succeeded or Failed"
    Oct  3 20:01:40.304: INFO: Trying to get logs from node 10.63.128.3 pod pod-15b3966d-3913-4eb5-adfa-15743f1e0b44 container test-container: <nil>
    STEP: delete the pod 10/03/22 20:01:40.33
    Oct  3 20:01:40.354: INFO: Waiting for pod pod-15b3966d-3913-4eb5-adfa-15743f1e0b44 to disappear
    Oct  3 20:01:40.365: INFO: Pod pod-15b3966d-3913-4eb5-adfa-15743f1e0b44 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Oct  3 20:01:40.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8914" for this suite. 10/03/22 20:01:40.381
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:01:40.405
Oct  3 20:01:40.406: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename security-context-test 10/03/22 20:01:40.407
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:40.442
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:40.452
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Oct  3 20:01:40.481: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78" in namespace "security-context-test-777" to be "Succeeded or Failed"
Oct  3 20:01:40.493: INFO: Pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78": Phase="Pending", Reason="", readiness=false. Elapsed: 11.619415ms
Oct  3 20:01:42.507: INFO: Pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025845421s
Oct  3 20:01:44.505: INFO: Pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023631483s
Oct  3 20:01:46.505: INFO: Pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024104432s
Oct  3 20:01:48.505: INFO: Pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024347444s
Oct  3 20:01:50.505: INFO: Pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.023450631s
Oct  3 20:01:50.505: INFO: Pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Oct  3 20:01:50.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-777" for this suite. 10/03/22 20:01:50.55
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":154,"skipped":3016,"failed":0}
------------------------------
• [SLOW TEST] [10.164 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:01:40.405
    Oct  3 20:01:40.406: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename security-context-test 10/03/22 20:01:40.407
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:40.442
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:40.452
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Oct  3 20:01:40.481: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78" in namespace "security-context-test-777" to be "Succeeded or Failed"
    Oct  3 20:01:40.493: INFO: Pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78": Phase="Pending", Reason="", readiness=false. Elapsed: 11.619415ms
    Oct  3 20:01:42.507: INFO: Pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025845421s
    Oct  3 20:01:44.505: INFO: Pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023631483s
    Oct  3 20:01:46.505: INFO: Pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024104432s
    Oct  3 20:01:48.505: INFO: Pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024347444s
    Oct  3 20:01:50.505: INFO: Pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.023450631s
    Oct  3 20:01:50.505: INFO: Pod "alpine-nnp-false-dd65c9c8-3b8d-4c07-ad20-b46b2ac5da78" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Oct  3 20:01:50.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-777" for this suite. 10/03/22 20:01:50.55
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:01:50.572
Oct  3 20:01:50.573: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 20:01:50.575
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:50.618
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:50.627
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-8615 10/03/22 20:01:50.637
STEP: creating replication controller nodeport-test in namespace services-8615 10/03/22 20:01:50.682
I1003 20:01:50.713646      22 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-8615, replica count: 2
I1003 20:01:53.765388      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  3 20:01:53.765: INFO: Creating new exec pod
Oct  3 20:01:53.782: INFO: Waiting up to 5m0s for pod "execpodjgjkb" in namespace "services-8615" to be "running"
Oct  3 20:01:53.793: INFO: Pod "execpodjgjkb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.629779ms
Oct  3 20:01:55.804: INFO: Pod "execpodjgjkb": Phase="Running", Reason="", readiness=true. Elapsed: 2.022781094s
Oct  3 20:01:55.805: INFO: Pod "execpodjgjkb" satisfied condition "running"
Oct  3 20:01:56.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Oct  3 20:01:57.148: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Oct  3 20:01:57.148: INFO: stdout: ""
Oct  3 20:01:58.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Oct  3 20:01:58.493: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Oct  3 20:01:58.493: INFO: stdout: ""
Oct  3 20:01:59.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Oct  3 20:01:59.467: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Oct  3 20:01:59.467: INFO: stdout: ""
Oct  3 20:02:00.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Oct  3 20:02:00.451: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Oct  3 20:02:00.451: INFO: stdout: ""
Oct  3 20:02:01.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Oct  3 20:02:01.497: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Oct  3 20:02:01.497: INFO: stdout: ""
Oct  3 20:02:02.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Oct  3 20:02:02.456: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Oct  3 20:02:02.456: INFO: stdout: ""
Oct  3 20:02:03.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Oct  3 20:02:03.425: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Oct  3 20:02:03.425: INFO: stdout: ""
Oct  3 20:02:04.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Oct  3 20:02:04.549: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Oct  3 20:02:04.549: INFO: stdout: "nodeport-test-26wdl"
Oct  3 20:02:04.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.53.19 80'
Oct  3 20:02:04.851: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.53.19 80\nConnection to 172.21.53.19 80 port [tcp/http] succeeded!\n"
Oct  3 20:02:04.851: INFO: stdout: ""
Oct  3 20:02:05.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.53.19 80'
Oct  3 20:02:06.144: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.53.19 80\nConnection to 172.21.53.19 80 port [tcp/http] succeeded!\n"
Oct  3 20:02:06.144: INFO: stdout: ""
Oct  3 20:02:06.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.53.19 80'
Oct  3 20:02:07.156: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.53.19 80\nConnection to 172.21.53.19 80 port [tcp/http] succeeded!\n"
Oct  3 20:02:07.156: INFO: stdout: "nodeport-test-26wdl"
Oct  3 20:02:07.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.13 30652'
Oct  3 20:02:07.467: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.13 30652\nConnection to 10.63.128.13 30652 port [tcp/*] succeeded!\n"
Oct  3 20:02:07.467: INFO: stdout: ""
Oct  3 20:02:08.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.13 30652'
Oct  3 20:02:08.774: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.13 30652\nConnection to 10.63.128.13 30652 port [tcp/*] succeeded!\n"
Oct  3 20:02:08.774: INFO: stdout: ""
Oct  3 20:02:09.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.13 30652'
Oct  3 20:02:09.779: INFO: stderr: "+ nc -v -t -w 2 10.63.128.13 30652\n+ echo hostName\nConnection to 10.63.128.13 30652 port [tcp/*] succeeded!\n"
Oct  3 20:02:09.779: INFO: stdout: "nodeport-test-qv2lb"
Oct  3 20:02:09.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.3 30652'
Oct  3 20:02:10.075: INFO: stderr: "+ nc -v -t -w 2 10.63.128.3 30652\n+ echo hostName\nConnection to 10.63.128.3 30652 port [tcp/*] succeeded!\n"
Oct  3 20:02:10.075: INFO: stdout: "nodeport-test-26wdl"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 20:02:10.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8615" for this suite. 10/03/22 20:02:10.093
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":155,"skipped":3021,"failed":0}
------------------------------
• [SLOW TEST] [19.539 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:01:50.572
    Oct  3 20:01:50.573: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 20:01:50.575
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:01:50.618
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:01:50.627
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-8615 10/03/22 20:01:50.637
    STEP: creating replication controller nodeport-test in namespace services-8615 10/03/22 20:01:50.682
    I1003 20:01:50.713646      22 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-8615, replica count: 2
    I1003 20:01:53.765388      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct  3 20:01:53.765: INFO: Creating new exec pod
    Oct  3 20:01:53.782: INFO: Waiting up to 5m0s for pod "execpodjgjkb" in namespace "services-8615" to be "running"
    Oct  3 20:01:53.793: INFO: Pod "execpodjgjkb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.629779ms
    Oct  3 20:01:55.804: INFO: Pod "execpodjgjkb": Phase="Running", Reason="", readiness=true. Elapsed: 2.022781094s
    Oct  3 20:01:55.805: INFO: Pod "execpodjgjkb" satisfied condition "running"
    Oct  3 20:01:56.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Oct  3 20:01:57.148: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Oct  3 20:01:57.148: INFO: stdout: ""
    Oct  3 20:01:58.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Oct  3 20:01:58.493: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Oct  3 20:01:58.493: INFO: stdout: ""
    Oct  3 20:01:59.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Oct  3 20:01:59.467: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Oct  3 20:01:59.467: INFO: stdout: ""
    Oct  3 20:02:00.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Oct  3 20:02:00.451: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Oct  3 20:02:00.451: INFO: stdout: ""
    Oct  3 20:02:01.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Oct  3 20:02:01.497: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Oct  3 20:02:01.497: INFO: stdout: ""
    Oct  3 20:02:02.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Oct  3 20:02:02.456: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Oct  3 20:02:02.456: INFO: stdout: ""
    Oct  3 20:02:03.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Oct  3 20:02:03.425: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Oct  3 20:02:03.425: INFO: stdout: ""
    Oct  3 20:02:04.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Oct  3 20:02:04.549: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Oct  3 20:02:04.549: INFO: stdout: "nodeport-test-26wdl"
    Oct  3 20:02:04.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.53.19 80'
    Oct  3 20:02:04.851: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.53.19 80\nConnection to 172.21.53.19 80 port [tcp/http] succeeded!\n"
    Oct  3 20:02:04.851: INFO: stdout: ""
    Oct  3 20:02:05.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.53.19 80'
    Oct  3 20:02:06.144: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.53.19 80\nConnection to 172.21.53.19 80 port [tcp/http] succeeded!\n"
    Oct  3 20:02:06.144: INFO: stdout: ""
    Oct  3 20:02:06.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.53.19 80'
    Oct  3 20:02:07.156: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.53.19 80\nConnection to 172.21.53.19 80 port [tcp/http] succeeded!\n"
    Oct  3 20:02:07.156: INFO: stdout: "nodeport-test-26wdl"
    Oct  3 20:02:07.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.13 30652'
    Oct  3 20:02:07.467: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.13 30652\nConnection to 10.63.128.13 30652 port [tcp/*] succeeded!\n"
    Oct  3 20:02:07.467: INFO: stdout: ""
    Oct  3 20:02:08.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.13 30652'
    Oct  3 20:02:08.774: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.13 30652\nConnection to 10.63.128.13 30652 port [tcp/*] succeeded!\n"
    Oct  3 20:02:08.774: INFO: stdout: ""
    Oct  3 20:02:09.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.13 30652'
    Oct  3 20:02:09.779: INFO: stderr: "+ nc -v -t -w 2 10.63.128.13 30652\n+ echo hostName\nConnection to 10.63.128.13 30652 port [tcp/*] succeeded!\n"
    Oct  3 20:02:09.779: INFO: stdout: "nodeport-test-qv2lb"
    Oct  3 20:02:09.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-8615 exec execpodjgjkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.3 30652'
    Oct  3 20:02:10.075: INFO: stderr: "+ nc -v -t -w 2 10.63.128.3 30652\n+ echo hostName\nConnection to 10.63.128.3 30652 port [tcp/*] succeeded!\n"
    Oct  3 20:02:10.075: INFO: stdout: "nodeport-test-26wdl"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 20:02:10.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8615" for this suite. 10/03/22 20:02:10.093
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:02:10.115
Oct  3 20:02:10.116: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 20:02:10.117
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:02:10.155
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:02:10.165
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 20:02:10.213
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:02:10.949
STEP: Deploying the webhook pod 10/03/22 20:02:10.971
STEP: Wait for the deployment to be ready 10/03/22 20:02:10.999
Oct  3 20:02:11.024: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/03/22 20:02:13.058
STEP: Verifying the service has paired with the endpoint 10/03/22 20:02:13.09
Oct  3 20:02:14.092: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 10/03/22 20:02:14.103
STEP: create a namespace for the webhook 10/03/22 20:02:14.175
STEP: create a configmap should be unconditionally rejected by the webhook 10/03/22 20:02:14.197
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:02:14.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-97" for this suite. 10/03/22 20:02:14.291
STEP: Destroying namespace "webhook-97-markers" for this suite. 10/03/22 20:02:14.316
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":156,"skipped":3038,"failed":0}
------------------------------
• [4.322 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:02:10.115
    Oct  3 20:02:10.116: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 20:02:10.117
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:02:10.155
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:02:10.165
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 20:02:10.213
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:02:10.949
    STEP: Deploying the webhook pod 10/03/22 20:02:10.971
    STEP: Wait for the deployment to be ready 10/03/22 20:02:10.999
    Oct  3 20:02:11.024: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/03/22 20:02:13.058
    STEP: Verifying the service has paired with the endpoint 10/03/22 20:02:13.09
    Oct  3 20:02:14.092: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 10/03/22 20:02:14.103
    STEP: create a namespace for the webhook 10/03/22 20:02:14.175
    STEP: create a configmap should be unconditionally rejected by the webhook 10/03/22 20:02:14.197
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:02:14.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-97" for this suite. 10/03/22 20:02:14.291
    STEP: Destroying namespace "webhook-97-markers" for this suite. 10/03/22 20:02:14.316
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:02:14.438
Oct  3 20:02:14.438: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename replicaset 10/03/22 20:02:14.439
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:02:14.473
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:02:14.482
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 10/03/22 20:02:14.492
Oct  3 20:02:14.517: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct  3 20:02:19.533: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 10/03/22 20:02:19.533
STEP: getting scale subresource 10/03/22 20:02:19.533
STEP: updating a scale subresource 10/03/22 20:02:19.545
STEP: verifying the replicaset Spec.Replicas was modified 10/03/22 20:02:19.579
STEP: Patch a scale subresource 10/03/22 20:02:19.59
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Oct  3 20:02:19.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5986" for this suite. 10/03/22 20:02:19.672
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":157,"skipped":3046,"failed":0}
------------------------------
• [SLOW TEST] [5.269 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:02:14.438
    Oct  3 20:02:14.438: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename replicaset 10/03/22 20:02:14.439
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:02:14.473
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:02:14.482
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 10/03/22 20:02:14.492
    Oct  3 20:02:14.517: INFO: Pod name sample-pod: Found 0 pods out of 1
    Oct  3 20:02:19.533: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 10/03/22 20:02:19.533
    STEP: getting scale subresource 10/03/22 20:02:19.533
    STEP: updating a scale subresource 10/03/22 20:02:19.545
    STEP: verifying the replicaset Spec.Replicas was modified 10/03/22 20:02:19.579
    STEP: Patch a scale subresource 10/03/22 20:02:19.59
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Oct  3 20:02:19.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-5986" for this suite. 10/03/22 20:02:19.672
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:02:19.72
Oct  3 20:02:19.721: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename disruption 10/03/22 20:02:19.722
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:02:19.782
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:02:19.791
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 10/03/22 20:02:19.803
STEP: Waiting for the pdb to be processed 10/03/22 20:02:19.817
STEP: First trying to evict a pod which shouldn't be evictable 10/03/22 20:02:19.842
STEP: Waiting for all pods to be running 10/03/22 20:02:19.842
Oct  3 20:02:19.854: INFO: pods: 0 < 3
Oct  3 20:02:21.867: INFO: running pods: 1 < 3
Oct  3 20:02:23.868: INFO: running pods: 2 < 3
STEP: locating a running pod 10/03/22 20:02:25.87
STEP: Updating the pdb to allow a pod to be evicted 10/03/22 20:02:25.901
STEP: Waiting for the pdb to be processed 10/03/22 20:02:25.924
STEP: Trying to evict the same pod we tried earlier which should now be evictable 10/03/22 20:02:25.934
STEP: Waiting for all pods to be running 10/03/22 20:02:25.934
STEP: Waiting for the pdb to observed all healthy pods 10/03/22 20:02:25.946
STEP: Patching the pdb to disallow a pod to be evicted 10/03/22 20:02:26.022
STEP: Waiting for the pdb to be processed 10/03/22 20:02:26.057
STEP: Waiting for all pods to be running 10/03/22 20:02:26.092
Oct  3 20:02:26.108: INFO: running pods: 2 < 3
STEP: locating a running pod 10/03/22 20:02:28.12
STEP: Deleting the pdb to allow a pod to be evicted 10/03/22 20:02:28.151
STEP: Waiting for the pdb to be deleted 10/03/22 20:02:28.169
STEP: Trying to evict the same pod we tried earlier which should now be evictable 10/03/22 20:02:28.207
STEP: Waiting for all pods to be running 10/03/22 20:02:28.207
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Oct  3 20:02:28.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-5610" for this suite. 10/03/22 20:02:28.278
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":158,"skipped":3077,"failed":0}
------------------------------
• [SLOW TEST] [8.585 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:02:19.72
    Oct  3 20:02:19.721: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename disruption 10/03/22 20:02:19.722
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:02:19.782
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:02:19.791
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 10/03/22 20:02:19.803
    STEP: Waiting for the pdb to be processed 10/03/22 20:02:19.817
    STEP: First trying to evict a pod which shouldn't be evictable 10/03/22 20:02:19.842
    STEP: Waiting for all pods to be running 10/03/22 20:02:19.842
    Oct  3 20:02:19.854: INFO: pods: 0 < 3
    Oct  3 20:02:21.867: INFO: running pods: 1 < 3
    Oct  3 20:02:23.868: INFO: running pods: 2 < 3
    STEP: locating a running pod 10/03/22 20:02:25.87
    STEP: Updating the pdb to allow a pod to be evicted 10/03/22 20:02:25.901
    STEP: Waiting for the pdb to be processed 10/03/22 20:02:25.924
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 10/03/22 20:02:25.934
    STEP: Waiting for all pods to be running 10/03/22 20:02:25.934
    STEP: Waiting for the pdb to observed all healthy pods 10/03/22 20:02:25.946
    STEP: Patching the pdb to disallow a pod to be evicted 10/03/22 20:02:26.022
    STEP: Waiting for the pdb to be processed 10/03/22 20:02:26.057
    STEP: Waiting for all pods to be running 10/03/22 20:02:26.092
    Oct  3 20:02:26.108: INFO: running pods: 2 < 3
    STEP: locating a running pod 10/03/22 20:02:28.12
    STEP: Deleting the pdb to allow a pod to be evicted 10/03/22 20:02:28.151
    STEP: Waiting for the pdb to be deleted 10/03/22 20:02:28.169
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 10/03/22 20:02:28.207
    STEP: Waiting for all pods to be running 10/03/22 20:02:28.207
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Oct  3 20:02:28.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-5610" for this suite. 10/03/22 20:02:28.278
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:02:28.306
Oct  3 20:02:28.306: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename runtimeclass 10/03/22 20:02:28.308
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:02:28.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:02:28.379
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Oct  3 20:02:28.449: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-1723 to be scheduled
Oct  3 20:02:28.490: INFO: 1 pods are not scheduled: [runtimeclass-1723/test-runtimeclass-runtimeclass-1723-preconfigured-handler-gsjvb(39eae152-06d8-4acc-aa70-4b5a7b5133d6)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Oct  3 20:02:30.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1723" for this suite. 10/03/22 20:02:30.555
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":159,"skipped":3085,"failed":0}
------------------------------
• [2.276 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:02:28.306
    Oct  3 20:02:28.306: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename runtimeclass 10/03/22 20:02:28.308
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:02:28.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:02:28.379
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Oct  3 20:02:28.449: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-1723 to be scheduled
    Oct  3 20:02:28.490: INFO: 1 pods are not scheduled: [runtimeclass-1723/test-runtimeclass-runtimeclass-1723-preconfigured-handler-gsjvb(39eae152-06d8-4acc-aa70-4b5a7b5133d6)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Oct  3 20:02:30.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1723" for this suite. 10/03/22 20:02:30.555
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:02:30.585
Oct  3 20:02:30.585: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-probe 10/03/22 20:02:30.586
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:02:30.633
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:02:30.643
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada in namespace container-probe-4499 10/03/22 20:02:30.656
Oct  3 20:02:30.681: INFO: Waiting up to 5m0s for pod "busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada" in namespace "container-probe-4499" to be "not pending"
Oct  3 20:02:30.691: INFO: Pod "busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada": Phase="Pending", Reason="", readiness=false. Elapsed: 10.30513ms
Oct  3 20:02:32.704: INFO: Pod "busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023114975s
Oct  3 20:02:34.733: INFO: Pod "busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada": Phase="Running", Reason="", readiness=true. Elapsed: 4.052603784s
Oct  3 20:02:34.733: INFO: Pod "busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada" satisfied condition "not pending"
Oct  3 20:02:34.733: INFO: Started pod busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada in namespace container-probe-4499
STEP: checking the pod's current state and verifying that restartCount is present 10/03/22 20:02:34.733
Oct  3 20:02:34.744: INFO: Initial restart count of pod busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada is 0
STEP: deleting the pod 10/03/22 20:06:36.329
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Oct  3 20:06:36.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4499" for this suite. 10/03/22 20:06:36.382
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":160,"skipped":3090,"failed":0}
------------------------------
• [SLOW TEST] [245.817 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:02:30.585
    Oct  3 20:02:30.585: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-probe 10/03/22 20:02:30.586
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:02:30.633
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:02:30.643
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada in namespace container-probe-4499 10/03/22 20:02:30.656
    Oct  3 20:02:30.681: INFO: Waiting up to 5m0s for pod "busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada" in namespace "container-probe-4499" to be "not pending"
    Oct  3 20:02:30.691: INFO: Pod "busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada": Phase="Pending", Reason="", readiness=false. Elapsed: 10.30513ms
    Oct  3 20:02:32.704: INFO: Pod "busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023114975s
    Oct  3 20:02:34.733: INFO: Pod "busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada": Phase="Running", Reason="", readiness=true. Elapsed: 4.052603784s
    Oct  3 20:02:34.733: INFO: Pod "busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada" satisfied condition "not pending"
    Oct  3 20:02:34.733: INFO: Started pod busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada in namespace container-probe-4499
    STEP: checking the pod's current state and verifying that restartCount is present 10/03/22 20:02:34.733
    Oct  3 20:02:34.744: INFO: Initial restart count of pod busybox-89c3fe76-51d2-4db4-bfa7-8ff8376c9ada is 0
    STEP: deleting the pod 10/03/22 20:06:36.329
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Oct  3 20:06:36.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4499" for this suite. 10/03/22 20:06:36.382
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:06:36.404
Oct  3 20:06:36.404: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename configmap 10/03/22 20:06:36.406
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:06:36.438
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:06:36.449
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-8167abcc-70a2-4baf-93db-34dbd602fc12 10/03/22 20:06:36.459
STEP: Creating a pod to test consume configMaps 10/03/22 20:06:36.472
Oct  3 20:06:36.493: INFO: Waiting up to 5m0s for pod "pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf" in namespace "configmap-4036" to be "Succeeded or Failed"
Oct  3 20:06:36.506: INFO: Pod "pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.485533ms
Oct  3 20:06:38.519: INFO: Pod "pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02548369s
Oct  3 20:06:40.517: INFO: Pod "pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024108926s
Oct  3 20:06:42.520: INFO: Pod "pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026934299s
STEP: Saw pod success 10/03/22 20:06:42.52
Oct  3 20:06:42.520: INFO: Pod "pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf" satisfied condition "Succeeded or Failed"
Oct  3 20:06:42.532: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf container configmap-volume-test: <nil>
STEP: delete the pod 10/03/22 20:06:42.626
Oct  3 20:06:42.664: INFO: Waiting for pod pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf to disappear
Oct  3 20:06:42.675: INFO: Pod pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Oct  3 20:06:42.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4036" for this suite. 10/03/22 20:06:42.691
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":161,"skipped":3118,"failed":0}
------------------------------
• [SLOW TEST] [6.305 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:06:36.404
    Oct  3 20:06:36.404: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename configmap 10/03/22 20:06:36.406
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:06:36.438
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:06:36.449
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-8167abcc-70a2-4baf-93db-34dbd602fc12 10/03/22 20:06:36.459
    STEP: Creating a pod to test consume configMaps 10/03/22 20:06:36.472
    Oct  3 20:06:36.493: INFO: Waiting up to 5m0s for pod "pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf" in namespace "configmap-4036" to be "Succeeded or Failed"
    Oct  3 20:06:36.506: INFO: Pod "pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.485533ms
    Oct  3 20:06:38.519: INFO: Pod "pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02548369s
    Oct  3 20:06:40.517: INFO: Pod "pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024108926s
    Oct  3 20:06:42.520: INFO: Pod "pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026934299s
    STEP: Saw pod success 10/03/22 20:06:42.52
    Oct  3 20:06:42.520: INFO: Pod "pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf" satisfied condition "Succeeded or Failed"
    Oct  3 20:06:42.532: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf container configmap-volume-test: <nil>
    STEP: delete the pod 10/03/22 20:06:42.626
    Oct  3 20:06:42.664: INFO: Waiting for pod pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf to disappear
    Oct  3 20:06:42.675: INFO: Pod pod-configmaps-460ab90c-ffdd-4040-8c6b-3fc614f772bf no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Oct  3 20:06:42.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4036" for this suite. 10/03/22 20:06:42.691
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:06:42.716
Oct  3 20:06:42.716: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename custom-resource-definition 10/03/22 20:06:42.717
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:06:42.749
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:06:42.76
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 10/03/22 20:06:42.77
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 10/03/22 20:06:42.775
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 10/03/22 20:06:42.775
STEP: fetching the /apis/apiextensions.k8s.io discovery document 10/03/22 20:06:42.775
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 10/03/22 20:06:42.78
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 10/03/22 20:06:42.78
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 10/03/22 20:06:42.785
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:06:42.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4456" for this suite. 10/03/22 20:06:42.799
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":162,"skipped":3154,"failed":0}
------------------------------
• [0.106 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:06:42.716
    Oct  3 20:06:42.716: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename custom-resource-definition 10/03/22 20:06:42.717
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:06:42.749
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:06:42.76
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 10/03/22 20:06:42.77
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 10/03/22 20:06:42.775
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 10/03/22 20:06:42.775
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 10/03/22 20:06:42.775
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 10/03/22 20:06:42.78
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 10/03/22 20:06:42.78
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 10/03/22 20:06:42.785
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:06:42.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-4456" for this suite. 10/03/22 20:06:42.799
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:06:42.822
Oct  3 20:06:42.822: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 20:06:42.823
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:06:42.855
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:06:42.865
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Oct  3 20:06:42.876: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 10/03/22 20:06:46.361
Oct  3 20:06:46.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-5164 --namespace=crd-publish-openapi-5164 create -f -'
Oct  3 20:06:47.234: INFO: stderr: ""
Oct  3 20:06:47.234: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Oct  3 20:06:47.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-5164 --namespace=crd-publish-openapi-5164 delete e2e-test-crd-publish-openapi-4231-crds test-cr'
Oct  3 20:06:47.349: INFO: stderr: ""
Oct  3 20:06:47.349: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Oct  3 20:06:47.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-5164 --namespace=crd-publish-openapi-5164 apply -f -'
Oct  3 20:06:48.018: INFO: stderr: ""
Oct  3 20:06:48.018: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Oct  3 20:06:48.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-5164 --namespace=crd-publish-openapi-5164 delete e2e-test-crd-publish-openapi-4231-crds test-cr'
Oct  3 20:06:48.142: INFO: stderr: ""
Oct  3 20:06:48.142: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 10/03/22 20:06:48.142
Oct  3 20:06:48.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-5164 explain e2e-test-crd-publish-openapi-4231-crds'
Oct  3 20:06:48.964: INFO: stderr: ""
Oct  3 20:06:48.964: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4231-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:06:52.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5164" for this suite. 10/03/22 20:06:52.48
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":163,"skipped":3154,"failed":0}
------------------------------
• [SLOW TEST] [9.677 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:06:42.822
    Oct  3 20:06:42.822: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 20:06:42.823
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:06:42.855
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:06:42.865
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Oct  3 20:06:42.876: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 10/03/22 20:06:46.361
    Oct  3 20:06:46.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-5164 --namespace=crd-publish-openapi-5164 create -f -'
    Oct  3 20:06:47.234: INFO: stderr: ""
    Oct  3 20:06:47.234: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Oct  3 20:06:47.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-5164 --namespace=crd-publish-openapi-5164 delete e2e-test-crd-publish-openapi-4231-crds test-cr'
    Oct  3 20:06:47.349: INFO: stderr: ""
    Oct  3 20:06:47.349: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Oct  3 20:06:47.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-5164 --namespace=crd-publish-openapi-5164 apply -f -'
    Oct  3 20:06:48.018: INFO: stderr: ""
    Oct  3 20:06:48.018: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Oct  3 20:06:48.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-5164 --namespace=crd-publish-openapi-5164 delete e2e-test-crd-publish-openapi-4231-crds test-cr'
    Oct  3 20:06:48.142: INFO: stderr: ""
    Oct  3 20:06:48.142: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 10/03/22 20:06:48.142
    Oct  3 20:06:48.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-5164 explain e2e-test-crd-publish-openapi-4231-crds'
    Oct  3 20:06:48.964: INFO: stderr: ""
    Oct  3 20:06:48.964: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4231-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:06:52.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5164" for this suite. 10/03/22 20:06:52.48
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:06:52.506
Oct  3 20:06:52.506: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 20:06:52.507
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:06:52.546
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:06:52.559
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 10/03/22 20:06:52.569
Oct  3 20:06:52.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8265 cluster-info'
Oct  3 20:06:52.677: INFO: stderr: ""
Oct  3 20:06:52.677: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 20:06:52.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8265" for this suite. 10/03/22 20:06:52.694
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":164,"skipped":3230,"failed":0}
------------------------------
• [0.207 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:06:52.506
    Oct  3 20:06:52.506: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 20:06:52.507
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:06:52.546
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:06:52.559
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 10/03/22 20:06:52.569
    Oct  3 20:06:52.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8265 cluster-info'
    Oct  3 20:06:52.677: INFO: stderr: ""
    Oct  3 20:06:52.677: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 20:06:52.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8265" for this suite. 10/03/22 20:06:52.694
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:06:52.716
Oct  3 20:06:52.717: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename configmap 10/03/22 20:06:52.718
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:06:52.77
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:06:52.778
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-aa21a707-074a-4cb6-825c-5c45a7108650 10/03/22 20:06:52.787
STEP: Creating a pod to test consume configMaps 10/03/22 20:06:52.798
Oct  3 20:06:52.820: INFO: Waiting up to 5m0s for pod "pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1" in namespace "configmap-1466" to be "Succeeded or Failed"
Oct  3 20:06:52.835: INFO: Pod "pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.173768ms
Oct  3 20:06:54.847: INFO: Pod "pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026858967s
Oct  3 20:06:56.848: INFO: Pod "pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02735711s
Oct  3 20:06:58.847: INFO: Pod "pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026626274s
STEP: Saw pod success 10/03/22 20:06:58.847
Oct  3 20:06:58.847: INFO: Pod "pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1" satisfied condition "Succeeded or Failed"
Oct  3 20:06:58.859: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1 container agnhost-container: <nil>
STEP: delete the pod 10/03/22 20:06:58.94
Oct  3 20:06:58.997: INFO: Waiting for pod pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1 to disappear
Oct  3 20:06:59.010: INFO: Pod pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Oct  3 20:06:59.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1466" for this suite. 10/03/22 20:06:59.026
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":165,"skipped":3242,"failed":0}
------------------------------
• [SLOW TEST] [6.329 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:06:52.716
    Oct  3 20:06:52.717: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename configmap 10/03/22 20:06:52.718
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:06:52.77
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:06:52.778
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-aa21a707-074a-4cb6-825c-5c45a7108650 10/03/22 20:06:52.787
    STEP: Creating a pod to test consume configMaps 10/03/22 20:06:52.798
    Oct  3 20:06:52.820: INFO: Waiting up to 5m0s for pod "pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1" in namespace "configmap-1466" to be "Succeeded or Failed"
    Oct  3 20:06:52.835: INFO: Pod "pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.173768ms
    Oct  3 20:06:54.847: INFO: Pod "pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026858967s
    Oct  3 20:06:56.848: INFO: Pod "pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02735711s
    Oct  3 20:06:58.847: INFO: Pod "pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026626274s
    STEP: Saw pod success 10/03/22 20:06:58.847
    Oct  3 20:06:58.847: INFO: Pod "pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1" satisfied condition "Succeeded or Failed"
    Oct  3 20:06:58.859: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1 container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 20:06:58.94
    Oct  3 20:06:58.997: INFO: Waiting for pod pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1 to disappear
    Oct  3 20:06:59.010: INFO: Pod pod-configmaps-ed579dc0-c3b1-48b3-8cc9-1605f56d52d1 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Oct  3 20:06:59.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1466" for this suite. 10/03/22 20:06:59.026
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:06:59.05
Oct  3 20:06:59.050: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 20:06:59.051
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:06:59.089
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:06:59.097
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 10/03/22 20:06:59.106
Oct  3 20:06:59.132: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d" in namespace "projected-1500" to be "Succeeded or Failed"
Oct  3 20:06:59.144: INFO: Pod "downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.566462ms
Oct  3 20:07:01.169: INFO: Pod "downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037093544s
Oct  3 20:07:03.157: INFO: Pod "downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025580647s
STEP: Saw pod success 10/03/22 20:07:03.157
Oct  3 20:07:03.157: INFO: Pod "downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d" satisfied condition "Succeeded or Failed"
Oct  3 20:07:03.169: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d container client-container: <nil>
STEP: delete the pod 10/03/22 20:07:03.197
Oct  3 20:07:03.242: INFO: Waiting for pod downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d to disappear
Oct  3 20:07:03.256: INFO: Pod downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Oct  3 20:07:03.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1500" for this suite. 10/03/22 20:07:03.273
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":166,"skipped":3255,"failed":0}
------------------------------
• [4.244 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:06:59.05
    Oct  3 20:06:59.050: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 20:06:59.051
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:06:59.089
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:06:59.097
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 10/03/22 20:06:59.106
    Oct  3 20:06:59.132: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d" in namespace "projected-1500" to be "Succeeded or Failed"
    Oct  3 20:06:59.144: INFO: Pod "downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.566462ms
    Oct  3 20:07:01.169: INFO: Pod "downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037093544s
    Oct  3 20:07:03.157: INFO: Pod "downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025580647s
    STEP: Saw pod success 10/03/22 20:07:03.157
    Oct  3 20:07:03.157: INFO: Pod "downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d" satisfied condition "Succeeded or Failed"
    Oct  3 20:07:03.169: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d container client-container: <nil>
    STEP: delete the pod 10/03/22 20:07:03.197
    Oct  3 20:07:03.242: INFO: Waiting for pod downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d to disappear
    Oct  3 20:07:03.256: INFO: Pod downwardapi-volume-f51b4742-fefe-4ae4-a662-8fd2dd16e06d no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Oct  3 20:07:03.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1500" for this suite. 10/03/22 20:07:03.273
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:07:03.295
Oct  3 20:07:03.295: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 20:07:03.296
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:07:03.344
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:07:03.353
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 10/03/22 20:07:03.362
Oct  3 20:07:03.363: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9634 proxy --unix-socket=/tmp/kubectl-proxy-unix328656444/test'
STEP: retrieving proxy /api/ output 10/03/22 20:07:03.431
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 20:07:03.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9634" for this suite. 10/03/22 20:07:03.452
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":167,"skipped":3261,"failed":0}
------------------------------
• [0.178 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:07:03.295
    Oct  3 20:07:03.295: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 20:07:03.296
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:07:03.344
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:07:03.353
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 10/03/22 20:07:03.362
    Oct  3 20:07:03.363: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9634 proxy --unix-socket=/tmp/kubectl-proxy-unix328656444/test'
    STEP: retrieving proxy /api/ output 10/03/22 20:07:03.431
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 20:07:03.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9634" for this suite. 10/03/22 20:07:03.452
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:07:03.475
Oct  3 20:07:03.475: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename configmap 10/03/22 20:07:03.479
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:07:03.519
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:07:03.528
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-b3f5877d-d2ec-4d95-85cb-ca8dfb641745 10/03/22 20:07:03.537
STEP: Creating a pod to test consume configMaps 10/03/22 20:07:03.548
Oct  3 20:07:03.569: INFO: Waiting up to 5m0s for pod "pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366" in namespace "configmap-3722" to be "Succeeded or Failed"
Oct  3 20:07:03.581: INFO: Pod "pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366": Phase="Pending", Reason="", readiness=false. Elapsed: 11.990743ms
Oct  3 20:07:05.593: INFO: Pod "pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024152423s
Oct  3 20:07:07.593: INFO: Pod "pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024438998s
Oct  3 20:07:09.594: INFO: Pod "pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025036969s
STEP: Saw pod success 10/03/22 20:07:09.594
Oct  3 20:07:09.595: INFO: Pod "pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366" satisfied condition "Succeeded or Failed"
Oct  3 20:07:09.605: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366 container agnhost-container: <nil>
STEP: delete the pod 10/03/22 20:07:09.631
Oct  3 20:07:09.668: INFO: Waiting for pod pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366 to disappear
Oct  3 20:07:09.680: INFO: Pod pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Oct  3 20:07:09.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3722" for this suite. 10/03/22 20:07:09.699
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":168,"skipped":3264,"failed":0}
------------------------------
• [SLOW TEST] [6.244 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:07:03.475
    Oct  3 20:07:03.475: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename configmap 10/03/22 20:07:03.479
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:07:03.519
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:07:03.528
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-b3f5877d-d2ec-4d95-85cb-ca8dfb641745 10/03/22 20:07:03.537
    STEP: Creating a pod to test consume configMaps 10/03/22 20:07:03.548
    Oct  3 20:07:03.569: INFO: Waiting up to 5m0s for pod "pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366" in namespace "configmap-3722" to be "Succeeded or Failed"
    Oct  3 20:07:03.581: INFO: Pod "pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366": Phase="Pending", Reason="", readiness=false. Elapsed: 11.990743ms
    Oct  3 20:07:05.593: INFO: Pod "pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024152423s
    Oct  3 20:07:07.593: INFO: Pod "pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024438998s
    Oct  3 20:07:09.594: INFO: Pod "pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025036969s
    STEP: Saw pod success 10/03/22 20:07:09.594
    Oct  3 20:07:09.595: INFO: Pod "pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366" satisfied condition "Succeeded or Failed"
    Oct  3 20:07:09.605: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366 container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 20:07:09.631
    Oct  3 20:07:09.668: INFO: Waiting for pod pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366 to disappear
    Oct  3 20:07:09.680: INFO: Pod pod-configmaps-b8b84c48-e7b8-4435-bd99-8e85f3aca366 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Oct  3 20:07:09.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3722" for this suite. 10/03/22 20:07:09.699
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:07:09.719
Oct  3 20:07:09.720: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename svcaccounts 10/03/22 20:07:09.721
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:07:09.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:07:09.767
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Oct  3 20:07:09.817: INFO: created pod
Oct  3 20:07:09.818: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-310" to be "Succeeded or Failed"
Oct  3 20:07:09.831: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 12.575955ms
Oct  3 20:07:11.844: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02654403s
Oct  3 20:07:13.844: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025869913s
Oct  3 20:07:15.843: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025235698s
STEP: Saw pod success 10/03/22 20:07:15.843
Oct  3 20:07:15.843: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Oct  3 20:07:45.844: INFO: polling logs
Oct  3 20:07:45.874: INFO: Pod logs: 
I1003 20:07:11.384003       1 log.go:195] OK: Got token
I1003 20:07:11.384054       1 log.go:195] validating with in-cluster discovery
I1003 20:07:11.384678       1 log.go:195] OK: got issuer https://kubernetes.default.svc
I1003 20:07:11.384722       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-310:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1664828230, NotBefore:1664827630, IssuedAt:1664827630, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-310", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c9659fc4-cd0c-4c85-915d-ffb062e0c601"}}}
I1003 20:07:11.427727       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
I1003 20:07:11.457420       1 log.go:195] OK: Validated signature on JWT
I1003 20:07:11.458048       1 log.go:195] OK: Got valid claims from token!
I1003 20:07:11.458537       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-310:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1664828230, NotBefore:1664827630, IssuedAt:1664827630, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-310", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c9659fc4-cd0c-4c85-915d-ffb062e0c601"}}}

Oct  3 20:07:45.874: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Oct  3 20:07:45.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-310" for this suite. 10/03/22 20:07:45.91
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":169,"skipped":3268,"failed":0}
------------------------------
• [SLOW TEST] [36.210 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:07:09.719
    Oct  3 20:07:09.720: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename svcaccounts 10/03/22 20:07:09.721
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:07:09.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:07:09.767
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Oct  3 20:07:09.817: INFO: created pod
    Oct  3 20:07:09.818: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-310" to be "Succeeded or Failed"
    Oct  3 20:07:09.831: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 12.575955ms
    Oct  3 20:07:11.844: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02654403s
    Oct  3 20:07:13.844: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025869913s
    Oct  3 20:07:15.843: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025235698s
    STEP: Saw pod success 10/03/22 20:07:15.843
    Oct  3 20:07:15.843: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Oct  3 20:07:45.844: INFO: polling logs
    Oct  3 20:07:45.874: INFO: Pod logs: 
    I1003 20:07:11.384003       1 log.go:195] OK: Got token
    I1003 20:07:11.384054       1 log.go:195] validating with in-cluster discovery
    I1003 20:07:11.384678       1 log.go:195] OK: got issuer https://kubernetes.default.svc
    I1003 20:07:11.384722       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-310:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1664828230, NotBefore:1664827630, IssuedAt:1664827630, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-310", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c9659fc4-cd0c-4c85-915d-ffb062e0c601"}}}
    I1003 20:07:11.427727       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
    I1003 20:07:11.457420       1 log.go:195] OK: Validated signature on JWT
    I1003 20:07:11.458048       1 log.go:195] OK: Got valid claims from token!
    I1003 20:07:11.458537       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-310:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1664828230, NotBefore:1664827630, IssuedAt:1664827630, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-310", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c9659fc4-cd0c-4c85-915d-ffb062e0c601"}}}

    Oct  3 20:07:45.874: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Oct  3 20:07:45.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-310" for this suite. 10/03/22 20:07:45.91
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:07:45.93
Oct  3 20:07:45.930: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 20:07:45.931
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:07:45.97
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:07:45.979
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-cd8c82d1-e33a-48fa-b5ff-01b5a3ff809b 10/03/22 20:07:45.987
STEP: Creating a pod to test consume configMaps 10/03/22 20:07:46
Oct  3 20:07:46.021: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef" in namespace "projected-284" to be "Succeeded or Failed"
Oct  3 20:07:46.035: INFO: Pod "pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef": Phase="Pending", Reason="", readiness=false. Elapsed: 13.521547ms
Oct  3 20:07:48.051: INFO: Pod "pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029433289s
Oct  3 20:07:50.048: INFO: Pod "pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02671124s
Oct  3 20:07:52.049: INFO: Pod "pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027573154s
STEP: Saw pod success 10/03/22 20:07:52.049
Oct  3 20:07:52.049: INFO: Pod "pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef" satisfied condition "Succeeded or Failed"
Oct  3 20:07:52.062: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef container agnhost-container: <nil>
STEP: delete the pod 10/03/22 20:07:52.089
Oct  3 20:07:52.118: INFO: Waiting for pod pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef to disappear
Oct  3 20:07:52.133: INFO: Pod pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Oct  3 20:07:52.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-284" for this suite. 10/03/22 20:07:52.149
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":170,"skipped":3276,"failed":0}
------------------------------
• [SLOW TEST] [6.238 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:07:45.93
    Oct  3 20:07:45.930: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 20:07:45.931
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:07:45.97
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:07:45.979
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-cd8c82d1-e33a-48fa-b5ff-01b5a3ff809b 10/03/22 20:07:45.987
    STEP: Creating a pod to test consume configMaps 10/03/22 20:07:46
    Oct  3 20:07:46.021: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef" in namespace "projected-284" to be "Succeeded or Failed"
    Oct  3 20:07:46.035: INFO: Pod "pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef": Phase="Pending", Reason="", readiness=false. Elapsed: 13.521547ms
    Oct  3 20:07:48.051: INFO: Pod "pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029433289s
    Oct  3 20:07:50.048: INFO: Pod "pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02671124s
    Oct  3 20:07:52.049: INFO: Pod "pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027573154s
    STEP: Saw pod success 10/03/22 20:07:52.049
    Oct  3 20:07:52.049: INFO: Pod "pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef" satisfied condition "Succeeded or Failed"
    Oct  3 20:07:52.062: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 20:07:52.089
    Oct  3 20:07:52.118: INFO: Waiting for pod pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef to disappear
    Oct  3 20:07:52.133: INFO: Pod pod-projected-configmaps-cd8eb92f-7f1b-4a2e-87d7-9b66bf384eef no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Oct  3 20:07:52.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-284" for this suite. 10/03/22 20:07:52.149
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:07:52.187
Oct  3 20:07:52.188: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename configmap 10/03/22 20:07:52.19
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:07:52.232
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:07:52.242
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-bd3a9988-bd0d-406a-b644-f657d8f6c0e6 10/03/22 20:07:52.252
STEP: Creating a pod to test consume configMaps 10/03/22 20:07:52.265
Oct  3 20:07:52.292: INFO: Waiting up to 5m0s for pod "pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb" in namespace "configmap-8137" to be "Succeeded or Failed"
Oct  3 20:07:52.308: INFO: Pod "pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb": Phase="Pending", Reason="", readiness=false. Elapsed: 16.813097ms
Oct  3 20:07:54.321: INFO: Pod "pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029168367s
Oct  3 20:07:56.323: INFO: Pod "pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031382377s
Oct  3 20:07:58.323: INFO: Pod "pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031376887s
STEP: Saw pod success 10/03/22 20:07:58.323
Oct  3 20:07:58.323: INFO: Pod "pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb" satisfied condition "Succeeded or Failed"
Oct  3 20:07:58.338: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb container agnhost-container: <nil>
STEP: delete the pod 10/03/22 20:07:58.364
Oct  3 20:07:58.394: INFO: Waiting for pod pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb to disappear
Oct  3 20:07:58.406: INFO: Pod pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Oct  3 20:07:58.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8137" for this suite. 10/03/22 20:07:58.423
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":171,"skipped":3313,"failed":0}
------------------------------
• [SLOW TEST] [6.255 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:07:52.187
    Oct  3 20:07:52.188: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename configmap 10/03/22 20:07:52.19
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:07:52.232
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:07:52.242
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-bd3a9988-bd0d-406a-b644-f657d8f6c0e6 10/03/22 20:07:52.252
    STEP: Creating a pod to test consume configMaps 10/03/22 20:07:52.265
    Oct  3 20:07:52.292: INFO: Waiting up to 5m0s for pod "pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb" in namespace "configmap-8137" to be "Succeeded or Failed"
    Oct  3 20:07:52.308: INFO: Pod "pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb": Phase="Pending", Reason="", readiness=false. Elapsed: 16.813097ms
    Oct  3 20:07:54.321: INFO: Pod "pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029168367s
    Oct  3 20:07:56.323: INFO: Pod "pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031382377s
    Oct  3 20:07:58.323: INFO: Pod "pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031376887s
    STEP: Saw pod success 10/03/22 20:07:58.323
    Oct  3 20:07:58.323: INFO: Pod "pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb" satisfied condition "Succeeded or Failed"
    Oct  3 20:07:58.338: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 20:07:58.364
    Oct  3 20:07:58.394: INFO: Waiting for pod pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb to disappear
    Oct  3 20:07:58.406: INFO: Pod pod-configmaps-96bf700c-3ec3-4cbf-8997-cf8dd1ff00cb no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Oct  3 20:07:58.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8137" for this suite. 10/03/22 20:07:58.423
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:07:58.444
Oct  3 20:07:58.444: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename resourcequota 10/03/22 20:07:58.445
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:07:58.489
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:07:58.498
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 10/03/22 20:07:58.507
STEP: Getting a ResourceQuota 10/03/22 20:07:58.519
STEP: Updating a ResourceQuota 10/03/22 20:07:58.529
STEP: Verifying a ResourceQuota was modified 10/03/22 20:07:58.541
STEP: Deleting a ResourceQuota 10/03/22 20:07:58.554
STEP: Verifying the deleted ResourceQuota 10/03/22 20:07:58.57
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Oct  3 20:07:58.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9020" for this suite. 10/03/22 20:07:58.598
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":172,"skipped":3320,"failed":0}
------------------------------
• [0.176 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:07:58.444
    Oct  3 20:07:58.444: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename resourcequota 10/03/22 20:07:58.445
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:07:58.489
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:07:58.498
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 10/03/22 20:07:58.507
    STEP: Getting a ResourceQuota 10/03/22 20:07:58.519
    STEP: Updating a ResourceQuota 10/03/22 20:07:58.529
    STEP: Verifying a ResourceQuota was modified 10/03/22 20:07:58.541
    STEP: Deleting a ResourceQuota 10/03/22 20:07:58.554
    STEP: Verifying the deleted ResourceQuota 10/03/22 20:07:58.57
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Oct  3 20:07:58.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9020" for this suite. 10/03/22 20:07:58.598
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:07:58.621
Oct  3 20:07:58.621: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 20:07:58.622
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:07:58.664
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:07:58.674
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Oct  3 20:07:58.699: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 10/03/22 20:08:02.277
Oct  3 20:08:02.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 create -f -'
Oct  3 20:08:03.167: INFO: stderr: ""
Oct  3 20:08:03.167: INFO: stdout: "e2e-test-crd-publish-openapi-9804-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Oct  3 20:08:03.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 delete e2e-test-crd-publish-openapi-9804-crds test-foo'
Oct  3 20:08:03.361: INFO: stderr: ""
Oct  3 20:08:03.361: INFO: stdout: "e2e-test-crd-publish-openapi-9804-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Oct  3 20:08:03.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 apply -f -'
Oct  3 20:08:03.716: INFO: stderr: ""
Oct  3 20:08:03.716: INFO: stdout: "e2e-test-crd-publish-openapi-9804-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Oct  3 20:08:03.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 delete e2e-test-crd-publish-openapi-9804-crds test-foo'
Oct  3 20:08:03.908: INFO: stderr: ""
Oct  3 20:08:03.909: INFO: stdout: "e2e-test-crd-publish-openapi-9804-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 10/03/22 20:08:03.909
Oct  3 20:08:03.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 create -f -'
Oct  3 20:08:04.526: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 10/03/22 20:08:04.526
Oct  3 20:08:04.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 create -f -'
Oct  3 20:08:05.252: INFO: rc: 1
Oct  3 20:08:05.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 apply -f -'
Oct  3 20:08:05.591: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 10/03/22 20:08:05.591
Oct  3 20:08:05.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 create -f -'
Oct  3 20:08:05.893: INFO: rc: 1
Oct  3 20:08:05.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 apply -f -'
Oct  3 20:08:06.206: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 10/03/22 20:08:06.206
Oct  3 20:08:06.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 explain e2e-test-crd-publish-openapi-9804-crds'
Oct  3 20:08:06.538: INFO: stderr: ""
Oct  3 20:08:06.538: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9804-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 10/03/22 20:08:06.539
Oct  3 20:08:06.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 explain e2e-test-crd-publish-openapi-9804-crds.metadata'
Oct  3 20:08:06.831: INFO: stderr: ""
Oct  3 20:08:06.831: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9804-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Oct  3 20:08:06.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 explain e2e-test-crd-publish-openapi-9804-crds.spec'
Oct  3 20:08:07.126: INFO: stderr: ""
Oct  3 20:08:07.126: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9804-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Oct  3 20:08:07.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 explain e2e-test-crd-publish-openapi-9804-crds.spec.bars'
Oct  3 20:08:07.457: INFO: stderr: ""
Oct  3 20:08:07.457: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9804-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 10/03/22 20:08:07.457
Oct  3 20:08:07.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 explain e2e-test-crd-publish-openapi-9804-crds.spec.bars2'
Oct  3 20:08:07.747: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:08:12.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2501" for this suite. 10/03/22 20:08:12.699
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":173,"skipped":3327,"failed":0}
------------------------------
• [SLOW TEST] [14.097 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:07:58.621
    Oct  3 20:07:58.621: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 20:07:58.622
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:07:58.664
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:07:58.674
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Oct  3 20:07:58.699: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 10/03/22 20:08:02.277
    Oct  3 20:08:02.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 create -f -'
    Oct  3 20:08:03.167: INFO: stderr: ""
    Oct  3 20:08:03.167: INFO: stdout: "e2e-test-crd-publish-openapi-9804-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Oct  3 20:08:03.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 delete e2e-test-crd-publish-openapi-9804-crds test-foo'
    Oct  3 20:08:03.361: INFO: stderr: ""
    Oct  3 20:08:03.361: INFO: stdout: "e2e-test-crd-publish-openapi-9804-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Oct  3 20:08:03.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 apply -f -'
    Oct  3 20:08:03.716: INFO: stderr: ""
    Oct  3 20:08:03.716: INFO: stdout: "e2e-test-crd-publish-openapi-9804-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Oct  3 20:08:03.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 delete e2e-test-crd-publish-openapi-9804-crds test-foo'
    Oct  3 20:08:03.908: INFO: stderr: ""
    Oct  3 20:08:03.909: INFO: stdout: "e2e-test-crd-publish-openapi-9804-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 10/03/22 20:08:03.909
    Oct  3 20:08:03.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 create -f -'
    Oct  3 20:08:04.526: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 10/03/22 20:08:04.526
    Oct  3 20:08:04.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 create -f -'
    Oct  3 20:08:05.252: INFO: rc: 1
    Oct  3 20:08:05.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 apply -f -'
    Oct  3 20:08:05.591: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 10/03/22 20:08:05.591
    Oct  3 20:08:05.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 create -f -'
    Oct  3 20:08:05.893: INFO: rc: 1
    Oct  3 20:08:05.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 --namespace=crd-publish-openapi-2501 apply -f -'
    Oct  3 20:08:06.206: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 10/03/22 20:08:06.206
    Oct  3 20:08:06.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 explain e2e-test-crd-publish-openapi-9804-crds'
    Oct  3 20:08:06.538: INFO: stderr: ""
    Oct  3 20:08:06.538: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9804-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 10/03/22 20:08:06.539
    Oct  3 20:08:06.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 explain e2e-test-crd-publish-openapi-9804-crds.metadata'
    Oct  3 20:08:06.831: INFO: stderr: ""
    Oct  3 20:08:06.831: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9804-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Oct  3 20:08:06.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 explain e2e-test-crd-publish-openapi-9804-crds.spec'
    Oct  3 20:08:07.126: INFO: stderr: ""
    Oct  3 20:08:07.126: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9804-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Oct  3 20:08:07.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 explain e2e-test-crd-publish-openapi-9804-crds.spec.bars'
    Oct  3 20:08:07.457: INFO: stderr: ""
    Oct  3 20:08:07.457: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9804-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 10/03/22 20:08:07.457
    Oct  3 20:08:07.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=crd-publish-openapi-2501 explain e2e-test-crd-publish-openapi-9804-crds.spec.bars2'
    Oct  3 20:08:07.747: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:08:12.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2501" for this suite. 10/03/22 20:08:12.699
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:08:12.719
Oct  3 20:08:12.719: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename pods 10/03/22 20:08:12.721
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:08:12.754
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:08:12.76
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Oct  3 20:08:12.786: INFO: Waiting up to 5m0s for pod "server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3" in namespace "pods-5839" to be "running and ready"
Oct  3 20:08:12.795: INFO: Pod "server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.130868ms
Oct  3 20:08:12.795: INFO: The phase of Pod server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:08:14.805: INFO: Pod "server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019012124s
Oct  3 20:08:14.806: INFO: The phase of Pod server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:08:16.805: INFO: Pod "server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3": Phase="Running", Reason="", readiness=true. Elapsed: 4.018183136s
Oct  3 20:08:16.805: INFO: The phase of Pod server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3 is Running (Ready = true)
Oct  3 20:08:16.805: INFO: Pod "server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3" satisfied condition "running and ready"
Oct  3 20:08:16.858: INFO: Waiting up to 5m0s for pod "client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a" in namespace "pods-5839" to be "Succeeded or Failed"
Oct  3 20:08:16.870: INFO: Pod "client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.41484ms
Oct  3 20:08:18.879: INFO: Pod "client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02072403s
Oct  3 20:08:20.880: INFO: Pod "client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022176086s
Oct  3 20:08:22.880: INFO: Pod "client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021544692s
STEP: Saw pod success 10/03/22 20:08:22.88
Oct  3 20:08:22.880: INFO: Pod "client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a" satisfied condition "Succeeded or Failed"
Oct  3 20:08:22.890: INFO: Trying to get logs from node 10.63.128.3 pod client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a container env3cont: <nil>
STEP: delete the pod 10/03/22 20:08:22.957
Oct  3 20:08:22.990: INFO: Waiting for pod client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a to disappear
Oct  3 20:08:23.000: INFO: Pod client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Oct  3 20:08:23.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5839" for this suite. 10/03/22 20:08:23.015
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":174,"skipped":3327,"failed":0}
------------------------------
• [SLOW TEST] [10.314 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:08:12.719
    Oct  3 20:08:12.719: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename pods 10/03/22 20:08:12.721
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:08:12.754
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:08:12.76
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Oct  3 20:08:12.786: INFO: Waiting up to 5m0s for pod "server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3" in namespace "pods-5839" to be "running and ready"
    Oct  3 20:08:12.795: INFO: Pod "server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.130868ms
    Oct  3 20:08:12.795: INFO: The phase of Pod server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:08:14.805: INFO: Pod "server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019012124s
    Oct  3 20:08:14.806: INFO: The phase of Pod server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:08:16.805: INFO: Pod "server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3": Phase="Running", Reason="", readiness=true. Elapsed: 4.018183136s
    Oct  3 20:08:16.805: INFO: The phase of Pod server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3 is Running (Ready = true)
    Oct  3 20:08:16.805: INFO: Pod "server-envvars-e4f61398-f8bf-476a-8562-4ba66ec6fdf3" satisfied condition "running and ready"
    Oct  3 20:08:16.858: INFO: Waiting up to 5m0s for pod "client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a" in namespace "pods-5839" to be "Succeeded or Failed"
    Oct  3 20:08:16.870: INFO: Pod "client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.41484ms
    Oct  3 20:08:18.879: INFO: Pod "client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02072403s
    Oct  3 20:08:20.880: INFO: Pod "client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022176086s
    Oct  3 20:08:22.880: INFO: Pod "client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021544692s
    STEP: Saw pod success 10/03/22 20:08:22.88
    Oct  3 20:08:22.880: INFO: Pod "client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a" satisfied condition "Succeeded or Failed"
    Oct  3 20:08:22.890: INFO: Trying to get logs from node 10.63.128.3 pod client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a container env3cont: <nil>
    STEP: delete the pod 10/03/22 20:08:22.957
    Oct  3 20:08:22.990: INFO: Waiting for pod client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a to disappear
    Oct  3 20:08:23.000: INFO: Pod client-envvars-352bd250-b444-4447-97c5-ed516f25fc6a no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Oct  3 20:08:23.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5839" for this suite. 10/03/22 20:08:23.015
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:08:23.037
Oct  3 20:08:23.037: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-runtime 10/03/22 20:08:23.039
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:08:23.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:08:23.078
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 10/03/22 20:08:23.083
STEP: wait for the container to reach Failed 10/03/22 20:08:23.102
STEP: get the container status 10/03/22 20:08:28.164
STEP: the container should be terminated 10/03/22 20:08:28.173
STEP: the termination message should be set 10/03/22 20:08:28.173
Oct  3 20:08:28.173: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 10/03/22 20:08:28.173
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Oct  3 20:08:28.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5116" for this suite. 10/03/22 20:08:28.226
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":175,"skipped":3333,"failed":0}
------------------------------
• [SLOW TEST] [5.225 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:08:23.037
    Oct  3 20:08:23.037: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-runtime 10/03/22 20:08:23.039
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:08:23.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:08:23.078
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 10/03/22 20:08:23.083
    STEP: wait for the container to reach Failed 10/03/22 20:08:23.102
    STEP: get the container status 10/03/22 20:08:28.164
    STEP: the container should be terminated 10/03/22 20:08:28.173
    STEP: the termination message should be set 10/03/22 20:08:28.173
    Oct  3 20:08:28.173: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 10/03/22 20:08:28.173
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Oct  3 20:08:28.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5116" for this suite. 10/03/22 20:08:28.226
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:08:28.264
Oct  3 20:08:28.264: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-probe 10/03/22 20:08:28.265
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:08:28.315
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:08:28.321
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-cea9c111-1ed8-4926-846d-8159fa44f105 in namespace container-probe-3032 10/03/22 20:08:28.328
Oct  3 20:08:28.347: INFO: Waiting up to 5m0s for pod "liveness-cea9c111-1ed8-4926-846d-8159fa44f105" in namespace "container-probe-3032" to be "not pending"
Oct  3 20:08:28.357: INFO: Pod "liveness-cea9c111-1ed8-4926-846d-8159fa44f105": Phase="Pending", Reason="", readiness=false. Elapsed: 9.696447ms
Oct  3 20:08:30.368: INFO: Pod "liveness-cea9c111-1ed8-4926-846d-8159fa44f105": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020686894s
Oct  3 20:08:32.368: INFO: Pod "liveness-cea9c111-1ed8-4926-846d-8159fa44f105": Phase="Running", Reason="", readiness=true. Elapsed: 4.020441126s
Oct  3 20:08:32.368: INFO: Pod "liveness-cea9c111-1ed8-4926-846d-8159fa44f105" satisfied condition "not pending"
Oct  3 20:08:32.368: INFO: Started pod liveness-cea9c111-1ed8-4926-846d-8159fa44f105 in namespace container-probe-3032
STEP: checking the pod's current state and verifying that restartCount is present 10/03/22 20:08:32.368
Oct  3 20:08:32.378: INFO: Initial restart count of pod liveness-cea9c111-1ed8-4926-846d-8159fa44f105 is 0
Oct  3 20:08:50.481: INFO: Restart count of pod container-probe-3032/liveness-cea9c111-1ed8-4926-846d-8159fa44f105 is now 1 (18.103034271s elapsed)
STEP: deleting the pod 10/03/22 20:08:50.481
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Oct  3 20:08:50.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3032" for this suite. 10/03/22 20:08:50.527
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":176,"skipped":3345,"failed":0}
------------------------------
• [SLOW TEST] [22.281 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:08:28.264
    Oct  3 20:08:28.264: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-probe 10/03/22 20:08:28.265
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:08:28.315
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:08:28.321
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-cea9c111-1ed8-4926-846d-8159fa44f105 in namespace container-probe-3032 10/03/22 20:08:28.328
    Oct  3 20:08:28.347: INFO: Waiting up to 5m0s for pod "liveness-cea9c111-1ed8-4926-846d-8159fa44f105" in namespace "container-probe-3032" to be "not pending"
    Oct  3 20:08:28.357: INFO: Pod "liveness-cea9c111-1ed8-4926-846d-8159fa44f105": Phase="Pending", Reason="", readiness=false. Elapsed: 9.696447ms
    Oct  3 20:08:30.368: INFO: Pod "liveness-cea9c111-1ed8-4926-846d-8159fa44f105": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020686894s
    Oct  3 20:08:32.368: INFO: Pod "liveness-cea9c111-1ed8-4926-846d-8159fa44f105": Phase="Running", Reason="", readiness=true. Elapsed: 4.020441126s
    Oct  3 20:08:32.368: INFO: Pod "liveness-cea9c111-1ed8-4926-846d-8159fa44f105" satisfied condition "not pending"
    Oct  3 20:08:32.368: INFO: Started pod liveness-cea9c111-1ed8-4926-846d-8159fa44f105 in namespace container-probe-3032
    STEP: checking the pod's current state and verifying that restartCount is present 10/03/22 20:08:32.368
    Oct  3 20:08:32.378: INFO: Initial restart count of pod liveness-cea9c111-1ed8-4926-846d-8159fa44f105 is 0
    Oct  3 20:08:50.481: INFO: Restart count of pod container-probe-3032/liveness-cea9c111-1ed8-4926-846d-8159fa44f105 is now 1 (18.103034271s elapsed)
    STEP: deleting the pod 10/03/22 20:08:50.481
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Oct  3 20:08:50.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3032" for this suite. 10/03/22 20:08:50.527
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:08:50.554
Oct  3 20:08:50.555: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 20:08:50.556
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:08:50.587
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:08:50.592
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-2822 10/03/22 20:08:50.598
STEP: creating service affinity-nodeport-transition in namespace services-2822 10/03/22 20:08:50.599
STEP: creating replication controller affinity-nodeport-transition in namespace services-2822 10/03/22 20:08:50.643
I1003 20:08:50.656716      22 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-2822, replica count: 3
I1003 20:08:53.708561      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  3 20:08:53.738: INFO: Creating new exec pod
Oct  3 20:08:53.749: INFO: Waiting up to 5m0s for pod "execpod-affinity5s5c8" in namespace "services-2822" to be "running"
Oct  3 20:08:53.758: INFO: Pod "execpod-affinity5s5c8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.684539ms
Oct  3 20:08:55.771: INFO: Pod "execpod-affinity5s5c8": Phase="Running", Reason="", readiness=true. Elapsed: 2.022258722s
Oct  3 20:08:55.771: INFO: Pod "execpod-affinity5s5c8" satisfied condition "running"
Oct  3 20:08:56.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2822 exec execpod-affinity5s5c8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Oct  3 20:08:57.155: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Oct  3 20:08:57.155: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:08:57.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2822 exec execpod-affinity5s5c8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.178.75 80'
Oct  3 20:08:57.491: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.178.75 80\nConnection to 172.21.178.75 80 port [tcp/http] succeeded!\n"
Oct  3 20:08:57.491: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:08:57.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2822 exec execpod-affinity5s5c8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.3 32577'
Oct  3 20:08:57.823: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.3 32577\nConnection to 10.63.128.3 32577 port [tcp/*] succeeded!\n"
Oct  3 20:08:57.823: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:08:57.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2822 exec execpod-affinity5s5c8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.51 32577'
Oct  3 20:08:58.199: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.51 32577\nConnection to 10.63.128.51 32577 port [tcp/*] succeeded!\n"
Oct  3 20:08:58.199: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:08:58.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2822 exec execpod-affinity5s5c8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.63.128.13:32577/ ; done'
Oct  3 20:08:58.730: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n"
Oct  3 20:08:58.731: INFO: stdout: "\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq"
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:28.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2822 exec execpod-affinity5s5c8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.63.128.13:32577/ ; done'
Oct  3 20:09:29.235: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n"
Oct  3 20:09:29.235: INFO: stdout: "\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-96t7b\naffinity-nodeport-transition-96t7b\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-96t7b\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-jlsqq"
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-96t7b
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-96t7b
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-96t7b
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2822 exec execpod-affinity5s5c8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.63.128.13:32577/ ; done'
Oct  3 20:09:29.784: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n"
Oct  3 20:09:29.785: INFO: stdout: "\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq"
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
Oct  3 20:09:29.785: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-2822, will wait for the garbage collector to delete the pods 10/03/22 20:09:29.817
Oct  3 20:09:29.896: INFO: Deleting ReplicationController affinity-nodeport-transition took: 18.142682ms
Oct  3 20:09:29.998: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 102.126236ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 20:09:32.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2822" for this suite. 10/03/22 20:09:32.578
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":177,"skipped":3370,"failed":0}
------------------------------
• [SLOW TEST] [42.042 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:08:50.554
    Oct  3 20:08:50.555: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 20:08:50.556
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:08:50.587
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:08:50.592
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-2822 10/03/22 20:08:50.598
    STEP: creating service affinity-nodeport-transition in namespace services-2822 10/03/22 20:08:50.599
    STEP: creating replication controller affinity-nodeport-transition in namespace services-2822 10/03/22 20:08:50.643
    I1003 20:08:50.656716      22 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-2822, replica count: 3
    I1003 20:08:53.708561      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct  3 20:08:53.738: INFO: Creating new exec pod
    Oct  3 20:08:53.749: INFO: Waiting up to 5m0s for pod "execpod-affinity5s5c8" in namespace "services-2822" to be "running"
    Oct  3 20:08:53.758: INFO: Pod "execpod-affinity5s5c8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.684539ms
    Oct  3 20:08:55.771: INFO: Pod "execpod-affinity5s5c8": Phase="Running", Reason="", readiness=true. Elapsed: 2.022258722s
    Oct  3 20:08:55.771: INFO: Pod "execpod-affinity5s5c8" satisfied condition "running"
    Oct  3 20:08:56.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2822 exec execpod-affinity5s5c8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Oct  3 20:08:57.155: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Oct  3 20:08:57.155: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:08:57.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2822 exec execpod-affinity5s5c8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.178.75 80'
    Oct  3 20:08:57.491: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.178.75 80\nConnection to 172.21.178.75 80 port [tcp/http] succeeded!\n"
    Oct  3 20:08:57.491: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:08:57.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2822 exec execpod-affinity5s5c8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.3 32577'
    Oct  3 20:08:57.823: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.3 32577\nConnection to 10.63.128.3 32577 port [tcp/*] succeeded!\n"
    Oct  3 20:08:57.823: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:08:57.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2822 exec execpod-affinity5s5c8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.51 32577'
    Oct  3 20:08:58.199: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.51 32577\nConnection to 10.63.128.51 32577 port [tcp/*] succeeded!\n"
    Oct  3 20:08:58.199: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:08:58.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2822 exec execpod-affinity5s5c8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.63.128.13:32577/ ; done'
    Oct  3 20:08:58.730: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n"
    Oct  3 20:08:58.731: INFO: stdout: "\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq"
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:08:58.731: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:28.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2822 exec execpod-affinity5s5c8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.63.128.13:32577/ ; done'
    Oct  3 20:09:29.235: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n"
    Oct  3 20:09:29.235: INFO: stdout: "\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-96t7b\naffinity-nodeport-transition-96t7b\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-96t7b\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-l5d6n\naffinity-nodeport-transition-jlsqq"
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-96t7b
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-96t7b
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-96t7b
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-l5d6n
    Oct  3 20:09:29.235: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2822 exec execpod-affinity5s5c8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.63.128.13:32577/ ; done'
    Oct  3 20:09:29.784: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:32577/\n"
    Oct  3 20:09:29.785: INFO: stdout: "\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq\naffinity-nodeport-transition-jlsqq"
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Received response from host: affinity-nodeport-transition-jlsqq
    Oct  3 20:09:29.785: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-2822, will wait for the garbage collector to delete the pods 10/03/22 20:09:29.817
    Oct  3 20:09:29.896: INFO: Deleting ReplicationController affinity-nodeport-transition took: 18.142682ms
    Oct  3 20:09:29.998: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 102.126236ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 20:09:32.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2822" for this suite. 10/03/22 20:09:32.578
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:09:32.598
Oct  3 20:09:32.598: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename secrets 10/03/22 20:09:32.6
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:09:32.633
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:09:32.639
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-3b19ff7e-bf64-45ec-96c5-7c6a83726503 10/03/22 20:09:32.658
STEP: Creating secret with name s-test-opt-upd-853ba3c2-d28e-45df-b401-fd4d4792e425 10/03/22 20:09:32.671
STEP: Creating the pod 10/03/22 20:09:32.683
Oct  3 20:09:32.703: INFO: Waiting up to 5m0s for pod "pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344" in namespace "secrets-3434" to be "running and ready"
Oct  3 20:09:32.711: INFO: Pod "pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344": Phase="Pending", Reason="", readiness=false. Elapsed: 8.300689ms
Oct  3 20:09:32.711: INFO: The phase of Pod pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:09:34.721: INFO: Pod "pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018329762s
Oct  3 20:09:34.721: INFO: The phase of Pod pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:09:36.721: INFO: Pod "pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344": Phase="Running", Reason="", readiness=true. Elapsed: 4.018667442s
Oct  3 20:09:36.721: INFO: The phase of Pod pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344 is Running (Ready = true)
Oct  3 20:09:36.721: INFO: Pod "pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-3b19ff7e-bf64-45ec-96c5-7c6a83726503 10/03/22 20:09:36.807
STEP: Updating secret s-test-opt-upd-853ba3c2-d28e-45df-b401-fd4d4792e425 10/03/22 20:09:36.825
STEP: Creating secret with name s-test-opt-create-7fe74207-d51b-41bc-91a0-0e25ae5e9a48 10/03/22 20:09:36.838
STEP: waiting to observe update in volume 10/03/22 20:09:36.85
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Oct  3 20:09:40.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3434" for this suite. 10/03/22 20:09:41.021
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":178,"skipped":3373,"failed":0}
------------------------------
• [SLOW TEST] [8.441 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:09:32.598
    Oct  3 20:09:32.598: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename secrets 10/03/22 20:09:32.6
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:09:32.633
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:09:32.639
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-3b19ff7e-bf64-45ec-96c5-7c6a83726503 10/03/22 20:09:32.658
    STEP: Creating secret with name s-test-opt-upd-853ba3c2-d28e-45df-b401-fd4d4792e425 10/03/22 20:09:32.671
    STEP: Creating the pod 10/03/22 20:09:32.683
    Oct  3 20:09:32.703: INFO: Waiting up to 5m0s for pod "pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344" in namespace "secrets-3434" to be "running and ready"
    Oct  3 20:09:32.711: INFO: Pod "pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344": Phase="Pending", Reason="", readiness=false. Elapsed: 8.300689ms
    Oct  3 20:09:32.711: INFO: The phase of Pod pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:09:34.721: INFO: Pod "pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018329762s
    Oct  3 20:09:34.721: INFO: The phase of Pod pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:09:36.721: INFO: Pod "pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344": Phase="Running", Reason="", readiness=true. Elapsed: 4.018667442s
    Oct  3 20:09:36.721: INFO: The phase of Pod pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344 is Running (Ready = true)
    Oct  3 20:09:36.721: INFO: Pod "pod-secrets-be9ff9da-490e-49ef-98b0-0c6648f22344" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-3b19ff7e-bf64-45ec-96c5-7c6a83726503 10/03/22 20:09:36.807
    STEP: Updating secret s-test-opt-upd-853ba3c2-d28e-45df-b401-fd4d4792e425 10/03/22 20:09:36.825
    STEP: Creating secret with name s-test-opt-create-7fe74207-d51b-41bc-91a0-0e25ae5e9a48 10/03/22 20:09:36.838
    STEP: waiting to observe update in volume 10/03/22 20:09:36.85
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Oct  3 20:09:40.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3434" for this suite. 10/03/22 20:09:41.021
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:09:41.042
Oct  3 20:09:41.042: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename watch 10/03/22 20:09:41.043
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:09:41.074
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:09:41.081
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 10/03/22 20:09:41.085
STEP: starting a background goroutine to produce watch events 10/03/22 20:09:41.096
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 10/03/22 20:09:41.097
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Oct  3 20:09:43.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9605" for this suite. 10/03/22 20:09:43.907
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":179,"skipped":3382,"failed":0}
------------------------------
• [2.920 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:09:41.042
    Oct  3 20:09:41.042: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename watch 10/03/22 20:09:41.043
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:09:41.074
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:09:41.081
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 10/03/22 20:09:41.085
    STEP: starting a background goroutine to produce watch events 10/03/22 20:09:41.096
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 10/03/22 20:09:41.097
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Oct  3 20:09:43.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-9605" for this suite. 10/03/22 20:09:43.907
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:09:43.965
Oct  3 20:09:43.965: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 20:09:43.966
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:09:44.003
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:09:44.013
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 10/03/22 20:09:44.022
Oct  3 20:09:44.042: INFO: Waiting up to 5m0s for pod "labelsupdate10f188bf-065b-485c-a6d6-16a4917f69fa" in namespace "projected-4334" to be "running and ready"
Oct  3 20:09:44.051: INFO: Pod "labelsupdate10f188bf-065b-485c-a6d6-16a4917f69fa": Phase="Pending", Reason="", readiness=false. Elapsed: 8.769497ms
Oct  3 20:09:44.051: INFO: The phase of Pod labelsupdate10f188bf-065b-485c-a6d6-16a4917f69fa is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:09:46.059: INFO: Pod "labelsupdate10f188bf-065b-485c-a6d6-16a4917f69fa": Phase="Running", Reason="", readiness=true. Elapsed: 2.017682366s
Oct  3 20:09:46.060: INFO: The phase of Pod labelsupdate10f188bf-065b-485c-a6d6-16a4917f69fa is Running (Ready = true)
Oct  3 20:09:46.060: INFO: Pod "labelsupdate10f188bf-065b-485c-a6d6-16a4917f69fa" satisfied condition "running and ready"
Oct  3 20:09:46.625: INFO: Successfully updated pod "labelsupdate10f188bf-065b-485c-a6d6-16a4917f69fa"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Oct  3 20:09:48.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4334" for this suite. 10/03/22 20:09:48.692
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":180,"skipped":3414,"failed":0}
------------------------------
• [4.745 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:09:43.965
    Oct  3 20:09:43.965: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 20:09:43.966
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:09:44.003
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:09:44.013
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 10/03/22 20:09:44.022
    Oct  3 20:09:44.042: INFO: Waiting up to 5m0s for pod "labelsupdate10f188bf-065b-485c-a6d6-16a4917f69fa" in namespace "projected-4334" to be "running and ready"
    Oct  3 20:09:44.051: INFO: Pod "labelsupdate10f188bf-065b-485c-a6d6-16a4917f69fa": Phase="Pending", Reason="", readiness=false. Elapsed: 8.769497ms
    Oct  3 20:09:44.051: INFO: The phase of Pod labelsupdate10f188bf-065b-485c-a6d6-16a4917f69fa is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:09:46.059: INFO: Pod "labelsupdate10f188bf-065b-485c-a6d6-16a4917f69fa": Phase="Running", Reason="", readiness=true. Elapsed: 2.017682366s
    Oct  3 20:09:46.060: INFO: The phase of Pod labelsupdate10f188bf-065b-485c-a6d6-16a4917f69fa is Running (Ready = true)
    Oct  3 20:09:46.060: INFO: Pod "labelsupdate10f188bf-065b-485c-a6d6-16a4917f69fa" satisfied condition "running and ready"
    Oct  3 20:09:46.625: INFO: Successfully updated pod "labelsupdate10f188bf-065b-485c-a6d6-16a4917f69fa"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Oct  3 20:09:48.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4334" for this suite. 10/03/22 20:09:48.692
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:09:48.71
Oct  3 20:09:48.710: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename sysctl 10/03/22 20:09:48.712
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:09:48.743
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:09:48.748
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 10/03/22 20:09:48.754
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Oct  3 20:09:48.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-155" for this suite. 10/03/22 20:09:48.777
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":181,"skipped":3414,"failed":0}
------------------------------
• [0.083 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:09:48.71
    Oct  3 20:09:48.710: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename sysctl 10/03/22 20:09:48.712
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:09:48.743
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:09:48.748
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 10/03/22 20:09:48.754
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Oct  3 20:09:48.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-155" for this suite. 10/03/22 20:09:48.777
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:09:48.795
Oct  3 20:09:48.795: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename replicaset 10/03/22 20:09:48.797
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:09:48.828
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:09:48.834
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 10/03/22 20:09:48.839
Oct  3 20:09:48.857: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-5800" to be "running and ready"
Oct  3 20:09:48.866: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 8.644571ms
Oct  3 20:09:48.866: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:09:50.877: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019988252s
Oct  3 20:09:50.877: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:09:52.877: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 4.01930949s
Oct  3 20:09:52.877: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Oct  3 20:09:52.877: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 10/03/22 20:09:52.885
STEP: Then the orphan pod is adopted 10/03/22 20:09:52.895
STEP: When the matched label of one of its pods change 10/03/22 20:09:53.914
Oct  3 20:09:53.923: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 10/03/22 20:09:53.945
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Oct  3 20:09:54.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5800" for this suite. 10/03/22 20:09:54.976
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":182,"skipped":3421,"failed":0}
------------------------------
• [SLOW TEST] [6.202 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:09:48.795
    Oct  3 20:09:48.795: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename replicaset 10/03/22 20:09:48.797
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:09:48.828
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:09:48.834
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 10/03/22 20:09:48.839
    Oct  3 20:09:48.857: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-5800" to be "running and ready"
    Oct  3 20:09:48.866: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 8.644571ms
    Oct  3 20:09:48.866: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:09:50.877: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019988252s
    Oct  3 20:09:50.877: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:09:52.877: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 4.01930949s
    Oct  3 20:09:52.877: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Oct  3 20:09:52.877: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 10/03/22 20:09:52.885
    STEP: Then the orphan pod is adopted 10/03/22 20:09:52.895
    STEP: When the matched label of one of its pods change 10/03/22 20:09:53.914
    Oct  3 20:09:53.923: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 10/03/22 20:09:53.945
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Oct  3 20:09:54.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-5800" for this suite. 10/03/22 20:09:54.976
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:09:54.999
Oct  3 20:09:55.000: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 20:09:55.002
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:09:55.053
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:09:55.057
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 10/03/22 20:09:55.063
Oct  3 20:09:55.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 create -f -'
Oct  3 20:09:55.861: INFO: stderr: ""
Oct  3 20:09:55.861: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 10/03/22 20:09:55.861
Oct  3 20:09:55.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct  3 20:09:55.975: INFO: stderr: ""
Oct  3 20:09:55.975: INFO: stdout: "update-demo-nautilus-lhkfp update-demo-nautilus-m9ffn "
Oct  3 20:09:55.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-lhkfp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct  3 20:09:56.067: INFO: stderr: ""
Oct  3 20:09:56.068: INFO: stdout: ""
Oct  3 20:09:56.068: INFO: update-demo-nautilus-lhkfp is created but not running
Oct  3 20:10:01.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct  3 20:10:01.239: INFO: stderr: ""
Oct  3 20:10:01.239: INFO: stdout: "update-demo-nautilus-lhkfp update-demo-nautilus-m9ffn "
Oct  3 20:10:01.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-lhkfp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct  3 20:10:01.358: INFO: stderr: ""
Oct  3 20:10:01.358: INFO: stdout: "true"
Oct  3 20:10:01.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-lhkfp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct  3 20:10:01.474: INFO: stderr: ""
Oct  3 20:10:01.474: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Oct  3 20:10:01.474: INFO: validating pod update-demo-nautilus-lhkfp
Oct  3 20:10:01.518: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  3 20:10:01.518: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  3 20:10:01.518: INFO: update-demo-nautilus-lhkfp is verified up and running
Oct  3 20:10:01.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-m9ffn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct  3 20:10:01.631: INFO: stderr: ""
Oct  3 20:10:01.631: INFO: stdout: "true"
Oct  3 20:10:01.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-m9ffn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct  3 20:10:01.741: INFO: stderr: ""
Oct  3 20:10:01.741: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Oct  3 20:10:01.741: INFO: validating pod update-demo-nautilus-m9ffn
Oct  3 20:10:01.773: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  3 20:10:01.773: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  3 20:10:01.773: INFO: update-demo-nautilus-m9ffn is verified up and running
STEP: scaling down the replication controller 10/03/22 20:10:01.773
Oct  3 20:10:01.775: INFO: scanned /root for discovery docs: <nil>
Oct  3 20:10:01.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Oct  3 20:10:02.931: INFO: stderr: ""
Oct  3 20:10:02.931: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 10/03/22 20:10:02.931
Oct  3 20:10:02.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct  3 20:10:03.042: INFO: stderr: ""
Oct  3 20:10:03.042: INFO: stdout: "update-demo-nautilus-lhkfp update-demo-nautilus-m9ffn "
STEP: Replicas for name=update-demo: expected=1 actual=2 10/03/22 20:10:03.042
Oct  3 20:10:08.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct  3 20:10:08.159: INFO: stderr: ""
Oct  3 20:10:08.159: INFO: stdout: "update-demo-nautilus-lhkfp "
Oct  3 20:10:08.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-lhkfp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct  3 20:10:08.283: INFO: stderr: ""
Oct  3 20:10:08.283: INFO: stdout: "true"
Oct  3 20:10:08.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-lhkfp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct  3 20:10:08.381: INFO: stderr: ""
Oct  3 20:10:08.381: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Oct  3 20:10:08.382: INFO: validating pod update-demo-nautilus-lhkfp
Oct  3 20:10:08.398: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  3 20:10:08.398: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  3 20:10:08.398: INFO: update-demo-nautilus-lhkfp is verified up and running
STEP: scaling up the replication controller 10/03/22 20:10:08.398
Oct  3 20:10:08.400: INFO: scanned /root for discovery docs: <nil>
Oct  3 20:10:08.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Oct  3 20:10:09.544: INFO: stderr: ""
Oct  3 20:10:09.544: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 10/03/22 20:10:09.544
Oct  3 20:10:09.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct  3 20:10:09.650: INFO: stderr: ""
Oct  3 20:10:09.650: INFO: stdout: "update-demo-nautilus-c878g update-demo-nautilus-lhkfp "
Oct  3 20:10:09.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-c878g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct  3 20:10:09.759: INFO: stderr: ""
Oct  3 20:10:09.759: INFO: stdout: ""
Oct  3 20:10:09.759: INFO: update-demo-nautilus-c878g is created but not running
Oct  3 20:10:14.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct  3 20:10:14.916: INFO: stderr: ""
Oct  3 20:10:14.916: INFO: stdout: "update-demo-nautilus-c878g update-demo-nautilus-lhkfp "
Oct  3 20:10:14.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-c878g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct  3 20:10:15.023: INFO: stderr: ""
Oct  3 20:10:15.023: INFO: stdout: "true"
Oct  3 20:10:15.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-c878g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct  3 20:10:15.139: INFO: stderr: ""
Oct  3 20:10:15.139: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Oct  3 20:10:15.139: INFO: validating pod update-demo-nautilus-c878g
Oct  3 20:10:15.182: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  3 20:10:15.182: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  3 20:10:15.182: INFO: update-demo-nautilus-c878g is verified up and running
Oct  3 20:10:15.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-lhkfp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct  3 20:10:15.287: INFO: stderr: ""
Oct  3 20:10:15.287: INFO: stdout: "true"
Oct  3 20:10:15.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-lhkfp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct  3 20:10:15.392: INFO: stderr: ""
Oct  3 20:10:15.392: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Oct  3 20:10:15.392: INFO: validating pod update-demo-nautilus-lhkfp
Oct  3 20:10:15.408: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  3 20:10:15.408: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  3 20:10:15.408: INFO: update-demo-nautilus-lhkfp is verified up and running
STEP: using delete to clean up resources 10/03/22 20:10:15.408
Oct  3 20:10:15.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 delete --grace-period=0 --force -f -'
Oct  3 20:10:15.516: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  3 20:10:15.516: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct  3 20:10:15.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get rc,svc -l name=update-demo --no-headers'
Oct  3 20:10:15.653: INFO: stderr: "No resources found in kubectl-7517 namespace.\n"
Oct  3 20:10:15.653: INFO: stdout: ""
Oct  3 20:10:15.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  3 20:10:15.791: INFO: stderr: ""
Oct  3 20:10:15.791: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 20:10:15.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7517" for this suite. 10/03/22 20:10:15.803
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":183,"skipped":3426,"failed":0}
------------------------------
• [SLOW TEST] [20.820 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:09:54.999
    Oct  3 20:09:55.000: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 20:09:55.002
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:09:55.053
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:09:55.057
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 10/03/22 20:09:55.063
    Oct  3 20:09:55.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 create -f -'
    Oct  3 20:09:55.861: INFO: stderr: ""
    Oct  3 20:09:55.861: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 10/03/22 20:09:55.861
    Oct  3 20:09:55.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct  3 20:09:55.975: INFO: stderr: ""
    Oct  3 20:09:55.975: INFO: stdout: "update-demo-nautilus-lhkfp update-demo-nautilus-m9ffn "
    Oct  3 20:09:55.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-lhkfp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct  3 20:09:56.067: INFO: stderr: ""
    Oct  3 20:09:56.068: INFO: stdout: ""
    Oct  3 20:09:56.068: INFO: update-demo-nautilus-lhkfp is created but not running
    Oct  3 20:10:01.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct  3 20:10:01.239: INFO: stderr: ""
    Oct  3 20:10:01.239: INFO: stdout: "update-demo-nautilus-lhkfp update-demo-nautilus-m9ffn "
    Oct  3 20:10:01.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-lhkfp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct  3 20:10:01.358: INFO: stderr: ""
    Oct  3 20:10:01.358: INFO: stdout: "true"
    Oct  3 20:10:01.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-lhkfp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Oct  3 20:10:01.474: INFO: stderr: ""
    Oct  3 20:10:01.474: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Oct  3 20:10:01.474: INFO: validating pod update-demo-nautilus-lhkfp
    Oct  3 20:10:01.518: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Oct  3 20:10:01.518: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Oct  3 20:10:01.518: INFO: update-demo-nautilus-lhkfp is verified up and running
    Oct  3 20:10:01.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-m9ffn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct  3 20:10:01.631: INFO: stderr: ""
    Oct  3 20:10:01.631: INFO: stdout: "true"
    Oct  3 20:10:01.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-m9ffn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Oct  3 20:10:01.741: INFO: stderr: ""
    Oct  3 20:10:01.741: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Oct  3 20:10:01.741: INFO: validating pod update-demo-nautilus-m9ffn
    Oct  3 20:10:01.773: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Oct  3 20:10:01.773: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Oct  3 20:10:01.773: INFO: update-demo-nautilus-m9ffn is verified up and running
    STEP: scaling down the replication controller 10/03/22 20:10:01.773
    Oct  3 20:10:01.775: INFO: scanned /root for discovery docs: <nil>
    Oct  3 20:10:01.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Oct  3 20:10:02.931: INFO: stderr: ""
    Oct  3 20:10:02.931: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 10/03/22 20:10:02.931
    Oct  3 20:10:02.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct  3 20:10:03.042: INFO: stderr: ""
    Oct  3 20:10:03.042: INFO: stdout: "update-demo-nautilus-lhkfp update-demo-nautilus-m9ffn "
    STEP: Replicas for name=update-demo: expected=1 actual=2 10/03/22 20:10:03.042
    Oct  3 20:10:08.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct  3 20:10:08.159: INFO: stderr: ""
    Oct  3 20:10:08.159: INFO: stdout: "update-demo-nautilus-lhkfp "
    Oct  3 20:10:08.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-lhkfp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct  3 20:10:08.283: INFO: stderr: ""
    Oct  3 20:10:08.283: INFO: stdout: "true"
    Oct  3 20:10:08.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-lhkfp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Oct  3 20:10:08.381: INFO: stderr: ""
    Oct  3 20:10:08.381: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Oct  3 20:10:08.382: INFO: validating pod update-demo-nautilus-lhkfp
    Oct  3 20:10:08.398: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Oct  3 20:10:08.398: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Oct  3 20:10:08.398: INFO: update-demo-nautilus-lhkfp is verified up and running
    STEP: scaling up the replication controller 10/03/22 20:10:08.398
    Oct  3 20:10:08.400: INFO: scanned /root for discovery docs: <nil>
    Oct  3 20:10:08.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Oct  3 20:10:09.544: INFO: stderr: ""
    Oct  3 20:10:09.544: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 10/03/22 20:10:09.544
    Oct  3 20:10:09.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct  3 20:10:09.650: INFO: stderr: ""
    Oct  3 20:10:09.650: INFO: stdout: "update-demo-nautilus-c878g update-demo-nautilus-lhkfp "
    Oct  3 20:10:09.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-c878g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct  3 20:10:09.759: INFO: stderr: ""
    Oct  3 20:10:09.759: INFO: stdout: ""
    Oct  3 20:10:09.759: INFO: update-demo-nautilus-c878g is created but not running
    Oct  3 20:10:14.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct  3 20:10:14.916: INFO: stderr: ""
    Oct  3 20:10:14.916: INFO: stdout: "update-demo-nautilus-c878g update-demo-nautilus-lhkfp "
    Oct  3 20:10:14.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-c878g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct  3 20:10:15.023: INFO: stderr: ""
    Oct  3 20:10:15.023: INFO: stdout: "true"
    Oct  3 20:10:15.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-c878g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Oct  3 20:10:15.139: INFO: stderr: ""
    Oct  3 20:10:15.139: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Oct  3 20:10:15.139: INFO: validating pod update-demo-nautilus-c878g
    Oct  3 20:10:15.182: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Oct  3 20:10:15.182: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Oct  3 20:10:15.182: INFO: update-demo-nautilus-c878g is verified up and running
    Oct  3 20:10:15.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-lhkfp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct  3 20:10:15.287: INFO: stderr: ""
    Oct  3 20:10:15.287: INFO: stdout: "true"
    Oct  3 20:10:15.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods update-demo-nautilus-lhkfp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Oct  3 20:10:15.392: INFO: stderr: ""
    Oct  3 20:10:15.392: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Oct  3 20:10:15.392: INFO: validating pod update-demo-nautilus-lhkfp
    Oct  3 20:10:15.408: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Oct  3 20:10:15.408: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Oct  3 20:10:15.408: INFO: update-demo-nautilus-lhkfp is verified up and running
    STEP: using delete to clean up resources 10/03/22 20:10:15.408
    Oct  3 20:10:15.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 delete --grace-period=0 --force -f -'
    Oct  3 20:10:15.516: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct  3 20:10:15.516: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Oct  3 20:10:15.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get rc,svc -l name=update-demo --no-headers'
    Oct  3 20:10:15.653: INFO: stderr: "No resources found in kubectl-7517 namespace.\n"
    Oct  3 20:10:15.653: INFO: stdout: ""
    Oct  3 20:10:15.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-7517 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Oct  3 20:10:15.791: INFO: stderr: ""
    Oct  3 20:10:15.791: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 20:10:15.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7517" for this suite. 10/03/22 20:10:15.803
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:10:15.823
Oct  3 20:10:15.824: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename events 10/03/22 20:10:15.825
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:10:15.868
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:10:15.875
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 10/03/22 20:10:15.88
Oct  3 20:10:15.891: INFO: created test-event-1
Oct  3 20:10:15.903: INFO: created test-event-2
Oct  3 20:10:15.920: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 10/03/22 20:10:15.92
STEP: delete collection of events 10/03/22 20:10:15.93
Oct  3 20:10:15.930: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 10/03/22 20:10:16.012
Oct  3 20:10:16.012: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Oct  3 20:10:16.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8744" for this suite. 10/03/22 20:10:16.043
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":184,"skipped":3474,"failed":0}
------------------------------
• [0.236 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:10:15.823
    Oct  3 20:10:15.824: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename events 10/03/22 20:10:15.825
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:10:15.868
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:10:15.875
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 10/03/22 20:10:15.88
    Oct  3 20:10:15.891: INFO: created test-event-1
    Oct  3 20:10:15.903: INFO: created test-event-2
    Oct  3 20:10:15.920: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 10/03/22 20:10:15.92
    STEP: delete collection of events 10/03/22 20:10:15.93
    Oct  3 20:10:15.930: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 10/03/22 20:10:16.012
    Oct  3 20:10:16.012: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Oct  3 20:10:16.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-8744" for this suite. 10/03/22 20:10:16.043
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:10:16.061
Oct  3 20:10:16.061: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename dns 10/03/22 20:10:16.063
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:10:16.094
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:10:16.1
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1030.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-1030.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 10/03/22 20:10:16.105
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1030.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-1030.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 10/03/22 20:10:16.106
STEP: creating a pod to probe /etc/hosts 10/03/22 20:10:16.106
STEP: submitting the pod to kubernetes 10/03/22 20:10:16.106
Oct  3 20:10:16.123: INFO: Waiting up to 15m0s for pod "dns-test-457541bc-ec9b-49cd-95e6-cb876d06a4de" in namespace "dns-1030" to be "running"
Oct  3 20:10:16.135: INFO: Pod "dns-test-457541bc-ec9b-49cd-95e6-cb876d06a4de": Phase="Pending", Reason="", readiness=false. Elapsed: 11.66921ms
Oct  3 20:10:18.146: INFO: Pod "dns-test-457541bc-ec9b-49cd-95e6-cb876d06a4de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022783882s
Oct  3 20:10:20.146: INFO: Pod "dns-test-457541bc-ec9b-49cd-95e6-cb876d06a4de": Phase="Running", Reason="", readiness=true. Elapsed: 4.023254816s
Oct  3 20:10:20.146: INFO: Pod "dns-test-457541bc-ec9b-49cd-95e6-cb876d06a4de" satisfied condition "running"
STEP: retrieving the pod 10/03/22 20:10:20.146
STEP: looking for the results for each expected name from probers 10/03/22 20:10:20.155
Oct  3 20:10:20.234: INFO: DNS probes using dns-1030/dns-test-457541bc-ec9b-49cd-95e6-cb876d06a4de succeeded

STEP: deleting the pod 10/03/22 20:10:20.234
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Oct  3 20:10:20.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1030" for this suite. 10/03/22 20:10:20.273
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":185,"skipped":3475,"failed":0}
------------------------------
• [4.229 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:10:16.061
    Oct  3 20:10:16.061: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename dns 10/03/22 20:10:16.063
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:10:16.094
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:10:16.1
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1030.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-1030.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     10/03/22 20:10:16.105
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1030.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-1030.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     10/03/22 20:10:16.106
    STEP: creating a pod to probe /etc/hosts 10/03/22 20:10:16.106
    STEP: submitting the pod to kubernetes 10/03/22 20:10:16.106
    Oct  3 20:10:16.123: INFO: Waiting up to 15m0s for pod "dns-test-457541bc-ec9b-49cd-95e6-cb876d06a4de" in namespace "dns-1030" to be "running"
    Oct  3 20:10:16.135: INFO: Pod "dns-test-457541bc-ec9b-49cd-95e6-cb876d06a4de": Phase="Pending", Reason="", readiness=false. Elapsed: 11.66921ms
    Oct  3 20:10:18.146: INFO: Pod "dns-test-457541bc-ec9b-49cd-95e6-cb876d06a4de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022783882s
    Oct  3 20:10:20.146: INFO: Pod "dns-test-457541bc-ec9b-49cd-95e6-cb876d06a4de": Phase="Running", Reason="", readiness=true. Elapsed: 4.023254816s
    Oct  3 20:10:20.146: INFO: Pod "dns-test-457541bc-ec9b-49cd-95e6-cb876d06a4de" satisfied condition "running"
    STEP: retrieving the pod 10/03/22 20:10:20.146
    STEP: looking for the results for each expected name from probers 10/03/22 20:10:20.155
    Oct  3 20:10:20.234: INFO: DNS probes using dns-1030/dns-test-457541bc-ec9b-49cd-95e6-cb876d06a4de succeeded

    STEP: deleting the pod 10/03/22 20:10:20.234
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Oct  3 20:10:20.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1030" for this suite. 10/03/22 20:10:20.273
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:10:20.292
Oct  3 20:10:20.292: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename svcaccounts 10/03/22 20:10:20.293
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:10:20.323
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:10:20.329
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Oct  3 20:10:20.343: INFO: Got root ca configmap in namespace "svcaccounts-8964"
Oct  3 20:10:20.361: INFO: Deleted root ca configmap in namespace "svcaccounts-8964"
STEP: waiting for a new root ca configmap created 10/03/22 20:10:20.862
Oct  3 20:10:20.872: INFO: Recreated root ca configmap in namespace "svcaccounts-8964"
Oct  3 20:10:20.884: INFO: Updated root ca configmap in namespace "svcaccounts-8964"
STEP: waiting for the root ca configmap reconciled 10/03/22 20:10:21.385
Oct  3 20:10:21.397: INFO: Reconciled root ca configmap in namespace "svcaccounts-8964"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Oct  3 20:10:21.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8964" for this suite. 10/03/22 20:10:21.413
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":186,"skipped":3488,"failed":0}
------------------------------
• [1.139 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:10:20.292
    Oct  3 20:10:20.292: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename svcaccounts 10/03/22 20:10:20.293
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:10:20.323
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:10:20.329
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Oct  3 20:10:20.343: INFO: Got root ca configmap in namespace "svcaccounts-8964"
    Oct  3 20:10:20.361: INFO: Deleted root ca configmap in namespace "svcaccounts-8964"
    STEP: waiting for a new root ca configmap created 10/03/22 20:10:20.862
    Oct  3 20:10:20.872: INFO: Recreated root ca configmap in namespace "svcaccounts-8964"
    Oct  3 20:10:20.884: INFO: Updated root ca configmap in namespace "svcaccounts-8964"
    STEP: waiting for the root ca configmap reconciled 10/03/22 20:10:21.385
    Oct  3 20:10:21.397: INFO: Reconciled root ca configmap in namespace "svcaccounts-8964"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Oct  3 20:10:21.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-8964" for this suite. 10/03/22 20:10:21.413
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:10:21.436
Oct  3 20:10:21.437: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubelet-test 10/03/22 20:10:21.439
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:10:21.473
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:10:21.481
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Oct  3 20:10:21.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4857" for this suite. 10/03/22 20:10:21.545
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":187,"skipped":3501,"failed":0}
------------------------------
• [0.125 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:10:21.436
    Oct  3 20:10:21.437: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubelet-test 10/03/22 20:10:21.439
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:10:21.473
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:10:21.481
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Oct  3 20:10:21.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-4857" for this suite. 10/03/22 20:10:21.545
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:10:21.562
Oct  3 20:10:21.562: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename job 10/03/22 20:10:21.564
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:10:21.593
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:10:21.598
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 10/03/22 20:10:21.614
STEP: Patching the Job 10/03/22 20:10:21.625
STEP: Watching for Job to be patched 10/03/22 20:10:21.638
Oct  3 20:10:21.641: INFO: Event ADDED observed for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9] and annotations: map[batch.kubernetes.io/job-tracking:]
Oct  3 20:10:21.641: INFO: Event MODIFIED found for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 10/03/22 20:10:21.642
STEP: Watching for Job to be updated 10/03/22 20:10:21.667
Oct  3 20:10:21.670: INFO: Event MODIFIED found for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Oct  3 20:10:21.670: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 10/03/22 20:10:21.67
Oct  3 20:10:21.678: INFO: Job: e2e-qdlg9 as labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched]
STEP: Waiting for job to complete 10/03/22 20:10:21.679
STEP: Delete a job collection with a labelselector 10/03/22 20:10:33.691
STEP: Watching for Job to be deleted 10/03/22 20:10:33.713
Oct  3 20:10:33.716: INFO: Event MODIFIED observed for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Oct  3 20:10:33.716: INFO: Event MODIFIED observed for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Oct  3 20:10:33.716: INFO: Event MODIFIED observed for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Oct  3 20:10:33.716: INFO: Event MODIFIED observed for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Oct  3 20:10:33.717: INFO: Event MODIFIED observed for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Oct  3 20:10:33.717: INFO: Event DELETED found for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 10/03/22 20:10:33.717
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Oct  3 20:10:33.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1416" for this suite. 10/03/22 20:10:33.764
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":188,"skipped":3501,"failed":0}
------------------------------
• [SLOW TEST] [12.218 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:10:21.562
    Oct  3 20:10:21.562: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename job 10/03/22 20:10:21.564
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:10:21.593
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:10:21.598
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 10/03/22 20:10:21.614
    STEP: Patching the Job 10/03/22 20:10:21.625
    STEP: Watching for Job to be patched 10/03/22 20:10:21.638
    Oct  3 20:10:21.641: INFO: Event ADDED observed for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9] and annotations: map[batch.kubernetes.io/job-tracking:]
    Oct  3 20:10:21.641: INFO: Event MODIFIED found for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 10/03/22 20:10:21.642
    STEP: Watching for Job to be updated 10/03/22 20:10:21.667
    Oct  3 20:10:21.670: INFO: Event MODIFIED found for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Oct  3 20:10:21.670: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 10/03/22 20:10:21.67
    Oct  3 20:10:21.678: INFO: Job: e2e-qdlg9 as labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched]
    STEP: Waiting for job to complete 10/03/22 20:10:21.679
    STEP: Delete a job collection with a labelselector 10/03/22 20:10:33.691
    STEP: Watching for Job to be deleted 10/03/22 20:10:33.713
    Oct  3 20:10:33.716: INFO: Event MODIFIED observed for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Oct  3 20:10:33.716: INFO: Event MODIFIED observed for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Oct  3 20:10:33.716: INFO: Event MODIFIED observed for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Oct  3 20:10:33.716: INFO: Event MODIFIED observed for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Oct  3 20:10:33.717: INFO: Event MODIFIED observed for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Oct  3 20:10:33.717: INFO: Event DELETED found for Job e2e-qdlg9 in namespace job-1416 with labels: map[e2e-job-label:e2e-qdlg9 e2e-qdlg9:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 10/03/22 20:10:33.717
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Oct  3 20:10:33.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-1416" for this suite. 10/03/22 20:10:33.764
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:10:33.782
Oct  3 20:10:33.782: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename sched-preemption 10/03/22 20:10:33.784
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:10:33.832
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:10:33.838
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Oct  3 20:10:33.881: INFO: Waiting up to 1m0s for all nodes to be ready
Oct  3 20:11:33.961: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 10/03/22 20:11:33.973
Oct  3 20:11:34.051: INFO: Created pod: pod0-0-sched-preemption-low-priority
Oct  3 20:11:34.065: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Oct  3 20:11:34.106: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Oct  3 20:11:34.134: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Oct  3 20:11:34.197: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Oct  3 20:11:34.226: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 10/03/22 20:11:34.226
Oct  3 20:11:34.226: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-1948" to be "running"
Oct  3 20:11:34.236: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 9.752194ms
Oct  3 20:11:36.247: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02106508s
Oct  3 20:11:38.248: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021128517s
Oct  3 20:11:40.247: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0208549s
Oct  3 20:11:42.249: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.022226523s
Oct  3 20:11:44.246: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.019440517s
Oct  3 20:11:44.246: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Oct  3 20:11:44.246: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-1948" to be "running"
Oct  3 20:11:44.256: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.040429ms
Oct  3 20:11:44.256: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Oct  3 20:11:44.256: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-1948" to be "running"
Oct  3 20:11:44.265: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.751325ms
Oct  3 20:11:46.275: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.01894021s
Oct  3 20:11:46.275: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Oct  3 20:11:46.275: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-1948" to be "running"
Oct  3 20:11:46.285: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.294429ms
Oct  3 20:11:46.285: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Oct  3 20:11:46.285: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-1948" to be "running"
Oct  3 20:11:46.293: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.101983ms
Oct  3 20:11:46.293: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Oct  3 20:11:46.293: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-1948" to be "running"
Oct  3 20:11:46.302: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.28858ms
Oct  3 20:11:46.302: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 10/03/22 20:11:46.302
Oct  3 20:11:46.313: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-1948" to be "running"
Oct  3 20:11:46.322: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.799937ms
Oct  3 20:11:48.333: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01986947s
Oct  3 20:11:50.333: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.019409942s
Oct  3 20:11:50.333: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Oct  3 20:11:50.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-1948" for this suite. 10/03/22 20:11:50.416
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":189,"skipped":3504,"failed":0}
------------------------------
• [SLOW TEST] [76.766 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:10:33.782
    Oct  3 20:10:33.782: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename sched-preemption 10/03/22 20:10:33.784
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:10:33.832
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:10:33.838
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Oct  3 20:10:33.881: INFO: Waiting up to 1m0s for all nodes to be ready
    Oct  3 20:11:33.961: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 10/03/22 20:11:33.973
    Oct  3 20:11:34.051: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Oct  3 20:11:34.065: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Oct  3 20:11:34.106: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Oct  3 20:11:34.134: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Oct  3 20:11:34.197: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Oct  3 20:11:34.226: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 10/03/22 20:11:34.226
    Oct  3 20:11:34.226: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-1948" to be "running"
    Oct  3 20:11:34.236: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 9.752194ms
    Oct  3 20:11:36.247: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02106508s
    Oct  3 20:11:38.248: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021128517s
    Oct  3 20:11:40.247: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0208549s
    Oct  3 20:11:42.249: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.022226523s
    Oct  3 20:11:44.246: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.019440517s
    Oct  3 20:11:44.246: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Oct  3 20:11:44.246: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-1948" to be "running"
    Oct  3 20:11:44.256: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.040429ms
    Oct  3 20:11:44.256: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Oct  3 20:11:44.256: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-1948" to be "running"
    Oct  3 20:11:44.265: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.751325ms
    Oct  3 20:11:46.275: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.01894021s
    Oct  3 20:11:46.275: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Oct  3 20:11:46.275: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-1948" to be "running"
    Oct  3 20:11:46.285: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.294429ms
    Oct  3 20:11:46.285: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Oct  3 20:11:46.285: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-1948" to be "running"
    Oct  3 20:11:46.293: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.101983ms
    Oct  3 20:11:46.293: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Oct  3 20:11:46.293: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-1948" to be "running"
    Oct  3 20:11:46.302: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.28858ms
    Oct  3 20:11:46.302: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 10/03/22 20:11:46.302
    Oct  3 20:11:46.313: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-1948" to be "running"
    Oct  3 20:11:46.322: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.799937ms
    Oct  3 20:11:48.333: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01986947s
    Oct  3 20:11:50.333: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.019409942s
    Oct  3 20:11:50.333: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 20:11:50.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-1948" for this suite. 10/03/22 20:11:50.416
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:11:50.551
Oct  3 20:11:50.551: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 20:11:50.553
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:11:50.586
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:11:50.591
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 10/03/22 20:11:50.596
Oct  3 20:11:50.597: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: rename a version 10/03/22 20:12:02.381
STEP: check the new version name is served 10/03/22 20:12:02.403
STEP: check the old version name is removed 10/03/22 20:12:06.832
STEP: check the other version is not changed 10/03/22 20:12:08.997
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:12:18.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1219" for this suite. 10/03/22 20:12:18.263
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":190,"skipped":3517,"failed":0}
------------------------------
• [SLOW TEST] [27.736 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:11:50.551
    Oct  3 20:11:50.551: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 20:11:50.553
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:11:50.586
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:11:50.591
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 10/03/22 20:11:50.596
    Oct  3 20:11:50.597: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: rename a version 10/03/22 20:12:02.381
    STEP: check the new version name is served 10/03/22 20:12:02.403
    STEP: check the old version name is removed 10/03/22 20:12:06.832
    STEP: check the other version is not changed 10/03/22 20:12:08.997
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:12:18.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1219" for this suite. 10/03/22 20:12:18.263
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:12:18.295
Oct  3 20:12:18.295: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename pod-network-test 10/03/22 20:12:18.297
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:12:18.344
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:12:18.357
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-3562 10/03/22 20:12:18.366
STEP: creating a selector 10/03/22 20:12:18.367
STEP: Creating the service pods in kubernetes 10/03/22 20:12:18.367
Oct  3 20:12:18.367: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Oct  3 20:12:18.470: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3562" to be "running and ready"
Oct  3 20:12:18.484: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.089948ms
Oct  3 20:12:18.484: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:12:20.499: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029194666s
Oct  3 20:12:20.499: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:12:22.500: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.030101044s
Oct  3 20:12:22.500: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:12:24.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.031371011s
Oct  3 20:12:24.501: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:12:26.498: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.027972693s
Oct  3 20:12:26.498: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:12:28.500: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.029682558s
Oct  3 20:12:28.500: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:12:30.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.030865287s
Oct  3 20:12:30.501: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:12:32.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.031214433s
Oct  3 20:12:32.501: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:12:34.500: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.030424388s
Oct  3 20:12:34.500: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:12:36.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.031367619s
Oct  3 20:12:36.501: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:12:38.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.031222305s
Oct  3 20:12:38.501: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:12:40.500: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.030238677s
Oct  3 20:12:40.500: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Oct  3 20:12:40.500: INFO: Pod "netserver-0" satisfied condition "running and ready"
Oct  3 20:12:40.514: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3562" to be "running and ready"
Oct  3 20:12:40.528: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 13.830854ms
Oct  3 20:12:40.528: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Oct  3 20:12:40.528: INFO: Pod "netserver-1" satisfied condition "running and ready"
Oct  3 20:12:40.542: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3562" to be "running and ready"
Oct  3 20:12:40.556: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 14.049961ms
Oct  3 20:12:40.556: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Oct  3 20:12:40.556: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 10/03/22 20:12:40.57
Oct  3 20:12:40.610: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3562" to be "running"
Oct  3 20:12:40.632: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 21.76691ms
Oct  3 20:12:42.647: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037202008s
Oct  3 20:12:44.646: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.036101758s
Oct  3 20:12:44.646: INFO: Pod "test-container-pod" satisfied condition "running"
Oct  3 20:12:44.660: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-3562" to be "running"
Oct  3 20:12:44.673: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 13.345723ms
Oct  3 20:12:44.673: INFO: Pod "host-test-container-pod" satisfied condition "running"
Oct  3 20:12:44.687: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Oct  3 20:12:44.687: INFO: Going to poll 172.30.35.224 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Oct  3 20:12:44.700: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.35.224:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3562 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:12:44.701: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:12:44.701: INFO: ExecWithOptions: Clientset creation
Oct  3 20:12:44.702: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3562/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.35.224%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct  3 20:12:44.953: INFO: Found all 1 expected endpoints: [netserver-0]
Oct  3 20:12:44.953: INFO: Going to poll 172.30.49.11 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Oct  3 20:12:44.968: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.49.11:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3562 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:12:44.969: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:12:44.970: INFO: ExecWithOptions: Clientset creation
Oct  3 20:12:44.970: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3562/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.49.11%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct  3 20:12:45.195: INFO: Found all 1 expected endpoints: [netserver-1]
Oct  3 20:12:45.195: INFO: Going to poll 172.30.174.218 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Oct  3 20:12:45.209: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.174.218:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3562 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:12:45.209: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:12:45.210: INFO: ExecWithOptions: Clientset creation
Oct  3 20:12:45.210: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3562/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.174.218%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct  3 20:12:45.422: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Oct  3 20:12:45.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3562" for this suite. 10/03/22 20:12:45.441
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":191,"skipped":3560,"failed":0}
------------------------------
• [SLOW TEST] [27.170 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:12:18.295
    Oct  3 20:12:18.295: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename pod-network-test 10/03/22 20:12:18.297
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:12:18.344
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:12:18.357
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-3562 10/03/22 20:12:18.366
    STEP: creating a selector 10/03/22 20:12:18.367
    STEP: Creating the service pods in kubernetes 10/03/22 20:12:18.367
    Oct  3 20:12:18.367: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Oct  3 20:12:18.470: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3562" to be "running and ready"
    Oct  3 20:12:18.484: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.089948ms
    Oct  3 20:12:18.484: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:12:20.499: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029194666s
    Oct  3 20:12:20.499: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:12:22.500: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.030101044s
    Oct  3 20:12:22.500: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:12:24.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.031371011s
    Oct  3 20:12:24.501: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:12:26.498: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.027972693s
    Oct  3 20:12:26.498: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:12:28.500: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.029682558s
    Oct  3 20:12:28.500: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:12:30.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.030865287s
    Oct  3 20:12:30.501: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:12:32.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.031214433s
    Oct  3 20:12:32.501: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:12:34.500: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.030424388s
    Oct  3 20:12:34.500: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:12:36.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.031367619s
    Oct  3 20:12:36.501: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:12:38.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.031222305s
    Oct  3 20:12:38.501: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:12:40.500: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.030238677s
    Oct  3 20:12:40.500: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Oct  3 20:12:40.500: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Oct  3 20:12:40.514: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3562" to be "running and ready"
    Oct  3 20:12:40.528: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 13.830854ms
    Oct  3 20:12:40.528: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Oct  3 20:12:40.528: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Oct  3 20:12:40.542: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3562" to be "running and ready"
    Oct  3 20:12:40.556: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 14.049961ms
    Oct  3 20:12:40.556: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Oct  3 20:12:40.556: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 10/03/22 20:12:40.57
    Oct  3 20:12:40.610: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3562" to be "running"
    Oct  3 20:12:40.632: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 21.76691ms
    Oct  3 20:12:42.647: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037202008s
    Oct  3 20:12:44.646: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.036101758s
    Oct  3 20:12:44.646: INFO: Pod "test-container-pod" satisfied condition "running"
    Oct  3 20:12:44.660: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-3562" to be "running"
    Oct  3 20:12:44.673: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 13.345723ms
    Oct  3 20:12:44.673: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Oct  3 20:12:44.687: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Oct  3 20:12:44.687: INFO: Going to poll 172.30.35.224 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Oct  3 20:12:44.700: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.35.224:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3562 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:12:44.701: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:12:44.701: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:12:44.702: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3562/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.35.224%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Oct  3 20:12:44.953: INFO: Found all 1 expected endpoints: [netserver-0]
    Oct  3 20:12:44.953: INFO: Going to poll 172.30.49.11 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Oct  3 20:12:44.968: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.49.11:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3562 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:12:44.969: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:12:44.970: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:12:44.970: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3562/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.49.11%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Oct  3 20:12:45.195: INFO: Found all 1 expected endpoints: [netserver-1]
    Oct  3 20:12:45.195: INFO: Going to poll 172.30.174.218 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Oct  3 20:12:45.209: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.174.218:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3562 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:12:45.209: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:12:45.210: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:12:45.210: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3562/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.174.218%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Oct  3 20:12:45.422: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Oct  3 20:12:45.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-3562" for this suite. 10/03/22 20:12:45.441
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:12:45.466
Oct  3 20:12:45.466: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename runtimeclass 10/03/22 20:12:45.467
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:12:45.524
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:12:45.535
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Oct  3 20:12:45.587: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-300 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Oct  3 20:12:45.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-300" for this suite. 10/03/22 20:12:45.65
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":192,"skipped":3570,"failed":0}
------------------------------
• [0.209 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:12:45.466
    Oct  3 20:12:45.466: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename runtimeclass 10/03/22 20:12:45.467
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:12:45.524
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:12:45.535
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Oct  3 20:12:45.587: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-300 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Oct  3 20:12:45.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-300" for this suite. 10/03/22 20:12:45.65
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:12:45.676
Oct  3 20:12:45.676: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename resourcequota 10/03/22 20:12:45.677
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:12:45.72
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:12:45.732
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 10/03/22 20:12:45.742
STEP: Creating a ResourceQuota 10/03/22 20:12:50.758
STEP: Ensuring resource quota status is calculated 10/03/22 20:12:50.775
STEP: Creating a Service 10/03/22 20:12:52.791
STEP: Creating a NodePort Service 10/03/22 20:12:52.838
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 10/03/22 20:12:52.9
STEP: Ensuring resource quota status captures service creation 10/03/22 20:12:52.971
STEP: Deleting Services 10/03/22 20:12:54.984
STEP: Ensuring resource quota status released usage 10/03/22 20:12:55.078
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Oct  3 20:12:57.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9376" for this suite. 10/03/22 20:12:57.114
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":193,"skipped":3575,"failed":0}
------------------------------
• [SLOW TEST] [11.466 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:12:45.676
    Oct  3 20:12:45.676: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename resourcequota 10/03/22 20:12:45.677
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:12:45.72
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:12:45.732
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 10/03/22 20:12:45.742
    STEP: Creating a ResourceQuota 10/03/22 20:12:50.758
    STEP: Ensuring resource quota status is calculated 10/03/22 20:12:50.775
    STEP: Creating a Service 10/03/22 20:12:52.791
    STEP: Creating a NodePort Service 10/03/22 20:12:52.838
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 10/03/22 20:12:52.9
    STEP: Ensuring resource quota status captures service creation 10/03/22 20:12:52.971
    STEP: Deleting Services 10/03/22 20:12:54.984
    STEP: Ensuring resource quota status released usage 10/03/22 20:12:55.078
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Oct  3 20:12:57.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9376" for this suite. 10/03/22 20:12:57.114
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:12:57.149
Oct  3 20:12:57.149: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 20:12:57.151
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:12:57.204
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:12:57.219
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 20:12:57.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6089" for this suite. 10/03/22 20:12:57.261
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":194,"skipped":3661,"failed":0}
------------------------------
• [0.137 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:12:57.149
    Oct  3 20:12:57.149: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 20:12:57.151
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:12:57.204
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:12:57.219
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 20:12:57.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6089" for this suite. 10/03/22 20:12:57.261
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:12:57.29
Oct  3 20:12:57.291: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename podtemplate 10/03/22 20:12:57.292
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:12:57.346
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:12:57.358
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 10/03/22 20:12:57.371
Oct  3 20:12:57.388: INFO: created test-podtemplate-1
Oct  3 20:12:57.406: INFO: created test-podtemplate-2
Oct  3 20:12:57.424: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 10/03/22 20:12:57.424
STEP: delete collection of pod templates 10/03/22 20:12:57.438
Oct  3 20:12:57.439: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 10/03/22 20:12:57.505
Oct  3 20:12:57.505: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Oct  3 20:12:57.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-405" for this suite. 10/03/22 20:12:57.538
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":195,"skipped":3671,"failed":0}
------------------------------
• [0.270 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:12:57.29
    Oct  3 20:12:57.291: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename podtemplate 10/03/22 20:12:57.292
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:12:57.346
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:12:57.358
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 10/03/22 20:12:57.371
    Oct  3 20:12:57.388: INFO: created test-podtemplate-1
    Oct  3 20:12:57.406: INFO: created test-podtemplate-2
    Oct  3 20:12:57.424: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 10/03/22 20:12:57.424
    STEP: delete collection of pod templates 10/03/22 20:12:57.438
    Oct  3 20:12:57.439: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 10/03/22 20:12:57.505
    Oct  3 20:12:57.505: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Oct  3 20:12:57.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-405" for this suite. 10/03/22 20:12:57.538
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:12:57.561
Oct  3 20:12:57.561: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename replication-controller 10/03/22 20:12:57.563
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:12:57.612
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:12:57.623
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673 10/03/22 20:12:57.648
Oct  3 20:12:57.679: INFO: Pod name my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673: Found 0 pods out of 1
Oct  3 20:13:02.696: INFO: Pod name my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673: Found 1 pods out of 1
Oct  3 20:13:02.696: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673" are running
Oct  3 20:13:02.696: INFO: Waiting up to 5m0s for pod "my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673-7kkvh" in namespace "replication-controller-8940" to be "running"
Oct  3 20:13:02.711: INFO: Pod "my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673-7kkvh": Phase="Running", Reason="", readiness=true. Elapsed: 14.520913ms
Oct  3 20:13:02.711: INFO: Pod "my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673-7kkvh" satisfied condition "running"
Oct  3 20:13:02.711: INFO: Pod "my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673-7kkvh" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 20:12:57 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 20:13:00 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 20:13:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 20:12:57 +0000 UTC Reason: Message:}])
Oct  3 20:13:02.711: INFO: Trying to dial the pod
Oct  3 20:13:07.786: INFO: Controller my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673: Got expected result from replica 1 [my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673-7kkvh]: "my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673-7kkvh", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Oct  3 20:13:07.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8940" for this suite. 10/03/22 20:13:07.807
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":196,"skipped":3671,"failed":0}
------------------------------
• [SLOW TEST] [10.270 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:12:57.561
    Oct  3 20:12:57.561: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename replication-controller 10/03/22 20:12:57.563
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:12:57.612
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:12:57.623
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673 10/03/22 20:12:57.648
    Oct  3 20:12:57.679: INFO: Pod name my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673: Found 0 pods out of 1
    Oct  3 20:13:02.696: INFO: Pod name my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673: Found 1 pods out of 1
    Oct  3 20:13:02.696: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673" are running
    Oct  3 20:13:02.696: INFO: Waiting up to 5m0s for pod "my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673-7kkvh" in namespace "replication-controller-8940" to be "running"
    Oct  3 20:13:02.711: INFO: Pod "my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673-7kkvh": Phase="Running", Reason="", readiness=true. Elapsed: 14.520913ms
    Oct  3 20:13:02.711: INFO: Pod "my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673-7kkvh" satisfied condition "running"
    Oct  3 20:13:02.711: INFO: Pod "my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673-7kkvh" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 20:12:57 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 20:13:00 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 20:13:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-03 20:12:57 +0000 UTC Reason: Message:}])
    Oct  3 20:13:02.711: INFO: Trying to dial the pod
    Oct  3 20:13:07.786: INFO: Controller my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673: Got expected result from replica 1 [my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673-7kkvh]: "my-hostname-basic-d2d3f250-9c91-42eb-93a3-c87ab6aa3673-7kkvh", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Oct  3 20:13:07.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-8940" for this suite. 10/03/22 20:13:07.807
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:13:07.833
Oct  3 20:13:07.834: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename custom-resource-definition 10/03/22 20:13:07.836
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:13:07.903
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:13:07.921
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Oct  3 20:13:07.934: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:13:14.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3610" for this suite. 10/03/22 20:13:14.689
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":197,"skipped":3676,"failed":0}
------------------------------
• [SLOW TEST] [6.877 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:13:07.833
    Oct  3 20:13:07.834: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename custom-resource-definition 10/03/22 20:13:07.836
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:13:07.903
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:13:07.921
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Oct  3 20:13:07.934: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:13:14.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-3610" for this suite. 10/03/22 20:13:14.689
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:13:14.718
Oct  3 20:13:14.719: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename dns 10/03/22 20:13:14.72
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:13:14.78
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:13:14.802
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 10/03/22 20:13:14.812
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7868.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local; sleep 1; done
 10/03/22 20:13:14.826
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7868.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7868.svc.cluster.local; sleep 1; done
 10/03/22 20:13:14.826
STEP: creating a pod to probe DNS 10/03/22 20:13:14.826
STEP: submitting the pod to kubernetes 10/03/22 20:13:14.826
Oct  3 20:13:14.848: INFO: Waiting up to 15m0s for pod "dns-test-c41756b7-28eb-4fd0-b153-2694113dd38f" in namespace "dns-7868" to be "running"
Oct  3 20:13:14.871: INFO: Pod "dns-test-c41756b7-28eb-4fd0-b153-2694113dd38f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.076881ms
Oct  3 20:13:16.884: INFO: Pod "dns-test-c41756b7-28eb-4fd0-b153-2694113dd38f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035557602s
Oct  3 20:13:18.883: INFO: Pod "dns-test-c41756b7-28eb-4fd0-b153-2694113dd38f": Phase="Running", Reason="", readiness=true. Elapsed: 4.034293213s
Oct  3 20:13:18.883: INFO: Pod "dns-test-c41756b7-28eb-4fd0-b153-2694113dd38f" satisfied condition "running"
STEP: retrieving the pod 10/03/22 20:13:18.883
STEP: looking for the results for each expected name from probers 10/03/22 20:13:18.895
Oct  3 20:13:18.956: INFO: DNS probes using dns-test-c41756b7-28eb-4fd0-b153-2694113dd38f succeeded

STEP: deleting the pod 10/03/22 20:13:18.956
STEP: changing the externalName to bar.example.com 10/03/22 20:13:18.992
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7868.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local; sleep 1; done
 10/03/22 20:13:19.016
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7868.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7868.svc.cluster.local; sleep 1; done
 10/03/22 20:13:19.017
STEP: creating a second pod to probe DNS 10/03/22 20:13:19.017
STEP: submitting the pod to kubernetes 10/03/22 20:13:19.017
Oct  3 20:13:19.040: INFO: Waiting up to 15m0s for pod "dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab" in namespace "dns-7868" to be "running"
Oct  3 20:13:19.053: INFO: Pod "dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab": Phase="Pending", Reason="", readiness=false. Elapsed: 13.038705ms
Oct  3 20:13:21.067: INFO: Pod "dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027037433s
Oct  3 20:13:23.069: INFO: Pod "dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab": Phase="Running", Reason="", readiness=true. Elapsed: 4.028710486s
Oct  3 20:13:23.069: INFO: Pod "dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab" satisfied condition "running"
STEP: retrieving the pod 10/03/22 20:13:23.069
STEP: looking for the results for each expected name from probers 10/03/22 20:13:23.081
Oct  3 20:13:23.119: INFO: File wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local from pod  dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct  3 20:13:23.137: INFO: File jessie_udp@dns-test-service-3.dns-7868.svc.cluster.local from pod  dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct  3 20:13:23.137: INFO: Lookups using dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab failed for: [wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local jessie_udp@dns-test-service-3.dns-7868.svc.cluster.local]

Oct  3 20:13:28.158: INFO: File wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local from pod  dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct  3 20:13:28.177: INFO: Lookups using dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab failed for: [wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local]

Oct  3 20:13:33.159: INFO: File wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local from pod  dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct  3 20:13:33.176: INFO: File jessie_udp@dns-test-service-3.dns-7868.svc.cluster.local from pod  dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct  3 20:13:33.177: INFO: Lookups using dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab failed for: [wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local jessie_udp@dns-test-service-3.dns-7868.svc.cluster.local]

Oct  3 20:13:38.156: INFO: File wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local from pod  dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct  3 20:13:38.174: INFO: Lookups using dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab failed for: [wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local]

Oct  3 20:13:43.176: INFO: DNS probes using dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab succeeded

STEP: deleting the pod 10/03/22 20:13:43.176
STEP: changing the service to type=ClusterIP 10/03/22 20:13:43.205
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7868.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local; sleep 1; done
 10/03/22 20:13:43.25
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7868.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7868.svc.cluster.local; sleep 1; done
 10/03/22 20:13:43.251
STEP: creating a third pod to probe DNS 10/03/22 20:13:43.251
STEP: submitting the pod to kubernetes 10/03/22 20:13:43.263
Oct  3 20:13:43.277: INFO: Waiting up to 15m0s for pod "dns-test-9b2099c2-48dd-4c4b-86e2-0288f005710a" in namespace "dns-7868" to be "running"
Oct  3 20:13:43.292: INFO: Pod "dns-test-9b2099c2-48dd-4c4b-86e2-0288f005710a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.857654ms
Oct  3 20:13:45.304: INFO: Pod "dns-test-9b2099c2-48dd-4c4b-86e2-0288f005710a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026952726s
Oct  3 20:13:47.308: INFO: Pod "dns-test-9b2099c2-48dd-4c4b-86e2-0288f005710a": Phase="Running", Reason="", readiness=true. Elapsed: 4.030915426s
Oct  3 20:13:47.308: INFO: Pod "dns-test-9b2099c2-48dd-4c4b-86e2-0288f005710a" satisfied condition "running"
STEP: retrieving the pod 10/03/22 20:13:47.308
STEP: looking for the results for each expected name from probers 10/03/22 20:13:47.321
Oct  3 20:13:47.382: INFO: DNS probes using dns-test-9b2099c2-48dd-4c4b-86e2-0288f005710a succeeded

STEP: deleting the pod 10/03/22 20:13:47.382
STEP: deleting the test externalName service 10/03/22 20:13:47.413
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Oct  3 20:13:47.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7868" for this suite. 10/03/22 20:13:47.469
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":198,"skipped":3689,"failed":0}
------------------------------
• [SLOW TEST] [32.770 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:13:14.718
    Oct  3 20:13:14.719: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename dns 10/03/22 20:13:14.72
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:13:14.78
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:13:14.802
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 10/03/22 20:13:14.812
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7868.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local; sleep 1; done
     10/03/22 20:13:14.826
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7868.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7868.svc.cluster.local; sleep 1; done
     10/03/22 20:13:14.826
    STEP: creating a pod to probe DNS 10/03/22 20:13:14.826
    STEP: submitting the pod to kubernetes 10/03/22 20:13:14.826
    Oct  3 20:13:14.848: INFO: Waiting up to 15m0s for pod "dns-test-c41756b7-28eb-4fd0-b153-2694113dd38f" in namespace "dns-7868" to be "running"
    Oct  3 20:13:14.871: INFO: Pod "dns-test-c41756b7-28eb-4fd0-b153-2694113dd38f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.076881ms
    Oct  3 20:13:16.884: INFO: Pod "dns-test-c41756b7-28eb-4fd0-b153-2694113dd38f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035557602s
    Oct  3 20:13:18.883: INFO: Pod "dns-test-c41756b7-28eb-4fd0-b153-2694113dd38f": Phase="Running", Reason="", readiness=true. Elapsed: 4.034293213s
    Oct  3 20:13:18.883: INFO: Pod "dns-test-c41756b7-28eb-4fd0-b153-2694113dd38f" satisfied condition "running"
    STEP: retrieving the pod 10/03/22 20:13:18.883
    STEP: looking for the results for each expected name from probers 10/03/22 20:13:18.895
    Oct  3 20:13:18.956: INFO: DNS probes using dns-test-c41756b7-28eb-4fd0-b153-2694113dd38f succeeded

    STEP: deleting the pod 10/03/22 20:13:18.956
    STEP: changing the externalName to bar.example.com 10/03/22 20:13:18.992
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7868.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local; sleep 1; done
     10/03/22 20:13:19.016
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7868.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7868.svc.cluster.local; sleep 1; done
     10/03/22 20:13:19.017
    STEP: creating a second pod to probe DNS 10/03/22 20:13:19.017
    STEP: submitting the pod to kubernetes 10/03/22 20:13:19.017
    Oct  3 20:13:19.040: INFO: Waiting up to 15m0s for pod "dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab" in namespace "dns-7868" to be "running"
    Oct  3 20:13:19.053: INFO: Pod "dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab": Phase="Pending", Reason="", readiness=false. Elapsed: 13.038705ms
    Oct  3 20:13:21.067: INFO: Pod "dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027037433s
    Oct  3 20:13:23.069: INFO: Pod "dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab": Phase="Running", Reason="", readiness=true. Elapsed: 4.028710486s
    Oct  3 20:13:23.069: INFO: Pod "dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab" satisfied condition "running"
    STEP: retrieving the pod 10/03/22 20:13:23.069
    STEP: looking for the results for each expected name from probers 10/03/22 20:13:23.081
    Oct  3 20:13:23.119: INFO: File wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local from pod  dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Oct  3 20:13:23.137: INFO: File jessie_udp@dns-test-service-3.dns-7868.svc.cluster.local from pod  dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Oct  3 20:13:23.137: INFO: Lookups using dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab failed for: [wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local jessie_udp@dns-test-service-3.dns-7868.svc.cluster.local]

    Oct  3 20:13:28.158: INFO: File wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local from pod  dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Oct  3 20:13:28.177: INFO: Lookups using dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab failed for: [wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local]

    Oct  3 20:13:33.159: INFO: File wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local from pod  dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Oct  3 20:13:33.176: INFO: File jessie_udp@dns-test-service-3.dns-7868.svc.cluster.local from pod  dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Oct  3 20:13:33.177: INFO: Lookups using dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab failed for: [wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local jessie_udp@dns-test-service-3.dns-7868.svc.cluster.local]

    Oct  3 20:13:38.156: INFO: File wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local from pod  dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Oct  3 20:13:38.174: INFO: Lookups using dns-7868/dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab failed for: [wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local]

    Oct  3 20:13:43.176: INFO: DNS probes using dns-test-206a3e85-c26d-4b6e-b012-7ade99b182ab succeeded

    STEP: deleting the pod 10/03/22 20:13:43.176
    STEP: changing the service to type=ClusterIP 10/03/22 20:13:43.205
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7868.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7868.svc.cluster.local; sleep 1; done
     10/03/22 20:13:43.25
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7868.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7868.svc.cluster.local; sleep 1; done
     10/03/22 20:13:43.251
    STEP: creating a third pod to probe DNS 10/03/22 20:13:43.251
    STEP: submitting the pod to kubernetes 10/03/22 20:13:43.263
    Oct  3 20:13:43.277: INFO: Waiting up to 15m0s for pod "dns-test-9b2099c2-48dd-4c4b-86e2-0288f005710a" in namespace "dns-7868" to be "running"
    Oct  3 20:13:43.292: INFO: Pod "dns-test-9b2099c2-48dd-4c4b-86e2-0288f005710a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.857654ms
    Oct  3 20:13:45.304: INFO: Pod "dns-test-9b2099c2-48dd-4c4b-86e2-0288f005710a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026952726s
    Oct  3 20:13:47.308: INFO: Pod "dns-test-9b2099c2-48dd-4c4b-86e2-0288f005710a": Phase="Running", Reason="", readiness=true. Elapsed: 4.030915426s
    Oct  3 20:13:47.308: INFO: Pod "dns-test-9b2099c2-48dd-4c4b-86e2-0288f005710a" satisfied condition "running"
    STEP: retrieving the pod 10/03/22 20:13:47.308
    STEP: looking for the results for each expected name from probers 10/03/22 20:13:47.321
    Oct  3 20:13:47.382: INFO: DNS probes using dns-test-9b2099c2-48dd-4c4b-86e2-0288f005710a succeeded

    STEP: deleting the pod 10/03/22 20:13:47.382
    STEP: deleting the test externalName service 10/03/22 20:13:47.413
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Oct  3 20:13:47.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7868" for this suite. 10/03/22 20:13:47.469
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:13:47.491
Oct  3 20:13:47.491: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename pods 10/03/22 20:13:47.494
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:13:47.535
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:13:47.545
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 10/03/22 20:13:47.556
Oct  3 20:13:47.577: INFO: Waiting up to 5m0s for pod "pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace" in namespace "pods-7730" to be "running and ready"
Oct  3 20:13:47.590: INFO: Pod "pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace": Phase="Pending", Reason="", readiness=false. Elapsed: 12.799933ms
Oct  3 20:13:47.590: INFO: The phase of Pod pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:13:49.604: INFO: Pod "pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026738883s
Oct  3 20:13:49.604: INFO: The phase of Pod pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:13:51.602: INFO: Pod "pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace": Phase="Running", Reason="", readiness=true. Elapsed: 4.024495593s
Oct  3 20:13:51.602: INFO: The phase of Pod pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace is Running (Ready = true)
Oct  3 20:13:51.602: INFO: Pod "pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace" satisfied condition "running and ready"
Oct  3 20:13:51.623: INFO: Pod pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace has hostIP: 10.63.128.3
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Oct  3 20:13:51.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7730" for this suite. 10/03/22 20:13:51.637
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":199,"skipped":3692,"failed":0}
------------------------------
• [4.167 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:13:47.491
    Oct  3 20:13:47.491: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename pods 10/03/22 20:13:47.494
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:13:47.535
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:13:47.545
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 10/03/22 20:13:47.556
    Oct  3 20:13:47.577: INFO: Waiting up to 5m0s for pod "pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace" in namespace "pods-7730" to be "running and ready"
    Oct  3 20:13:47.590: INFO: Pod "pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace": Phase="Pending", Reason="", readiness=false. Elapsed: 12.799933ms
    Oct  3 20:13:47.590: INFO: The phase of Pod pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:13:49.604: INFO: Pod "pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026738883s
    Oct  3 20:13:49.604: INFO: The phase of Pod pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:13:51.602: INFO: Pod "pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace": Phase="Running", Reason="", readiness=true. Elapsed: 4.024495593s
    Oct  3 20:13:51.602: INFO: The phase of Pod pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace is Running (Ready = true)
    Oct  3 20:13:51.602: INFO: Pod "pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace" satisfied condition "running and ready"
    Oct  3 20:13:51.623: INFO: Pod pod-hostip-a9111efd-7a7d-48f0-ab32-3352e4c15ace has hostIP: 10.63.128.3
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Oct  3 20:13:51.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7730" for this suite. 10/03/22 20:13:51.637
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:13:51.659
Oct  3 20:13:51.660: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 20:13:51.661
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:13:51.701
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:13:51.712
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-26d15de6-b270-4bf5-a319-1941b4e8f3e5 10/03/22 20:13:51.722
STEP: Creating a pod to test consume secrets 10/03/22 20:13:51.737
Oct  3 20:13:51.781: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6" in namespace "projected-611" to be "Succeeded or Failed"
Oct  3 20:13:51.794: INFO: Pod "pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6": Phase="Pending", Reason="", readiness=false. Elapsed: 13.03296ms
Oct  3 20:13:53.807: INFO: Pod "pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025403422s
Oct  3 20:13:55.808: INFO: Pod "pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026407606s
Oct  3 20:13:57.807: INFO: Pod "pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025723795s
STEP: Saw pod success 10/03/22 20:13:57.807
Oct  3 20:13:57.807: INFO: Pod "pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6" satisfied condition "Succeeded or Failed"
Oct  3 20:13:57.818: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6 container projected-secret-volume-test: <nil>
STEP: delete the pod 10/03/22 20:13:57.891
Oct  3 20:13:57.926: INFO: Waiting for pod pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6 to disappear
Oct  3 20:13:57.939: INFO: Pod pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Oct  3 20:13:57.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-611" for this suite. 10/03/22 20:13:57.956
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":200,"skipped":3694,"failed":0}
------------------------------
• [SLOW TEST] [6.316 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:13:51.659
    Oct  3 20:13:51.660: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 20:13:51.661
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:13:51.701
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:13:51.712
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-26d15de6-b270-4bf5-a319-1941b4e8f3e5 10/03/22 20:13:51.722
    STEP: Creating a pod to test consume secrets 10/03/22 20:13:51.737
    Oct  3 20:13:51.781: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6" in namespace "projected-611" to be "Succeeded or Failed"
    Oct  3 20:13:51.794: INFO: Pod "pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6": Phase="Pending", Reason="", readiness=false. Elapsed: 13.03296ms
    Oct  3 20:13:53.807: INFO: Pod "pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025403422s
    Oct  3 20:13:55.808: INFO: Pod "pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026407606s
    Oct  3 20:13:57.807: INFO: Pod "pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025723795s
    STEP: Saw pod success 10/03/22 20:13:57.807
    Oct  3 20:13:57.807: INFO: Pod "pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6" satisfied condition "Succeeded or Failed"
    Oct  3 20:13:57.818: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6 container projected-secret-volume-test: <nil>
    STEP: delete the pod 10/03/22 20:13:57.891
    Oct  3 20:13:57.926: INFO: Waiting for pod pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6 to disappear
    Oct  3 20:13:57.939: INFO: Pod pod-projected-secrets-90e33c23-20ca-4e11-ac43-49f017ae5ea6 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Oct  3 20:13:57.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-611" for this suite. 10/03/22 20:13:57.956
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:13:57.98
Oct  3 20:13:57.980: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename var-expansion 10/03/22 20:13:57.981
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:13:58.016
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:13:58.027
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 10/03/22 20:13:58.038
Oct  3 20:13:58.059: INFO: Waiting up to 5m0s for pod "var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1" in namespace "var-expansion-9324" to be "Succeeded or Failed"
Oct  3 20:13:58.103: INFO: Pod "var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1": Phase="Pending", Reason="", readiness=false. Elapsed: 44.171127ms
Oct  3 20:14:00.117: INFO: Pod "var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057711316s
Oct  3 20:14:02.115: INFO: Pod "var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.056238237s
Oct  3 20:14:04.117: INFO: Pod "var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.057896809s
STEP: Saw pod success 10/03/22 20:14:04.117
Oct  3 20:14:04.117: INFO: Pod "var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1" satisfied condition "Succeeded or Failed"
Oct  3 20:14:04.129: INFO: Trying to get logs from node 10.63.128.3 pod var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1 container dapi-container: <nil>
STEP: delete the pod 10/03/22 20:14:04.156
Oct  3 20:14:04.183: INFO: Waiting for pod var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1 to disappear
Oct  3 20:14:04.194: INFO: Pod var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Oct  3 20:14:04.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9324" for this suite. 10/03/22 20:14:04.21
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":201,"skipped":3707,"failed":0}
------------------------------
• [SLOW TEST] [6.251 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:13:57.98
    Oct  3 20:13:57.980: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename var-expansion 10/03/22 20:13:57.981
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:13:58.016
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:13:58.027
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 10/03/22 20:13:58.038
    Oct  3 20:13:58.059: INFO: Waiting up to 5m0s for pod "var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1" in namespace "var-expansion-9324" to be "Succeeded or Failed"
    Oct  3 20:13:58.103: INFO: Pod "var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1": Phase="Pending", Reason="", readiness=false. Elapsed: 44.171127ms
    Oct  3 20:14:00.117: INFO: Pod "var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057711316s
    Oct  3 20:14:02.115: INFO: Pod "var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.056238237s
    Oct  3 20:14:04.117: INFO: Pod "var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.057896809s
    STEP: Saw pod success 10/03/22 20:14:04.117
    Oct  3 20:14:04.117: INFO: Pod "var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1" satisfied condition "Succeeded or Failed"
    Oct  3 20:14:04.129: INFO: Trying to get logs from node 10.63.128.3 pod var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1 container dapi-container: <nil>
    STEP: delete the pod 10/03/22 20:14:04.156
    Oct  3 20:14:04.183: INFO: Waiting for pod var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1 to disappear
    Oct  3 20:14:04.194: INFO: Pod var-expansion-107bd7b3-bef2-4576-ae33-72684bc829b1 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Oct  3 20:14:04.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-9324" for this suite. 10/03/22 20:14:04.21
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:14:04.232
Oct  3 20:14:04.232: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 20:14:04.234
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:14:04.269
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:14:04.28
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-7123 10/03/22 20:14:04.291
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 10/03/22 20:14:04.34
STEP: creating service externalsvc in namespace services-7123 10/03/22 20:14:04.34
STEP: creating replication controller externalsvc in namespace services-7123 10/03/22 20:14:04.372
I1003 20:14:04.388425      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7123, replica count: 2
I1003 20:14:07.440033      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 10/03/22 20:14:07.452
Oct  3 20:14:07.512: INFO: Creating new exec pod
Oct  3 20:14:07.526: INFO: Waiting up to 5m0s for pod "execpodq244b" in namespace "services-7123" to be "running"
Oct  3 20:14:07.538: INFO: Pod "execpodq244b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.980486ms
Oct  3 20:14:09.552: INFO: Pod "execpodq244b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025409338s
Oct  3 20:14:11.552: INFO: Pod "execpodq244b": Phase="Running", Reason="", readiness=true. Elapsed: 4.026063327s
Oct  3 20:14:11.552: INFO: Pod "execpodq244b" satisfied condition "running"
Oct  3 20:14:11.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-7123 exec execpodq244b -- /bin/sh -x -c nslookup nodeport-service.services-7123.svc.cluster.local'
Oct  3 20:14:11.875: INFO: stderr: "+ nslookup nodeport-service.services-7123.svc.cluster.local\n"
Oct  3 20:14:11.875: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nnodeport-service.services-7123.svc.cluster.local\tcanonical name = externalsvc.services-7123.svc.cluster.local.\nName:\texternalsvc.services-7123.svc.cluster.local\nAddress: 172.21.34.161\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7123, will wait for the garbage collector to delete the pods 10/03/22 20:14:11.875
Oct  3 20:14:12.005: INFO: Deleting ReplicationController externalsvc took: 65.64769ms
Oct  3 20:14:12.106: INFO: Terminating ReplicationController externalsvc pods took: 100.893634ms
Oct  3 20:14:14.862: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 20:14:14.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7123" for this suite. 10/03/22 20:14:14.911
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":202,"skipped":3707,"failed":0}
------------------------------
• [SLOW TEST] [10.698 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:14:04.232
    Oct  3 20:14:04.232: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 20:14:04.234
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:14:04.269
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:14:04.28
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-7123 10/03/22 20:14:04.291
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 10/03/22 20:14:04.34
    STEP: creating service externalsvc in namespace services-7123 10/03/22 20:14:04.34
    STEP: creating replication controller externalsvc in namespace services-7123 10/03/22 20:14:04.372
    I1003 20:14:04.388425      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7123, replica count: 2
    I1003 20:14:07.440033      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 10/03/22 20:14:07.452
    Oct  3 20:14:07.512: INFO: Creating new exec pod
    Oct  3 20:14:07.526: INFO: Waiting up to 5m0s for pod "execpodq244b" in namespace "services-7123" to be "running"
    Oct  3 20:14:07.538: INFO: Pod "execpodq244b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.980486ms
    Oct  3 20:14:09.552: INFO: Pod "execpodq244b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025409338s
    Oct  3 20:14:11.552: INFO: Pod "execpodq244b": Phase="Running", Reason="", readiness=true. Elapsed: 4.026063327s
    Oct  3 20:14:11.552: INFO: Pod "execpodq244b" satisfied condition "running"
    Oct  3 20:14:11.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-7123 exec execpodq244b -- /bin/sh -x -c nslookup nodeport-service.services-7123.svc.cluster.local'
    Oct  3 20:14:11.875: INFO: stderr: "+ nslookup nodeport-service.services-7123.svc.cluster.local\n"
    Oct  3 20:14:11.875: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nnodeport-service.services-7123.svc.cluster.local\tcanonical name = externalsvc.services-7123.svc.cluster.local.\nName:\texternalsvc.services-7123.svc.cluster.local\nAddress: 172.21.34.161\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-7123, will wait for the garbage collector to delete the pods 10/03/22 20:14:11.875
    Oct  3 20:14:12.005: INFO: Deleting ReplicationController externalsvc took: 65.64769ms
    Oct  3 20:14:12.106: INFO: Terminating ReplicationController externalsvc pods took: 100.893634ms
    Oct  3 20:14:14.862: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 20:14:14.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7123" for this suite. 10/03/22 20:14:14.911
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:14:14.932
Oct  3 20:14:14.933: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 20:14:14.934
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:14:14.971
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:14:14.982
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-8913d944-dad0-4e93-81a8-5183e2d30515 10/03/22 20:14:14.992
STEP: Creating a pod to test consume secrets 10/03/22 20:14:15.01
Oct  3 20:14:15.031: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113" in namespace "projected-5254" to be "Succeeded or Failed"
Oct  3 20:14:15.044: INFO: Pod "pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113": Phase="Pending", Reason="", readiness=false. Elapsed: 12.620135ms
Oct  3 20:14:17.056: INFO: Pod "pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113": Phase="Running", Reason="", readiness=true. Elapsed: 2.025401186s
Oct  3 20:14:19.058: INFO: Pod "pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113": Phase="Running", Reason="", readiness=false. Elapsed: 4.027263634s
Oct  3 20:14:21.057: INFO: Pod "pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026302116s
STEP: Saw pod success 10/03/22 20:14:21.057
Oct  3 20:14:21.058: INFO: Pod "pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113" satisfied condition "Succeeded or Failed"
Oct  3 20:14:21.069: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113 container projected-secret-volume-test: <nil>
STEP: delete the pod 10/03/22 20:14:21.095
Oct  3 20:14:21.126: INFO: Waiting for pod pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113 to disappear
Oct  3 20:14:21.137: INFO: Pod pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Oct  3 20:14:21.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5254" for this suite. 10/03/22 20:14:21.154
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":203,"skipped":3717,"failed":0}
------------------------------
• [SLOW TEST] [6.244 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:14:14.932
    Oct  3 20:14:14.933: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 20:14:14.934
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:14:14.971
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:14:14.982
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-8913d944-dad0-4e93-81a8-5183e2d30515 10/03/22 20:14:14.992
    STEP: Creating a pod to test consume secrets 10/03/22 20:14:15.01
    Oct  3 20:14:15.031: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113" in namespace "projected-5254" to be "Succeeded or Failed"
    Oct  3 20:14:15.044: INFO: Pod "pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113": Phase="Pending", Reason="", readiness=false. Elapsed: 12.620135ms
    Oct  3 20:14:17.056: INFO: Pod "pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113": Phase="Running", Reason="", readiness=true. Elapsed: 2.025401186s
    Oct  3 20:14:19.058: INFO: Pod "pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113": Phase="Running", Reason="", readiness=false. Elapsed: 4.027263634s
    Oct  3 20:14:21.057: INFO: Pod "pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026302116s
    STEP: Saw pod success 10/03/22 20:14:21.057
    Oct  3 20:14:21.058: INFO: Pod "pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113" satisfied condition "Succeeded or Failed"
    Oct  3 20:14:21.069: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113 container projected-secret-volume-test: <nil>
    STEP: delete the pod 10/03/22 20:14:21.095
    Oct  3 20:14:21.126: INFO: Waiting for pod pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113 to disappear
    Oct  3 20:14:21.137: INFO: Pod pod-projected-secrets-ae7ccdec-ae5b-46e9-98f0-17cf595b8113 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Oct  3 20:14:21.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5254" for this suite. 10/03/22 20:14:21.154
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:14:21.19
Oct  3 20:14:21.190: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename certificates 10/03/22 20:14:21.191
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:14:21.228
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:14:21.239
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 10/03/22 20:14:22.001
STEP: getting /apis/certificates.k8s.io 10/03/22 20:14:22.012
STEP: getting /apis/certificates.k8s.io/v1 10/03/22 20:14:22.017
STEP: creating 10/03/22 20:14:22.022
STEP: getting 10/03/22 20:14:22.061
STEP: listing 10/03/22 20:14:22.072
STEP: watching 10/03/22 20:14:22.083
Oct  3 20:14:22.083: INFO: starting watch
STEP: patching 10/03/22 20:14:22.088
STEP: updating 10/03/22 20:14:22.102
Oct  3 20:14:22.116: INFO: waiting for watch events with expected annotations
Oct  3 20:14:22.116: INFO: saw patched and updated annotations
STEP: getting /approval 10/03/22 20:14:22.116
STEP: patching /approval 10/03/22 20:14:22.128
STEP: updating /approval 10/03/22 20:14:22.142
STEP: getting /status 10/03/22 20:14:22.157
STEP: patching /status 10/03/22 20:14:22.169
STEP: updating /status 10/03/22 20:14:22.184
STEP: deleting 10/03/22 20:14:22.205
STEP: deleting a collection 10/03/22 20:14:22.249
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:14:22.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-6566" for this suite. 10/03/22 20:14:22.317
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":204,"skipped":3846,"failed":0}
------------------------------
• [1.147 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:14:21.19
    Oct  3 20:14:21.190: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename certificates 10/03/22 20:14:21.191
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:14:21.228
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:14:21.239
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 10/03/22 20:14:22.001
    STEP: getting /apis/certificates.k8s.io 10/03/22 20:14:22.012
    STEP: getting /apis/certificates.k8s.io/v1 10/03/22 20:14:22.017
    STEP: creating 10/03/22 20:14:22.022
    STEP: getting 10/03/22 20:14:22.061
    STEP: listing 10/03/22 20:14:22.072
    STEP: watching 10/03/22 20:14:22.083
    Oct  3 20:14:22.083: INFO: starting watch
    STEP: patching 10/03/22 20:14:22.088
    STEP: updating 10/03/22 20:14:22.102
    Oct  3 20:14:22.116: INFO: waiting for watch events with expected annotations
    Oct  3 20:14:22.116: INFO: saw patched and updated annotations
    STEP: getting /approval 10/03/22 20:14:22.116
    STEP: patching /approval 10/03/22 20:14:22.128
    STEP: updating /approval 10/03/22 20:14:22.142
    STEP: getting /status 10/03/22 20:14:22.157
    STEP: patching /status 10/03/22 20:14:22.169
    STEP: updating /status 10/03/22 20:14:22.184
    STEP: deleting 10/03/22 20:14:22.205
    STEP: deleting a collection 10/03/22 20:14:22.249
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:14:22.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-6566" for this suite. 10/03/22 20:14:22.317
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:14:22.343
Oct  3 20:14:22.343: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename configmap 10/03/22 20:14:22.345
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:14:22.38
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:14:22.392
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Oct  3 20:14:22.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7366" for this suite. 10/03/22 20:14:22.578
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":205,"skipped":3871,"failed":0}
------------------------------
• [0.255 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:14:22.343
    Oct  3 20:14:22.343: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename configmap 10/03/22 20:14:22.345
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:14:22.38
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:14:22.392
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Oct  3 20:14:22.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7366" for this suite. 10/03/22 20:14:22.578
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:14:22.599
Oct  3 20:14:22.599: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 20:14:22.6
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:14:22.632
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:14:22.643
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-8d61f591-a96c-469e-8b9a-29118adea765 10/03/22 20:14:22.684
STEP: Creating configMap with name cm-test-opt-upd-d7191f2d-b1ca-47ec-a107-503e550c1bd8 10/03/22 20:14:22.699
STEP: Creating the pod 10/03/22 20:14:22.715
Oct  3 20:14:22.737: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351" in namespace "projected-4689" to be "running and ready"
Oct  3 20:14:22.752: INFO: Pod "pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351": Phase="Pending", Reason="", readiness=false. Elapsed: 14.640056ms
Oct  3 20:14:22.752: INFO: The phase of Pod pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:14:24.766: INFO: Pod "pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028138685s
Oct  3 20:14:24.766: INFO: The phase of Pod pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:14:26.767: INFO: Pod "pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351": Phase="Running", Reason="", readiness=true. Elapsed: 4.029116349s
Oct  3 20:14:26.767: INFO: The phase of Pod pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351 is Running (Ready = true)
Oct  3 20:14:26.767: INFO: Pod "pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-8d61f591-a96c-469e-8b9a-29118adea765 10/03/22 20:14:26.932
STEP: Updating configmap cm-test-opt-upd-d7191f2d-b1ca-47ec-a107-503e550c1bd8 10/03/22 20:14:26.95
STEP: Creating configMap with name cm-test-opt-create-ea84826f-e421-499a-b5ec-79a43393d315 10/03/22 20:14:26.964
STEP: waiting to observe update in volume 10/03/22 20:14:26.988
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Oct  3 20:15:54.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4689" for this suite. 10/03/22 20:15:54.547
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":206,"skipped":3874,"failed":0}
------------------------------
• [SLOW TEST] [91.971 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:14:22.599
    Oct  3 20:14:22.599: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 20:14:22.6
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:14:22.632
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:14:22.643
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-8d61f591-a96c-469e-8b9a-29118adea765 10/03/22 20:14:22.684
    STEP: Creating configMap with name cm-test-opt-upd-d7191f2d-b1ca-47ec-a107-503e550c1bd8 10/03/22 20:14:22.699
    STEP: Creating the pod 10/03/22 20:14:22.715
    Oct  3 20:14:22.737: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351" in namespace "projected-4689" to be "running and ready"
    Oct  3 20:14:22.752: INFO: Pod "pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351": Phase="Pending", Reason="", readiness=false. Elapsed: 14.640056ms
    Oct  3 20:14:22.752: INFO: The phase of Pod pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:14:24.766: INFO: Pod "pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028138685s
    Oct  3 20:14:24.766: INFO: The phase of Pod pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:14:26.767: INFO: Pod "pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351": Phase="Running", Reason="", readiness=true. Elapsed: 4.029116349s
    Oct  3 20:14:26.767: INFO: The phase of Pod pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351 is Running (Ready = true)
    Oct  3 20:14:26.767: INFO: Pod "pod-projected-configmaps-b02c28a7-e7db-47fd-a658-e8fc34077351" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-8d61f591-a96c-469e-8b9a-29118adea765 10/03/22 20:14:26.932
    STEP: Updating configmap cm-test-opt-upd-d7191f2d-b1ca-47ec-a107-503e550c1bd8 10/03/22 20:14:26.95
    STEP: Creating configMap with name cm-test-opt-create-ea84826f-e421-499a-b5ec-79a43393d315 10/03/22 20:14:26.964
    STEP: waiting to observe update in volume 10/03/22 20:14:26.988
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Oct  3 20:15:54.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4689" for this suite. 10/03/22 20:15:54.547
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:15:54.571
Oct  3 20:15:54.571: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename watch 10/03/22 20:15:54.573
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:15:54.617
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:15:54.629
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 10/03/22 20:15:54.639
STEP: creating a watch on configmaps with label B 10/03/22 20:15:54.645
STEP: creating a watch on configmaps with label A or B 10/03/22 20:15:54.65
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 10/03/22 20:15:54.655
Oct  3 20:15:54.667: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32083 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Oct  3 20:15:54.668: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32083 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 10/03/22 20:15:54.668
Oct  3 20:15:54.693: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32084 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct  3 20:15:54.693: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32084 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 10/03/22 20:15:54.694
Oct  3 20:15:54.715: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32085 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct  3 20:15:54.715: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32085 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 10/03/22 20:15:54.715
Oct  3 20:15:54.741: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32086 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct  3 20:15:54.741: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32086 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 10/03/22 20:15:54.741
Oct  3 20:15:54.755: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2425  bf4a06ef-512f-4033-8e1f-f595d9cb8585 32087 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Oct  3 20:15:54.756: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2425  bf4a06ef-512f-4033-8e1f-f595d9cb8585 32087 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 10/03/22 20:16:04.756
Oct  3 20:16:04.775: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2425  bf4a06ef-512f-4033-8e1f-f595d9cb8585 32121 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Oct  3 20:16:04.775: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2425  bf4a06ef-512f-4033-8e1f-f595d9cb8585 32121 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Oct  3 20:16:14.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2425" for this suite. 10/03/22 20:16:14.797
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":207,"skipped":3880,"failed":0}
------------------------------
• [SLOW TEST] [20.248 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:15:54.571
    Oct  3 20:15:54.571: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename watch 10/03/22 20:15:54.573
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:15:54.617
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:15:54.629
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 10/03/22 20:15:54.639
    STEP: creating a watch on configmaps with label B 10/03/22 20:15:54.645
    STEP: creating a watch on configmaps with label A or B 10/03/22 20:15:54.65
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 10/03/22 20:15:54.655
    Oct  3 20:15:54.667: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32083 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct  3 20:15:54.668: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32083 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 10/03/22 20:15:54.668
    Oct  3 20:15:54.693: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32084 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct  3 20:15:54.693: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32084 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 10/03/22 20:15:54.694
    Oct  3 20:15:54.715: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32085 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct  3 20:15:54.715: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32085 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 10/03/22 20:15:54.715
    Oct  3 20:15:54.741: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32086 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct  3 20:15:54.741: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2425  11267967-e86d-47df-b091-d8212cfedec2 32086 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 10/03/22 20:15:54.741
    Oct  3 20:15:54.755: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2425  bf4a06ef-512f-4033-8e1f-f595d9cb8585 32087 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct  3 20:15:54.756: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2425  bf4a06ef-512f-4033-8e1f-f595d9cb8585 32087 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 10/03/22 20:16:04.756
    Oct  3 20:16:04.775: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2425  bf4a06ef-512f-4033-8e1f-f595d9cb8585 32121 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct  3 20:16:04.775: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2425  bf4a06ef-512f-4033-8e1f-f595d9cb8585 32121 0 2022-10-03 20:15:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-10-03 20:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Oct  3 20:16:14.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2425" for this suite. 10/03/22 20:16:14.797
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:16:14.822
Oct  3 20:16:14.822: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename ingress 10/03/22 20:16:14.823
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:16:14.873
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:16:14.884
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 10/03/22 20:16:14.894
STEP: getting /apis/networking.k8s.io 10/03/22 20:16:14.903
STEP: getting /apis/networking.k8s.iov1 10/03/22 20:16:14.907
STEP: creating 10/03/22 20:16:14.911
STEP: getting 10/03/22 20:16:14.96
STEP: listing 10/03/22 20:16:14.987
STEP: watching 10/03/22 20:16:15.007
Oct  3 20:16:15.008: INFO: starting watch
STEP: cluster-wide listing 10/03/22 20:16:15.038
STEP: cluster-wide watching 10/03/22 20:16:15.06
Oct  3 20:16:15.067: INFO: starting watch
STEP: patching 10/03/22 20:16:15.072
STEP: updating 10/03/22 20:16:15.1
Oct  3 20:16:15.160: INFO: waiting for watch events with expected annotations
Oct  3 20:16:15.160: INFO: saw patched and updated annotations
STEP: patching /status 10/03/22 20:16:15.16
STEP: updating /status 10/03/22 20:16:15.185
STEP: get /status 10/03/22 20:16:15.216
STEP: deleting 10/03/22 20:16:15.236
STEP: deleting a collection 10/03/22 20:16:15.28
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Oct  3 20:16:15.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-1845" for this suite. 10/03/22 20:16:15.36
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":208,"skipped":3919,"failed":0}
------------------------------
• [0.560 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:16:14.822
    Oct  3 20:16:14.822: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename ingress 10/03/22 20:16:14.823
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:16:14.873
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:16:14.884
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 10/03/22 20:16:14.894
    STEP: getting /apis/networking.k8s.io 10/03/22 20:16:14.903
    STEP: getting /apis/networking.k8s.iov1 10/03/22 20:16:14.907
    STEP: creating 10/03/22 20:16:14.911
    STEP: getting 10/03/22 20:16:14.96
    STEP: listing 10/03/22 20:16:14.987
    STEP: watching 10/03/22 20:16:15.007
    Oct  3 20:16:15.008: INFO: starting watch
    STEP: cluster-wide listing 10/03/22 20:16:15.038
    STEP: cluster-wide watching 10/03/22 20:16:15.06
    Oct  3 20:16:15.067: INFO: starting watch
    STEP: patching 10/03/22 20:16:15.072
    STEP: updating 10/03/22 20:16:15.1
    Oct  3 20:16:15.160: INFO: waiting for watch events with expected annotations
    Oct  3 20:16:15.160: INFO: saw patched and updated annotations
    STEP: patching /status 10/03/22 20:16:15.16
    STEP: updating /status 10/03/22 20:16:15.185
    STEP: get /status 10/03/22 20:16:15.216
    STEP: deleting 10/03/22 20:16:15.236
    STEP: deleting a collection 10/03/22 20:16:15.28
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Oct  3 20:16:15.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-1845" for this suite. 10/03/22 20:16:15.36
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:16:15.391
Oct  3 20:16:15.391: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 20:16:15.392
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:16:15.435
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:16:15.446
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-218 10/03/22 20:16:15.456
Oct  3 20:16:15.486: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-218" to be "running and ready"
Oct  3 20:16:15.501: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 14.236242ms
Oct  3 20:16:15.501: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:16:17.517: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.030155143s
Oct  3 20:16:17.517: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Oct  3 20:16:17.517: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Oct  3 20:16:17.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Oct  3 20:16:17.823: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Oct  3 20:16:17.823: INFO: stdout: "iptables"
Oct  3 20:16:17.823: INFO: proxyMode: iptables
Oct  3 20:16:17.866: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Oct  3 20:16:17.879: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-218 10/03/22 20:16:17.88
STEP: creating replication controller affinity-nodeport-timeout in namespace services-218 10/03/22 20:16:17.93
I1003 20:16:17.945408      22 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-218, replica count: 3
I1003 20:16:20.996229      22 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  3 20:16:21.042: INFO: Creating new exec pod
Oct  3 20:16:21.060: INFO: Waiting up to 5m0s for pod "execpod-affinitykfqrp" in namespace "services-218" to be "running"
Oct  3 20:16:21.078: INFO: Pod "execpod-affinitykfqrp": Phase="Pending", Reason="", readiness=false. Elapsed: 17.512299ms
Oct  3 20:16:23.093: INFO: Pod "execpod-affinitykfqrp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032619698s
Oct  3 20:16:25.093: INFO: Pod "execpod-affinitykfqrp": Phase="Running", Reason="", readiness=true. Elapsed: 4.032581686s
Oct  3 20:16:25.093: INFO: Pod "execpod-affinitykfqrp" satisfied condition "running"
Oct  3 20:16:26.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Oct  3 20:16:26.450: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Oct  3 20:16:26.450: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:16:26.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.60.213 80'
Oct  3 20:16:26.785: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.60.213 80\nConnection to 172.21.60.213 80 port [tcp/http] succeeded!\n"
Oct  3 20:16:26.785: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:16:26.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.13 30828'
Oct  3 20:16:27.106: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.13 30828\nConnection to 10.63.128.13 30828 port [tcp/*] succeeded!\n"
Oct  3 20:16:27.106: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:16:27.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.3 30828'
Oct  3 20:16:27.399: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.3 30828\nConnection to 10.63.128.3 30828 port [tcp/*] succeeded!\n"
Oct  3 20:16:27.399: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:16:27.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.63.128.13:30828/ ; done'
Oct  3 20:16:27.807: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n"
Oct  3 20:16:27.807: INFO: stdout: "\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv"
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
Oct  3 20:16:27.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.63.128.13:30828/'
Oct  3 20:16:28.138: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n"
Oct  3 20:16:28.138: INFO: stdout: "affinity-nodeport-timeout-4jgmv"
Oct  3 20:16:48.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.63.128.13:30828/'
Oct  3 20:16:48.446: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n"
Oct  3 20:16:48.446: INFO: stdout: "affinity-nodeport-timeout-4jgmv"
Oct  3 20:17:08.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.63.128.13:30828/'
Oct  3 20:17:08.933: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n"
Oct  3 20:17:08.933: INFO: stdout: "affinity-nodeport-timeout-l985k"
Oct  3 20:17:08.933: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-218, will wait for the garbage collector to delete the pods 10/03/22 20:17:08.974
Oct  3 20:17:09.053: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 18.418266ms
Oct  3 20:17:09.153: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.401692ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 20:17:11.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-218" for this suite. 10/03/22 20:17:11.943
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":209,"skipped":3964,"failed":0}
------------------------------
• [SLOW TEST] [56.594 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:16:15.391
    Oct  3 20:16:15.391: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 20:16:15.392
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:16:15.435
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:16:15.446
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-218 10/03/22 20:16:15.456
    Oct  3 20:16:15.486: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-218" to be "running and ready"
    Oct  3 20:16:15.501: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 14.236242ms
    Oct  3 20:16:15.501: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:16:17.517: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.030155143s
    Oct  3 20:16:17.517: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Oct  3 20:16:17.517: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Oct  3 20:16:17.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Oct  3 20:16:17.823: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Oct  3 20:16:17.823: INFO: stdout: "iptables"
    Oct  3 20:16:17.823: INFO: proxyMode: iptables
    Oct  3 20:16:17.866: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Oct  3 20:16:17.879: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-218 10/03/22 20:16:17.88
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-218 10/03/22 20:16:17.93
    I1003 20:16:17.945408      22 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-218, replica count: 3
    I1003 20:16:20.996229      22 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct  3 20:16:21.042: INFO: Creating new exec pod
    Oct  3 20:16:21.060: INFO: Waiting up to 5m0s for pod "execpod-affinitykfqrp" in namespace "services-218" to be "running"
    Oct  3 20:16:21.078: INFO: Pod "execpod-affinitykfqrp": Phase="Pending", Reason="", readiness=false. Elapsed: 17.512299ms
    Oct  3 20:16:23.093: INFO: Pod "execpod-affinitykfqrp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032619698s
    Oct  3 20:16:25.093: INFO: Pod "execpod-affinitykfqrp": Phase="Running", Reason="", readiness=true. Elapsed: 4.032581686s
    Oct  3 20:16:25.093: INFO: Pod "execpod-affinitykfqrp" satisfied condition "running"
    Oct  3 20:16:26.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Oct  3 20:16:26.450: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Oct  3 20:16:26.450: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:16:26.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.60.213 80'
    Oct  3 20:16:26.785: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.60.213 80\nConnection to 172.21.60.213 80 port [tcp/http] succeeded!\n"
    Oct  3 20:16:26.785: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:16:26.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.13 30828'
    Oct  3 20:16:27.106: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.13 30828\nConnection to 10.63.128.13 30828 port [tcp/*] succeeded!\n"
    Oct  3 20:16:27.106: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:16:27.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.3 30828'
    Oct  3 20:16:27.399: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.3 30828\nConnection to 10.63.128.3 30828 port [tcp/*] succeeded!\n"
    Oct  3 20:16:27.399: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:16:27.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.63.128.13:30828/ ; done'
    Oct  3 20:16:27.807: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n"
    Oct  3 20:16:27.807: INFO: stdout: "\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv\naffinity-nodeport-timeout-4jgmv"
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Received response from host: affinity-nodeport-timeout-4jgmv
    Oct  3 20:16:27.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.63.128.13:30828/'
    Oct  3 20:16:28.138: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n"
    Oct  3 20:16:28.138: INFO: stdout: "affinity-nodeport-timeout-4jgmv"
    Oct  3 20:16:48.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.63.128.13:30828/'
    Oct  3 20:16:48.446: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n"
    Oct  3 20:16:48.446: INFO: stdout: "affinity-nodeport-timeout-4jgmv"
    Oct  3 20:17:08.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-218 exec execpod-affinitykfqrp -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.63.128.13:30828/'
    Oct  3 20:17:08.933: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.63.128.13:30828/\n"
    Oct  3 20:17:08.933: INFO: stdout: "affinity-nodeport-timeout-l985k"
    Oct  3 20:17:08.933: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-218, will wait for the garbage collector to delete the pods 10/03/22 20:17:08.974
    Oct  3 20:17:09.053: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 18.418266ms
    Oct  3 20:17:09.153: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.401692ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 20:17:11.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-218" for this suite. 10/03/22 20:17:11.943
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:17:11.992
Oct  3 20:17:11.993: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 20:17:11.994
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:12.049
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:12.059
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 20:17:12.117
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:17:12.749
STEP: Deploying the webhook pod 10/03/22 20:17:12.769
STEP: Wait for the deployment to be ready 10/03/22 20:17:12.804
Oct  3 20:17:12.830: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/03/22 20:17:14.875
STEP: Verifying the service has paired with the endpoint 10/03/22 20:17:14.905
Oct  3 20:17:15.906: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 10/03/22 20:17:15.917
STEP: Creating a configMap that does not comply to the validation webhook rules 10/03/22 20:17:15.992
STEP: Updating a validating webhook configuration's rules to not include the create operation 10/03/22 20:17:16.046
STEP: Creating a configMap that does not comply to the validation webhook rules 10/03/22 20:17:16.072
STEP: Patching a validating webhook configuration's rules to include the create operation 10/03/22 20:17:16.1
STEP: Creating a configMap that does not comply to the validation webhook rules 10/03/22 20:17:16.113
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:17:16.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9343" for this suite. 10/03/22 20:17:16.162
STEP: Destroying namespace "webhook-9343-markers" for this suite. 10/03/22 20:17:16.186
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":210,"skipped":4008,"failed":0}
------------------------------
• [4.322 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:17:11.992
    Oct  3 20:17:11.993: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 20:17:11.994
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:12.049
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:12.059
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 20:17:12.117
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:17:12.749
    STEP: Deploying the webhook pod 10/03/22 20:17:12.769
    STEP: Wait for the deployment to be ready 10/03/22 20:17:12.804
    Oct  3 20:17:12.830: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/03/22 20:17:14.875
    STEP: Verifying the service has paired with the endpoint 10/03/22 20:17:14.905
    Oct  3 20:17:15.906: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 10/03/22 20:17:15.917
    STEP: Creating a configMap that does not comply to the validation webhook rules 10/03/22 20:17:15.992
    STEP: Updating a validating webhook configuration's rules to not include the create operation 10/03/22 20:17:16.046
    STEP: Creating a configMap that does not comply to the validation webhook rules 10/03/22 20:17:16.072
    STEP: Patching a validating webhook configuration's rules to include the create operation 10/03/22 20:17:16.1
    STEP: Creating a configMap that does not comply to the validation webhook rules 10/03/22 20:17:16.113
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:17:16.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9343" for this suite. 10/03/22 20:17:16.162
    STEP: Destroying namespace "webhook-9343-markers" for this suite. 10/03/22 20:17:16.186
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:17:16.315
Oct  3 20:17:16.315: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename svcaccounts 10/03/22 20:17:16.316
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:16.357
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:16.369
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  10/03/22 20:17:16.38
Oct  3 20:17:16.405: INFO: Waiting up to 5m0s for pod "test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de" in namespace "svcaccounts-6123" to be "Succeeded or Failed"
Oct  3 20:17:16.419: INFO: Pod "test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de": Phase="Pending", Reason="", readiness=false. Elapsed: 13.358833ms
Oct  3 20:17:18.435: INFO: Pod "test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029522185s
Oct  3 20:17:20.434: INFO: Pod "test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028846765s
Oct  3 20:17:22.433: INFO: Pod "test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02734186s
STEP: Saw pod success 10/03/22 20:17:22.433
Oct  3 20:17:22.433: INFO: Pod "test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de" satisfied condition "Succeeded or Failed"
Oct  3 20:17:22.447: INFO: Trying to get logs from node 10.63.128.3 pod test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de container agnhost-container: <nil>
STEP: delete the pod 10/03/22 20:17:22.476
Oct  3 20:17:22.520: INFO: Waiting for pod test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de to disappear
Oct  3 20:17:22.533: INFO: Pod test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Oct  3 20:17:22.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6123" for this suite. 10/03/22 20:17:22.55
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":211,"skipped":4013,"failed":0}
------------------------------
• [SLOW TEST] [6.269 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:17:16.315
    Oct  3 20:17:16.315: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename svcaccounts 10/03/22 20:17:16.316
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:16.357
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:16.369
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  10/03/22 20:17:16.38
    Oct  3 20:17:16.405: INFO: Waiting up to 5m0s for pod "test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de" in namespace "svcaccounts-6123" to be "Succeeded or Failed"
    Oct  3 20:17:16.419: INFO: Pod "test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de": Phase="Pending", Reason="", readiness=false. Elapsed: 13.358833ms
    Oct  3 20:17:18.435: INFO: Pod "test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029522185s
    Oct  3 20:17:20.434: INFO: Pod "test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028846765s
    Oct  3 20:17:22.433: INFO: Pod "test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02734186s
    STEP: Saw pod success 10/03/22 20:17:22.433
    Oct  3 20:17:22.433: INFO: Pod "test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de" satisfied condition "Succeeded or Failed"
    Oct  3 20:17:22.447: INFO: Trying to get logs from node 10.63.128.3 pod test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 20:17:22.476
    Oct  3 20:17:22.520: INFO: Waiting for pod test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de to disappear
    Oct  3 20:17:22.533: INFO: Pod test-pod-dc403dbe-c23e-4c80-87c7-aa753472a8de no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Oct  3 20:17:22.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-6123" for this suite. 10/03/22 20:17:22.55
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:17:22.593
Oct  3 20:17:22.593: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir 10/03/22 20:17:22.594
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:22.659
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:22.671
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 10/03/22 20:17:22.684
Oct  3 20:17:22.713: INFO: Waiting up to 5m0s for pod "pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e" in namespace "emptydir-3680" to be "Succeeded or Failed"
Oct  3 20:17:22.726: INFO: Pod "pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.039792ms
Oct  3 20:17:24.743: INFO: Pod "pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029429175s
Oct  3 20:17:26.743: INFO: Pod "pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029429024s
Oct  3 20:17:28.744: INFO: Pod "pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031308632s
STEP: Saw pod success 10/03/22 20:17:28.745
Oct  3 20:17:28.745: INFO: Pod "pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e" satisfied condition "Succeeded or Failed"
Oct  3 20:17:28.758: INFO: Trying to get logs from node 10.63.128.3 pod pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e container test-container: <nil>
STEP: delete the pod 10/03/22 20:17:28.791
Oct  3 20:17:28.848: INFO: Waiting for pod pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e to disappear
Oct  3 20:17:28.888: INFO: Pod pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Oct  3 20:17:28.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3680" for this suite. 10/03/22 20:17:28.907
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":212,"skipped":4093,"failed":0}
------------------------------
• [SLOW TEST] [6.337 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:17:22.593
    Oct  3 20:17:22.593: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir 10/03/22 20:17:22.594
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:22.659
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:22.671
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 10/03/22 20:17:22.684
    Oct  3 20:17:22.713: INFO: Waiting up to 5m0s for pod "pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e" in namespace "emptydir-3680" to be "Succeeded or Failed"
    Oct  3 20:17:22.726: INFO: Pod "pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.039792ms
    Oct  3 20:17:24.743: INFO: Pod "pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029429175s
    Oct  3 20:17:26.743: INFO: Pod "pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029429024s
    Oct  3 20:17:28.744: INFO: Pod "pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031308632s
    STEP: Saw pod success 10/03/22 20:17:28.745
    Oct  3 20:17:28.745: INFO: Pod "pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e" satisfied condition "Succeeded or Failed"
    Oct  3 20:17:28.758: INFO: Trying to get logs from node 10.63.128.3 pod pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e container test-container: <nil>
    STEP: delete the pod 10/03/22 20:17:28.791
    Oct  3 20:17:28.848: INFO: Waiting for pod pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e to disappear
    Oct  3 20:17:28.888: INFO: Pod pod-b0ba7eac-28d3-4d9e-a463-008e37d60f3e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Oct  3 20:17:28.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3680" for this suite. 10/03/22 20:17:28.907
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:17:28.94
Oct  3 20:17:28.940: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename job 10/03/22 20:17:28.941
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:28.988
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:29
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 10/03/22 20:17:29.013
STEP: Ensure pods equal to paralellism count is attached to the job 10/03/22 20:17:29.026
STEP: patching /status 10/03/22 20:17:33.041
STEP: updating /status 10/03/22 20:17:33.056
STEP: get /status 10/03/22 20:17:33.081
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Oct  3 20:17:33.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2738" for this suite. 10/03/22 20:17:33.113
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":213,"skipped":4133,"failed":0}
------------------------------
• [4.198 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:17:28.94
    Oct  3 20:17:28.940: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename job 10/03/22 20:17:28.941
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:28.988
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:29
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 10/03/22 20:17:29.013
    STEP: Ensure pods equal to paralellism count is attached to the job 10/03/22 20:17:29.026
    STEP: patching /status 10/03/22 20:17:33.041
    STEP: updating /status 10/03/22 20:17:33.056
    STEP: get /status 10/03/22 20:17:33.081
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Oct  3 20:17:33.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-2738" for this suite. 10/03/22 20:17:33.113
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:17:33.144
Oct  3 20:17:33.144: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 20:17:33.145
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:33.194
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:33.205
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 10/03/22 20:17:33.216
Oct  3 20:17:33.217: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Oct  3 20:17:33.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 create -f -'
Oct  3 20:17:33.580: INFO: stderr: ""
Oct  3 20:17:33.580: INFO: stdout: "service/agnhost-replica created\n"
Oct  3 20:17:33.580: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Oct  3 20:17:33.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 create -f -'
Oct  3 20:17:33.992: INFO: stderr: ""
Oct  3 20:17:33.992: INFO: stdout: "service/agnhost-primary created\n"
Oct  3 20:17:33.993: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct  3 20:17:33.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 create -f -'
Oct  3 20:17:34.307: INFO: stderr: ""
Oct  3 20:17:34.307: INFO: stdout: "service/frontend created\n"
Oct  3 20:17:34.307: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Oct  3 20:17:34.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 create -f -'
Oct  3 20:17:34.633: INFO: stderr: ""
Oct  3 20:17:34.633: INFO: stdout: "deployment.apps/frontend created\n"
Oct  3 20:17:34.633: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct  3 20:17:34.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 create -f -'
Oct  3 20:17:34.973: INFO: stderr: ""
Oct  3 20:17:34.973: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Oct  3 20:17:34.973: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct  3 20:17:34.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 create -f -'
Oct  3 20:17:35.287: INFO: stderr: ""
Oct  3 20:17:35.287: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 10/03/22 20:17:35.287
Oct  3 20:17:35.287: INFO: Waiting for all frontend pods to be Running.
Oct  3 20:17:40.339: INFO: Waiting for frontend to serve content.
Oct  3 20:17:40.402: INFO: Trying to add a new entry to the guestbook.
Oct  3 20:17:40.456: INFO: Verifying that added entry can be retrieved.
Oct  3 20:17:40.502: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
STEP: using delete to clean up resources 10/03/22 20:17:45.533
Oct  3 20:17:45.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 delete --grace-period=0 --force -f -'
Oct  3 20:17:45.690: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  3 20:17:45.690: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 10/03/22 20:17:45.69
Oct  3 20:17:45.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 delete --grace-period=0 --force -f -'
Oct  3 20:17:45.859: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  3 20:17:45.859: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 10/03/22 20:17:45.859
Oct  3 20:17:45.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 delete --grace-period=0 --force -f -'
Oct  3 20:17:46.065: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  3 20:17:46.065: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 10/03/22 20:17:46.065
Oct  3 20:17:46.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 delete --grace-period=0 --force -f -'
Oct  3 20:17:46.174: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  3 20:17:46.174: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 10/03/22 20:17:46.174
Oct  3 20:17:46.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 delete --grace-period=0 --force -f -'
Oct  3 20:17:46.293: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  3 20:17:46.293: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 10/03/22 20:17:46.293
Oct  3 20:17:46.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 delete --grace-period=0 --force -f -'
Oct  3 20:17:46.433: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  3 20:17:46.433: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 20:17:46.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9793" for this suite. 10/03/22 20:17:46.454
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":214,"skipped":4171,"failed":0}
------------------------------
• [SLOW TEST] [13.337 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:17:33.144
    Oct  3 20:17:33.144: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 20:17:33.145
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:33.194
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:33.205
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 10/03/22 20:17:33.216
    Oct  3 20:17:33.217: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Oct  3 20:17:33.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 create -f -'
    Oct  3 20:17:33.580: INFO: stderr: ""
    Oct  3 20:17:33.580: INFO: stdout: "service/agnhost-replica created\n"
    Oct  3 20:17:33.580: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Oct  3 20:17:33.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 create -f -'
    Oct  3 20:17:33.992: INFO: stderr: ""
    Oct  3 20:17:33.992: INFO: stdout: "service/agnhost-primary created\n"
    Oct  3 20:17:33.993: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Oct  3 20:17:33.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 create -f -'
    Oct  3 20:17:34.307: INFO: stderr: ""
    Oct  3 20:17:34.307: INFO: stdout: "service/frontend created\n"
    Oct  3 20:17:34.307: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Oct  3 20:17:34.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 create -f -'
    Oct  3 20:17:34.633: INFO: stderr: ""
    Oct  3 20:17:34.633: INFO: stdout: "deployment.apps/frontend created\n"
    Oct  3 20:17:34.633: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Oct  3 20:17:34.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 create -f -'
    Oct  3 20:17:34.973: INFO: stderr: ""
    Oct  3 20:17:34.973: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Oct  3 20:17:34.973: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Oct  3 20:17:34.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 create -f -'
    Oct  3 20:17:35.287: INFO: stderr: ""
    Oct  3 20:17:35.287: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 10/03/22 20:17:35.287
    Oct  3 20:17:35.287: INFO: Waiting for all frontend pods to be Running.
    Oct  3 20:17:40.339: INFO: Waiting for frontend to serve content.
    Oct  3 20:17:40.402: INFO: Trying to add a new entry to the guestbook.
    Oct  3 20:17:40.456: INFO: Verifying that added entry can be retrieved.
    Oct  3 20:17:40.502: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
    STEP: using delete to clean up resources 10/03/22 20:17:45.533
    Oct  3 20:17:45.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 delete --grace-period=0 --force -f -'
    Oct  3 20:17:45.690: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct  3 20:17:45.690: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 10/03/22 20:17:45.69
    Oct  3 20:17:45.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 delete --grace-period=0 --force -f -'
    Oct  3 20:17:45.859: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct  3 20:17:45.859: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 10/03/22 20:17:45.859
    Oct  3 20:17:45.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 delete --grace-period=0 --force -f -'
    Oct  3 20:17:46.065: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct  3 20:17:46.065: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 10/03/22 20:17:46.065
    Oct  3 20:17:46.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 delete --grace-period=0 --force -f -'
    Oct  3 20:17:46.174: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct  3 20:17:46.174: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 10/03/22 20:17:46.174
    Oct  3 20:17:46.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 delete --grace-period=0 --force -f -'
    Oct  3 20:17:46.293: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct  3 20:17:46.293: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 10/03/22 20:17:46.293
    Oct  3 20:17:46.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9793 delete --grace-period=0 --force -f -'
    Oct  3 20:17:46.433: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct  3 20:17:46.433: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 20:17:46.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9793" for this suite. 10/03/22 20:17:46.454
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:17:46.484
Oct  3 20:17:46.484: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename gc 10/03/22 20:17:46.487
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:46.533
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:46.551
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 10/03/22 20:17:46.585
STEP: delete the rc 10/03/22 20:17:51.614
STEP: wait for the rc to be deleted 10/03/22 20:17:51.635
Oct  3 20:17:52.677: INFO: 0 pods remaining
Oct  3 20:17:52.677: INFO: 0 pods has nil DeletionTimestamp
Oct  3 20:17:52.677: INFO: 
STEP: Gathering metrics 10/03/22 20:17:53.666
W1003 20:17:53.711874      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Oct  3 20:17:53.711: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Oct  3 20:17:53.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8754" for this suite. 10/03/22 20:17:53.754
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":215,"skipped":4195,"failed":0}
------------------------------
• [SLOW TEST] [7.295 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:17:46.484
    Oct  3 20:17:46.484: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename gc 10/03/22 20:17:46.487
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:46.533
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:46.551
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 10/03/22 20:17:46.585
    STEP: delete the rc 10/03/22 20:17:51.614
    STEP: wait for the rc to be deleted 10/03/22 20:17:51.635
    Oct  3 20:17:52.677: INFO: 0 pods remaining
    Oct  3 20:17:52.677: INFO: 0 pods has nil DeletionTimestamp
    Oct  3 20:17:52.677: INFO: 
    STEP: Gathering metrics 10/03/22 20:17:53.666
    W1003 20:17:53.711874      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Oct  3 20:17:53.711: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Oct  3 20:17:53.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-8754" for this suite. 10/03/22 20:17:53.754
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:17:53.781
Oct  3 20:17:53.781: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename podtemplate 10/03/22 20:17:53.782
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:53.84
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:53.867
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Oct  3 20:17:54.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-2298" for this suite. 10/03/22 20:17:54.068
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":216,"skipped":4212,"failed":0}
------------------------------
• [0.323 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:17:53.781
    Oct  3 20:17:53.781: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename podtemplate 10/03/22 20:17:53.782
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:53.84
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:53.867
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Oct  3 20:17:54.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-2298" for this suite. 10/03/22 20:17:54.068
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:17:54.108
Oct  3 20:17:54.108: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename replication-controller 10/03/22 20:17:54.116
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:54.173
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:54.186
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 10/03/22 20:17:54.199
Oct  3 20:17:54.228: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-3307" to be "running and ready"
Oct  3 20:17:54.247: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 18.55014ms
Oct  3 20:17:54.247: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:17:56.263: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03421862s
Oct  3 20:17:56.263: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:17:58.266: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037610871s
Oct  3 20:17:58.266: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:18:00.262: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 6.033693401s
Oct  3 20:18:00.262: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Oct  3 20:18:00.262: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 10/03/22 20:18:00.275
STEP: Then the orphan pod is adopted 10/03/22 20:18:00.294
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Oct  3 20:18:01.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3307" for this suite. 10/03/22 20:18:01.338
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":217,"skipped":4252,"failed":0}
------------------------------
• [SLOW TEST] [7.254 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:17:54.108
    Oct  3 20:17:54.108: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename replication-controller 10/03/22 20:17:54.116
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:17:54.173
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:17:54.186
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 10/03/22 20:17:54.199
    Oct  3 20:17:54.228: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-3307" to be "running and ready"
    Oct  3 20:17:54.247: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 18.55014ms
    Oct  3 20:17:54.247: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:17:56.263: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03421862s
    Oct  3 20:17:56.263: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:17:58.266: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037610871s
    Oct  3 20:17:58.266: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:18:00.262: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 6.033693401s
    Oct  3 20:18:00.262: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Oct  3 20:18:00.262: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 10/03/22 20:18:00.275
    STEP: Then the orphan pod is adopted 10/03/22 20:18:00.294
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Oct  3 20:18:01.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-3307" for this suite. 10/03/22 20:18:01.338
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:18:01.364
Oct  3 20:18:01.364: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir 10/03/22 20:18:01.366
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:18:01.413
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:18:01.423
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 10/03/22 20:18:01.434
Oct  3 20:18:01.499: INFO: Waiting up to 5m0s for pod "pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807" in namespace "emptydir-1860" to be "Succeeded or Failed"
Oct  3 20:18:01.514: INFO: Pod "pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807": Phase="Pending", Reason="", readiness=false. Elapsed: 14.658934ms
Oct  3 20:18:03.529: INFO: Pod "pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029706769s
Oct  3 20:18:05.529: INFO: Pod "pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030087408s
STEP: Saw pod success 10/03/22 20:18:05.529
Oct  3 20:18:05.529: INFO: Pod "pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807" satisfied condition "Succeeded or Failed"
Oct  3 20:18:05.543: INFO: Trying to get logs from node 10.63.128.3 pod pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807 container test-container: <nil>
STEP: delete the pod 10/03/22 20:18:05.578
Oct  3 20:18:05.622: INFO: Waiting for pod pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807 to disappear
Oct  3 20:18:05.637: INFO: Pod pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Oct  3 20:18:05.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1860" for this suite. 10/03/22 20:18:05.657
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":218,"skipped":4275,"failed":0}
------------------------------
• [4.319 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:18:01.364
    Oct  3 20:18:01.364: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir 10/03/22 20:18:01.366
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:18:01.413
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:18:01.423
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 10/03/22 20:18:01.434
    Oct  3 20:18:01.499: INFO: Waiting up to 5m0s for pod "pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807" in namespace "emptydir-1860" to be "Succeeded or Failed"
    Oct  3 20:18:01.514: INFO: Pod "pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807": Phase="Pending", Reason="", readiness=false. Elapsed: 14.658934ms
    Oct  3 20:18:03.529: INFO: Pod "pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029706769s
    Oct  3 20:18:05.529: INFO: Pod "pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030087408s
    STEP: Saw pod success 10/03/22 20:18:05.529
    Oct  3 20:18:05.529: INFO: Pod "pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807" satisfied condition "Succeeded or Failed"
    Oct  3 20:18:05.543: INFO: Trying to get logs from node 10.63.128.3 pod pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807 container test-container: <nil>
    STEP: delete the pod 10/03/22 20:18:05.578
    Oct  3 20:18:05.622: INFO: Waiting for pod pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807 to disappear
    Oct  3 20:18:05.637: INFO: Pod pod-f063feaa-a526-4ed9-8209-ef9e6b4ed807 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Oct  3 20:18:05.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1860" for this suite. 10/03/22 20:18:05.657
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:18:05.685
Oct  3 20:18:05.685: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 20:18:05.687
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:18:05.764
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:18:05.773
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 10/03/22 20:18:05.783
Oct  3 20:18:05.785: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:18:11.307: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:18:29.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6872" for this suite. 10/03/22 20:18:30
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":219,"skipped":4285,"failed":0}
------------------------------
• [SLOW TEST] [24.334 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:18:05.685
    Oct  3 20:18:05.685: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 20:18:05.687
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:18:05.764
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:18:05.773
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 10/03/22 20:18:05.783
    Oct  3 20:18:05.785: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:18:11.307: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:18:29.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6872" for this suite. 10/03/22 20:18:30
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:18:30.024
Oct  3 20:18:30.024: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename init-container 10/03/22 20:18:30.025
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:18:30.063
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:18:30.069
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 10/03/22 20:18:30.079
Oct  3 20:18:30.079: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Oct  3 20:18:34.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1749" for this suite. 10/03/22 20:18:34.77
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":220,"skipped":4310,"failed":0}
------------------------------
• [4.768 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:18:30.024
    Oct  3 20:18:30.024: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename init-container 10/03/22 20:18:30.025
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:18:30.063
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:18:30.069
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 10/03/22 20:18:30.079
    Oct  3 20:18:30.079: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Oct  3 20:18:34.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-1749" for this suite. 10/03/22 20:18:34.77
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:18:34.795
Oct  3 20:18:34.795: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename pod-network-test 10/03/22 20:18:34.796
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:18:34.834
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:18:34.844
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-6517 10/03/22 20:18:34.857
STEP: creating a selector 10/03/22 20:18:34.857
STEP: Creating the service pods in kubernetes 10/03/22 20:18:34.857
Oct  3 20:18:34.857: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Oct  3 20:18:34.967: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6517" to be "running and ready"
Oct  3 20:18:34.986: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.645316ms
Oct  3 20:18:34.986: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:18:37.001: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.033442388s
Oct  3 20:18:37.001: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:18:38.999: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.031846948s
Oct  3 20:18:38.999: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:18:41.000: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.032440814s
Oct  3 20:18:41.000: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:18:43.000: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.032582665s
Oct  3 20:18:43.000: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:18:45.000: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.032916218s
Oct  3 20:18:45.000: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:18:47.000: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.032335448s
Oct  3 20:18:47.000: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:18:49.002: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.034711291s
Oct  3 20:18:49.002: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:18:50.999: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.031270236s
Oct  3 20:18:50.999: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:18:52.999: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.031703871s
Oct  3 20:18:52.999: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:18:54.998: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.031079229s
Oct  3 20:18:54.998: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:18:57.003: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.03565188s
Oct  3 20:18:57.003: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Oct  3 20:18:57.003: INFO: Pod "netserver-0" satisfied condition "running and ready"
Oct  3 20:18:57.014: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6517" to be "running and ready"
Oct  3 20:18:57.027: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 12.589214ms
Oct  3 20:18:57.027: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Oct  3 20:18:57.027: INFO: Pod "netserver-1" satisfied condition "running and ready"
Oct  3 20:18:57.039: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6517" to be "running and ready"
Oct  3 20:18:57.051: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 11.934861ms
Oct  3 20:18:57.051: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Oct  3 20:18:57.051: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 10/03/22 20:18:57.062
Oct  3 20:18:57.076: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6517" to be "running"
Oct  3 20:18:57.087: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.417445ms
Oct  3 20:18:59.100: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023803658s
Oct  3 20:18:59.100: INFO: Pod "test-container-pod" satisfied condition "running"
Oct  3 20:18:59.112: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Oct  3 20:18:59.112: INFO: Breadth first check of 172.30.35.250 on host 10.63.128.13...
Oct  3 20:18:59.124: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.49.57:9080/dial?request=hostname&protocol=http&host=172.30.35.250&port=8083&tries=1'] Namespace:pod-network-test-6517 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:18:59.124: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:18:59.125: INFO: ExecWithOptions: Clientset creation
Oct  3 20:18:59.125: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6517/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.49.57%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.35.250%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct  3 20:18:59.345: INFO: Waiting for responses: map[]
Oct  3 20:18:59.346: INFO: reached 172.30.35.250 after 0/1 tries
Oct  3 20:18:59.346: INFO: Breadth first check of 172.30.49.59 on host 10.63.128.3...
Oct  3 20:18:59.358: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.49.57:9080/dial?request=hostname&protocol=http&host=172.30.49.59&port=8083&tries=1'] Namespace:pod-network-test-6517 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:18:59.358: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:18:59.359: INFO: ExecWithOptions: Clientset creation
Oct  3 20:18:59.359: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6517/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.49.57%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.49.59%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct  3 20:18:59.551: INFO: Waiting for responses: map[]
Oct  3 20:18:59.551: INFO: reached 172.30.49.59 after 0/1 tries
Oct  3 20:18:59.551: INFO: Breadth first check of 172.30.174.247 on host 10.63.128.51...
Oct  3 20:18:59.563: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.49.57:9080/dial?request=hostname&protocol=http&host=172.30.174.247&port=8083&tries=1'] Namespace:pod-network-test-6517 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:18:59.563: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:18:59.564: INFO: ExecWithOptions: Clientset creation
Oct  3 20:18:59.564: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6517/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.49.57%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.174.247%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct  3 20:18:59.775: INFO: Waiting for responses: map[]
Oct  3 20:18:59.776: INFO: reached 172.30.174.247 after 0/1 tries
Oct  3 20:18:59.776: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Oct  3 20:18:59.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6517" for this suite. 10/03/22 20:18:59.794
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":221,"skipped":4339,"failed":0}
------------------------------
• [SLOW TEST] [25.019 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:18:34.795
    Oct  3 20:18:34.795: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename pod-network-test 10/03/22 20:18:34.796
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:18:34.834
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:18:34.844
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-6517 10/03/22 20:18:34.857
    STEP: creating a selector 10/03/22 20:18:34.857
    STEP: Creating the service pods in kubernetes 10/03/22 20:18:34.857
    Oct  3 20:18:34.857: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Oct  3 20:18:34.967: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6517" to be "running and ready"
    Oct  3 20:18:34.986: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.645316ms
    Oct  3 20:18:34.986: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:18:37.001: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.033442388s
    Oct  3 20:18:37.001: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:18:38.999: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.031846948s
    Oct  3 20:18:38.999: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:18:41.000: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.032440814s
    Oct  3 20:18:41.000: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:18:43.000: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.032582665s
    Oct  3 20:18:43.000: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:18:45.000: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.032916218s
    Oct  3 20:18:45.000: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:18:47.000: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.032335448s
    Oct  3 20:18:47.000: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:18:49.002: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.034711291s
    Oct  3 20:18:49.002: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:18:50.999: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.031270236s
    Oct  3 20:18:50.999: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:18:52.999: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.031703871s
    Oct  3 20:18:52.999: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:18:54.998: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.031079229s
    Oct  3 20:18:54.998: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:18:57.003: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.03565188s
    Oct  3 20:18:57.003: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Oct  3 20:18:57.003: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Oct  3 20:18:57.014: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6517" to be "running and ready"
    Oct  3 20:18:57.027: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 12.589214ms
    Oct  3 20:18:57.027: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Oct  3 20:18:57.027: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Oct  3 20:18:57.039: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6517" to be "running and ready"
    Oct  3 20:18:57.051: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 11.934861ms
    Oct  3 20:18:57.051: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Oct  3 20:18:57.051: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 10/03/22 20:18:57.062
    Oct  3 20:18:57.076: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6517" to be "running"
    Oct  3 20:18:57.087: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.417445ms
    Oct  3 20:18:59.100: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023803658s
    Oct  3 20:18:59.100: INFO: Pod "test-container-pod" satisfied condition "running"
    Oct  3 20:18:59.112: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Oct  3 20:18:59.112: INFO: Breadth first check of 172.30.35.250 on host 10.63.128.13...
    Oct  3 20:18:59.124: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.49.57:9080/dial?request=hostname&protocol=http&host=172.30.35.250&port=8083&tries=1'] Namespace:pod-network-test-6517 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:18:59.124: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:18:59.125: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:18:59.125: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6517/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.49.57%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.35.250%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Oct  3 20:18:59.345: INFO: Waiting for responses: map[]
    Oct  3 20:18:59.346: INFO: reached 172.30.35.250 after 0/1 tries
    Oct  3 20:18:59.346: INFO: Breadth first check of 172.30.49.59 on host 10.63.128.3...
    Oct  3 20:18:59.358: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.49.57:9080/dial?request=hostname&protocol=http&host=172.30.49.59&port=8083&tries=1'] Namespace:pod-network-test-6517 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:18:59.358: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:18:59.359: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:18:59.359: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6517/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.49.57%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.49.59%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Oct  3 20:18:59.551: INFO: Waiting for responses: map[]
    Oct  3 20:18:59.551: INFO: reached 172.30.49.59 after 0/1 tries
    Oct  3 20:18:59.551: INFO: Breadth first check of 172.30.174.247 on host 10.63.128.51...
    Oct  3 20:18:59.563: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.49.57:9080/dial?request=hostname&protocol=http&host=172.30.174.247&port=8083&tries=1'] Namespace:pod-network-test-6517 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:18:59.563: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:18:59.564: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:18:59.564: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6517/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.49.57%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.174.247%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Oct  3 20:18:59.775: INFO: Waiting for responses: map[]
    Oct  3 20:18:59.776: INFO: reached 172.30.174.247 after 0/1 tries
    Oct  3 20:18:59.776: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Oct  3 20:18:59.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-6517" for this suite. 10/03/22 20:18:59.794
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:18:59.814
Oct  3 20:18:59.814: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename replication-controller 10/03/22 20:18:59.816
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:18:59.856
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:18:59.867
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 10/03/22 20:18:59.886
STEP: waiting for RC to be added 10/03/22 20:18:59.898
STEP: waiting for available Replicas 10/03/22 20:18:59.899
STEP: patching ReplicationController 10/03/22 20:19:01.965
STEP: waiting for RC to be modified 10/03/22 20:19:01.981
STEP: patching ReplicationController status 10/03/22 20:19:01.981
STEP: waiting for RC to be modified 10/03/22 20:19:01.994
STEP: waiting for available Replicas 10/03/22 20:19:01.994
STEP: fetching ReplicationController status 10/03/22 20:19:02.015
STEP: patching ReplicationController scale 10/03/22 20:19:02.025
STEP: waiting for RC to be modified 10/03/22 20:19:02.041
STEP: waiting for ReplicationController's scale to be the max amount 10/03/22 20:19:02.041
STEP: fetching ReplicationController; ensuring that it's patched 10/03/22 20:19:03.822
STEP: updating ReplicationController status 10/03/22 20:19:03.832
STEP: waiting for RC to be modified 10/03/22 20:19:03.846
STEP: listing all ReplicationControllers 10/03/22 20:19:03.846
STEP: checking that ReplicationController has expected values 10/03/22 20:19:03.857
STEP: deleting ReplicationControllers by collection 10/03/22 20:19:03.857
STEP: waiting for ReplicationController to have a DELETED watchEvent 10/03/22 20:19:03.876
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Oct  3 20:19:03.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8299" for this suite. 10/03/22 20:19:03.998
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":222,"skipped":4340,"failed":0}
------------------------------
• [4.203 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:18:59.814
    Oct  3 20:18:59.814: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename replication-controller 10/03/22 20:18:59.816
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:18:59.856
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:18:59.867
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 10/03/22 20:18:59.886
    STEP: waiting for RC to be added 10/03/22 20:18:59.898
    STEP: waiting for available Replicas 10/03/22 20:18:59.899
    STEP: patching ReplicationController 10/03/22 20:19:01.965
    STEP: waiting for RC to be modified 10/03/22 20:19:01.981
    STEP: patching ReplicationController status 10/03/22 20:19:01.981
    STEP: waiting for RC to be modified 10/03/22 20:19:01.994
    STEP: waiting for available Replicas 10/03/22 20:19:01.994
    STEP: fetching ReplicationController status 10/03/22 20:19:02.015
    STEP: patching ReplicationController scale 10/03/22 20:19:02.025
    STEP: waiting for RC to be modified 10/03/22 20:19:02.041
    STEP: waiting for ReplicationController's scale to be the max amount 10/03/22 20:19:02.041
    STEP: fetching ReplicationController; ensuring that it's patched 10/03/22 20:19:03.822
    STEP: updating ReplicationController status 10/03/22 20:19:03.832
    STEP: waiting for RC to be modified 10/03/22 20:19:03.846
    STEP: listing all ReplicationControllers 10/03/22 20:19:03.846
    STEP: checking that ReplicationController has expected values 10/03/22 20:19:03.857
    STEP: deleting ReplicationControllers by collection 10/03/22 20:19:03.857
    STEP: waiting for ReplicationController to have a DELETED watchEvent 10/03/22 20:19:03.876
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Oct  3 20:19:03.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-8299" for this suite. 10/03/22 20:19:03.998
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:19:04.018
Oct  3 20:19:04.018: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 20:19:04.019
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:19:04.061
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:19:04.07
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 20:19:04.111
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:19:04.782
STEP: Deploying the webhook pod 10/03/22 20:19:04.802
STEP: Wait for the deployment to be ready 10/03/22 20:19:04.826
Oct  3 20:19:04.846: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  3 20:19:06.894: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 20, 19, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 19, 4, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 20, 19, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 19, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 10/03/22 20:19:08.905
STEP: Verifying the service has paired with the endpoint 10/03/22 20:19:08.936
Oct  3 20:19:09.937: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Oct  3 20:19:09.950: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2040-crds.webhook.example.com via the AdmissionRegistration API 10/03/22 20:19:10.478
STEP: Creating a custom resource while v1 is storage version 10/03/22 20:19:10.552
STEP: Patching Custom Resource Definition to set v2 as storage 10/03/22 20:19:12.688
STEP: Patching the custom resource while v2 is storage version 10/03/22 20:19:12.718
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:19:13.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4368" for this suite. 10/03/22 20:19:13.355
STEP: Destroying namespace "webhook-4368-markers" for this suite. 10/03/22 20:19:13.375
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":223,"skipped":4342,"failed":0}
------------------------------
• [SLOW TEST] [9.515 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:19:04.018
    Oct  3 20:19:04.018: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 20:19:04.019
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:19:04.061
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:19:04.07
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 20:19:04.111
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:19:04.782
    STEP: Deploying the webhook pod 10/03/22 20:19:04.802
    STEP: Wait for the deployment to be ready 10/03/22 20:19:04.826
    Oct  3 20:19:04.846: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Oct  3 20:19:06.894: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 20, 19, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 19, 4, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 20, 19, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 19, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 10/03/22 20:19:08.905
    STEP: Verifying the service has paired with the endpoint 10/03/22 20:19:08.936
    Oct  3 20:19:09.937: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Oct  3 20:19:09.950: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2040-crds.webhook.example.com via the AdmissionRegistration API 10/03/22 20:19:10.478
    STEP: Creating a custom resource while v1 is storage version 10/03/22 20:19:10.552
    STEP: Patching Custom Resource Definition to set v2 as storage 10/03/22 20:19:12.688
    STEP: Patching the custom resource while v2 is storage version 10/03/22 20:19:12.718
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:19:13.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4368" for this suite. 10/03/22 20:19:13.355
    STEP: Destroying namespace "webhook-4368-markers" for this suite. 10/03/22 20:19:13.375
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:19:13.536
Oct  3 20:19:13.536: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename podtemplate 10/03/22 20:19:13.538
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:19:13.605
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:19:13.611
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 10/03/22 20:19:13.618
STEP: Replace a pod template 10/03/22 20:19:13.631
Oct  3 20:19:13.658: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Oct  3 20:19:13.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-7506" for this suite. 10/03/22 20:19:13.671
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":224,"skipped":4364,"failed":0}
------------------------------
• [0.152 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:19:13.536
    Oct  3 20:19:13.536: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename podtemplate 10/03/22 20:19:13.538
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:19:13.605
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:19:13.611
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 10/03/22 20:19:13.618
    STEP: Replace a pod template 10/03/22 20:19:13.631
    Oct  3 20:19:13.658: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Oct  3 20:19:13.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-7506" for this suite. 10/03/22 20:19:13.671
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:19:13.689
Oct  3 20:19:13.689: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir 10/03/22 20:19:13.69
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:19:13.722
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:19:13.73
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 10/03/22 20:19:13.737
Oct  3 20:19:13.756: INFO: Waiting up to 5m0s for pod "pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a" in namespace "emptydir-6039" to be "Succeeded or Failed"
Oct  3 20:19:13.765: INFO: Pod "pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.992404ms
Oct  3 20:19:15.776: INFO: Pod "pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01997854s
Oct  3 20:19:17.777: INFO: Pod "pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020740728s
Oct  3 20:19:19.776: INFO: Pod "pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019476252s
STEP: Saw pod success 10/03/22 20:19:19.776
Oct  3 20:19:19.776: INFO: Pod "pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a" satisfied condition "Succeeded or Failed"
Oct  3 20:19:19.785: INFO: Trying to get logs from node 10.63.128.3 pod pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a container test-container: <nil>
STEP: delete the pod 10/03/22 20:19:19.862
Oct  3 20:19:19.886: INFO: Waiting for pod pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a to disappear
Oct  3 20:19:19.895: INFO: Pod pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Oct  3 20:19:19.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6039" for this suite. 10/03/22 20:19:19.907
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":225,"skipped":4364,"failed":0}
------------------------------
• [SLOW TEST] [6.235 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:19:13.689
    Oct  3 20:19:13.689: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir 10/03/22 20:19:13.69
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:19:13.722
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:19:13.73
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 10/03/22 20:19:13.737
    Oct  3 20:19:13.756: INFO: Waiting up to 5m0s for pod "pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a" in namespace "emptydir-6039" to be "Succeeded or Failed"
    Oct  3 20:19:13.765: INFO: Pod "pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.992404ms
    Oct  3 20:19:15.776: INFO: Pod "pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01997854s
    Oct  3 20:19:17.777: INFO: Pod "pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020740728s
    Oct  3 20:19:19.776: INFO: Pod "pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019476252s
    STEP: Saw pod success 10/03/22 20:19:19.776
    Oct  3 20:19:19.776: INFO: Pod "pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a" satisfied condition "Succeeded or Failed"
    Oct  3 20:19:19.785: INFO: Trying to get logs from node 10.63.128.3 pod pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a container test-container: <nil>
    STEP: delete the pod 10/03/22 20:19:19.862
    Oct  3 20:19:19.886: INFO: Waiting for pod pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a to disappear
    Oct  3 20:19:19.895: INFO: Pod pod-f58b3135-70f0-4f8d-a062-8fdb8536c98a no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Oct  3 20:19:19.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6039" for this suite. 10/03/22 20:19:19.907
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:19:19.943
Oct  3 20:19:19.943: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 20:19:19.944
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:19:19.984
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:19:19.989
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-225789ea-72d8-4844-ac5a-1fd18becaa71 10/03/22 20:19:19.994
STEP: Creating a pod to test consume secrets 10/03/22 20:19:20.006
Oct  3 20:19:20.023: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010" in namespace "projected-8373" to be "Succeeded or Failed"
Oct  3 20:19:20.031: INFO: Pod "pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010": Phase="Pending", Reason="", readiness=false. Elapsed: 8.530261ms
Oct  3 20:19:22.042: INFO: Pod "pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018738216s
Oct  3 20:19:24.041: INFO: Pod "pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018353629s
Oct  3 20:19:26.042: INFO: Pod "pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019221085s
STEP: Saw pod success 10/03/22 20:19:26.042
Oct  3 20:19:26.042: INFO: Pod "pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010" satisfied condition "Succeeded or Failed"
Oct  3 20:19:26.051: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010 container projected-secret-volume-test: <nil>
STEP: delete the pod 10/03/22 20:19:26.075
Oct  3 20:19:26.098: INFO: Waiting for pod pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010 to disappear
Oct  3 20:19:26.107: INFO: Pod pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Oct  3 20:19:26.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8373" for this suite. 10/03/22 20:19:26.122
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":226,"skipped":4416,"failed":0}
------------------------------
• [SLOW TEST] [6.195 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:19:19.943
    Oct  3 20:19:19.943: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 20:19:19.944
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:19:19.984
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:19:19.989
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-225789ea-72d8-4844-ac5a-1fd18becaa71 10/03/22 20:19:19.994
    STEP: Creating a pod to test consume secrets 10/03/22 20:19:20.006
    Oct  3 20:19:20.023: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010" in namespace "projected-8373" to be "Succeeded or Failed"
    Oct  3 20:19:20.031: INFO: Pod "pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010": Phase="Pending", Reason="", readiness=false. Elapsed: 8.530261ms
    Oct  3 20:19:22.042: INFO: Pod "pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018738216s
    Oct  3 20:19:24.041: INFO: Pod "pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018353629s
    Oct  3 20:19:26.042: INFO: Pod "pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019221085s
    STEP: Saw pod success 10/03/22 20:19:26.042
    Oct  3 20:19:26.042: INFO: Pod "pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010" satisfied condition "Succeeded or Failed"
    Oct  3 20:19:26.051: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010 container projected-secret-volume-test: <nil>
    STEP: delete the pod 10/03/22 20:19:26.075
    Oct  3 20:19:26.098: INFO: Waiting for pod pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010 to disappear
    Oct  3 20:19:26.107: INFO: Pod pod-projected-secrets-2fd0928f-b7ff-46c1-83ed-de687ba82010 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Oct  3 20:19:26.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8373" for this suite. 10/03/22 20:19:26.122
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:19:26.14
Oct  3 20:19:26.141: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename taint-single-pod 10/03/22 20:19:26.142
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:19:26.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:19:26.182
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Oct  3 20:19:26.188: INFO: Waiting up to 1m0s for all nodes to be ready
Oct  3 20:20:26.247: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Oct  3 20:20:26.259: INFO: Starting informer...
STEP: Starting pod... 10/03/22 20:20:26.259
Oct  3 20:20:26.493: INFO: Pod is running on 10.63.128.3. Tainting Node
STEP: Trying to apply a taint on the Node 10/03/22 20:20:26.493
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/03/22 20:20:26.524
STEP: Waiting short time to make sure Pod is queued for deletion 10/03/22 20:20:26.538
Oct  3 20:20:26.538: INFO: Pod wasn't evicted. Proceeding
Oct  3 20:20:26.538: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/03/22 20:20:26.616
STEP: Waiting some time to make sure that toleration time passed. 10/03/22 20:20:26.626
Oct  3 20:21:41.628: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Oct  3 20:21:41.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-9373" for this suite. 10/03/22 20:21:41.641
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":227,"skipped":4417,"failed":0}
------------------------------
• [SLOW TEST] [135.518 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:19:26.14
    Oct  3 20:19:26.141: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename taint-single-pod 10/03/22 20:19:26.142
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:19:26.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:19:26.182
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Oct  3 20:19:26.188: INFO: Waiting up to 1m0s for all nodes to be ready
    Oct  3 20:20:26.247: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Oct  3 20:20:26.259: INFO: Starting informer...
    STEP: Starting pod... 10/03/22 20:20:26.259
    Oct  3 20:20:26.493: INFO: Pod is running on 10.63.128.3. Tainting Node
    STEP: Trying to apply a taint on the Node 10/03/22 20:20:26.493
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/03/22 20:20:26.524
    STEP: Waiting short time to make sure Pod is queued for deletion 10/03/22 20:20:26.538
    Oct  3 20:20:26.538: INFO: Pod wasn't evicted. Proceeding
    Oct  3 20:20:26.538: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/03/22 20:20:26.616
    STEP: Waiting some time to make sure that toleration time passed. 10/03/22 20:20:26.626
    Oct  3 20:21:41.628: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 20:21:41.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-9373" for this suite. 10/03/22 20:21:41.641
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:21:41.659
Oct  3 20:21:41.660: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 20:21:41.661
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:21:41.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:21:41.696
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 20:21:41.736
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:21:42.358
STEP: Deploying the webhook pod 10/03/22 20:21:42.378
STEP: Wait for the deployment to be ready 10/03/22 20:21:42.402
Oct  3 20:21:42.424: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  3 20:21:44.453: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 20, 21, 42, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 21, 42, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 20, 21, 42, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 21, 42, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 10/03/22 20:21:46.464
STEP: Verifying the service has paired with the endpoint 10/03/22 20:21:46.493
Oct  3 20:21:47.494: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 10/03/22 20:21:47.504
STEP: create a pod that should be denied by the webhook 10/03/22 20:21:47.565
STEP: create a pod that causes the webhook to hang 10/03/22 20:21:47.619
STEP: create a configmap that should be denied by the webhook 10/03/22 20:21:57.633
STEP: create a configmap that should be admitted by the webhook 10/03/22 20:21:57.68
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 10/03/22 20:21:57.72
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 10/03/22 20:21:57.748
STEP: create a namespace that bypass the webhook 10/03/22 20:21:57.766
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 10/03/22 20:21:57.785
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:21:57.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5153" for this suite. 10/03/22 20:21:57.88
STEP: Destroying namespace "webhook-5153-markers" for this suite. 10/03/22 20:21:57.897
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":228,"skipped":4419,"failed":0}
------------------------------
• [SLOW TEST] [16.353 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:21:41.659
    Oct  3 20:21:41.660: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 20:21:41.661
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:21:41.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:21:41.696
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 20:21:41.736
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:21:42.358
    STEP: Deploying the webhook pod 10/03/22 20:21:42.378
    STEP: Wait for the deployment to be ready 10/03/22 20:21:42.402
    Oct  3 20:21:42.424: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Oct  3 20:21:44.453: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 20, 21, 42, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 21, 42, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 20, 21, 42, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 21, 42, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 10/03/22 20:21:46.464
    STEP: Verifying the service has paired with the endpoint 10/03/22 20:21:46.493
    Oct  3 20:21:47.494: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 10/03/22 20:21:47.504
    STEP: create a pod that should be denied by the webhook 10/03/22 20:21:47.565
    STEP: create a pod that causes the webhook to hang 10/03/22 20:21:47.619
    STEP: create a configmap that should be denied by the webhook 10/03/22 20:21:57.633
    STEP: create a configmap that should be admitted by the webhook 10/03/22 20:21:57.68
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 10/03/22 20:21:57.72
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 10/03/22 20:21:57.748
    STEP: create a namespace that bypass the webhook 10/03/22 20:21:57.766
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 10/03/22 20:21:57.785
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:21:57.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5153" for this suite. 10/03/22 20:21:57.88
    STEP: Destroying namespace "webhook-5153-markers" for this suite. 10/03/22 20:21:57.897
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:21:58.016
Oct  3 20:21:58.016: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename conformance-tests 10/03/22 20:21:58.017
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:21:58.048
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:21:58.053
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 10/03/22 20:21:58.063
Oct  3 20:21:58.063: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Oct  3 20:21:58.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-1189" for this suite. 10/03/22 20:21:58.093
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":229,"skipped":4471,"failed":0}
------------------------------
• [0.095 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:21:58.016
    Oct  3 20:21:58.016: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename conformance-tests 10/03/22 20:21:58.017
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:21:58.048
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:21:58.053
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 10/03/22 20:21:58.063
    Oct  3 20:21:58.063: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Oct  3 20:21:58.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-1189" for this suite. 10/03/22 20:21:58.093
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:21:58.114
Oct  3 20:21:58.115: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename configmap 10/03/22 20:21:58.116
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:21:58.145
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:21:58.151
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-7905/configmap-test-ab88dd21-9dd3-4aa0-ad99-7e04dcd4d19c 10/03/22 20:21:58.156
STEP: Creating a pod to test consume configMaps 10/03/22 20:21:58.17
Oct  3 20:21:58.208: INFO: Waiting up to 5m0s for pod "pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e" in namespace "configmap-7905" to be "Succeeded or Failed"
Oct  3 20:21:58.216: INFO: Pod "pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.409189ms
Oct  3 20:22:00.228: INFO: Pod "pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e": Phase="Running", Reason="", readiness=true. Elapsed: 2.020560075s
Oct  3 20:22:02.227: INFO: Pod "pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e": Phase="Running", Reason="", readiness=false. Elapsed: 4.019013649s
Oct  3 20:22:04.226: INFO: Pod "pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018201807s
STEP: Saw pod success 10/03/22 20:22:04.226
Oct  3 20:22:04.227: INFO: Pod "pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e" satisfied condition "Succeeded or Failed"
Oct  3 20:22:04.236: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e container env-test: <nil>
STEP: delete the pod 10/03/22 20:22:04.306
Oct  3 20:22:04.339: INFO: Waiting for pod pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e to disappear
Oct  3 20:22:04.349: INFO: Pod pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Oct  3 20:22:04.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7905" for this suite. 10/03/22 20:22:04.361
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":230,"skipped":4487,"failed":0}
------------------------------
• [SLOW TEST] [6.266 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:21:58.114
    Oct  3 20:21:58.115: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename configmap 10/03/22 20:21:58.116
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:21:58.145
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:21:58.151
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-7905/configmap-test-ab88dd21-9dd3-4aa0-ad99-7e04dcd4d19c 10/03/22 20:21:58.156
    STEP: Creating a pod to test consume configMaps 10/03/22 20:21:58.17
    Oct  3 20:21:58.208: INFO: Waiting up to 5m0s for pod "pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e" in namespace "configmap-7905" to be "Succeeded or Failed"
    Oct  3 20:21:58.216: INFO: Pod "pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.409189ms
    Oct  3 20:22:00.228: INFO: Pod "pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e": Phase="Running", Reason="", readiness=true. Elapsed: 2.020560075s
    Oct  3 20:22:02.227: INFO: Pod "pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e": Phase="Running", Reason="", readiness=false. Elapsed: 4.019013649s
    Oct  3 20:22:04.226: INFO: Pod "pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018201807s
    STEP: Saw pod success 10/03/22 20:22:04.226
    Oct  3 20:22:04.227: INFO: Pod "pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e" satisfied condition "Succeeded or Failed"
    Oct  3 20:22:04.236: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e container env-test: <nil>
    STEP: delete the pod 10/03/22 20:22:04.306
    Oct  3 20:22:04.339: INFO: Waiting for pod pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e to disappear
    Oct  3 20:22:04.349: INFO: Pod pod-configmaps-0ba729f2-312e-4f62-8f68-b13f1705648e no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Oct  3 20:22:04.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7905" for this suite. 10/03/22 20:22:04.361
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:22:04.382
Oct  3 20:22:04.382: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename configmap 10/03/22 20:22:04.384
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:22:04.418
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:22:04.425
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-fa4b250b-b1f9-4165-8c0d-d769279b3cdc 10/03/22 20:22:04.43
STEP: Creating a pod to test consume configMaps 10/03/22 20:22:04.446
Oct  3 20:22:04.466: INFO: Waiting up to 5m0s for pod "pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c" in namespace "configmap-4941" to be "Succeeded or Failed"
Oct  3 20:22:04.475: INFO: Pod "pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.044264ms
Oct  3 20:22:06.485: INFO: Pod "pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019470568s
Oct  3 20:22:08.486: INFO: Pod "pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020731752s
Oct  3 20:22:10.485: INFO: Pod "pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019001664s
STEP: Saw pod success 10/03/22 20:22:10.485
Oct  3 20:22:10.485: INFO: Pod "pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c" satisfied condition "Succeeded or Failed"
Oct  3 20:22:10.494: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c container agnhost-container: <nil>
STEP: delete the pod 10/03/22 20:22:10.518
Oct  3 20:22:10.555: INFO: Waiting for pod pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c to disappear
Oct  3 20:22:10.563: INFO: Pod pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Oct  3 20:22:10.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4941" for this suite. 10/03/22 20:22:10.575
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":231,"skipped":4488,"failed":0}
------------------------------
• [SLOW TEST] [6.211 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:22:04.382
    Oct  3 20:22:04.382: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename configmap 10/03/22 20:22:04.384
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:22:04.418
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:22:04.425
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-fa4b250b-b1f9-4165-8c0d-d769279b3cdc 10/03/22 20:22:04.43
    STEP: Creating a pod to test consume configMaps 10/03/22 20:22:04.446
    Oct  3 20:22:04.466: INFO: Waiting up to 5m0s for pod "pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c" in namespace "configmap-4941" to be "Succeeded or Failed"
    Oct  3 20:22:04.475: INFO: Pod "pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.044264ms
    Oct  3 20:22:06.485: INFO: Pod "pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019470568s
    Oct  3 20:22:08.486: INFO: Pod "pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020731752s
    Oct  3 20:22:10.485: INFO: Pod "pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019001664s
    STEP: Saw pod success 10/03/22 20:22:10.485
    Oct  3 20:22:10.485: INFO: Pod "pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c" satisfied condition "Succeeded or Failed"
    Oct  3 20:22:10.494: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 20:22:10.518
    Oct  3 20:22:10.555: INFO: Waiting for pod pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c to disappear
    Oct  3 20:22:10.563: INFO: Pod pod-configmaps-4e7dba6d-7583-4a2b-84a0-11f8e4cd920c no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Oct  3 20:22:10.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4941" for this suite. 10/03/22 20:22:10.575
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:22:10.595
Oct  3 20:22:10.595: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-runtime 10/03/22 20:22:10.597
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:22:10.63
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:22:10.636
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 10/03/22 20:22:10.641
STEP: wait for the container to reach Succeeded 10/03/22 20:22:10.66
STEP: get the container status 10/03/22 20:22:15.72
STEP: the container should be terminated 10/03/22 20:22:15.76
STEP: the termination message should be set 10/03/22 20:22:15.761
Oct  3 20:22:15.761: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 10/03/22 20:22:15.761
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Oct  3 20:22:15.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6499" for this suite. 10/03/22 20:22:15.82
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":232,"skipped":4501,"failed":0}
------------------------------
• [SLOW TEST] [5.246 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:22:10.595
    Oct  3 20:22:10.595: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-runtime 10/03/22 20:22:10.597
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:22:10.63
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:22:10.636
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 10/03/22 20:22:10.641
    STEP: wait for the container to reach Succeeded 10/03/22 20:22:10.66
    STEP: get the container status 10/03/22 20:22:15.72
    STEP: the container should be terminated 10/03/22 20:22:15.76
    STEP: the termination message should be set 10/03/22 20:22:15.761
    Oct  3 20:22:15.761: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 10/03/22 20:22:15.761
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Oct  3 20:22:15.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-6499" for this suite. 10/03/22 20:22:15.82
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:22:15.844
Oct  3 20:22:15.844: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename gc 10/03/22 20:22:15.845
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:22:15.88
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:22:15.886
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 10/03/22 20:22:15.891
STEP: Wait for the Deployment to create new ReplicaSet 10/03/22 20:22:15.907
STEP: delete the deployment 10/03/22 20:22:16.434
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 10/03/22 20:22:16.451
STEP: Gathering metrics 10/03/22 20:22:17.039
W1003 20:22:17.126558      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Oct  3 20:22:17.126: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Oct  3 20:22:17.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3057" for this suite. 10/03/22 20:22:17.139
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":233,"skipped":4516,"failed":0}
------------------------------
• [1.345 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:22:15.844
    Oct  3 20:22:15.844: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename gc 10/03/22 20:22:15.845
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:22:15.88
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:22:15.886
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 10/03/22 20:22:15.891
    STEP: Wait for the Deployment to create new ReplicaSet 10/03/22 20:22:15.907
    STEP: delete the deployment 10/03/22 20:22:16.434
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 10/03/22 20:22:16.451
    STEP: Gathering metrics 10/03/22 20:22:17.039
    W1003 20:22:17.126558      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Oct  3 20:22:17.126: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Oct  3 20:22:17.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-3057" for this suite. 10/03/22 20:22:17.139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:22:17.197
Oct  3 20:22:17.198: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-probe 10/03/22 20:22:17.199
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:22:17.241
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:22:17.263
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-049bd927-20a7-4cae-874c-3150b9dbaafa in namespace container-probe-8237 10/03/22 20:22:17.272
Oct  3 20:22:17.300: INFO: Waiting up to 5m0s for pod "liveness-049bd927-20a7-4cae-874c-3150b9dbaafa" in namespace "container-probe-8237" to be "not pending"
Oct  3 20:22:17.317: INFO: Pod "liveness-049bd927-20a7-4cae-874c-3150b9dbaafa": Phase="Pending", Reason="", readiness=false. Elapsed: 16.624393ms
Oct  3 20:22:19.338: INFO: Pod "liveness-049bd927-20a7-4cae-874c-3150b9dbaafa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037531929s
Oct  3 20:22:21.332: INFO: Pod "liveness-049bd927-20a7-4cae-874c-3150b9dbaafa": Phase="Running", Reason="", readiness=true. Elapsed: 4.031862451s
Oct  3 20:22:21.332: INFO: Pod "liveness-049bd927-20a7-4cae-874c-3150b9dbaafa" satisfied condition "not pending"
Oct  3 20:22:21.332: INFO: Started pod liveness-049bd927-20a7-4cae-874c-3150b9dbaafa in namespace container-probe-8237
STEP: checking the pod's current state and verifying that restartCount is present 10/03/22 20:22:21.332
Oct  3 20:22:21.345: INFO: Initial restart count of pod liveness-049bd927-20a7-4cae-874c-3150b9dbaafa is 0
STEP: deleting the pod 10/03/22 20:26:22.91
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Oct  3 20:26:22.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8237" for this suite. 10/03/22 20:26:22.994
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":234,"skipped":4544,"failed":0}
------------------------------
• [SLOW TEST] [245.817 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:22:17.197
    Oct  3 20:22:17.198: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-probe 10/03/22 20:22:17.199
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:22:17.241
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:22:17.263
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-049bd927-20a7-4cae-874c-3150b9dbaafa in namespace container-probe-8237 10/03/22 20:22:17.272
    Oct  3 20:22:17.300: INFO: Waiting up to 5m0s for pod "liveness-049bd927-20a7-4cae-874c-3150b9dbaafa" in namespace "container-probe-8237" to be "not pending"
    Oct  3 20:22:17.317: INFO: Pod "liveness-049bd927-20a7-4cae-874c-3150b9dbaafa": Phase="Pending", Reason="", readiness=false. Elapsed: 16.624393ms
    Oct  3 20:22:19.338: INFO: Pod "liveness-049bd927-20a7-4cae-874c-3150b9dbaafa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037531929s
    Oct  3 20:22:21.332: INFO: Pod "liveness-049bd927-20a7-4cae-874c-3150b9dbaafa": Phase="Running", Reason="", readiness=true. Elapsed: 4.031862451s
    Oct  3 20:22:21.332: INFO: Pod "liveness-049bd927-20a7-4cae-874c-3150b9dbaafa" satisfied condition "not pending"
    Oct  3 20:22:21.332: INFO: Started pod liveness-049bd927-20a7-4cae-874c-3150b9dbaafa in namespace container-probe-8237
    STEP: checking the pod's current state and verifying that restartCount is present 10/03/22 20:22:21.332
    Oct  3 20:22:21.345: INFO: Initial restart count of pod liveness-049bd927-20a7-4cae-874c-3150b9dbaafa is 0
    STEP: deleting the pod 10/03/22 20:26:22.91
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Oct  3 20:26:22.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8237" for this suite. 10/03/22 20:26:22.994
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:26:23.015
Oct  3 20:26:23.015: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename resourcequota 10/03/22 20:26:23.017
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:26:23.054
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:26:23.063
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 10/03/22 20:26:23.08
STEP: Creating a ResourceQuota 10/03/22 20:26:28.089
STEP: Ensuring resource quota status is calculated 10/03/22 20:26:28.102
STEP: Creating a Pod that fits quota 10/03/22 20:26:30.114
STEP: Ensuring ResourceQuota status captures the pod usage 10/03/22 20:26:30.148
STEP: Not allowing a pod to be created that exceeds remaining quota 10/03/22 20:26:32.159
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 10/03/22 20:26:32.165
STEP: Ensuring a pod cannot update its resource requirements 10/03/22 20:26:32.171
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 10/03/22 20:26:32.184
STEP: Deleting the pod 10/03/22 20:26:34.196
STEP: Ensuring resource quota status released the pod usage 10/03/22 20:26:34.232
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Oct  3 20:26:36.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4955" for this suite. 10/03/22 20:26:36.262
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":235,"skipped":4552,"failed":0}
------------------------------
• [SLOW TEST] [13.267 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:26:23.015
    Oct  3 20:26:23.015: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename resourcequota 10/03/22 20:26:23.017
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:26:23.054
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:26:23.063
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 10/03/22 20:26:23.08
    STEP: Creating a ResourceQuota 10/03/22 20:26:28.089
    STEP: Ensuring resource quota status is calculated 10/03/22 20:26:28.102
    STEP: Creating a Pod that fits quota 10/03/22 20:26:30.114
    STEP: Ensuring ResourceQuota status captures the pod usage 10/03/22 20:26:30.148
    STEP: Not allowing a pod to be created that exceeds remaining quota 10/03/22 20:26:32.159
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 10/03/22 20:26:32.165
    STEP: Ensuring a pod cannot update its resource requirements 10/03/22 20:26:32.171
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 10/03/22 20:26:32.184
    STEP: Deleting the pod 10/03/22 20:26:34.196
    STEP: Ensuring resource quota status released the pod usage 10/03/22 20:26:34.232
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Oct  3 20:26:36.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4955" for this suite. 10/03/22 20:26:36.262
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:26:36.301
Oct  3 20:26:36.302: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 20:26:36.312
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:26:36.352
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:26:36.362
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-2247 10/03/22 20:26:36.371
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2247 to expose endpoints map[] 10/03/22 20:26:36.397
Oct  3 20:26:36.422: INFO: successfully validated that service multi-endpoint-test in namespace services-2247 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-2247 10/03/22 20:26:36.422
Oct  3 20:26:36.445: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-2247" to be "running and ready"
Oct  3 20:26:36.457: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.90592ms
Oct  3 20:26:36.457: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:26:38.468: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023619388s
Oct  3 20:26:38.468: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:26:40.469: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.024652262s
Oct  3 20:26:40.469: INFO: The phase of Pod pod1 is Running (Ready = true)
Oct  3 20:26:40.469: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2247 to expose endpoints map[pod1:[100]] 10/03/22 20:26:40.481
Oct  3 20:26:40.515: INFO: successfully validated that service multi-endpoint-test in namespace services-2247 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-2247 10/03/22 20:26:40.515
Oct  3 20:26:40.547: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-2247" to be "running and ready"
Oct  3 20:26:40.559: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.179381ms
Oct  3 20:26:40.559: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:26:42.572: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025571297s
Oct  3 20:26:42.573: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:26:44.571: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.024551917s
Oct  3 20:26:44.571: INFO: The phase of Pod pod2 is Running (Ready = true)
Oct  3 20:26:44.571: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2247 to expose endpoints map[pod1:[100] pod2:[101]] 10/03/22 20:26:44.583
Oct  3 20:26:44.630: INFO: successfully validated that service multi-endpoint-test in namespace services-2247 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 10/03/22 20:26:44.63
Oct  3 20:26:44.630: INFO: Creating new exec pod
Oct  3 20:26:44.644: INFO: Waiting up to 5m0s for pod "execpodwjh5j" in namespace "services-2247" to be "running"
Oct  3 20:26:44.655: INFO: Pod "execpodwjh5j": Phase="Pending", Reason="", readiness=false. Elapsed: 11.103279ms
Oct  3 20:26:46.669: INFO: Pod "execpodwjh5j": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024870279s
Oct  3 20:26:48.668: INFO: Pod "execpodwjh5j": Phase="Running", Reason="", readiness=true. Elapsed: 4.023530745s
Oct  3 20:26:48.668: INFO: Pod "execpodwjh5j" satisfied condition "running"
Oct  3 20:26:49.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2247 exec execpodwjh5j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Oct  3 20:26:49.955: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Oct  3 20:26:49.955: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:26:49.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2247 exec execpodwjh5j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.156.160 80'
Oct  3 20:26:50.261: INFO: stderr: "+ nc -v -t -w 2 172.21.156.160 80\n+ echo hostName\nConnection to 172.21.156.160 80 port [tcp/http] succeeded!\n"
Oct  3 20:26:50.261: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:26:50.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2247 exec execpodwjh5j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Oct  3 20:26:50.600: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Oct  3 20:26:50.600: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:26:50.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2247 exec execpodwjh5j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.156.160 81'
Oct  3 20:26:50.922: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.156.160 81\nConnection to 172.21.156.160 81 port [tcp/*] succeeded!\n"
Oct  3 20:26:50.922: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-2247 10/03/22 20:26:50.922
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2247 to expose endpoints map[pod2:[101]] 10/03/22 20:26:50.964
Oct  3 20:26:51.031: INFO: successfully validated that service multi-endpoint-test in namespace services-2247 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-2247 10/03/22 20:26:51.031
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2247 to expose endpoints map[] 10/03/22 20:26:51.063
Oct  3 20:26:51.117: INFO: successfully validated that service multi-endpoint-test in namespace services-2247 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 20:26:51.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2247" for this suite. 10/03/22 20:26:51.192
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":236,"skipped":4613,"failed":0}
------------------------------
• [SLOW TEST] [14.913 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:26:36.301
    Oct  3 20:26:36.302: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 20:26:36.312
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:26:36.352
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:26:36.362
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-2247 10/03/22 20:26:36.371
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2247 to expose endpoints map[] 10/03/22 20:26:36.397
    Oct  3 20:26:36.422: INFO: successfully validated that service multi-endpoint-test in namespace services-2247 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-2247 10/03/22 20:26:36.422
    Oct  3 20:26:36.445: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-2247" to be "running and ready"
    Oct  3 20:26:36.457: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.90592ms
    Oct  3 20:26:36.457: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:26:38.468: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023619388s
    Oct  3 20:26:38.468: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:26:40.469: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.024652262s
    Oct  3 20:26:40.469: INFO: The phase of Pod pod1 is Running (Ready = true)
    Oct  3 20:26:40.469: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2247 to expose endpoints map[pod1:[100]] 10/03/22 20:26:40.481
    Oct  3 20:26:40.515: INFO: successfully validated that service multi-endpoint-test in namespace services-2247 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-2247 10/03/22 20:26:40.515
    Oct  3 20:26:40.547: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-2247" to be "running and ready"
    Oct  3 20:26:40.559: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.179381ms
    Oct  3 20:26:40.559: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:26:42.572: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025571297s
    Oct  3 20:26:42.573: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:26:44.571: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.024551917s
    Oct  3 20:26:44.571: INFO: The phase of Pod pod2 is Running (Ready = true)
    Oct  3 20:26:44.571: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2247 to expose endpoints map[pod1:[100] pod2:[101]] 10/03/22 20:26:44.583
    Oct  3 20:26:44.630: INFO: successfully validated that service multi-endpoint-test in namespace services-2247 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 10/03/22 20:26:44.63
    Oct  3 20:26:44.630: INFO: Creating new exec pod
    Oct  3 20:26:44.644: INFO: Waiting up to 5m0s for pod "execpodwjh5j" in namespace "services-2247" to be "running"
    Oct  3 20:26:44.655: INFO: Pod "execpodwjh5j": Phase="Pending", Reason="", readiness=false. Elapsed: 11.103279ms
    Oct  3 20:26:46.669: INFO: Pod "execpodwjh5j": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024870279s
    Oct  3 20:26:48.668: INFO: Pod "execpodwjh5j": Phase="Running", Reason="", readiness=true. Elapsed: 4.023530745s
    Oct  3 20:26:48.668: INFO: Pod "execpodwjh5j" satisfied condition "running"
    Oct  3 20:26:49.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2247 exec execpodwjh5j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Oct  3 20:26:49.955: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Oct  3 20:26:49.955: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:26:49.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2247 exec execpodwjh5j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.156.160 80'
    Oct  3 20:26:50.261: INFO: stderr: "+ nc -v -t -w 2 172.21.156.160 80\n+ echo hostName\nConnection to 172.21.156.160 80 port [tcp/http] succeeded!\n"
    Oct  3 20:26:50.261: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:26:50.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2247 exec execpodwjh5j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Oct  3 20:26:50.600: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Oct  3 20:26:50.600: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:26:50.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-2247 exec execpodwjh5j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.156.160 81'
    Oct  3 20:26:50.922: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.156.160 81\nConnection to 172.21.156.160 81 port [tcp/*] succeeded!\n"
    Oct  3 20:26:50.922: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-2247 10/03/22 20:26:50.922
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2247 to expose endpoints map[pod2:[101]] 10/03/22 20:26:50.964
    Oct  3 20:26:51.031: INFO: successfully validated that service multi-endpoint-test in namespace services-2247 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-2247 10/03/22 20:26:51.031
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2247 to expose endpoints map[] 10/03/22 20:26:51.063
    Oct  3 20:26:51.117: INFO: successfully validated that service multi-endpoint-test in namespace services-2247 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 20:26:51.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2247" for this suite. 10/03/22 20:26:51.192
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:26:51.214
Oct  3 20:26:51.214: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename job 10/03/22 20:26:51.216
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:26:51.26
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:26:51.268
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 10/03/22 20:26:51.277
STEP: Ensuring job reaches completions 10/03/22 20:26:51.291
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Oct  3 20:27:05.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-780" for this suite. 10/03/22 20:27:05.32
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":237,"skipped":4618,"failed":0}
------------------------------
• [SLOW TEST] [14.154 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:26:51.214
    Oct  3 20:26:51.214: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename job 10/03/22 20:26:51.216
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:26:51.26
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:26:51.268
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 10/03/22 20:26:51.277
    STEP: Ensuring job reaches completions 10/03/22 20:26:51.291
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Oct  3 20:27:05.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-780" for this suite. 10/03/22 20:27:05.32
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:27:05.37
Oct  3 20:27:05.371: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename sched-pred 10/03/22 20:27:05.372
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:27:05.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:27:05.425
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Oct  3 20:27:05.433: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  3 20:27:05.470: INFO: Waiting for terminating namespaces to be deleted...
Oct  3 20:27:05.484: INFO: 
Logging pods the apiserver thinks is on node 10.63.128.13 before test
Oct  3 20:27:05.529: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-5lm6l from ibm-system started at 2022-10-03 17:16:04 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.529: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
Oct  3 20:27:05.529: INFO: calico-node-zpr9s from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.529: INFO: 	Container calico-node ready: true, restart count 0
Oct  3 20:27:05.529: INFO: calico-typha-644fdcd5f-w67fp from kube-system started at 2022-10-03 17:11:18 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.529: INFO: 	Container calico-typha ready: true, restart count 0
Oct  3 20:27:05.529: INFO: coredns-6754846f95-bl2wt from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.529: INFO: 	Container coredns ready: true, restart count 0
Oct  3 20:27:05.529: INFO: ibm-keepalived-watcher-nw2l6 from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.529: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  3 20:27:05.529: INFO: ibm-master-proxy-static-10.63.128.13 from kube-system started at 2022-10-03 17:10:55 +0000 UTC (2 container statuses recorded)
Oct  3 20:27:05.529: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct  3 20:27:05.529: INFO: 	Container pause ready: true, restart count 0
Oct  3 20:27:05.529: INFO: ibmcloud-block-storage-driver-f5thb from kube-system started at 2022-10-03 17:11:06 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.529: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct  3 20:27:05.529: INFO: ingress-cluster-healthcheck-6dbd7f8d47-vx87x from kube-system started at 2022-10-03 18:44:30 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.529: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Oct  3 20:27:05.529: INFO: konnectivity-agent-qv9fn from kube-system started at 2022-10-03 17:19:11 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.529: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct  3 20:27:05.529: INFO: metrics-server-668b4d7ddd-7glct from kube-system started at 2022-10-03 17:55:22 +0000 UTC (3 container statuses recorded)
Oct  3 20:27:05.529: INFO: 	Container config-watcher ready: true, restart count 0
Oct  3 20:27:05.529: INFO: 	Container metrics-server ready: true, restart count 0
Oct  3 20:27:05.529: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct  3 20:27:05.529: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-7vk57 from kube-system started at 2022-10-03 19:52:24 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.529: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct  3 20:27:05.529: INFO: sonobuoy-e2e-job-2c5abccdc00d487c from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 20:27:05.529: INFO: 	Container e2e ready: true, restart count 0
Oct  3 20:27:05.529: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 20:27:05.529: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-cwlqc from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 20:27:05.529: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 20:27:05.529: INFO: 	Container systemd-logs ready: true, restart count 0
Oct  3 20:27:05.529: INFO: 
Logging pods the apiserver thinks is on node 10.63.128.3 before test
Oct  3 20:27:05.566: INFO: fail-once-local-7sd92 from job-780 started at 2022-10-03 20:26:57 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.566: INFO: 	Container c ready: false, restart count 1
Oct  3 20:27:05.566: INFO: fail-once-local-gfxr2 from job-780 started at 2022-10-03 20:26:57 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.566: INFO: 	Container c ready: false, restart count 1
Oct  3 20:27:05.566: INFO: fail-once-local-sb8vv from job-780 started at 2022-10-03 20:26:51 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.566: INFO: 	Container c ready: false, restart count 1
Oct  3 20:27:05.566: INFO: fail-once-local-tvmv5 from job-780 started at 2022-10-03 20:26:51 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.566: INFO: 	Container c ready: false, restart count 1
Oct  3 20:27:05.566: INFO: calico-node-zrfj4 from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.566: INFO: 	Container calico-node ready: true, restart count 0
Oct  3 20:27:05.566: INFO: calico-typha-644fdcd5f-rskkx from kube-system started at 2022-10-03 20:20:28 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.566: INFO: 	Container calico-typha ready: true, restart count 0
Oct  3 20:27:05.566: INFO: ibm-keepalived-watcher-jr7cc from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.566: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  3 20:27:05.566: INFO: ibm-master-proxy-static-10.63.128.3 from kube-system started at 2022-10-03 17:10:52 +0000 UTC (2 container statuses recorded)
Oct  3 20:27:05.566: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct  3 20:27:05.566: INFO: 	Container pause ready: true, restart count 0
Oct  3 20:27:05.566: INFO: ibmcloud-block-storage-driver-j765w from kube-system started at 2022-10-03 17:11:13 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.566: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct  3 20:27:05.566: INFO: konnectivity-agent-n5jcf from kube-system started at 2022-10-03 17:19:17 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.566: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct  3 20:27:05.566: INFO: sonobuoy from sonobuoy started at 2022-10-03 19:13:32 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.566: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  3 20:27:05.566: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-lpx2r from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 20:27:05.566: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 20:27:05.566: INFO: 	Container systemd-logs ready: true, restart count 0
Oct  3 20:27:05.566: INFO: 
Logging pods the apiserver thinks is on node 10.63.128.51 before test
Oct  3 20:27:05.605: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-6mpp7 from ibm-system started at 2022-10-03 19:20:52 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.605: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
Oct  3 20:27:05.605: INFO: calico-kube-controllers-5ccfdf4b6d-qxssd from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.605: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct  3 20:27:05.605: INFO: calico-node-zfv55 from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.605: INFO: 	Container calico-node ready: true, restart count 0
Oct  3 20:27:05.605: INFO: calico-typha-644fdcd5f-7qcns from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.605: INFO: 	Container calico-typha ready: true, restart count 0
Oct  3 20:27:05.605: INFO: coredns-6754846f95-9q5kh from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.605: INFO: 	Container coredns ready: true, restart count 0
Oct  3 20:27:05.605: INFO: coredns-6754846f95-c7x4x from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.605: INFO: 	Container coredns ready: true, restart count 0
Oct  3 20:27:05.605: INFO: coredns-autoscaler-669cf746f6-wwqwh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.605: INFO: 	Container autoscaler ready: true, restart count 0
Oct  3 20:27:05.605: INFO: dashboard-metrics-scraper-c964d5594-bvc48 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.605: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Oct  3 20:27:05.605: INFO: ibm-file-plugin-bdf4f476-5nc82 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.605: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct  3 20:27:05.605: INFO: ibm-keepalived-watcher-8t2hv from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.605: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  3 20:27:05.605: INFO: ibm-master-proxy-static-10.63.128.51 from kube-system started at 2022-10-03 17:10:31 +0000 UTC (2 container statuses recorded)
Oct  3 20:27:05.605: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct  3 20:27:05.605: INFO: 	Container pause ready: true, restart count 0
Oct  3 20:27:05.605: INFO: ibm-storage-watcher-64fb9cdcfc-bsg7k from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.606: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct  3 20:27:05.606: INFO: ibmcloud-block-storage-driver-fdv2t from kube-system started at 2022-10-03 17:10:51 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.606: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct  3 20:27:05.606: INFO: ibmcloud-block-storage-plugin-7c4cfb55cb-72zmh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.606: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Oct  3 20:27:05.606: INFO: konnectivity-agent-lc67p from kube-system started at 2022-10-03 17:19:14 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.606: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct  3 20:27:05.606: INFO: kubernetes-dashboard-55c4d56798-qwrbg from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.606: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct  3 20:27:05.606: INFO: metrics-server-668b4d7ddd-mpnsv from kube-system started at 2022-10-03 19:20:52 +0000 UTC (3 container statuses recorded)
Oct  3 20:27:05.606: INFO: 	Container config-watcher ready: true, restart count 0
Oct  3 20:27:05.606: INFO: 	Container metrics-server ready: true, restart count 0
Oct  3 20:27:05.606: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct  3 20:27:05.606: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-cc7hf from kube-system started at 2022-10-03 20:20:26 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.606: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct  3 20:27:05.606: INFO: snapshot-controller-c5c6dddff-2mxr6 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.606: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct  3 20:27:05.606: INFO: snapshot-controller-c5c6dddff-m6kpt from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.606: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct  3 20:27:05.606: INFO: snapshot-controller-c5c6dddff-wjxf9 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:27:05.606: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct  3 20:27:05.606: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-z8psd from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 20:27:05.606: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 20:27:05.606: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 10/03/22 20:27:05.606
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.171aa8ff0e47376d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 10/03/22 20:27:05.69
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Oct  3 20:27:06.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2349" for this suite. 10/03/22 20:27:06.705
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":238,"skipped":4628,"failed":0}
------------------------------
• [1.354 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:27:05.37
    Oct  3 20:27:05.371: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename sched-pred 10/03/22 20:27:05.372
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:27:05.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:27:05.425
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Oct  3 20:27:05.433: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Oct  3 20:27:05.470: INFO: Waiting for terminating namespaces to be deleted...
    Oct  3 20:27:05.484: INFO: 
    Logging pods the apiserver thinks is on node 10.63.128.13 before test
    Oct  3 20:27:05.529: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-5lm6l from ibm-system started at 2022-10-03 17:16:04 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.529: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: calico-node-zpr9s from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.529: INFO: 	Container calico-node ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: calico-typha-644fdcd5f-w67fp from kube-system started at 2022-10-03 17:11:18 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.529: INFO: 	Container calico-typha ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: coredns-6754846f95-bl2wt from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.529: INFO: 	Container coredns ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: ibm-keepalived-watcher-nw2l6 from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.529: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: ibm-master-proxy-static-10.63.128.13 from kube-system started at 2022-10-03 17:10:55 +0000 UTC (2 container statuses recorded)
    Oct  3 20:27:05.529: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: 	Container pause ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: ibmcloud-block-storage-driver-f5thb from kube-system started at 2022-10-03 17:11:06 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.529: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: ingress-cluster-healthcheck-6dbd7f8d47-vx87x from kube-system started at 2022-10-03 18:44:30 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.529: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: konnectivity-agent-qv9fn from kube-system started at 2022-10-03 17:19:11 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.529: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: metrics-server-668b4d7ddd-7glct from kube-system started at 2022-10-03 17:55:22 +0000 UTC (3 container statuses recorded)
    Oct  3 20:27:05.529: INFO: 	Container config-watcher ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: 	Container metrics-server ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-7vk57 from kube-system started at 2022-10-03 19:52:24 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.529: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: sonobuoy-e2e-job-2c5abccdc00d487c from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 20:27:05.529: INFO: 	Container e2e ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-cwlqc from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 20:27:05.529: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct  3 20:27:05.529: INFO: 
    Logging pods the apiserver thinks is on node 10.63.128.3 before test
    Oct  3 20:27:05.566: INFO: fail-once-local-7sd92 from job-780 started at 2022-10-03 20:26:57 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.566: INFO: 	Container c ready: false, restart count 1
    Oct  3 20:27:05.566: INFO: fail-once-local-gfxr2 from job-780 started at 2022-10-03 20:26:57 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.566: INFO: 	Container c ready: false, restart count 1
    Oct  3 20:27:05.566: INFO: fail-once-local-sb8vv from job-780 started at 2022-10-03 20:26:51 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.566: INFO: 	Container c ready: false, restart count 1
    Oct  3 20:27:05.566: INFO: fail-once-local-tvmv5 from job-780 started at 2022-10-03 20:26:51 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.566: INFO: 	Container c ready: false, restart count 1
    Oct  3 20:27:05.566: INFO: calico-node-zrfj4 from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.566: INFO: 	Container calico-node ready: true, restart count 0
    Oct  3 20:27:05.566: INFO: calico-typha-644fdcd5f-rskkx from kube-system started at 2022-10-03 20:20:28 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.566: INFO: 	Container calico-typha ready: true, restart count 0
    Oct  3 20:27:05.566: INFO: ibm-keepalived-watcher-jr7cc from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.566: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct  3 20:27:05.566: INFO: ibm-master-proxy-static-10.63.128.3 from kube-system started at 2022-10-03 17:10:52 +0000 UTC (2 container statuses recorded)
    Oct  3 20:27:05.566: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct  3 20:27:05.566: INFO: 	Container pause ready: true, restart count 0
    Oct  3 20:27:05.566: INFO: ibmcloud-block-storage-driver-j765w from kube-system started at 2022-10-03 17:11:13 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.566: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct  3 20:27:05.566: INFO: konnectivity-agent-n5jcf from kube-system started at 2022-10-03 17:19:17 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.566: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct  3 20:27:05.566: INFO: sonobuoy from sonobuoy started at 2022-10-03 19:13:32 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.566: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Oct  3 20:27:05.566: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-lpx2r from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 20:27:05.566: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 20:27:05.566: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct  3 20:27:05.566: INFO: 
    Logging pods the apiserver thinks is on node 10.63.128.51 before test
    Oct  3 20:27:05.605: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-6mpp7 from ibm-system started at 2022-10-03 19:20:52 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.605: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
    Oct  3 20:27:05.605: INFO: calico-kube-controllers-5ccfdf4b6d-qxssd from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.605: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Oct  3 20:27:05.605: INFO: calico-node-zfv55 from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.605: INFO: 	Container calico-node ready: true, restart count 0
    Oct  3 20:27:05.605: INFO: calico-typha-644fdcd5f-7qcns from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.605: INFO: 	Container calico-typha ready: true, restart count 0
    Oct  3 20:27:05.605: INFO: coredns-6754846f95-9q5kh from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.605: INFO: 	Container coredns ready: true, restart count 0
    Oct  3 20:27:05.605: INFO: coredns-6754846f95-c7x4x from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.605: INFO: 	Container coredns ready: true, restart count 0
    Oct  3 20:27:05.605: INFO: coredns-autoscaler-669cf746f6-wwqwh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.605: INFO: 	Container autoscaler ready: true, restart count 0
    Oct  3 20:27:05.605: INFO: dashboard-metrics-scraper-c964d5594-bvc48 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.605: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Oct  3 20:27:05.605: INFO: ibm-file-plugin-bdf4f476-5nc82 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.605: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Oct  3 20:27:05.605: INFO: ibm-keepalived-watcher-8t2hv from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.605: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct  3 20:27:05.605: INFO: ibm-master-proxy-static-10.63.128.51 from kube-system started at 2022-10-03 17:10:31 +0000 UTC (2 container statuses recorded)
    Oct  3 20:27:05.605: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct  3 20:27:05.605: INFO: 	Container pause ready: true, restart count 0
    Oct  3 20:27:05.605: INFO: ibm-storage-watcher-64fb9cdcfc-bsg7k from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.606: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Oct  3 20:27:05.606: INFO: ibmcloud-block-storage-driver-fdv2t from kube-system started at 2022-10-03 17:10:51 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.606: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct  3 20:27:05.606: INFO: ibmcloud-block-storage-plugin-7c4cfb55cb-72zmh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.606: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Oct  3 20:27:05.606: INFO: konnectivity-agent-lc67p from kube-system started at 2022-10-03 17:19:14 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.606: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct  3 20:27:05.606: INFO: kubernetes-dashboard-55c4d56798-qwrbg from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.606: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Oct  3 20:27:05.606: INFO: metrics-server-668b4d7ddd-mpnsv from kube-system started at 2022-10-03 19:20:52 +0000 UTC (3 container statuses recorded)
    Oct  3 20:27:05.606: INFO: 	Container config-watcher ready: true, restart count 0
    Oct  3 20:27:05.606: INFO: 	Container metrics-server ready: true, restart count 0
    Oct  3 20:27:05.606: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct  3 20:27:05.606: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-cc7hf from kube-system started at 2022-10-03 20:20:26 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.606: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct  3 20:27:05.606: INFO: snapshot-controller-c5c6dddff-2mxr6 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.606: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct  3 20:27:05.606: INFO: snapshot-controller-c5c6dddff-m6kpt from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.606: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct  3 20:27:05.606: INFO: snapshot-controller-c5c6dddff-wjxf9 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:27:05.606: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct  3 20:27:05.606: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-z8psd from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 20:27:05.606: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 20:27:05.606: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 10/03/22 20:27:05.606
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.171aa8ff0e47376d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 10/03/22 20:27:05.69
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 20:27:06.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-2349" for this suite. 10/03/22 20:27:06.705
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:27:06.729
Oct  3 20:27:06.730: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename job 10/03/22 20:27:06.731
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:27:06.769
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:27:06.778
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 10/03/22 20:27:06.787
STEP: Ensuring active pods == parallelism 10/03/22 20:27:06.799
STEP: delete a job 10/03/22 20:27:10.814
STEP: deleting Job.batch foo in namespace job-7467, will wait for the garbage collector to delete the pods 10/03/22 20:27:10.814
Oct  3 20:27:10.892: INFO: Deleting Job.batch foo took: 17.102699ms
Oct  3 20:27:10.992: INFO: Terminating Job.batch foo pods took: 100.557283ms
STEP: Ensuring job was deleted 10/03/22 20:27:43.093
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Oct  3 20:27:43.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7467" for this suite. 10/03/22 20:27:43.121
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":239,"skipped":4653,"failed":0}
------------------------------
• [SLOW TEST] [36.412 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:27:06.729
    Oct  3 20:27:06.730: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename job 10/03/22 20:27:06.731
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:27:06.769
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:27:06.778
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 10/03/22 20:27:06.787
    STEP: Ensuring active pods == parallelism 10/03/22 20:27:06.799
    STEP: delete a job 10/03/22 20:27:10.814
    STEP: deleting Job.batch foo in namespace job-7467, will wait for the garbage collector to delete the pods 10/03/22 20:27:10.814
    Oct  3 20:27:10.892: INFO: Deleting Job.batch foo took: 17.102699ms
    Oct  3 20:27:10.992: INFO: Terminating Job.batch foo pods took: 100.557283ms
    STEP: Ensuring job was deleted 10/03/22 20:27:43.093
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Oct  3 20:27:43.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-7467" for this suite. 10/03/22 20:27:43.121
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:27:43.144
Oct  3 20:27:43.145: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename statefulset 10/03/22 20:27:43.146
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:27:43.187
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:27:43.195
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6396 10/03/22 20:27:43.204
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Oct  3 20:27:43.242: INFO: Found 0 stateful pods, waiting for 1
Oct  3 20:27:53.257: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 10/03/22 20:27:53.279
W1003 20:27:53.297135      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Oct  3 20:27:53.321: INFO: Found 1 stateful pods, waiting for 2
Oct  3 20:28:03.335: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  3 20:28:03.335: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 10/03/22 20:28:03.357
STEP: Delete all of the StatefulSets 10/03/22 20:28:03.368
STEP: Verify that StatefulSets have been deleted 10/03/22 20:28:03.391
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct  3 20:28:03.401: INFO: Deleting all statefulset in ns statefulset-6396
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Oct  3 20:28:03.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6396" for this suite. 10/03/22 20:28:03.461
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":240,"skipped":4655,"failed":0}
------------------------------
• [SLOW TEST] [20.338 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:27:43.144
    Oct  3 20:27:43.145: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename statefulset 10/03/22 20:27:43.146
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:27:43.187
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:27:43.195
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6396 10/03/22 20:27:43.204
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Oct  3 20:27:43.242: INFO: Found 0 stateful pods, waiting for 1
    Oct  3 20:27:53.257: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 10/03/22 20:27:53.279
    W1003 20:27:53.297135      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Oct  3 20:27:53.321: INFO: Found 1 stateful pods, waiting for 2
    Oct  3 20:28:03.335: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Oct  3 20:28:03.335: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 10/03/22 20:28:03.357
    STEP: Delete all of the StatefulSets 10/03/22 20:28:03.368
    STEP: Verify that StatefulSets have been deleted 10/03/22 20:28:03.391
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Oct  3 20:28:03.401: INFO: Deleting all statefulset in ns statefulset-6396
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Oct  3 20:28:03.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6396" for this suite. 10/03/22 20:28:03.461
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:28:03.494
Oct  3 20:28:03.494: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename pods 10/03/22 20:28:03.495
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:28:03.536
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:28:03.545
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 10/03/22 20:28:03.565
STEP: submitting the pod to kubernetes 10/03/22 20:28:03.566
Oct  3 20:28:03.591: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3" in namespace "pods-5687" to be "running and ready"
Oct  3 20:28:03.607: INFO: Pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3": Phase="Pending", Reason="", readiness=false. Elapsed: 15.52767ms
Oct  3 20:28:03.607: INFO: The phase of Pod pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:28:05.620: INFO: Pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0287386s
Oct  3 20:28:05.620: INFO: The phase of Pod pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:28:07.619: INFO: Pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3": Phase="Running", Reason="", readiness=true. Elapsed: 4.028036371s
Oct  3 20:28:07.619: INFO: The phase of Pod pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3 is Running (Ready = true)
Oct  3 20:28:07.619: INFO: Pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 10/03/22 20:28:07.631
STEP: updating the pod 10/03/22 20:28:07.642
Oct  3 20:28:08.174: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3"
Oct  3 20:28:08.174: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3" in namespace "pods-5687" to be "terminated with reason DeadlineExceeded"
Oct  3 20:28:08.187: INFO: Pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3": Phase="Running", Reason="", readiness=true. Elapsed: 12.649802ms
Oct  3 20:28:10.200: INFO: Pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.025767224s
Oct  3 20:28:10.200: INFO: Pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Oct  3 20:28:10.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5687" for this suite. 10/03/22 20:28:10.217
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":241,"skipped":4749,"failed":0}
------------------------------
• [SLOW TEST] [6.742 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:28:03.494
    Oct  3 20:28:03.494: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename pods 10/03/22 20:28:03.495
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:28:03.536
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:28:03.545
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 10/03/22 20:28:03.565
    STEP: submitting the pod to kubernetes 10/03/22 20:28:03.566
    Oct  3 20:28:03.591: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3" in namespace "pods-5687" to be "running and ready"
    Oct  3 20:28:03.607: INFO: Pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3": Phase="Pending", Reason="", readiness=false. Elapsed: 15.52767ms
    Oct  3 20:28:03.607: INFO: The phase of Pod pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:28:05.620: INFO: Pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0287386s
    Oct  3 20:28:05.620: INFO: The phase of Pod pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:28:07.619: INFO: Pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3": Phase="Running", Reason="", readiness=true. Elapsed: 4.028036371s
    Oct  3 20:28:07.619: INFO: The phase of Pod pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3 is Running (Ready = true)
    Oct  3 20:28:07.619: INFO: Pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 10/03/22 20:28:07.631
    STEP: updating the pod 10/03/22 20:28:07.642
    Oct  3 20:28:08.174: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3"
    Oct  3 20:28:08.174: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3" in namespace "pods-5687" to be "terminated with reason DeadlineExceeded"
    Oct  3 20:28:08.187: INFO: Pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3": Phase="Running", Reason="", readiness=true. Elapsed: 12.649802ms
    Oct  3 20:28:10.200: INFO: Pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.025767224s
    Oct  3 20:28:10.200: INFO: Pod "pod-update-activedeadlineseconds-a5f9596a-52fb-4455-ac00-5367d9f99ae3" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Oct  3 20:28:10.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5687" for this suite. 10/03/22 20:28:10.217
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:28:10.239
Oct  3 20:28:10.239: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename resourcequota 10/03/22 20:28:10.24
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:28:10.279
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:28:10.287
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 10/03/22 20:28:10.296
STEP: Ensuring ResourceQuota status is calculated 10/03/22 20:28:10.31
STEP: Creating a ResourceQuota with not terminating scope 10/03/22 20:28:12.321
STEP: Ensuring ResourceQuota status is calculated 10/03/22 20:28:12.334
STEP: Creating a long running pod 10/03/22 20:28:14.345
STEP: Ensuring resource quota with not terminating scope captures the pod usage 10/03/22 20:28:14.376
STEP: Ensuring resource quota with terminating scope ignored the pod usage 10/03/22 20:28:16.388
STEP: Deleting the pod 10/03/22 20:28:18.4
STEP: Ensuring resource quota status released the pod usage 10/03/22 20:28:18.441
STEP: Creating a terminating pod 10/03/22 20:28:20.452
STEP: Ensuring resource quota with terminating scope captures the pod usage 10/03/22 20:28:20.477
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 10/03/22 20:28:22.487
STEP: Deleting the pod 10/03/22 20:28:24.5
STEP: Ensuring resource quota status released the pod usage 10/03/22 20:28:24.53
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Oct  3 20:28:26.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5593" for this suite. 10/03/22 20:28:26.557
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":242,"skipped":4758,"failed":0}
------------------------------
• [SLOW TEST] [16.338 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:28:10.239
    Oct  3 20:28:10.239: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename resourcequota 10/03/22 20:28:10.24
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:28:10.279
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:28:10.287
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 10/03/22 20:28:10.296
    STEP: Ensuring ResourceQuota status is calculated 10/03/22 20:28:10.31
    STEP: Creating a ResourceQuota with not terminating scope 10/03/22 20:28:12.321
    STEP: Ensuring ResourceQuota status is calculated 10/03/22 20:28:12.334
    STEP: Creating a long running pod 10/03/22 20:28:14.345
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 10/03/22 20:28:14.376
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 10/03/22 20:28:16.388
    STEP: Deleting the pod 10/03/22 20:28:18.4
    STEP: Ensuring resource quota status released the pod usage 10/03/22 20:28:18.441
    STEP: Creating a terminating pod 10/03/22 20:28:20.452
    STEP: Ensuring resource quota with terminating scope captures the pod usage 10/03/22 20:28:20.477
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 10/03/22 20:28:22.487
    STEP: Deleting the pod 10/03/22 20:28:24.5
    STEP: Ensuring resource quota status released the pod usage 10/03/22 20:28:24.53
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Oct  3 20:28:26.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5593" for this suite. 10/03/22 20:28:26.557
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:28:26.579
Oct  3 20:28:26.579: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename sched-preemption 10/03/22 20:28:26.58
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:28:26.619
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:28:26.643
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Oct  3 20:28:26.684: INFO: Waiting up to 1m0s for all nodes to be ready
Oct  3 20:29:26.771: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:29:26.784
Oct  3 20:29:26.785: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename sched-preemption-path 10/03/22 20:29:26.786
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:29:26.828
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:29:26.837
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 10/03/22 20:29:26.845
STEP: Trying to launch a pod without a label to get a node which can launch it. 10/03/22 20:29:26.845
Oct  3 20:29:26.866: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-1772" to be "running"
Oct  3 20:29:26.877: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 10.69793ms
Oct  3 20:29:28.890: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023613705s
Oct  3 20:29:30.890: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.024324177s
Oct  3 20:29:30.890: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 10/03/22 20:29:30.902
Oct  3 20:29:30.941: INFO: found a healthy node: 10.63.128.3
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Oct  3 20:29:47.145: INFO: pods created so far: [1 1 1]
Oct  3 20:29:47.145: INFO: length of pods created so far: 3
Oct  3 20:29:49.173: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Oct  3 20:29:56.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-1772" for this suite. 10/03/22 20:29:56.19
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Oct  3 20:29:56.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-160" for this suite. 10/03/22 20:29:56.322
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":243,"skipped":4778,"failed":0}
------------------------------
• [SLOW TEST] [89.892 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:28:26.579
    Oct  3 20:28:26.579: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename sched-preemption 10/03/22 20:28:26.58
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:28:26.619
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:28:26.643
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Oct  3 20:28:26.684: INFO: Waiting up to 1m0s for all nodes to be ready
    Oct  3 20:29:26.771: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:29:26.784
    Oct  3 20:29:26.785: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename sched-preemption-path 10/03/22 20:29:26.786
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:29:26.828
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:29:26.837
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 10/03/22 20:29:26.845
    STEP: Trying to launch a pod without a label to get a node which can launch it. 10/03/22 20:29:26.845
    Oct  3 20:29:26.866: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-1772" to be "running"
    Oct  3 20:29:26.877: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 10.69793ms
    Oct  3 20:29:28.890: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023613705s
    Oct  3 20:29:30.890: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.024324177s
    Oct  3 20:29:30.890: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 10/03/22 20:29:30.902
    Oct  3 20:29:30.941: INFO: found a healthy node: 10.63.128.3
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Oct  3 20:29:47.145: INFO: pods created so far: [1 1 1]
    Oct  3 20:29:47.145: INFO: length of pods created so far: 3
    Oct  3 20:29:49.173: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Oct  3 20:29:56.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-1772" for this suite. 10/03/22 20:29:56.19
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 20:29:56.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-160" for this suite. 10/03/22 20:29:56.322
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:29:56.477
Oct  3 20:29:56.477: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir 10/03/22 20:29:56.478
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:29:56.521
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:29:56.529
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 10/03/22 20:29:56.538
Oct  3 20:29:56.560: INFO: Waiting up to 5m0s for pod "pod-91c61cab-1d79-4323-ac53-5d24b5e76af7" in namespace "emptydir-8649" to be "Succeeded or Failed"
Oct  3 20:29:56.571: INFO: Pod "pod-91c61cab-1d79-4323-ac53-5d24b5e76af7": Phase="Pending", Reason="", readiness=false. Elapsed: 11.276564ms
Oct  3 20:29:58.585: INFO: Pod "pod-91c61cab-1d79-4323-ac53-5d24b5e76af7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024560711s
Oct  3 20:30:00.585: INFO: Pod "pod-91c61cab-1d79-4323-ac53-5d24b5e76af7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024590846s
STEP: Saw pod success 10/03/22 20:30:00.585
Oct  3 20:30:00.585: INFO: Pod "pod-91c61cab-1d79-4323-ac53-5d24b5e76af7" satisfied condition "Succeeded or Failed"
Oct  3 20:30:00.597: INFO: Trying to get logs from node 10.63.128.3 pod pod-91c61cab-1d79-4323-ac53-5d24b5e76af7 container test-container: <nil>
STEP: delete the pod 10/03/22 20:30:00.679
Oct  3 20:30:00.717: INFO: Waiting for pod pod-91c61cab-1d79-4323-ac53-5d24b5e76af7 to disappear
Oct  3 20:30:00.728: INFO: Pod pod-91c61cab-1d79-4323-ac53-5d24b5e76af7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Oct  3 20:30:00.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8649" for this suite. 10/03/22 20:30:00.745
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":244,"skipped":4803,"failed":0}
------------------------------
• [4.287 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:29:56.477
    Oct  3 20:29:56.477: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir 10/03/22 20:29:56.478
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:29:56.521
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:29:56.529
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 10/03/22 20:29:56.538
    Oct  3 20:29:56.560: INFO: Waiting up to 5m0s for pod "pod-91c61cab-1d79-4323-ac53-5d24b5e76af7" in namespace "emptydir-8649" to be "Succeeded or Failed"
    Oct  3 20:29:56.571: INFO: Pod "pod-91c61cab-1d79-4323-ac53-5d24b5e76af7": Phase="Pending", Reason="", readiness=false. Elapsed: 11.276564ms
    Oct  3 20:29:58.585: INFO: Pod "pod-91c61cab-1d79-4323-ac53-5d24b5e76af7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024560711s
    Oct  3 20:30:00.585: INFO: Pod "pod-91c61cab-1d79-4323-ac53-5d24b5e76af7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024590846s
    STEP: Saw pod success 10/03/22 20:30:00.585
    Oct  3 20:30:00.585: INFO: Pod "pod-91c61cab-1d79-4323-ac53-5d24b5e76af7" satisfied condition "Succeeded or Failed"
    Oct  3 20:30:00.597: INFO: Trying to get logs from node 10.63.128.3 pod pod-91c61cab-1d79-4323-ac53-5d24b5e76af7 container test-container: <nil>
    STEP: delete the pod 10/03/22 20:30:00.679
    Oct  3 20:30:00.717: INFO: Waiting for pod pod-91c61cab-1d79-4323-ac53-5d24b5e76af7 to disappear
    Oct  3 20:30:00.728: INFO: Pod pod-91c61cab-1d79-4323-ac53-5d24b5e76af7 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Oct  3 20:30:00.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8649" for this suite. 10/03/22 20:30:00.745
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:30:00.766
Oct  3 20:30:00.766: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename pods 10/03/22 20:30:00.767
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:30:00.806
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:30:00.815
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Oct  3 20:30:00.824: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: creating the pod 10/03/22 20:30:00.825
STEP: submitting the pod to kubernetes 10/03/22 20:30:00.825
Oct  3 20:30:00.845: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa" in namespace "pods-709" to be "running and ready"
Oct  3 20:30:00.856: INFO: Pod "pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa": Phase="Pending", Reason="", readiness=false. Elapsed: 11.322517ms
Oct  3 20:30:00.856: INFO: The phase of Pod pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:30:02.872: INFO: Pod "pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026625815s
Oct  3 20:30:02.872: INFO: The phase of Pod pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:30:04.869: INFO: Pod "pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa": Phase="Running", Reason="", readiness=true. Elapsed: 4.023775862s
Oct  3 20:30:04.869: INFO: The phase of Pod pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa is Running (Ready = true)
Oct  3 20:30:04.869: INFO: Pod "pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Oct  3 20:30:05.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-709" for this suite. 10/03/22 20:30:05.116
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":245,"skipped":4818,"failed":0}
------------------------------
• [4.371 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:30:00.766
    Oct  3 20:30:00.766: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename pods 10/03/22 20:30:00.767
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:30:00.806
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:30:00.815
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Oct  3 20:30:00.824: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: creating the pod 10/03/22 20:30:00.825
    STEP: submitting the pod to kubernetes 10/03/22 20:30:00.825
    Oct  3 20:30:00.845: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa" in namespace "pods-709" to be "running and ready"
    Oct  3 20:30:00.856: INFO: Pod "pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa": Phase="Pending", Reason="", readiness=false. Elapsed: 11.322517ms
    Oct  3 20:30:00.856: INFO: The phase of Pod pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:30:02.872: INFO: Pod "pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026625815s
    Oct  3 20:30:02.872: INFO: The phase of Pod pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:30:04.869: INFO: Pod "pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa": Phase="Running", Reason="", readiness=true. Elapsed: 4.023775862s
    Oct  3 20:30:04.869: INFO: The phase of Pod pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa is Running (Ready = true)
    Oct  3 20:30:04.869: INFO: Pod "pod-exec-websocket-8104a3d5-4b5f-4a72-af74-8c14e2d24afa" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Oct  3 20:30:05.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-709" for this suite. 10/03/22 20:30:05.116
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:30:05.141
Oct  3 20:30:05.141: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 20:30:05.142
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:30:05.183
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:30:05.192
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 10/03/22 20:30:05.201
Oct  3 20:30:05.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2692 create -f -'
Oct  3 20:30:05.537: INFO: stderr: ""
Oct  3 20:30:05.537: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 10/03/22 20:30:05.537
Oct  3 20:30:05.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2692 diff -f -'
Oct  3 20:30:06.547: INFO: rc: 1
Oct  3 20:30:06.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2692 delete -f -'
Oct  3 20:30:06.663: INFO: stderr: ""
Oct  3 20:30:06.663: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 20:30:06.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2692" for this suite. 10/03/22 20:30:06.716
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":246,"skipped":4869,"failed":0}
------------------------------
• [1.626 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:30:05.141
    Oct  3 20:30:05.141: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 20:30:05.142
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:30:05.183
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:30:05.192
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 10/03/22 20:30:05.201
    Oct  3 20:30:05.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2692 create -f -'
    Oct  3 20:30:05.537: INFO: stderr: ""
    Oct  3 20:30:05.537: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 10/03/22 20:30:05.537
    Oct  3 20:30:05.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2692 diff -f -'
    Oct  3 20:30:06.547: INFO: rc: 1
    Oct  3 20:30:06.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-2692 delete -f -'
    Oct  3 20:30:06.663: INFO: stderr: ""
    Oct  3 20:30:06.663: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 20:30:06.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2692" for this suite. 10/03/22 20:30:06.716
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:30:06.77
Oct  3 20:30:06.770: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-lifecycle-hook 10/03/22 20:30:06.771
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:30:06.811
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:30:06.82
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 10/03/22 20:30:06.873
Oct  3 20:30:06.894: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2882" to be "running and ready"
Oct  3 20:30:06.907: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 12.333097ms
Oct  3 20:30:06.907: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:30:08.920: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025499913s
Oct  3 20:30:08.920: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:30:10.938: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.043595621s
Oct  3 20:30:10.938: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Oct  3 20:30:10.938: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 10/03/22 20:30:10.949
Oct  3 20:30:10.963: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-2882" to be "running and ready"
Oct  3 20:30:10.976: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 13.123242ms
Oct  3 20:30:10.976: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:30:12.990: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026999482s
Oct  3 20:30:12.990: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:30:14.994: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.031161711s
Oct  3 20:30:14.994: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Oct  3 20:30:14.994: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 10/03/22 20:30:15.006
STEP: delete the pod with lifecycle hook 10/03/22 20:30:15.101
Oct  3 20:30:15.122: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  3 20:30:15.134: INFO: Pod pod-with-poststart-http-hook still exists
Oct  3 20:30:17.135: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  3 20:30:17.154: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Oct  3 20:30:17.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2882" for this suite. 10/03/22 20:30:17.172
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":247,"skipped":4884,"failed":0}
------------------------------
• [SLOW TEST] [10.426 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:30:06.77
    Oct  3 20:30:06.770: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-lifecycle-hook 10/03/22 20:30:06.771
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:30:06.811
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:30:06.82
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 10/03/22 20:30:06.873
    Oct  3 20:30:06.894: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2882" to be "running and ready"
    Oct  3 20:30:06.907: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 12.333097ms
    Oct  3 20:30:06.907: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:30:08.920: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025499913s
    Oct  3 20:30:08.920: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:30:10.938: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.043595621s
    Oct  3 20:30:10.938: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Oct  3 20:30:10.938: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 10/03/22 20:30:10.949
    Oct  3 20:30:10.963: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-2882" to be "running and ready"
    Oct  3 20:30:10.976: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 13.123242ms
    Oct  3 20:30:10.976: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:30:12.990: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026999482s
    Oct  3 20:30:12.990: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:30:14.994: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.031161711s
    Oct  3 20:30:14.994: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Oct  3 20:30:14.994: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 10/03/22 20:30:15.006
    STEP: delete the pod with lifecycle hook 10/03/22 20:30:15.101
    Oct  3 20:30:15.122: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Oct  3 20:30:15.134: INFO: Pod pod-with-poststart-http-hook still exists
    Oct  3 20:30:17.135: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Oct  3 20:30:17.154: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Oct  3 20:30:17.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-2882" for this suite. 10/03/22 20:30:17.172
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:30:17.203
Oct  3 20:30:17.203: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename dns 10/03/22 20:30:17.204
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:30:17.247
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:30:17.255
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 10/03/22 20:30:17.264
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8371 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8371;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8371 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8371;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8371.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8371.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8371.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8371.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8371.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8371.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8371.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8371.svc;check="$$(dig +notcp +noall +answer +search 109.3.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.3.109_udp@PTR;check="$$(dig +tcp +noall +answer +search 109.3.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.3.109_tcp@PTR;sleep 1; done
 10/03/22 20:30:17.316
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8371 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8371;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8371 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8371;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8371.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8371.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8371.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8371.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8371.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8371.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8371.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8371.svc;check="$$(dig +notcp +noall +answer +search 109.3.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.3.109_udp@PTR;check="$$(dig +tcp +noall +answer +search 109.3.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.3.109_tcp@PTR;sleep 1; done
 10/03/22 20:30:17.316
STEP: creating a pod to probe DNS 10/03/22 20:30:17.316
STEP: submitting the pod to kubernetes 10/03/22 20:30:17.317
Oct  3 20:30:17.340: INFO: Waiting up to 15m0s for pod "dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff" in namespace "dns-8371" to be "running"
Oct  3 20:30:17.369: INFO: Pod "dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff": Phase="Pending", Reason="", readiness=false. Elapsed: 28.956041ms
Oct  3 20:30:19.392: INFO: Pod "dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05182372s
Oct  3 20:30:21.383: INFO: Pod "dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff": Phase="Running", Reason="", readiness=true. Elapsed: 4.042910757s
Oct  3 20:30:21.383: INFO: Pod "dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff" satisfied condition "running"
STEP: retrieving the pod 10/03/22 20:30:21.383
STEP: looking for the results for each expected name from probers 10/03/22 20:30:21.396
Oct  3 20:30:21.439: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:21.455: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:21.496: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:21.538: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:21.554: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:21.594: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:21.727: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:21.742: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:21.759: INFO: Unable to read jessie_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:21.803: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:21.819: INFO: Unable to read jessie_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:21.883: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:22.031: INFO: Lookups using dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8371 wheezy_tcp@dns-test-service.dns-8371 wheezy_udp@dns-test-service.dns-8371.svc wheezy_tcp@dns-test-service.dns-8371.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8371 jessie_tcp@dns-test-service.dns-8371 jessie_udp@dns-test-service.dns-8371.svc jessie_tcp@dns-test-service.dns-8371.svc]

Oct  3 20:30:27.075: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:27.092: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:27.127: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:27.144: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:27.178: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:27.193: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:27.336: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:27.354: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:27.394: INFO: Unable to read jessie_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:27.411: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:27.428: INFO: Unable to read jessie_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:27.471: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:27.569: INFO: Lookups using dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8371 wheezy_tcp@dns-test-service.dns-8371 wheezy_udp@dns-test-service.dns-8371.svc wheezy_tcp@dns-test-service.dns-8371.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8371 jessie_tcp@dns-test-service.dns-8371 jessie_udp@dns-test-service.dns-8371.svc jessie_tcp@dns-test-service.dns-8371.svc]

Oct  3 20:30:32.049: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:32.071: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:32.092: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:32.136: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:32.179: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:32.196: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:32.326: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:32.341: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:32.356: INFO: Unable to read jessie_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:32.372: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:32.388: INFO: Unable to read jessie_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:32.404: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:32.500: INFO: Lookups using dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8371 wheezy_tcp@dns-test-service.dns-8371 wheezy_udp@dns-test-service.dns-8371.svc wheezy_tcp@dns-test-service.dns-8371.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8371 jessie_tcp@dns-test-service.dns-8371 jessie_udp@dns-test-service.dns-8371.svc jessie_tcp@dns-test-service.dns-8371.svc]

Oct  3 20:30:37.049: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:37.065: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:37.082: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:37.099: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:37.116: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:37.161: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:37.289: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:37.306: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:37.321: INFO: Unable to read jessie_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:37.337: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:37.371: INFO: Unable to read jessie_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:37.391: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:37.531: INFO: Lookups using dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8371 wheezy_tcp@dns-test-service.dns-8371 wheezy_udp@dns-test-service.dns-8371.svc wheezy_tcp@dns-test-service.dns-8371.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8371 jessie_tcp@dns-test-service.dns-8371 jessie_udp@dns-test-service.dns-8371.svc jessie_tcp@dns-test-service.dns-8371.svc]

Oct  3 20:30:42.049: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:42.085: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:42.100: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:42.115: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:42.130: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:42.145: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:42.266: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:42.305: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:42.349: INFO: Unable to read jessie_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:42.365: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:42.408: INFO: Unable to read jessie_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:42.423: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:42.557: INFO: Lookups using dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8371 wheezy_tcp@dns-test-service.dns-8371 wheezy_udp@dns-test-service.dns-8371.svc wheezy_tcp@dns-test-service.dns-8371.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8371 jessie_tcp@dns-test-service.dns-8371 jessie_udp@dns-test-service.dns-8371.svc jessie_tcp@dns-test-service.dns-8371.svc]

Oct  3 20:30:47.068: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:47.083: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:47.099: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:47.114: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:47.130: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:47.146: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:47.276: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:47.292: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:47.308: INFO: Unable to read jessie_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:47.324: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:47.338: INFO: Unable to read jessie_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:47.352: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
Oct  3 20:30:47.446: INFO: Lookups using dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8371 wheezy_tcp@dns-test-service.dns-8371 wheezy_udp@dns-test-service.dns-8371.svc wheezy_tcp@dns-test-service.dns-8371.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8371 jessie_tcp@dns-test-service.dns-8371 jessie_udp@dns-test-service.dns-8371.svc jessie_tcp@dns-test-service.dns-8371.svc]

Oct  3 20:30:52.475: INFO: DNS probes using dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff succeeded

STEP: deleting the pod 10/03/22 20:30:52.475
STEP: deleting the test service 10/03/22 20:30:52.521
STEP: deleting the test headless service 10/03/22 20:30:52.578
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Oct  3 20:30:52.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8371" for this suite. 10/03/22 20:30:52.648
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":248,"skipped":4923,"failed":0}
------------------------------
• [SLOW TEST] [35.466 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:30:17.203
    Oct  3 20:30:17.203: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename dns 10/03/22 20:30:17.204
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:30:17.247
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:30:17.255
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 10/03/22 20:30:17.264
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8371 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8371;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8371 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8371;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8371.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8371.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8371.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8371.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8371.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8371.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8371.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8371.svc;check="$$(dig +notcp +noall +answer +search 109.3.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.3.109_udp@PTR;check="$$(dig +tcp +noall +answer +search 109.3.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.3.109_tcp@PTR;sleep 1; done
     10/03/22 20:30:17.316
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8371 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8371;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8371 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8371;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8371.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8371.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8371.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8371.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8371.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8371.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8371.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8371.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8371.svc;check="$$(dig +notcp +noall +answer +search 109.3.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.3.109_udp@PTR;check="$$(dig +tcp +noall +answer +search 109.3.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.3.109_tcp@PTR;sleep 1; done
     10/03/22 20:30:17.316
    STEP: creating a pod to probe DNS 10/03/22 20:30:17.316
    STEP: submitting the pod to kubernetes 10/03/22 20:30:17.317
    Oct  3 20:30:17.340: INFO: Waiting up to 15m0s for pod "dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff" in namespace "dns-8371" to be "running"
    Oct  3 20:30:17.369: INFO: Pod "dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff": Phase="Pending", Reason="", readiness=false. Elapsed: 28.956041ms
    Oct  3 20:30:19.392: INFO: Pod "dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05182372s
    Oct  3 20:30:21.383: INFO: Pod "dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff": Phase="Running", Reason="", readiness=true. Elapsed: 4.042910757s
    Oct  3 20:30:21.383: INFO: Pod "dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff" satisfied condition "running"
    STEP: retrieving the pod 10/03/22 20:30:21.383
    STEP: looking for the results for each expected name from probers 10/03/22 20:30:21.396
    Oct  3 20:30:21.439: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:21.455: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:21.496: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:21.538: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:21.554: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:21.594: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:21.727: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:21.742: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:21.759: INFO: Unable to read jessie_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:21.803: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:21.819: INFO: Unable to read jessie_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:21.883: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:22.031: INFO: Lookups using dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8371 wheezy_tcp@dns-test-service.dns-8371 wheezy_udp@dns-test-service.dns-8371.svc wheezy_tcp@dns-test-service.dns-8371.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8371 jessie_tcp@dns-test-service.dns-8371 jessie_udp@dns-test-service.dns-8371.svc jessie_tcp@dns-test-service.dns-8371.svc]

    Oct  3 20:30:27.075: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:27.092: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:27.127: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:27.144: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:27.178: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:27.193: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:27.336: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:27.354: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:27.394: INFO: Unable to read jessie_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:27.411: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:27.428: INFO: Unable to read jessie_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:27.471: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:27.569: INFO: Lookups using dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8371 wheezy_tcp@dns-test-service.dns-8371 wheezy_udp@dns-test-service.dns-8371.svc wheezy_tcp@dns-test-service.dns-8371.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8371 jessie_tcp@dns-test-service.dns-8371 jessie_udp@dns-test-service.dns-8371.svc jessie_tcp@dns-test-service.dns-8371.svc]

    Oct  3 20:30:32.049: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:32.071: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:32.092: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:32.136: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:32.179: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:32.196: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:32.326: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:32.341: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:32.356: INFO: Unable to read jessie_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:32.372: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:32.388: INFO: Unable to read jessie_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:32.404: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:32.500: INFO: Lookups using dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8371 wheezy_tcp@dns-test-service.dns-8371 wheezy_udp@dns-test-service.dns-8371.svc wheezy_tcp@dns-test-service.dns-8371.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8371 jessie_tcp@dns-test-service.dns-8371 jessie_udp@dns-test-service.dns-8371.svc jessie_tcp@dns-test-service.dns-8371.svc]

    Oct  3 20:30:37.049: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:37.065: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:37.082: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:37.099: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:37.116: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:37.161: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:37.289: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:37.306: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:37.321: INFO: Unable to read jessie_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:37.337: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:37.371: INFO: Unable to read jessie_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:37.391: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:37.531: INFO: Lookups using dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8371 wheezy_tcp@dns-test-service.dns-8371 wheezy_udp@dns-test-service.dns-8371.svc wheezy_tcp@dns-test-service.dns-8371.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8371 jessie_tcp@dns-test-service.dns-8371 jessie_udp@dns-test-service.dns-8371.svc jessie_tcp@dns-test-service.dns-8371.svc]

    Oct  3 20:30:42.049: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:42.085: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:42.100: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:42.115: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:42.130: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:42.145: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:42.266: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:42.305: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:42.349: INFO: Unable to read jessie_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:42.365: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:42.408: INFO: Unable to read jessie_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:42.423: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:42.557: INFO: Lookups using dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8371 wheezy_tcp@dns-test-service.dns-8371 wheezy_udp@dns-test-service.dns-8371.svc wheezy_tcp@dns-test-service.dns-8371.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8371 jessie_tcp@dns-test-service.dns-8371 jessie_udp@dns-test-service.dns-8371.svc jessie_tcp@dns-test-service.dns-8371.svc]

    Oct  3 20:30:47.068: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:47.083: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:47.099: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:47.114: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:47.130: INFO: Unable to read wheezy_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:47.146: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:47.276: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:47.292: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:47.308: INFO: Unable to read jessie_udp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:47.324: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371 from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:47.338: INFO: Unable to read jessie_udp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:47.352: INFO: Unable to read jessie_tcp@dns-test-service.dns-8371.svc from pod dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff: the server could not find the requested resource (get pods dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff)
    Oct  3 20:30:47.446: INFO: Lookups using dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8371 wheezy_tcp@dns-test-service.dns-8371 wheezy_udp@dns-test-service.dns-8371.svc wheezy_tcp@dns-test-service.dns-8371.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8371 jessie_tcp@dns-test-service.dns-8371 jessie_udp@dns-test-service.dns-8371.svc jessie_tcp@dns-test-service.dns-8371.svc]

    Oct  3 20:30:52.475: INFO: DNS probes using dns-8371/dns-test-ae4d9b61-7925-467c-bc0b-a30f0017dfff succeeded

    STEP: deleting the pod 10/03/22 20:30:52.475
    STEP: deleting the test service 10/03/22 20:30:52.521
    STEP: deleting the test headless service 10/03/22 20:30:52.578
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Oct  3 20:30:52.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-8371" for this suite. 10/03/22 20:30:52.648
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:30:52.674
Oct  3 20:30:52.674: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename deployment 10/03/22 20:30:52.675
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:30:52.744
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:30:52.752
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Oct  3 20:30:52.793: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct  3 20:30:52.817: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct  3 20:30:57.833: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 10/03/22 20:30:57.833
Oct  3 20:30:57.833: INFO: Creating deployment "test-rolling-update-deployment"
Oct  3 20:30:57.845: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct  3 20:30:57.879: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Oct  3 20:30:59.901: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct  3 20:30:59.911: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct  3 20:30:59.940: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-8164  b2075ea2-3c1e-44a8-bfd1-e0ca6acc5fdc 36948 1 2022-10-03 20:30:57 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-10-03 20:30:57 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:30:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0041291c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-10-03 20:30:57 +0000 UTC,LastTransitionTime:2022-10-03 20:30:57 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-10-03 20:30:59 +0000 UTC,LastTransitionTime:2022-10-03 20:30:57 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct  3 20:30:59.949: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-8164  e0382f97-46c8-4e69-a286-ff40ea692a9b 36937 1 2022-10-03 20:30:57 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment b2075ea2-3c1e-44a8-bfd1-e0ca6acc5fdc 0xc0041296f7 0xc0041296f8}] [] [{kube-controller-manager Update apps/v1 2022-10-03 20:30:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b2075ea2-3c1e-44a8-bfd1-e0ca6acc5fdc\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:30:59 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0041297a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct  3 20:30:59.949: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct  3 20:30:59.949: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-8164  22ae48c6-54cb-4e41-92a6-86485631001f 36947 2 2022-10-03 20:30:52 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment b2075ea2-3c1e-44a8-bfd1-e0ca6acc5fdc 0xc0041295c7 0xc0041295c8}] [] [{e2e.test Update apps/v1 2022-10-03 20:30:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:30:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b2075ea2-3c1e-44a8-bfd1-e0ca6acc5fdc\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:30:59 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004129688 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  3 20:30:59.963: INFO: Pod "test-rolling-update-deployment-78f575d8ff-4768g" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-4768g test-rolling-update-deployment-78f575d8ff- deployment-8164  6ec33c7d-8d23-4010-8d49-8c0d3e8ac589 36936 0 2022-10-03 20:30:57 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:eba5110754b33df78b57b3627ed83102ad8c95fd7a4966a64b318db3acbc3083 cni.projectcalico.org/podIP:172.30.49.52/32 cni.projectcalico.org/podIPs:172.30.49.52/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff e0382f97-46c8-4e69-a286-ff40ea692a9b 0xc004dfb3a7 0xc004dfb3a8}] [] [{kube-controller-manager Update v1 2022-10-03 20:30:57 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0382f97-46c8-4e69-a286-ff40ea692a9b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 20:30:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 20:30:59 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.52\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8hprm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8hprm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:30:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:30:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:30:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:30:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.52,StartTime:2022-10-03 20:30:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 20:30:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://86836dff99e8146662bced2eb2f417df91d0f2d08784161aaad0bdb9e2e62846,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.52,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Oct  3 20:30:59.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8164" for this suite. 10/03/22 20:30:59.992
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":249,"skipped":4985,"failed":0}
------------------------------
• [SLOW TEST] [7.338 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:30:52.674
    Oct  3 20:30:52.674: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename deployment 10/03/22 20:30:52.675
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:30:52.744
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:30:52.752
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Oct  3 20:30:52.793: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Oct  3 20:30:52.817: INFO: Pod name sample-pod: Found 0 pods out of 1
    Oct  3 20:30:57.833: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 10/03/22 20:30:57.833
    Oct  3 20:30:57.833: INFO: Creating deployment "test-rolling-update-deployment"
    Oct  3 20:30:57.845: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Oct  3 20:30:57.879: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
    Oct  3 20:30:59.901: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Oct  3 20:30:59.911: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct  3 20:30:59.940: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-8164  b2075ea2-3c1e-44a8-bfd1-e0ca6acc5fdc 36948 1 2022-10-03 20:30:57 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-10-03 20:30:57 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:30:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0041291c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-10-03 20:30:57 +0000 UTC,LastTransitionTime:2022-10-03 20:30:57 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-10-03 20:30:59 +0000 UTC,LastTransitionTime:2022-10-03 20:30:57 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Oct  3 20:30:59.949: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-8164  e0382f97-46c8-4e69-a286-ff40ea692a9b 36937 1 2022-10-03 20:30:57 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment b2075ea2-3c1e-44a8-bfd1-e0ca6acc5fdc 0xc0041296f7 0xc0041296f8}] [] [{kube-controller-manager Update apps/v1 2022-10-03 20:30:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b2075ea2-3c1e-44a8-bfd1-e0ca6acc5fdc\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:30:59 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0041297a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Oct  3 20:30:59.949: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Oct  3 20:30:59.949: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-8164  22ae48c6-54cb-4e41-92a6-86485631001f 36947 2 2022-10-03 20:30:52 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment b2075ea2-3c1e-44a8-bfd1-e0ca6acc5fdc 0xc0041295c7 0xc0041295c8}] [] [{e2e.test Update apps/v1 2022-10-03 20:30:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:30:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b2075ea2-3c1e-44a8-bfd1-e0ca6acc5fdc\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:30:59 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004129688 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Oct  3 20:30:59.963: INFO: Pod "test-rolling-update-deployment-78f575d8ff-4768g" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-4768g test-rolling-update-deployment-78f575d8ff- deployment-8164  6ec33c7d-8d23-4010-8d49-8c0d3e8ac589 36936 0 2022-10-03 20:30:57 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:eba5110754b33df78b57b3627ed83102ad8c95fd7a4966a64b318db3acbc3083 cni.projectcalico.org/podIP:172.30.49.52/32 cni.projectcalico.org/podIPs:172.30.49.52/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff e0382f97-46c8-4e69-a286-ff40ea692a9b 0xc004dfb3a7 0xc004dfb3a8}] [] [{kube-controller-manager Update v1 2022-10-03 20:30:57 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0382f97-46c8-4e69-a286-ff40ea692a9b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 20:30:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 20:30:59 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.52\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8hprm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8hprm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:30:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:30:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:30:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:30:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.52,StartTime:2022-10-03 20:30:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 20:30:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://86836dff99e8146662bced2eb2f417df91d0f2d08784161aaad0bdb9e2e62846,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.52,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Oct  3 20:30:59.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8164" for this suite. 10/03/22 20:30:59.992
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:31:00.013
Oct  3 20:31:00.014: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename pod-network-test 10/03/22 20:31:00.015
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:31:00.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:31:00.081
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-5995 10/03/22 20:31:00.091
STEP: creating a selector 10/03/22 20:31:00.091
STEP: Creating the service pods in kubernetes 10/03/22 20:31:00.092
Oct  3 20:31:00.092: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Oct  3 20:31:00.178: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5995" to be "running and ready"
Oct  3 20:31:00.192: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.387798ms
Oct  3 20:31:00.193: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:31:02.206: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.027441069s
Oct  3 20:31:02.206: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:31:04.206: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.02769709s
Oct  3 20:31:04.206: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:31:06.204: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.026027946s
Oct  3 20:31:06.204: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:31:08.206: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.027529905s
Oct  3 20:31:08.206: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:31:10.206: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.027988339s
Oct  3 20:31:10.206: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:31:12.207: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.02888782s
Oct  3 20:31:12.207: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:31:14.206: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.027592781s
Oct  3 20:31:14.206: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:31:16.205: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.027096436s
Oct  3 20:31:16.205: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:31:18.206: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.027465483s
Oct  3 20:31:18.206: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:31:20.205: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.027307477s
Oct  3 20:31:20.205: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:31:22.208: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.029616389s
Oct  3 20:31:22.208: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Oct  3 20:31:22.208: INFO: Pod "netserver-0" satisfied condition "running and ready"
Oct  3 20:31:22.220: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5995" to be "running and ready"
Oct  3 20:31:22.232: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 11.889679ms
Oct  3 20:31:22.232: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Oct  3 20:31:22.232: INFO: Pod "netserver-1" satisfied condition "running and ready"
Oct  3 20:31:22.244: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5995" to be "running and ready"
Oct  3 20:31:22.256: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 11.372928ms
Oct  3 20:31:22.256: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Oct  3 20:31:22.256: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 10/03/22 20:31:22.266
Oct  3 20:31:22.281: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5995" to be "running"
Oct  3 20:31:22.294: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.931816ms
Oct  3 20:31:24.333: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.052242202s
Oct  3 20:31:24.333: INFO: Pod "test-container-pod" satisfied condition "running"
Oct  3 20:31:24.348: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Oct  3 20:31:24.348: INFO: Breadth first check of 172.30.35.255 on host 10.63.128.13...
Oct  3 20:31:24.359: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.49.53:9080/dial?request=hostname&protocol=udp&host=172.30.35.255&port=8081&tries=1'] Namespace:pod-network-test-5995 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:31:24.359: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:31:24.360: INFO: ExecWithOptions: Clientset creation
Oct  3 20:31:24.360: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5995/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.49.53%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.35.255%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct  3 20:31:24.602: INFO: Waiting for responses: map[]
Oct  3 20:31:24.602: INFO: reached 172.30.35.255 after 0/1 tries
Oct  3 20:31:24.602: INFO: Breadth first check of 172.30.49.55 on host 10.63.128.3...
Oct  3 20:31:24.615: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.49.53:9080/dial?request=hostname&protocol=udp&host=172.30.49.55&port=8081&tries=1'] Namespace:pod-network-test-5995 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:31:24.615: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:31:24.616: INFO: ExecWithOptions: Clientset creation
Oct  3 20:31:24.616: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5995/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.49.53%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.49.55%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct  3 20:31:24.838: INFO: Waiting for responses: map[]
Oct  3 20:31:24.838: INFO: reached 172.30.49.55 after 0/1 tries
Oct  3 20:31:24.838: INFO: Breadth first check of 172.30.174.248 on host 10.63.128.51...
Oct  3 20:31:24.850: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.49.53:9080/dial?request=hostname&protocol=udp&host=172.30.174.248&port=8081&tries=1'] Namespace:pod-network-test-5995 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:31:24.850: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:31:24.851: INFO: ExecWithOptions: Clientset creation
Oct  3 20:31:24.851: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5995/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.49.53%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.174.248%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct  3 20:31:25.076: INFO: Waiting for responses: map[]
Oct  3 20:31:25.076: INFO: reached 172.30.174.248 after 0/1 tries
Oct  3 20:31:25.076: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Oct  3 20:31:25.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5995" for this suite. 10/03/22 20:31:25.096
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":250,"skipped":4989,"failed":0}
------------------------------
• [SLOW TEST] [25.102 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:31:00.013
    Oct  3 20:31:00.014: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename pod-network-test 10/03/22 20:31:00.015
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:31:00.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:31:00.081
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-5995 10/03/22 20:31:00.091
    STEP: creating a selector 10/03/22 20:31:00.091
    STEP: Creating the service pods in kubernetes 10/03/22 20:31:00.092
    Oct  3 20:31:00.092: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Oct  3 20:31:00.178: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5995" to be "running and ready"
    Oct  3 20:31:00.192: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.387798ms
    Oct  3 20:31:00.193: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:31:02.206: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.027441069s
    Oct  3 20:31:02.206: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:31:04.206: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.02769709s
    Oct  3 20:31:04.206: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:31:06.204: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.026027946s
    Oct  3 20:31:06.204: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:31:08.206: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.027529905s
    Oct  3 20:31:08.206: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:31:10.206: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.027988339s
    Oct  3 20:31:10.206: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:31:12.207: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.02888782s
    Oct  3 20:31:12.207: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:31:14.206: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.027592781s
    Oct  3 20:31:14.206: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:31:16.205: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.027096436s
    Oct  3 20:31:16.205: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:31:18.206: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.027465483s
    Oct  3 20:31:18.206: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:31:20.205: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.027307477s
    Oct  3 20:31:20.205: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:31:22.208: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.029616389s
    Oct  3 20:31:22.208: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Oct  3 20:31:22.208: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Oct  3 20:31:22.220: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5995" to be "running and ready"
    Oct  3 20:31:22.232: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 11.889679ms
    Oct  3 20:31:22.232: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Oct  3 20:31:22.232: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Oct  3 20:31:22.244: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5995" to be "running and ready"
    Oct  3 20:31:22.256: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 11.372928ms
    Oct  3 20:31:22.256: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Oct  3 20:31:22.256: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 10/03/22 20:31:22.266
    Oct  3 20:31:22.281: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5995" to be "running"
    Oct  3 20:31:22.294: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.931816ms
    Oct  3 20:31:24.333: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.052242202s
    Oct  3 20:31:24.333: INFO: Pod "test-container-pod" satisfied condition "running"
    Oct  3 20:31:24.348: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Oct  3 20:31:24.348: INFO: Breadth first check of 172.30.35.255 on host 10.63.128.13...
    Oct  3 20:31:24.359: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.49.53:9080/dial?request=hostname&protocol=udp&host=172.30.35.255&port=8081&tries=1'] Namespace:pod-network-test-5995 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:31:24.359: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:31:24.360: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:31:24.360: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5995/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.49.53%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.35.255%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Oct  3 20:31:24.602: INFO: Waiting for responses: map[]
    Oct  3 20:31:24.602: INFO: reached 172.30.35.255 after 0/1 tries
    Oct  3 20:31:24.602: INFO: Breadth first check of 172.30.49.55 on host 10.63.128.3...
    Oct  3 20:31:24.615: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.49.53:9080/dial?request=hostname&protocol=udp&host=172.30.49.55&port=8081&tries=1'] Namespace:pod-network-test-5995 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:31:24.615: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:31:24.616: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:31:24.616: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5995/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.49.53%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.49.55%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Oct  3 20:31:24.838: INFO: Waiting for responses: map[]
    Oct  3 20:31:24.838: INFO: reached 172.30.49.55 after 0/1 tries
    Oct  3 20:31:24.838: INFO: Breadth first check of 172.30.174.248 on host 10.63.128.51...
    Oct  3 20:31:24.850: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.49.53:9080/dial?request=hostname&protocol=udp&host=172.30.174.248&port=8081&tries=1'] Namespace:pod-network-test-5995 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:31:24.850: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:31:24.851: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:31:24.851: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5995/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.49.53%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.174.248%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Oct  3 20:31:25.076: INFO: Waiting for responses: map[]
    Oct  3 20:31:25.076: INFO: reached 172.30.174.248 after 0/1 tries
    Oct  3 20:31:25.076: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Oct  3 20:31:25.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-5995" for this suite. 10/03/22 20:31:25.096
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:31:25.118
Oct  3 20:31:25.119: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 20:31:25.12
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:31:25.191
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:31:25.199
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-9229 10/03/22 20:31:25.208
Oct  3 20:31:25.230: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-9229" to be "running and ready"
Oct  3 20:31:25.263: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 33.523866ms
Oct  3 20:31:25.263: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:31:27.277: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.047339482s
Oct  3 20:31:27.277: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Oct  3 20:31:27.278: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Oct  3 20:31:27.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9229 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Oct  3 20:31:27.612: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Oct  3 20:31:27.612: INFO: stdout: "iptables"
Oct  3 20:31:27.612: INFO: proxyMode: iptables
Oct  3 20:31:27.664: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Oct  3 20:31:27.691: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-9229 10/03/22 20:31:27.691
STEP: creating replication controller affinity-clusterip-timeout in namespace services-9229 10/03/22 20:31:27.72
I1003 20:31:27.736428      22 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-9229, replica count: 3
I1003 20:31:30.788512      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  3 20:31:30.813: INFO: Creating new exec pod
Oct  3 20:31:30.826: INFO: Waiting up to 5m0s for pod "execpod-affinitycrknj" in namespace "services-9229" to be "running"
Oct  3 20:31:30.841: INFO: Pod "execpod-affinitycrknj": Phase="Pending", Reason="", readiness=false. Elapsed: 15.082922ms
Oct  3 20:31:32.854: INFO: Pod "execpod-affinitycrknj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027762135s
Oct  3 20:31:34.854: INFO: Pod "execpod-affinitycrknj": Phase="Running", Reason="", readiness=true. Elapsed: 4.02769679s
Oct  3 20:31:34.854: INFO: Pod "execpod-affinitycrknj" satisfied condition "running"
Oct  3 20:31:35.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9229 exec execpod-affinitycrknj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Oct  3 20:31:36.172: INFO: stderr: "+ echo hostName+ \nnc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Oct  3 20:31:36.172: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:31:36.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9229 exec execpod-affinitycrknj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.134.239 80'
Oct  3 20:31:36.504: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.134.239 80\nConnection to 172.21.134.239 80 port [tcp/http] succeeded!\n"
Oct  3 20:31:36.504: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:31:36.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9229 exec execpod-affinitycrknj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.134.239:80/ ; done'
Oct  3 20:31:36.995: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n"
Oct  3 20:31:36.995: INFO: stdout: "\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9"
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
Oct  3 20:31:36.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9229 exec execpod-affinitycrknj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.21.134.239:80/'
Oct  3 20:31:37.321: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n"
Oct  3 20:31:37.321: INFO: stdout: "affinity-clusterip-timeout-qvct9"
Oct  3 20:31:57.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9229 exec execpod-affinitycrknj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.21.134.239:80/'
Oct  3 20:31:57.698: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n"
Oct  3 20:31:57.698: INFO: stdout: "affinity-clusterip-timeout-qvct9"
Oct  3 20:32:17.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9229 exec execpod-affinitycrknj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.21.134.239:80/'
Oct  3 20:32:18.039: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n"
Oct  3 20:32:18.039: INFO: stdout: "affinity-clusterip-timeout-9cs74"
Oct  3 20:32:18.039: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-9229, will wait for the garbage collector to delete the pods 10/03/22 20:32:18.07
Oct  3 20:32:18.149: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 16.545019ms
Oct  3 20:32:18.249: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.423826ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 20:32:21.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9229" for this suite. 10/03/22 20:32:21.024
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":251,"skipped":4999,"failed":0}
------------------------------
• [SLOW TEST] [55.927 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:31:25.118
    Oct  3 20:31:25.119: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 20:31:25.12
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:31:25.191
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:31:25.199
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-9229 10/03/22 20:31:25.208
    Oct  3 20:31:25.230: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-9229" to be "running and ready"
    Oct  3 20:31:25.263: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 33.523866ms
    Oct  3 20:31:25.263: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:31:27.277: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.047339482s
    Oct  3 20:31:27.277: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Oct  3 20:31:27.278: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Oct  3 20:31:27.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9229 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Oct  3 20:31:27.612: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Oct  3 20:31:27.612: INFO: stdout: "iptables"
    Oct  3 20:31:27.612: INFO: proxyMode: iptables
    Oct  3 20:31:27.664: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Oct  3 20:31:27.691: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-9229 10/03/22 20:31:27.691
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-9229 10/03/22 20:31:27.72
    I1003 20:31:27.736428      22 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-9229, replica count: 3
    I1003 20:31:30.788512      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct  3 20:31:30.813: INFO: Creating new exec pod
    Oct  3 20:31:30.826: INFO: Waiting up to 5m0s for pod "execpod-affinitycrknj" in namespace "services-9229" to be "running"
    Oct  3 20:31:30.841: INFO: Pod "execpod-affinitycrknj": Phase="Pending", Reason="", readiness=false. Elapsed: 15.082922ms
    Oct  3 20:31:32.854: INFO: Pod "execpod-affinitycrknj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027762135s
    Oct  3 20:31:34.854: INFO: Pod "execpod-affinitycrknj": Phase="Running", Reason="", readiness=true. Elapsed: 4.02769679s
    Oct  3 20:31:34.854: INFO: Pod "execpod-affinitycrknj" satisfied condition "running"
    Oct  3 20:31:35.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9229 exec execpod-affinitycrknj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Oct  3 20:31:36.172: INFO: stderr: "+ echo hostName+ \nnc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Oct  3 20:31:36.172: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:31:36.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9229 exec execpod-affinitycrknj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.134.239 80'
    Oct  3 20:31:36.504: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.134.239 80\nConnection to 172.21.134.239 80 port [tcp/http] succeeded!\n"
    Oct  3 20:31:36.504: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:31:36.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9229 exec execpod-affinitycrknj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.134.239:80/ ; done'
    Oct  3 20:31:36.995: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n"
    Oct  3 20:31:36.995: INFO: stdout: "\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9\naffinity-clusterip-timeout-qvct9"
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.995: INFO: Received response from host: affinity-clusterip-timeout-qvct9
    Oct  3 20:31:36.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9229 exec execpod-affinitycrknj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.21.134.239:80/'
    Oct  3 20:31:37.321: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n"
    Oct  3 20:31:37.321: INFO: stdout: "affinity-clusterip-timeout-qvct9"
    Oct  3 20:31:57.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9229 exec execpod-affinitycrknj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.21.134.239:80/'
    Oct  3 20:31:57.698: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n"
    Oct  3 20:31:57.698: INFO: stdout: "affinity-clusterip-timeout-qvct9"
    Oct  3 20:32:17.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-9229 exec execpod-affinitycrknj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.21.134.239:80/'
    Oct  3 20:32:18.039: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.21.134.239:80/\n"
    Oct  3 20:32:18.039: INFO: stdout: "affinity-clusterip-timeout-9cs74"
    Oct  3 20:32:18.039: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-9229, will wait for the garbage collector to delete the pods 10/03/22 20:32:18.07
    Oct  3 20:32:18.149: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 16.545019ms
    Oct  3 20:32:18.249: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.423826ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 20:32:21.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9229" for this suite. 10/03/22 20:32:21.024
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:32:21.047
Oct  3 20:32:21.047: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename replicaset 10/03/22 20:32:21.048
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:32:21.089
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:32:21.097
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 10/03/22 20:32:21.117
STEP: Verify that the required pods have come up. 10/03/22 20:32:21.129
Oct  3 20:32:21.142: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct  3 20:32:26.155: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 10/03/22 20:32:26.155
STEP: Getting /status 10/03/22 20:32:26.156
Oct  3 20:32:26.168: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 10/03/22 20:32:26.168
Oct  3 20:32:26.192: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 10/03/22 20:32:26.192
Oct  3 20:32:26.197: INFO: Observed &ReplicaSet event: ADDED
Oct  3 20:32:26.197: INFO: Observed &ReplicaSet event: MODIFIED
Oct  3 20:32:26.197: INFO: Observed &ReplicaSet event: MODIFIED
Oct  3 20:32:26.198: INFO: Observed &ReplicaSet event: MODIFIED
Oct  3 20:32:26.198: INFO: Found replicaset test-rs in namespace replicaset-1811 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Oct  3 20:32:26.198: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 10/03/22 20:32:26.198
Oct  3 20:32:26.198: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Oct  3 20:32:26.211: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 10/03/22 20:32:26.211
Oct  3 20:32:26.216: INFO: Observed &ReplicaSet event: ADDED
Oct  3 20:32:26.216: INFO: Observed &ReplicaSet event: MODIFIED
Oct  3 20:32:26.216: INFO: Observed &ReplicaSet event: MODIFIED
Oct  3 20:32:26.217: INFO: Observed &ReplicaSet event: MODIFIED
Oct  3 20:32:26.217: INFO: Observed replicaset test-rs in namespace replicaset-1811 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Oct  3 20:32:26.217: INFO: Observed &ReplicaSet event: MODIFIED
Oct  3 20:32:26.217: INFO: Found replicaset test-rs in namespace replicaset-1811 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Oct  3 20:32:26.217: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Oct  3 20:32:26.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1811" for this suite. 10/03/22 20:32:26.238
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":252,"skipped":5015,"failed":0}
------------------------------
• [SLOW TEST] [5.212 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:32:21.047
    Oct  3 20:32:21.047: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename replicaset 10/03/22 20:32:21.048
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:32:21.089
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:32:21.097
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 10/03/22 20:32:21.117
    STEP: Verify that the required pods have come up. 10/03/22 20:32:21.129
    Oct  3 20:32:21.142: INFO: Pod name sample-pod: Found 0 pods out of 1
    Oct  3 20:32:26.155: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 10/03/22 20:32:26.155
    STEP: Getting /status 10/03/22 20:32:26.156
    Oct  3 20:32:26.168: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 10/03/22 20:32:26.168
    Oct  3 20:32:26.192: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 10/03/22 20:32:26.192
    Oct  3 20:32:26.197: INFO: Observed &ReplicaSet event: ADDED
    Oct  3 20:32:26.197: INFO: Observed &ReplicaSet event: MODIFIED
    Oct  3 20:32:26.197: INFO: Observed &ReplicaSet event: MODIFIED
    Oct  3 20:32:26.198: INFO: Observed &ReplicaSet event: MODIFIED
    Oct  3 20:32:26.198: INFO: Found replicaset test-rs in namespace replicaset-1811 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Oct  3 20:32:26.198: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 10/03/22 20:32:26.198
    Oct  3 20:32:26.198: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Oct  3 20:32:26.211: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 10/03/22 20:32:26.211
    Oct  3 20:32:26.216: INFO: Observed &ReplicaSet event: ADDED
    Oct  3 20:32:26.216: INFO: Observed &ReplicaSet event: MODIFIED
    Oct  3 20:32:26.216: INFO: Observed &ReplicaSet event: MODIFIED
    Oct  3 20:32:26.217: INFO: Observed &ReplicaSet event: MODIFIED
    Oct  3 20:32:26.217: INFO: Observed replicaset test-rs in namespace replicaset-1811 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Oct  3 20:32:26.217: INFO: Observed &ReplicaSet event: MODIFIED
    Oct  3 20:32:26.217: INFO: Found replicaset test-rs in namespace replicaset-1811 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Oct  3 20:32:26.217: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Oct  3 20:32:26.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-1811" for this suite. 10/03/22 20:32:26.238
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:32:26.259
Oct  3 20:32:26.259: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename pod-network-test 10/03/22 20:32:26.261
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:32:26.302
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:32:26.311
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-8218 10/03/22 20:32:26.32
STEP: creating a selector 10/03/22 20:32:26.32
STEP: Creating the service pods in kubernetes 10/03/22 20:32:26.32
Oct  3 20:32:26.320: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Oct  3 20:32:26.417: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-8218" to be "running and ready"
Oct  3 20:32:26.435: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 17.624461ms
Oct  3 20:32:26.435: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:32:28.448: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.030625766s
Oct  3 20:32:28.448: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:32:30.448: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.031041298s
Oct  3 20:32:30.448: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:32:32.447: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.030180013s
Oct  3 20:32:32.447: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:32:34.448: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.030563868s
Oct  3 20:32:34.448: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:32:36.448: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.031329777s
Oct  3 20:32:36.448: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:32:38.449: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.032119907s
Oct  3 20:32:38.449: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:32:40.448: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.030706241s
Oct  3 20:32:40.448: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:32:42.447: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.029778123s
Oct  3 20:32:42.447: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:32:44.449: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.03183284s
Oct  3 20:32:44.449: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:32:46.448: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.030540787s
Oct  3 20:32:46.448: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct  3 20:32:48.449: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.031857072s
Oct  3 20:32:48.449: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Oct  3 20:32:48.449: INFO: Pod "netserver-0" satisfied condition "running and ready"
Oct  3 20:32:48.460: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-8218" to be "running and ready"
Oct  3 20:32:48.472: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 11.744941ms
Oct  3 20:32:48.472: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Oct  3 20:32:48.472: INFO: Pod "netserver-1" satisfied condition "running and ready"
Oct  3 20:32:48.483: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-8218" to be "running and ready"
Oct  3 20:32:48.494: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 11.181428ms
Oct  3 20:32:48.495: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Oct  3 20:32:48.495: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 10/03/22 20:32:48.506
Oct  3 20:32:48.533: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-8218" to be "running"
Oct  3 20:32:48.546: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.622525ms
Oct  3 20:32:50.560: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026818246s
Oct  3 20:32:52.559: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.025897824s
Oct  3 20:32:52.559: INFO: Pod "test-container-pod" satisfied condition "running"
Oct  3 20:32:52.571: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-8218" to be "running"
Oct  3 20:32:52.582: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 11.552241ms
Oct  3 20:32:52.582: INFO: Pod "host-test-container-pod" satisfied condition "running"
Oct  3 20:32:52.593: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Oct  3 20:32:52.594: INFO: Going to poll 172.30.35.197 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Oct  3 20:32:52.628: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.35.197 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8218 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:32:52.628: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:32:52.629: INFO: ExecWithOptions: Clientset creation
Oct  3 20:32:52.629: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-8218/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.35.197+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct  3 20:32:53.826: INFO: Found all 1 expected endpoints: [netserver-0]
Oct  3 20:32:53.826: INFO: Going to poll 172.30.49.38 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Oct  3 20:32:53.839: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.49.38 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8218 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:32:53.839: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:32:53.840: INFO: ExecWithOptions: Clientset creation
Oct  3 20:32:53.840: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-8218/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.49.38+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct  3 20:32:55.051: INFO: Found all 1 expected endpoints: [netserver-1]
Oct  3 20:32:55.051: INFO: Going to poll 172.30.174.254 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Oct  3 20:32:55.063: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.174.254 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8218 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:32:55.063: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:32:55.064: INFO: ExecWithOptions: Clientset creation
Oct  3 20:32:55.064: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-8218/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.174.254+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct  3 20:32:56.287: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Oct  3 20:32:56.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8218" for this suite. 10/03/22 20:32:56.306
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":253,"skipped":5028,"failed":0}
------------------------------
• [SLOW TEST] [30.067 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:32:26.259
    Oct  3 20:32:26.259: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename pod-network-test 10/03/22 20:32:26.261
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:32:26.302
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:32:26.311
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-8218 10/03/22 20:32:26.32
    STEP: creating a selector 10/03/22 20:32:26.32
    STEP: Creating the service pods in kubernetes 10/03/22 20:32:26.32
    Oct  3 20:32:26.320: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Oct  3 20:32:26.417: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-8218" to be "running and ready"
    Oct  3 20:32:26.435: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 17.624461ms
    Oct  3 20:32:26.435: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:32:28.448: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.030625766s
    Oct  3 20:32:28.448: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:32:30.448: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.031041298s
    Oct  3 20:32:30.448: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:32:32.447: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.030180013s
    Oct  3 20:32:32.447: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:32:34.448: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.030563868s
    Oct  3 20:32:34.448: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:32:36.448: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.031329777s
    Oct  3 20:32:36.448: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:32:38.449: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.032119907s
    Oct  3 20:32:38.449: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:32:40.448: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.030706241s
    Oct  3 20:32:40.448: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:32:42.447: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.029778123s
    Oct  3 20:32:42.447: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:32:44.449: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.03183284s
    Oct  3 20:32:44.449: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:32:46.448: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.030540787s
    Oct  3 20:32:46.448: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct  3 20:32:48.449: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.031857072s
    Oct  3 20:32:48.449: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Oct  3 20:32:48.449: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Oct  3 20:32:48.460: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-8218" to be "running and ready"
    Oct  3 20:32:48.472: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 11.744941ms
    Oct  3 20:32:48.472: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Oct  3 20:32:48.472: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Oct  3 20:32:48.483: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-8218" to be "running and ready"
    Oct  3 20:32:48.494: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 11.181428ms
    Oct  3 20:32:48.495: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Oct  3 20:32:48.495: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 10/03/22 20:32:48.506
    Oct  3 20:32:48.533: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-8218" to be "running"
    Oct  3 20:32:48.546: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.622525ms
    Oct  3 20:32:50.560: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026818246s
    Oct  3 20:32:52.559: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.025897824s
    Oct  3 20:32:52.559: INFO: Pod "test-container-pod" satisfied condition "running"
    Oct  3 20:32:52.571: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-8218" to be "running"
    Oct  3 20:32:52.582: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 11.552241ms
    Oct  3 20:32:52.582: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Oct  3 20:32:52.593: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Oct  3 20:32:52.594: INFO: Going to poll 172.30.35.197 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Oct  3 20:32:52.628: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.35.197 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8218 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:32:52.628: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:32:52.629: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:32:52.629: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-8218/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.35.197+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Oct  3 20:32:53.826: INFO: Found all 1 expected endpoints: [netserver-0]
    Oct  3 20:32:53.826: INFO: Going to poll 172.30.49.38 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Oct  3 20:32:53.839: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.49.38 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8218 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:32:53.839: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:32:53.840: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:32:53.840: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-8218/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.49.38+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Oct  3 20:32:55.051: INFO: Found all 1 expected endpoints: [netserver-1]
    Oct  3 20:32:55.051: INFO: Going to poll 172.30.174.254 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Oct  3 20:32:55.063: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.174.254 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8218 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:32:55.063: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:32:55.064: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:32:55.064: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-8218/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.174.254+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Oct  3 20:32:56.287: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Oct  3 20:32:56.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-8218" for this suite. 10/03/22 20:32:56.306
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:32:56.327
Oct  3 20:32:56.328: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 20:32:56.329
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:32:56.369
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:32:56.378
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 10/03/22 20:32:56.397
STEP: watching for the Service to be added 10/03/22 20:32:56.43
Oct  3 20:32:56.435: INFO: Found Service test-service-rfr55 in namespace services-501 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Oct  3 20:32:56.436: INFO: Service test-service-rfr55 created
STEP: Getting /status 10/03/22 20:32:56.436
Oct  3 20:32:56.449: INFO: Service test-service-rfr55 has LoadBalancer: {[]}
STEP: patching the ServiceStatus 10/03/22 20:32:56.449
STEP: watching for the Service to be patched 10/03/22 20:32:56.465
Oct  3 20:32:56.470: INFO: observed Service test-service-rfr55 in namespace services-501 with annotations: map[] & LoadBalancer: {[]}
Oct  3 20:32:56.470: INFO: Found Service test-service-rfr55 in namespace services-501 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Oct  3 20:32:56.470: INFO: Service test-service-rfr55 has service status patched
STEP: updating the ServiceStatus 10/03/22 20:32:56.47
Oct  3 20:32:56.496: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 10/03/22 20:32:56.496
Oct  3 20:32:56.501: INFO: Observed Service test-service-rfr55 in namespace services-501 with annotations: map[] & Conditions: {[]}
Oct  3 20:32:56.501: INFO: Observed event: &Service{ObjectMeta:{test-service-rfr55  services-501  0c0ed214-87b1-45dc-bbe3-9697329473e8 37451 0 2022-10-03 20:32:56 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-10-03 20:32:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-10-03 20:32:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:172.21.161.24,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[172.21.161.24],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Oct  3 20:32:56.501: INFO: Found Service test-service-rfr55 in namespace services-501 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Oct  3 20:32:56.501: INFO: Service test-service-rfr55 has service status updated
STEP: patching the service 10/03/22 20:32:56.501
STEP: watching for the Service to be patched 10/03/22 20:32:56.517
Oct  3 20:32:56.521: INFO: observed Service test-service-rfr55 in namespace services-501 with labels: map[test-service-static:true]
Oct  3 20:32:56.521: INFO: observed Service test-service-rfr55 in namespace services-501 with labels: map[test-service-static:true]
Oct  3 20:32:56.521: INFO: observed Service test-service-rfr55 in namespace services-501 with labels: map[test-service-static:true]
Oct  3 20:32:56.521: INFO: Found Service test-service-rfr55 in namespace services-501 with labels: map[test-service:patched test-service-static:true]
Oct  3 20:32:56.521: INFO: Service test-service-rfr55 patched
STEP: deleting the service 10/03/22 20:32:56.521
STEP: watching for the Service to be deleted 10/03/22 20:32:56.566
Oct  3 20:32:56.570: INFO: Observed event: ADDED
Oct  3 20:32:56.570: INFO: Observed event: MODIFIED
Oct  3 20:32:56.571: INFO: Observed event: MODIFIED
Oct  3 20:32:56.571: INFO: Observed event: MODIFIED
Oct  3 20:32:56.571: INFO: Found Service test-service-rfr55 in namespace services-501 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Oct  3 20:32:56.571: INFO: Service test-service-rfr55 deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 20:32:56.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-501" for this suite. 10/03/22 20:32:56.59
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":254,"skipped":5028,"failed":0}
------------------------------
• [0.283 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:32:56.327
    Oct  3 20:32:56.328: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 20:32:56.329
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:32:56.369
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:32:56.378
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 10/03/22 20:32:56.397
    STEP: watching for the Service to be added 10/03/22 20:32:56.43
    Oct  3 20:32:56.435: INFO: Found Service test-service-rfr55 in namespace services-501 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Oct  3 20:32:56.436: INFO: Service test-service-rfr55 created
    STEP: Getting /status 10/03/22 20:32:56.436
    Oct  3 20:32:56.449: INFO: Service test-service-rfr55 has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 10/03/22 20:32:56.449
    STEP: watching for the Service to be patched 10/03/22 20:32:56.465
    Oct  3 20:32:56.470: INFO: observed Service test-service-rfr55 in namespace services-501 with annotations: map[] & LoadBalancer: {[]}
    Oct  3 20:32:56.470: INFO: Found Service test-service-rfr55 in namespace services-501 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Oct  3 20:32:56.470: INFO: Service test-service-rfr55 has service status patched
    STEP: updating the ServiceStatus 10/03/22 20:32:56.47
    Oct  3 20:32:56.496: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 10/03/22 20:32:56.496
    Oct  3 20:32:56.501: INFO: Observed Service test-service-rfr55 in namespace services-501 with annotations: map[] & Conditions: {[]}
    Oct  3 20:32:56.501: INFO: Observed event: &Service{ObjectMeta:{test-service-rfr55  services-501  0c0ed214-87b1-45dc-bbe3-9697329473e8 37451 0 2022-10-03 20:32:56 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-10-03 20:32:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-10-03 20:32:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:172.21.161.24,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[172.21.161.24],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Oct  3 20:32:56.501: INFO: Found Service test-service-rfr55 in namespace services-501 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Oct  3 20:32:56.501: INFO: Service test-service-rfr55 has service status updated
    STEP: patching the service 10/03/22 20:32:56.501
    STEP: watching for the Service to be patched 10/03/22 20:32:56.517
    Oct  3 20:32:56.521: INFO: observed Service test-service-rfr55 in namespace services-501 with labels: map[test-service-static:true]
    Oct  3 20:32:56.521: INFO: observed Service test-service-rfr55 in namespace services-501 with labels: map[test-service-static:true]
    Oct  3 20:32:56.521: INFO: observed Service test-service-rfr55 in namespace services-501 with labels: map[test-service-static:true]
    Oct  3 20:32:56.521: INFO: Found Service test-service-rfr55 in namespace services-501 with labels: map[test-service:patched test-service-static:true]
    Oct  3 20:32:56.521: INFO: Service test-service-rfr55 patched
    STEP: deleting the service 10/03/22 20:32:56.521
    STEP: watching for the Service to be deleted 10/03/22 20:32:56.566
    Oct  3 20:32:56.570: INFO: Observed event: ADDED
    Oct  3 20:32:56.570: INFO: Observed event: MODIFIED
    Oct  3 20:32:56.571: INFO: Observed event: MODIFIED
    Oct  3 20:32:56.571: INFO: Observed event: MODIFIED
    Oct  3 20:32:56.571: INFO: Found Service test-service-rfr55 in namespace services-501 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Oct  3 20:32:56.571: INFO: Service test-service-rfr55 deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 20:32:56.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-501" for this suite. 10/03/22 20:32:56.59
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:32:56.612
Oct  3 20:32:56.612: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename statefulset 10/03/22 20:32:56.613
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:32:56.653
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:32:56.661
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4720 10/03/22 20:32:56.67
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 10/03/22 20:32:56.684
STEP: Creating pod with conflicting port in namespace statefulset-4720 10/03/22 20:32:56.702
STEP: Waiting until pod test-pod will start running in namespace statefulset-4720 10/03/22 20:32:56.724
Oct  3 20:32:56.724: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-4720" to be "running"
Oct  3 20:32:56.736: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.247228ms
Oct  3 20:32:58.750: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025338429s
Oct  3 20:33:00.747: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.023014021s
Oct  3 20:33:00.747: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-4720 10/03/22 20:33:00.748
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4720 10/03/22 20:33:00.759
Oct  3 20:33:00.790: INFO: Observed stateful pod in namespace: statefulset-4720, name: ss-0, uid: 79c728db-9eed-4c1f-a2cd-b89b80928f82, status phase: Pending. Waiting for statefulset controller to delete.
Oct  3 20:33:00.824: INFO: Observed stateful pod in namespace: statefulset-4720, name: ss-0, uid: 79c728db-9eed-4c1f-a2cd-b89b80928f82, status phase: Failed. Waiting for statefulset controller to delete.
Oct  3 20:33:00.840: INFO: Observed stateful pod in namespace: statefulset-4720, name: ss-0, uid: 79c728db-9eed-4c1f-a2cd-b89b80928f82, status phase: Failed. Waiting for statefulset controller to delete.
Oct  3 20:33:00.846: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4720
STEP: Removing pod with conflicting port in namespace statefulset-4720 10/03/22 20:33:00.846
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4720 and will be in running state 10/03/22 20:33:00.897
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct  3 20:33:04.941: INFO: Deleting all statefulset in ns statefulset-4720
Oct  3 20:33:04.951: INFO: Scaling statefulset ss to 0
Oct  3 20:33:15.005: INFO: Waiting for statefulset status.replicas updated to 0
Oct  3 20:33:15.015: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Oct  3 20:33:15.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4720" for this suite. 10/03/22 20:33:15.073
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":255,"skipped":5029,"failed":0}
------------------------------
• [SLOW TEST] [18.481 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:32:56.612
    Oct  3 20:32:56.612: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename statefulset 10/03/22 20:32:56.613
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:32:56.653
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:32:56.661
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4720 10/03/22 20:32:56.67
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 10/03/22 20:32:56.684
    STEP: Creating pod with conflicting port in namespace statefulset-4720 10/03/22 20:32:56.702
    STEP: Waiting until pod test-pod will start running in namespace statefulset-4720 10/03/22 20:32:56.724
    Oct  3 20:32:56.724: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-4720" to be "running"
    Oct  3 20:32:56.736: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.247228ms
    Oct  3 20:32:58.750: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025338429s
    Oct  3 20:33:00.747: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.023014021s
    Oct  3 20:33:00.747: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-4720 10/03/22 20:33:00.748
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4720 10/03/22 20:33:00.759
    Oct  3 20:33:00.790: INFO: Observed stateful pod in namespace: statefulset-4720, name: ss-0, uid: 79c728db-9eed-4c1f-a2cd-b89b80928f82, status phase: Pending. Waiting for statefulset controller to delete.
    Oct  3 20:33:00.824: INFO: Observed stateful pod in namespace: statefulset-4720, name: ss-0, uid: 79c728db-9eed-4c1f-a2cd-b89b80928f82, status phase: Failed. Waiting for statefulset controller to delete.
    Oct  3 20:33:00.840: INFO: Observed stateful pod in namespace: statefulset-4720, name: ss-0, uid: 79c728db-9eed-4c1f-a2cd-b89b80928f82, status phase: Failed. Waiting for statefulset controller to delete.
    Oct  3 20:33:00.846: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4720
    STEP: Removing pod with conflicting port in namespace statefulset-4720 10/03/22 20:33:00.846
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4720 and will be in running state 10/03/22 20:33:00.897
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Oct  3 20:33:04.941: INFO: Deleting all statefulset in ns statefulset-4720
    Oct  3 20:33:04.951: INFO: Scaling statefulset ss to 0
    Oct  3 20:33:15.005: INFO: Waiting for statefulset status.replicas updated to 0
    Oct  3 20:33:15.015: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Oct  3 20:33:15.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4720" for this suite. 10/03/22 20:33:15.073
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:33:15.093
Oct  3 20:33:15.093: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 20:33:15.094
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:33:15.134
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:33:15.142
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-1aac2b1d-cb55-4d9b-ae19-7776819c6a09 10/03/22 20:33:15.151
STEP: Creating a pod to test consume configMaps 10/03/22 20:33:15.163
Oct  3 20:33:15.183: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0" in namespace "projected-7900" to be "Succeeded or Failed"
Oct  3 20:33:15.194: INFO: Pod "pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.838576ms
Oct  3 20:33:17.208: INFO: Pod "pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02428635s
Oct  3 20:33:19.206: INFO: Pod "pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023119409s
Oct  3 20:33:21.207: INFO: Pod "pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023362393s
STEP: Saw pod success 10/03/22 20:33:21.207
Oct  3 20:33:21.207: INFO: Pod "pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0" satisfied condition "Succeeded or Failed"
Oct  3 20:33:21.218: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0 container agnhost-container: <nil>
STEP: delete the pod 10/03/22 20:33:21.283
Oct  3 20:33:21.313: INFO: Waiting for pod pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0 to disappear
Oct  3 20:33:21.324: INFO: Pod pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Oct  3 20:33:21.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7900" for this suite. 10/03/22 20:33:21.346
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":256,"skipped":5032,"failed":0}
------------------------------
• [SLOW TEST] [6.273 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:33:15.093
    Oct  3 20:33:15.093: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 20:33:15.094
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:33:15.134
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:33:15.142
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-1aac2b1d-cb55-4d9b-ae19-7776819c6a09 10/03/22 20:33:15.151
    STEP: Creating a pod to test consume configMaps 10/03/22 20:33:15.163
    Oct  3 20:33:15.183: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0" in namespace "projected-7900" to be "Succeeded or Failed"
    Oct  3 20:33:15.194: INFO: Pod "pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.838576ms
    Oct  3 20:33:17.208: INFO: Pod "pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02428635s
    Oct  3 20:33:19.206: INFO: Pod "pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023119409s
    Oct  3 20:33:21.207: INFO: Pod "pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023362393s
    STEP: Saw pod success 10/03/22 20:33:21.207
    Oct  3 20:33:21.207: INFO: Pod "pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0" satisfied condition "Succeeded or Failed"
    Oct  3 20:33:21.218: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0 container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 20:33:21.283
    Oct  3 20:33:21.313: INFO: Waiting for pod pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0 to disappear
    Oct  3 20:33:21.324: INFO: Pod pod-projected-configmaps-fe07dee7-3553-436b-9337-bfecc6f045f0 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Oct  3 20:33:21.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7900" for this suite. 10/03/22 20:33:21.346
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:33:21.37
Oct  3 20:33:21.370: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-probe 10/03/22 20:33:21.371
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:33:21.413
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:33:21.422
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef in namespace container-probe-7616 10/03/22 20:33:21.431
Oct  3 20:33:21.454: INFO: Waiting up to 5m0s for pod "liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef" in namespace "container-probe-7616" to be "not pending"
Oct  3 20:33:21.470: INFO: Pod "liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef": Phase="Pending", Reason="", readiness=false. Elapsed: 15.513905ms
Oct  3 20:33:23.483: INFO: Pod "liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028110951s
Oct  3 20:33:25.484: INFO: Pod "liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef": Phase="Running", Reason="", readiness=true. Elapsed: 4.02949415s
Oct  3 20:33:25.484: INFO: Pod "liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef" satisfied condition "not pending"
Oct  3 20:33:25.484: INFO: Started pod liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef in namespace container-probe-7616
STEP: checking the pod's current state and verifying that restartCount is present 10/03/22 20:33:25.484
Oct  3 20:33:25.496: INFO: Initial restart count of pod liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef is 0
Oct  3 20:33:43.626: INFO: Restart count of pod container-probe-7616/liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef is now 1 (18.12997674s elapsed)
Oct  3 20:34:03.759: INFO: Restart count of pod container-probe-7616/liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef is now 2 (38.262959725s elapsed)
Oct  3 20:34:23.895: INFO: Restart count of pod container-probe-7616/liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef is now 3 (58.399050165s elapsed)
Oct  3 20:34:44.028: INFO: Restart count of pod container-probe-7616/liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef is now 4 (1m18.531859426s elapsed)
Oct  3 20:35:46.447: INFO: Restart count of pod container-probe-7616/liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef is now 5 (2m20.950605801s elapsed)
STEP: deleting the pod 10/03/22 20:35:46.447
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Oct  3 20:35:46.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7616" for this suite. 10/03/22 20:35:46.495
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":257,"skipped":5065,"failed":0}
------------------------------
• [SLOW TEST] [145.156 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:33:21.37
    Oct  3 20:33:21.370: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-probe 10/03/22 20:33:21.371
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:33:21.413
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:33:21.422
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef in namespace container-probe-7616 10/03/22 20:33:21.431
    Oct  3 20:33:21.454: INFO: Waiting up to 5m0s for pod "liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef" in namespace "container-probe-7616" to be "not pending"
    Oct  3 20:33:21.470: INFO: Pod "liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef": Phase="Pending", Reason="", readiness=false. Elapsed: 15.513905ms
    Oct  3 20:33:23.483: INFO: Pod "liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028110951s
    Oct  3 20:33:25.484: INFO: Pod "liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef": Phase="Running", Reason="", readiness=true. Elapsed: 4.02949415s
    Oct  3 20:33:25.484: INFO: Pod "liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef" satisfied condition "not pending"
    Oct  3 20:33:25.484: INFO: Started pod liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef in namespace container-probe-7616
    STEP: checking the pod's current state and verifying that restartCount is present 10/03/22 20:33:25.484
    Oct  3 20:33:25.496: INFO: Initial restart count of pod liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef is 0
    Oct  3 20:33:43.626: INFO: Restart count of pod container-probe-7616/liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef is now 1 (18.12997674s elapsed)
    Oct  3 20:34:03.759: INFO: Restart count of pod container-probe-7616/liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef is now 2 (38.262959725s elapsed)
    Oct  3 20:34:23.895: INFO: Restart count of pod container-probe-7616/liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef is now 3 (58.399050165s elapsed)
    Oct  3 20:34:44.028: INFO: Restart count of pod container-probe-7616/liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef is now 4 (1m18.531859426s elapsed)
    Oct  3 20:35:46.447: INFO: Restart count of pod container-probe-7616/liveness-742add2a-bb07-4e29-8f7a-766a4e55b9ef is now 5 (2m20.950605801s elapsed)
    STEP: deleting the pod 10/03/22 20:35:46.447
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Oct  3 20:35:46.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7616" for this suite. 10/03/22 20:35:46.495
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:35:46.532
Oct  3 20:35:46.532: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename watch 10/03/22 20:35:46.533
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:35:46.599
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:35:46.609
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 10/03/22 20:35:46.619
STEP: creating a new configmap 10/03/22 20:35:46.624
STEP: modifying the configmap once 10/03/22 20:35:46.637
STEP: closing the watch once it receives two notifications 10/03/22 20:35:46.662
Oct  3 20:35:46.662: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4442  b3d5b21e-8b3c-4f93-b0e9-66a501563b30 37851 0 2022-10-03 20:35:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-10-03 20:35:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Oct  3 20:35:46.663: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4442  b3d5b21e-8b3c-4f93-b0e9-66a501563b30 37852 0 2022-10-03 20:35:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-10-03 20:35:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 10/03/22 20:35:46.663
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 10/03/22 20:35:46.69
STEP: deleting the configmap 10/03/22 20:35:46.695
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 10/03/22 20:35:46.714
Oct  3 20:35:46.715: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4442  b3d5b21e-8b3c-4f93-b0e9-66a501563b30 37853 0 2022-10-03 20:35:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-10-03 20:35:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct  3 20:35:46.715: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4442  b3d5b21e-8b3c-4f93-b0e9-66a501563b30 37854 0 2022-10-03 20:35:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-10-03 20:35:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Oct  3 20:35:46.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4442" for this suite. 10/03/22 20:35:46.731
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":258,"skipped":5072,"failed":0}
------------------------------
• [0.220 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:35:46.532
    Oct  3 20:35:46.532: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename watch 10/03/22 20:35:46.533
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:35:46.599
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:35:46.609
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 10/03/22 20:35:46.619
    STEP: creating a new configmap 10/03/22 20:35:46.624
    STEP: modifying the configmap once 10/03/22 20:35:46.637
    STEP: closing the watch once it receives two notifications 10/03/22 20:35:46.662
    Oct  3 20:35:46.662: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4442  b3d5b21e-8b3c-4f93-b0e9-66a501563b30 37851 0 2022-10-03 20:35:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-10-03 20:35:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct  3 20:35:46.663: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4442  b3d5b21e-8b3c-4f93-b0e9-66a501563b30 37852 0 2022-10-03 20:35:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-10-03 20:35:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 10/03/22 20:35:46.663
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 10/03/22 20:35:46.69
    STEP: deleting the configmap 10/03/22 20:35:46.695
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 10/03/22 20:35:46.714
    Oct  3 20:35:46.715: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4442  b3d5b21e-8b3c-4f93-b0e9-66a501563b30 37853 0 2022-10-03 20:35:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-10-03 20:35:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct  3 20:35:46.715: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4442  b3d5b21e-8b3c-4f93-b0e9-66a501563b30 37854 0 2022-10-03 20:35:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-10-03 20:35:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Oct  3 20:35:46.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-4442" for this suite. 10/03/22 20:35:46.731
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:35:46.753
Oct  3 20:35:46.753: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 20:35:46.755
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:35:46.791
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:35:46.801
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 20:35:46.847
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:35:47.794
STEP: Deploying the webhook pod 10/03/22 20:35:47.816
STEP: Wait for the deployment to be ready 10/03/22 20:35:47.845
Oct  3 20:35:47.868: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  3 20:35:49.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 20, 35, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 35, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 20, 35, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 35, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 10/03/22 20:35:51.924
STEP: Verifying the service has paired with the endpoint 10/03/22 20:35:51.958
Oct  3 20:35:52.959: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 10/03/22 20:35:52.972
STEP: Registering slow webhook via the AdmissionRegistration API 10/03/22 20:35:52.973
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 10/03/22 20:35:53.04
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 10/03/22 20:35:54.065
STEP: Registering slow webhook via the AdmissionRegistration API 10/03/22 20:35:54.065
STEP: Having no error when timeout is longer than webhook latency 10/03/22 20:35:55.144
STEP: Registering slow webhook via the AdmissionRegistration API 10/03/22 20:35:55.144
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 10/03/22 20:36:00.26
STEP: Registering slow webhook via the AdmissionRegistration API 10/03/22 20:36:00.26
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:36:05.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2612" for this suite. 10/03/22 20:36:05.366
STEP: Destroying namespace "webhook-2612-markers" for this suite. 10/03/22 20:36:05.387
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":259,"skipped":5078,"failed":0}
------------------------------
• [SLOW TEST] [18.773 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:35:46.753
    Oct  3 20:35:46.753: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 20:35:46.755
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:35:46.791
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:35:46.801
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 20:35:46.847
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:35:47.794
    STEP: Deploying the webhook pod 10/03/22 20:35:47.816
    STEP: Wait for the deployment to be ready 10/03/22 20:35:47.845
    Oct  3 20:35:47.868: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Oct  3 20:35:49.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 20, 35, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 35, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 20, 35, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 35, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 10/03/22 20:35:51.924
    STEP: Verifying the service has paired with the endpoint 10/03/22 20:35:51.958
    Oct  3 20:35:52.959: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 10/03/22 20:35:52.972
    STEP: Registering slow webhook via the AdmissionRegistration API 10/03/22 20:35:52.973
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 10/03/22 20:35:53.04
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 10/03/22 20:35:54.065
    STEP: Registering slow webhook via the AdmissionRegistration API 10/03/22 20:35:54.065
    STEP: Having no error when timeout is longer than webhook latency 10/03/22 20:35:55.144
    STEP: Registering slow webhook via the AdmissionRegistration API 10/03/22 20:35:55.144
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 10/03/22 20:36:00.26
    STEP: Registering slow webhook via the AdmissionRegistration API 10/03/22 20:36:00.26
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:36:05.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2612" for this suite. 10/03/22 20:36:05.366
    STEP: Destroying namespace "webhook-2612-markers" for this suite. 10/03/22 20:36:05.387
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:36:05.528
Oct  3 20:36:05.528: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename endpointslicemirroring 10/03/22 20:36:05.53
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:36:05.564
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:36:05.574
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 10/03/22 20:36:05.613
Oct  3 20:36:05.641: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 10/03/22 20:36:07.654
STEP: mirroring deletion of a custom Endpoint 10/03/22 20:36:07.681
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Oct  3 20:36:07.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-6265" for this suite. 10/03/22 20:36:07.732
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":260,"skipped":5101,"failed":0}
------------------------------
• [2.224 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:36:05.528
    Oct  3 20:36:05.528: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename endpointslicemirroring 10/03/22 20:36:05.53
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:36:05.564
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:36:05.574
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 10/03/22 20:36:05.613
    Oct  3 20:36:05.641: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 10/03/22 20:36:07.654
    STEP: mirroring deletion of a custom Endpoint 10/03/22 20:36:07.681
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Oct  3 20:36:07.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-6265" for this suite. 10/03/22 20:36:07.732
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:36:07.752
Oct  3 20:36:07.753: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename custom-resource-definition 10/03/22 20:36:07.754
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:36:07.791
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:36:07.801
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Oct  3 20:36:07.811: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:36:08.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9227" for this suite. 10/03/22 20:36:08.422
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":261,"skipped":5103,"failed":0}
------------------------------
• [0.695 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:36:07.752
    Oct  3 20:36:07.753: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename custom-resource-definition 10/03/22 20:36:07.754
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:36:07.791
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:36:07.801
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Oct  3 20:36:07.811: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:36:08.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-9227" for this suite. 10/03/22 20:36:08.422
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:36:08.453
Oct  3 20:36:08.453: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-probe 10/03/22 20:36:08.455
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:36:08.486
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:36:08.496
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f in namespace container-probe-6616 10/03/22 20:36:08.506
Oct  3 20:36:08.527: INFO: Waiting up to 5m0s for pod "busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f" in namespace "container-probe-6616" to be "not pending"
Oct  3 20:36:08.538: INFO: Pod "busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.966002ms
Oct  3 20:36:10.552: INFO: Pod "busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f": Phase="Running", Reason="", readiness=true. Elapsed: 2.025593849s
Oct  3 20:36:10.552: INFO: Pod "busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f" satisfied condition "not pending"
Oct  3 20:36:10.553: INFO: Started pod busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f in namespace container-probe-6616
STEP: checking the pod's current state and verifying that restartCount is present 10/03/22 20:36:10.553
Oct  3 20:36:10.563: INFO: Initial restart count of pod busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f is 0
Oct  3 20:37:00.923: INFO: Restart count of pod container-probe-6616/busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f is now 1 (50.359866706s elapsed)
STEP: deleting the pod 10/03/22 20:37:00.923
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Oct  3 20:37:00.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6616" for this suite. 10/03/22 20:37:00.975
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":262,"skipped":5127,"failed":0}
------------------------------
• [SLOW TEST] [52.541 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:36:08.453
    Oct  3 20:36:08.453: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-probe 10/03/22 20:36:08.455
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:36:08.486
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:36:08.496
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f in namespace container-probe-6616 10/03/22 20:36:08.506
    Oct  3 20:36:08.527: INFO: Waiting up to 5m0s for pod "busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f" in namespace "container-probe-6616" to be "not pending"
    Oct  3 20:36:08.538: INFO: Pod "busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.966002ms
    Oct  3 20:36:10.552: INFO: Pod "busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f": Phase="Running", Reason="", readiness=true. Elapsed: 2.025593849s
    Oct  3 20:36:10.552: INFO: Pod "busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f" satisfied condition "not pending"
    Oct  3 20:36:10.553: INFO: Started pod busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f in namespace container-probe-6616
    STEP: checking the pod's current state and verifying that restartCount is present 10/03/22 20:36:10.553
    Oct  3 20:36:10.563: INFO: Initial restart count of pod busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f is 0
    Oct  3 20:37:00.923: INFO: Restart count of pod container-probe-6616/busybox-77ffa991-5973-4d10-95ef-f3dcbd32d28f is now 1 (50.359866706s elapsed)
    STEP: deleting the pod 10/03/22 20:37:00.923
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Oct  3 20:37:00.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6616" for this suite. 10/03/22 20:37:00.975
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:37:00.996
Oct  3 20:37:00.996: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename sched-pred 10/03/22 20:37:00.998
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:37:01.032
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:37:01.042
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Oct  3 20:37:01.052: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  3 20:37:01.088: INFO: Waiting for terminating namespaces to be deleted...
Oct  3 20:37:01.103: INFO: 
Logging pods the apiserver thinks is on node 10.63.128.13 before test
Oct  3 20:37:01.165: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-5lm6l from ibm-system started at 2022-10-03 17:16:04 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.165: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
Oct  3 20:37:01.165: INFO: calico-node-zpr9s from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.165: INFO: 	Container calico-node ready: true, restart count 0
Oct  3 20:37:01.165: INFO: calico-typha-644fdcd5f-w67fp from kube-system started at 2022-10-03 17:11:18 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.165: INFO: 	Container calico-typha ready: true, restart count 0
Oct  3 20:37:01.165: INFO: coredns-6754846f95-bl2wt from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.165: INFO: 	Container coredns ready: true, restart count 0
Oct  3 20:37:01.165: INFO: ibm-keepalived-watcher-nw2l6 from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.165: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  3 20:37:01.165: INFO: ibm-master-proxy-static-10.63.128.13 from kube-system started at 2022-10-03 17:10:55 +0000 UTC (2 container statuses recorded)
Oct  3 20:37:01.165: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct  3 20:37:01.165: INFO: 	Container pause ready: true, restart count 0
Oct  3 20:37:01.165: INFO: ibmcloud-block-storage-driver-f5thb from kube-system started at 2022-10-03 17:11:06 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.165: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct  3 20:37:01.165: INFO: ingress-cluster-healthcheck-6dbd7f8d47-vx87x from kube-system started at 2022-10-03 18:44:30 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.165: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Oct  3 20:37:01.165: INFO: konnectivity-agent-qv9fn from kube-system started at 2022-10-03 17:19:11 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.165: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct  3 20:37:01.165: INFO: metrics-server-668b4d7ddd-7glct from kube-system started at 2022-10-03 17:55:22 +0000 UTC (3 container statuses recorded)
Oct  3 20:37:01.165: INFO: 	Container config-watcher ready: true, restart count 0
Oct  3 20:37:01.166: INFO: 	Container metrics-server ready: true, restart count 0
Oct  3 20:37:01.166: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct  3 20:37:01.166: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-7vk57 from kube-system started at 2022-10-03 19:52:24 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.166: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct  3 20:37:01.166: INFO: sonobuoy-e2e-job-2c5abccdc00d487c from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 20:37:01.166: INFO: 	Container e2e ready: true, restart count 0
Oct  3 20:37:01.166: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 20:37:01.166: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-cwlqc from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 20:37:01.166: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 20:37:01.166: INFO: 	Container systemd-logs ready: true, restart count 0
Oct  3 20:37:01.166: INFO: 
Logging pods the apiserver thinks is on node 10.63.128.3 before test
Oct  3 20:37:01.203: INFO: calico-node-zrfj4 from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.203: INFO: 	Container calico-node ready: true, restart count 0
Oct  3 20:37:01.203: INFO: calico-typha-644fdcd5f-rskkx from kube-system started at 2022-10-03 20:20:28 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.203: INFO: 	Container calico-typha ready: true, restart count 0
Oct  3 20:37:01.203: INFO: ibm-keepalived-watcher-jr7cc from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.203: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  3 20:37:01.203: INFO: ibm-master-proxy-static-10.63.128.3 from kube-system started at 2022-10-03 17:10:52 +0000 UTC (2 container statuses recorded)
Oct  3 20:37:01.203: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct  3 20:37:01.203: INFO: 	Container pause ready: true, restart count 0
Oct  3 20:37:01.203: INFO: ibmcloud-block-storage-driver-j765w from kube-system started at 2022-10-03 17:11:13 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.203: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct  3 20:37:01.203: INFO: konnectivity-agent-n5jcf from kube-system started at 2022-10-03 17:19:17 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.203: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct  3 20:37:01.203: INFO: sonobuoy from sonobuoy started at 2022-10-03 19:13:32 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.204: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  3 20:37:01.204: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-lpx2r from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 20:37:01.204: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 20:37:01.204: INFO: 	Container systemd-logs ready: true, restart count 0
Oct  3 20:37:01.204: INFO: 
Logging pods the apiserver thinks is on node 10.63.128.51 before test
Oct  3 20:37:01.249: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-6mpp7 from ibm-system started at 2022-10-03 19:20:52 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.249: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
Oct  3 20:37:01.249: INFO: calico-kube-controllers-5ccfdf4b6d-qxssd from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.249: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct  3 20:37:01.249: INFO: calico-node-zfv55 from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.249: INFO: 	Container calico-node ready: true, restart count 0
Oct  3 20:37:01.249: INFO: calico-typha-644fdcd5f-7qcns from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.249: INFO: 	Container calico-typha ready: true, restart count 0
Oct  3 20:37:01.249: INFO: coredns-6754846f95-9q5kh from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.249: INFO: 	Container coredns ready: true, restart count 0
Oct  3 20:37:01.249: INFO: coredns-6754846f95-c7x4x from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.249: INFO: 	Container coredns ready: true, restart count 0
Oct  3 20:37:01.250: INFO: coredns-autoscaler-669cf746f6-wwqwh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container autoscaler ready: true, restart count 0
Oct  3 20:37:01.250: INFO: dashboard-metrics-scraper-c964d5594-bvc48 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Oct  3 20:37:01.250: INFO: ibm-file-plugin-bdf4f476-5nc82 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct  3 20:37:01.250: INFO: ibm-keepalived-watcher-8t2hv from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  3 20:37:01.250: INFO: ibm-master-proxy-static-10.63.128.51 from kube-system started at 2022-10-03 17:10:31 +0000 UTC (2 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct  3 20:37:01.250: INFO: 	Container pause ready: true, restart count 0
Oct  3 20:37:01.250: INFO: ibm-storage-watcher-64fb9cdcfc-bsg7k from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct  3 20:37:01.250: INFO: ibmcloud-block-storage-driver-fdv2t from kube-system started at 2022-10-03 17:10:51 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct  3 20:37:01.250: INFO: ibmcloud-block-storage-plugin-7c4cfb55cb-72zmh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Oct  3 20:37:01.250: INFO: konnectivity-agent-lc67p from kube-system started at 2022-10-03 17:19:14 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct  3 20:37:01.250: INFO: kubernetes-dashboard-55c4d56798-qwrbg from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct  3 20:37:01.250: INFO: metrics-server-668b4d7ddd-mpnsv from kube-system started at 2022-10-03 19:20:52 +0000 UTC (3 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container config-watcher ready: true, restart count 0
Oct  3 20:37:01.250: INFO: 	Container metrics-server ready: true, restart count 0
Oct  3 20:37:01.250: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct  3 20:37:01.250: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-cc7hf from kube-system started at 2022-10-03 20:20:26 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct  3 20:37:01.250: INFO: snapshot-controller-c5c6dddff-2mxr6 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct  3 20:37:01.250: INFO: snapshot-controller-c5c6dddff-m6kpt from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct  3 20:37:01.250: INFO: snapshot-controller-c5c6dddff-wjxf9 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct  3 20:37:01.250: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-z8psd from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 20:37:01.250: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 20:37:01.250: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 10/03/22 20:37:01.251
Oct  3 20:37:01.271: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9239" to be "running"
Oct  3 20:37:01.285: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 13.524398ms
Oct  3 20:37:03.298: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027300046s
Oct  3 20:37:05.297: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.025950006s
Oct  3 20:37:05.297: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 10/03/22 20:37:05.309
STEP: Trying to apply a random label on the found node. 10/03/22 20:37:05.344
STEP: verifying the node has the label kubernetes.io/e2e-f207f011-3fe3-4964-adcd-3ff82149151b 95 10/03/22 20:37:05.376
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 10/03/22 20:37:05.389
Oct  3 20:37:05.404: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-9239" to be "not pending"
Oct  3 20:37:05.415: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.662596ms
Oct  3 20:37:07.427: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022964208s
Oct  3 20:37:09.428: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 4.024202901s
Oct  3 20:37:09.428: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.63.128.3 on the node which pod4 resides and expect not scheduled 10/03/22 20:37:09.428
Oct  3 20:37:09.444: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-9239" to be "not pending"
Oct  3 20:37:09.455: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 11.692775ms
Oct  3 20:37:11.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02553678s
Oct  3 20:37:13.472: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02886264s
Oct  3 20:37:15.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024435445s
Oct  3 20:37:17.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.023873266s
Oct  3 20:37:19.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.025146692s
Oct  3 20:37:21.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.025913683s
Oct  3 20:37:23.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.025809403s
Oct  3 20:37:25.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.023861948s
Oct  3 20:37:27.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.025232883s
Oct  3 20:37:29.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.024669131s
Oct  3 20:37:31.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.024069453s
Oct  3 20:37:33.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.025735725s
Oct  3 20:37:35.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.02490724s
Oct  3 20:37:37.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.026785003s
Oct  3 20:37:39.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.023680077s
Oct  3 20:37:41.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.024151268s
Oct  3 20:37:43.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.024933986s
Oct  3 20:37:45.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.023727898s
Oct  3 20:37:47.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.0251257s
Oct  3 20:37:49.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.024422134s
Oct  3 20:37:51.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.025078131s
Oct  3 20:37:53.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.024500668s
Oct  3 20:37:55.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.02371317s
Oct  3 20:37:57.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.024613374s
Oct  3 20:37:59.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.024057271s
Oct  3 20:38:01.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.026904003s
Oct  3 20:38:03.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.02363087s
Oct  3 20:38:05.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.023571995s
Oct  3 20:38:07.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.023756997s
Oct  3 20:38:09.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.024487086s
Oct  3 20:38:11.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.024617649s
Oct  3 20:38:13.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.024003178s
Oct  3 20:38:15.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.024676726s
Oct  3 20:38:17.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.024941488s
Oct  3 20:38:19.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.02486099s
Oct  3 20:38:21.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.02528826s
Oct  3 20:38:23.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.024702225s
Oct  3 20:38:25.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.023923176s
Oct  3 20:38:27.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.025357919s
Oct  3 20:38:29.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.023900718s
Oct  3 20:38:31.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.024019832s
Oct  3 20:38:33.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.026646928s
Oct  3 20:38:35.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.024335586s
Oct  3 20:38:37.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.024337352s
Oct  3 20:38:39.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.023838351s
Oct  3 20:38:41.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.024186216s
Oct  3 20:38:43.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.023725119s
Oct  3 20:38:45.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.024587628s
Oct  3 20:38:47.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.024795908s
Oct  3 20:38:49.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.025916989s
Oct  3 20:38:51.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.023699004s
Oct  3 20:38:53.471: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.027308752s
Oct  3 20:38:55.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.023350369s
Oct  3 20:38:57.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.024709451s
Oct  3 20:38:59.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.025357884s
Oct  3 20:39:01.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.024221296s
Oct  3 20:39:03.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.02551531s
Oct  3 20:39:05.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.023815767s
Oct  3 20:39:07.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.023496156s
Oct  3 20:39:09.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.024606308s
Oct  3 20:39:11.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.024684757s
Oct  3 20:39:13.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.024935697s
Oct  3 20:39:15.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.023806123s
Oct  3 20:39:17.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.025404879s
Oct  3 20:39:19.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.024598281s
Oct  3 20:39:21.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.024868623s
Oct  3 20:39:23.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.026107696s
Oct  3 20:39:25.472: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.028612242s
Oct  3 20:39:27.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.025012729s
Oct  3 20:39:29.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.024366908s
Oct  3 20:39:31.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.025863053s
Oct  3 20:39:33.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.024622484s
Oct  3 20:39:35.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.023695466s
Oct  3 20:39:37.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.023137463s
Oct  3 20:39:39.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.024771894s
Oct  3 20:39:41.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.023697579s
Oct  3 20:39:43.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.023987687s
Oct  3 20:39:45.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.024755919s
Oct  3 20:39:47.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.024959524s
Oct  3 20:39:49.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.02324442s
Oct  3 20:39:51.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.024066636s
Oct  3 20:39:53.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.024315003s
Oct  3 20:39:55.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.024996997s
Oct  3 20:39:57.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.023583199s
Oct  3 20:39:59.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.024823663s
Oct  3 20:40:01.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.024412492s
Oct  3 20:40:03.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.023569444s
Oct  3 20:40:05.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.026533036s
Oct  3 20:40:07.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.023152616s
Oct  3 20:40:09.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.023563694s
Oct  3 20:40:11.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.023138638s
Oct  3 20:40:13.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.023706805s
Oct  3 20:40:15.498: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.054315394s
Oct  3 20:40:17.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.024012084s
Oct  3 20:40:19.466: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.022612686s
Oct  3 20:40:21.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.023600378s
Oct  3 20:40:23.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.023876913s
Oct  3 20:40:25.482: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.038055709s
Oct  3 20:40:27.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.024254467s
Oct  3 20:40:29.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.02437853s
Oct  3 20:40:31.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.024102926s
Oct  3 20:40:33.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.024501139s
Oct  3 20:40:35.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.023338959s
Oct  3 20:40:37.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.023873415s
Oct  3 20:40:39.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.026007397s
Oct  3 20:40:41.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.024997449s
Oct  3 20:40:43.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.025648286s
Oct  3 20:40:45.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.023391951s
Oct  3 20:40:47.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.023822301s
Oct  3 20:40:49.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.025019824s
Oct  3 20:40:51.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.024931492s
Oct  3 20:40:53.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.025308243s
Oct  3 20:40:55.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.024502907s
Oct  3 20:40:57.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.024284438s
Oct  3 20:40:59.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.024431934s
Oct  3 20:41:01.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.024655007s
Oct  3 20:41:03.472: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.028818185s
Oct  3 20:41:05.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.024267309s
Oct  3 20:41:07.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.025241299s
Oct  3 20:41:09.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.026238088s
Oct  3 20:41:11.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.023400858s
Oct  3 20:41:13.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.025747745s
Oct  3 20:41:15.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.023621383s
Oct  3 20:41:17.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.023789919s
Oct  3 20:41:19.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.023445975s
Oct  3 20:41:21.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.023938444s
Oct  3 20:41:23.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.023957544s
Oct  3 20:41:25.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.023661784s
Oct  3 20:41:27.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.02370192s
Oct  3 20:41:29.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.023533167s
Oct  3 20:41:31.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.023380561s
Oct  3 20:41:33.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.023624524s
Oct  3 20:41:35.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.023704332s
Oct  3 20:41:37.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.024615455s
Oct  3 20:41:39.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.024105003s
Oct  3 20:41:41.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.023432636s
Oct  3 20:41:43.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.024081688s
Oct  3 20:41:45.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.023735631s
Oct  3 20:41:47.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.024457016s
Oct  3 20:41:49.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.025086757s
Oct  3 20:41:51.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.023771938s
Oct  3 20:41:53.472: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.028014555s
Oct  3 20:41:55.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.024040935s
Oct  3 20:41:57.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.026829963s
Oct  3 20:41:59.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.024087515s
Oct  3 20:42:01.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.025489891s
Oct  3 20:42:03.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.024297141s
Oct  3 20:42:05.466: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.022835309s
Oct  3 20:42:07.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.024871093s
Oct  3 20:42:09.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.025143352s
Oct  3 20:42:09.479: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.03586197s
STEP: removing the label kubernetes.io/e2e-f207f011-3fe3-4964-adcd-3ff82149151b off the node 10.63.128.3 10/03/22 20:42:09.48
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f207f011-3fe3-4964-adcd-3ff82149151b 10/03/22 20:42:09.519
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Oct  3 20:42:09.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9239" for this suite. 10/03/22 20:42:09.546
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":263,"skipped":5130,"failed":0}
------------------------------
• [SLOW TEST] [308.569 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:37:00.996
    Oct  3 20:37:00.996: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename sched-pred 10/03/22 20:37:00.998
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:37:01.032
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:37:01.042
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Oct  3 20:37:01.052: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Oct  3 20:37:01.088: INFO: Waiting for terminating namespaces to be deleted...
    Oct  3 20:37:01.103: INFO: 
    Logging pods the apiserver thinks is on node 10.63.128.13 before test
    Oct  3 20:37:01.165: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-5lm6l from ibm-system started at 2022-10-03 17:16:04 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.165: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
    Oct  3 20:37:01.165: INFO: calico-node-zpr9s from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.165: INFO: 	Container calico-node ready: true, restart count 0
    Oct  3 20:37:01.165: INFO: calico-typha-644fdcd5f-w67fp from kube-system started at 2022-10-03 17:11:18 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.165: INFO: 	Container calico-typha ready: true, restart count 0
    Oct  3 20:37:01.165: INFO: coredns-6754846f95-bl2wt from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.165: INFO: 	Container coredns ready: true, restart count 0
    Oct  3 20:37:01.165: INFO: ibm-keepalived-watcher-nw2l6 from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.165: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct  3 20:37:01.165: INFO: ibm-master-proxy-static-10.63.128.13 from kube-system started at 2022-10-03 17:10:55 +0000 UTC (2 container statuses recorded)
    Oct  3 20:37:01.165: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct  3 20:37:01.165: INFO: 	Container pause ready: true, restart count 0
    Oct  3 20:37:01.165: INFO: ibmcloud-block-storage-driver-f5thb from kube-system started at 2022-10-03 17:11:06 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.165: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct  3 20:37:01.165: INFO: ingress-cluster-healthcheck-6dbd7f8d47-vx87x from kube-system started at 2022-10-03 18:44:30 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.165: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Oct  3 20:37:01.165: INFO: konnectivity-agent-qv9fn from kube-system started at 2022-10-03 17:19:11 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.165: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct  3 20:37:01.165: INFO: metrics-server-668b4d7ddd-7glct from kube-system started at 2022-10-03 17:55:22 +0000 UTC (3 container statuses recorded)
    Oct  3 20:37:01.165: INFO: 	Container config-watcher ready: true, restart count 0
    Oct  3 20:37:01.166: INFO: 	Container metrics-server ready: true, restart count 0
    Oct  3 20:37:01.166: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct  3 20:37:01.166: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-7vk57 from kube-system started at 2022-10-03 19:52:24 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.166: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct  3 20:37:01.166: INFO: sonobuoy-e2e-job-2c5abccdc00d487c from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 20:37:01.166: INFO: 	Container e2e ready: true, restart count 0
    Oct  3 20:37:01.166: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 20:37:01.166: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-cwlqc from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 20:37:01.166: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 20:37:01.166: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct  3 20:37:01.166: INFO: 
    Logging pods the apiserver thinks is on node 10.63.128.3 before test
    Oct  3 20:37:01.203: INFO: calico-node-zrfj4 from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.203: INFO: 	Container calico-node ready: true, restart count 0
    Oct  3 20:37:01.203: INFO: calico-typha-644fdcd5f-rskkx from kube-system started at 2022-10-03 20:20:28 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.203: INFO: 	Container calico-typha ready: true, restart count 0
    Oct  3 20:37:01.203: INFO: ibm-keepalived-watcher-jr7cc from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.203: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct  3 20:37:01.203: INFO: ibm-master-proxy-static-10.63.128.3 from kube-system started at 2022-10-03 17:10:52 +0000 UTC (2 container statuses recorded)
    Oct  3 20:37:01.203: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct  3 20:37:01.203: INFO: 	Container pause ready: true, restart count 0
    Oct  3 20:37:01.203: INFO: ibmcloud-block-storage-driver-j765w from kube-system started at 2022-10-03 17:11:13 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.203: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct  3 20:37:01.203: INFO: konnectivity-agent-n5jcf from kube-system started at 2022-10-03 17:19:17 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.203: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct  3 20:37:01.203: INFO: sonobuoy from sonobuoy started at 2022-10-03 19:13:32 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.204: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Oct  3 20:37:01.204: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-lpx2r from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 20:37:01.204: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 20:37:01.204: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct  3 20:37:01.204: INFO: 
    Logging pods the apiserver thinks is on node 10.63.128.51 before test
    Oct  3 20:37:01.249: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-6mpp7 from ibm-system started at 2022-10-03 19:20:52 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.249: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
    Oct  3 20:37:01.249: INFO: calico-kube-controllers-5ccfdf4b6d-qxssd from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.249: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Oct  3 20:37:01.249: INFO: calico-node-zfv55 from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.249: INFO: 	Container calico-node ready: true, restart count 0
    Oct  3 20:37:01.249: INFO: calico-typha-644fdcd5f-7qcns from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.249: INFO: 	Container calico-typha ready: true, restart count 0
    Oct  3 20:37:01.249: INFO: coredns-6754846f95-9q5kh from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.249: INFO: 	Container coredns ready: true, restart count 0
    Oct  3 20:37:01.249: INFO: coredns-6754846f95-c7x4x from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.249: INFO: 	Container coredns ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: coredns-autoscaler-669cf746f6-wwqwh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container autoscaler ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: dashboard-metrics-scraper-c964d5594-bvc48 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: ibm-file-plugin-bdf4f476-5nc82 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: ibm-keepalived-watcher-8t2hv from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: ibm-master-proxy-static-10.63.128.51 from kube-system started at 2022-10-03 17:10:31 +0000 UTC (2 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: 	Container pause ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: ibm-storage-watcher-64fb9cdcfc-bsg7k from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: ibmcloud-block-storage-driver-fdv2t from kube-system started at 2022-10-03 17:10:51 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: ibmcloud-block-storage-plugin-7c4cfb55cb-72zmh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: konnectivity-agent-lc67p from kube-system started at 2022-10-03 17:19:14 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: kubernetes-dashboard-55c4d56798-qwrbg from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: metrics-server-668b4d7ddd-mpnsv from kube-system started at 2022-10-03 19:20:52 +0000 UTC (3 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container config-watcher ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: 	Container metrics-server ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-cc7hf from kube-system started at 2022-10-03 20:20:26 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: snapshot-controller-c5c6dddff-2mxr6 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: snapshot-controller-c5c6dddff-m6kpt from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: snapshot-controller-c5c6dddff-wjxf9 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-z8psd from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 20:37:01.250: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 20:37:01.250: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 10/03/22 20:37:01.251
    Oct  3 20:37:01.271: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9239" to be "running"
    Oct  3 20:37:01.285: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 13.524398ms
    Oct  3 20:37:03.298: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027300046s
    Oct  3 20:37:05.297: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.025950006s
    Oct  3 20:37:05.297: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 10/03/22 20:37:05.309
    STEP: Trying to apply a random label on the found node. 10/03/22 20:37:05.344
    STEP: verifying the node has the label kubernetes.io/e2e-f207f011-3fe3-4964-adcd-3ff82149151b 95 10/03/22 20:37:05.376
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 10/03/22 20:37:05.389
    Oct  3 20:37:05.404: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-9239" to be "not pending"
    Oct  3 20:37:05.415: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.662596ms
    Oct  3 20:37:07.427: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022964208s
    Oct  3 20:37:09.428: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 4.024202901s
    Oct  3 20:37:09.428: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.63.128.3 on the node which pod4 resides and expect not scheduled 10/03/22 20:37:09.428
    Oct  3 20:37:09.444: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-9239" to be "not pending"
    Oct  3 20:37:09.455: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 11.692775ms
    Oct  3 20:37:11.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02553678s
    Oct  3 20:37:13.472: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02886264s
    Oct  3 20:37:15.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024435445s
    Oct  3 20:37:17.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.023873266s
    Oct  3 20:37:19.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.025146692s
    Oct  3 20:37:21.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.025913683s
    Oct  3 20:37:23.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.025809403s
    Oct  3 20:37:25.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.023861948s
    Oct  3 20:37:27.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.025232883s
    Oct  3 20:37:29.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.024669131s
    Oct  3 20:37:31.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.024069453s
    Oct  3 20:37:33.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.025735725s
    Oct  3 20:37:35.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.02490724s
    Oct  3 20:37:37.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.026785003s
    Oct  3 20:37:39.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.023680077s
    Oct  3 20:37:41.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.024151268s
    Oct  3 20:37:43.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.024933986s
    Oct  3 20:37:45.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.023727898s
    Oct  3 20:37:47.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.0251257s
    Oct  3 20:37:49.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.024422134s
    Oct  3 20:37:51.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.025078131s
    Oct  3 20:37:53.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.024500668s
    Oct  3 20:37:55.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.02371317s
    Oct  3 20:37:57.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.024613374s
    Oct  3 20:37:59.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.024057271s
    Oct  3 20:38:01.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.026904003s
    Oct  3 20:38:03.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.02363087s
    Oct  3 20:38:05.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.023571995s
    Oct  3 20:38:07.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.023756997s
    Oct  3 20:38:09.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.024487086s
    Oct  3 20:38:11.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.024617649s
    Oct  3 20:38:13.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.024003178s
    Oct  3 20:38:15.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.024676726s
    Oct  3 20:38:17.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.024941488s
    Oct  3 20:38:19.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.02486099s
    Oct  3 20:38:21.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.02528826s
    Oct  3 20:38:23.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.024702225s
    Oct  3 20:38:25.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.023923176s
    Oct  3 20:38:27.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.025357919s
    Oct  3 20:38:29.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.023900718s
    Oct  3 20:38:31.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.024019832s
    Oct  3 20:38:33.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.026646928s
    Oct  3 20:38:35.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.024335586s
    Oct  3 20:38:37.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.024337352s
    Oct  3 20:38:39.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.023838351s
    Oct  3 20:38:41.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.024186216s
    Oct  3 20:38:43.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.023725119s
    Oct  3 20:38:45.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.024587628s
    Oct  3 20:38:47.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.024795908s
    Oct  3 20:38:49.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.025916989s
    Oct  3 20:38:51.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.023699004s
    Oct  3 20:38:53.471: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.027308752s
    Oct  3 20:38:55.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.023350369s
    Oct  3 20:38:57.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.024709451s
    Oct  3 20:38:59.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.025357884s
    Oct  3 20:39:01.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.024221296s
    Oct  3 20:39:03.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.02551531s
    Oct  3 20:39:05.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.023815767s
    Oct  3 20:39:07.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.023496156s
    Oct  3 20:39:09.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.024606308s
    Oct  3 20:39:11.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.024684757s
    Oct  3 20:39:13.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.024935697s
    Oct  3 20:39:15.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.023806123s
    Oct  3 20:39:17.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.025404879s
    Oct  3 20:39:19.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.024598281s
    Oct  3 20:39:21.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.024868623s
    Oct  3 20:39:23.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.026107696s
    Oct  3 20:39:25.472: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.028612242s
    Oct  3 20:39:27.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.025012729s
    Oct  3 20:39:29.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.024366908s
    Oct  3 20:39:31.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.025863053s
    Oct  3 20:39:33.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.024622484s
    Oct  3 20:39:35.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.023695466s
    Oct  3 20:39:37.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.023137463s
    Oct  3 20:39:39.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.024771894s
    Oct  3 20:39:41.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.023697579s
    Oct  3 20:39:43.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.023987687s
    Oct  3 20:39:45.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.024755919s
    Oct  3 20:39:47.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.024959524s
    Oct  3 20:39:49.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.02324442s
    Oct  3 20:39:51.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.024066636s
    Oct  3 20:39:53.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.024315003s
    Oct  3 20:39:55.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.024996997s
    Oct  3 20:39:57.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.023583199s
    Oct  3 20:39:59.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.024823663s
    Oct  3 20:40:01.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.024412492s
    Oct  3 20:40:03.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.023569444s
    Oct  3 20:40:05.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.026533036s
    Oct  3 20:40:07.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.023152616s
    Oct  3 20:40:09.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.023563694s
    Oct  3 20:40:11.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.023138638s
    Oct  3 20:40:13.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.023706805s
    Oct  3 20:40:15.498: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.054315394s
    Oct  3 20:40:17.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.024012084s
    Oct  3 20:40:19.466: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.022612686s
    Oct  3 20:40:21.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.023600378s
    Oct  3 20:40:23.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.023876913s
    Oct  3 20:40:25.482: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.038055709s
    Oct  3 20:40:27.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.024254467s
    Oct  3 20:40:29.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.02437853s
    Oct  3 20:40:31.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.024102926s
    Oct  3 20:40:33.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.024501139s
    Oct  3 20:40:35.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.023338959s
    Oct  3 20:40:37.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.023873415s
    Oct  3 20:40:39.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.026007397s
    Oct  3 20:40:41.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.024997449s
    Oct  3 20:40:43.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.025648286s
    Oct  3 20:40:45.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.023391951s
    Oct  3 20:40:47.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.023822301s
    Oct  3 20:40:49.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.025019824s
    Oct  3 20:40:51.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.024931492s
    Oct  3 20:40:53.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.025308243s
    Oct  3 20:40:55.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.024502907s
    Oct  3 20:40:57.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.024284438s
    Oct  3 20:40:59.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.024431934s
    Oct  3 20:41:01.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.024655007s
    Oct  3 20:41:03.472: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.028818185s
    Oct  3 20:41:05.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.024267309s
    Oct  3 20:41:07.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.025241299s
    Oct  3 20:41:09.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.026238088s
    Oct  3 20:41:11.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.023400858s
    Oct  3 20:41:13.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.025747745s
    Oct  3 20:41:15.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.023621383s
    Oct  3 20:41:17.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.023789919s
    Oct  3 20:41:19.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.023445975s
    Oct  3 20:41:21.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.023938444s
    Oct  3 20:41:23.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.023957544s
    Oct  3 20:41:25.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.023661784s
    Oct  3 20:41:27.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.02370192s
    Oct  3 20:41:29.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.023533167s
    Oct  3 20:41:31.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.023380561s
    Oct  3 20:41:33.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.023624524s
    Oct  3 20:41:35.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.023704332s
    Oct  3 20:41:37.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.024615455s
    Oct  3 20:41:39.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.024105003s
    Oct  3 20:41:41.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.023432636s
    Oct  3 20:41:43.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.024081688s
    Oct  3 20:41:45.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.023735631s
    Oct  3 20:41:47.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.024457016s
    Oct  3 20:41:49.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.025086757s
    Oct  3 20:41:51.467: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.023771938s
    Oct  3 20:41:53.472: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.028014555s
    Oct  3 20:41:55.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.024040935s
    Oct  3 20:41:57.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.026829963s
    Oct  3 20:41:59.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.024087515s
    Oct  3 20:42:01.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.025489891s
    Oct  3 20:42:03.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.024297141s
    Oct  3 20:42:05.466: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.022835309s
    Oct  3 20:42:07.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.024871093s
    Oct  3 20:42:09.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.025143352s
    Oct  3 20:42:09.479: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.03586197s
    STEP: removing the label kubernetes.io/e2e-f207f011-3fe3-4964-adcd-3ff82149151b off the node 10.63.128.3 10/03/22 20:42:09.48
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-f207f011-3fe3-4964-adcd-3ff82149151b 10/03/22 20:42:09.519
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 20:42:09.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-9239" for this suite. 10/03/22 20:42:09.546
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:42:09.571
Oct  3 20:42:09.571: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename daemonsets 10/03/22 20:42:09.572
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:42:09.606
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:42:09.616
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 10/03/22 20:42:09.687
STEP: Check that daemon pods launch on every node of the cluster. 10/03/22 20:42:09.7
Oct  3 20:42:09.724: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 20:42:09.724: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 20:42:10.755: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 20:42:10.755: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 20:42:11.751: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 20:42:11.751: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 20:42:12.751: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct  3 20:42:12.751: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 10/03/22 20:42:12.762
Oct  3 20:42:12.819: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct  3 20:42:12.820: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 20:42:13.855: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct  3 20:42:13.855: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 20:42:14.852: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct  3 20:42:14.852: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 20:42:15.847: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct  3 20:42:15.847: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 10/03/22 20:42:15.847
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 10/03/22 20:42:15.87
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5528, will wait for the garbage collector to delete the pods 10/03/22 20:42:15.87
Oct  3 20:42:15.973: INFO: Deleting DaemonSet.extensions daemon-set took: 20.112063ms
Oct  3 20:42:16.073: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.437876ms
Oct  3 20:42:18.285: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 20:42:18.285: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct  3 20:42:18.296: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38539"},"items":null}

Oct  3 20:42:18.310: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38539"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Oct  3 20:42:18.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5528" for this suite. 10/03/22 20:42:18.371
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":264,"skipped":5185,"failed":0}
------------------------------
• [SLOW TEST] [8.820 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:42:09.571
    Oct  3 20:42:09.571: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename daemonsets 10/03/22 20:42:09.572
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:42:09.606
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:42:09.616
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 10/03/22 20:42:09.687
    STEP: Check that daemon pods launch on every node of the cluster. 10/03/22 20:42:09.7
    Oct  3 20:42:09.724: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 20:42:09.724: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 20:42:10.755: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 20:42:10.755: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 20:42:11.751: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 20:42:11.751: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 20:42:12.751: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct  3 20:42:12.751: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 10/03/22 20:42:12.762
    Oct  3 20:42:12.819: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct  3 20:42:12.820: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 20:42:13.855: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct  3 20:42:13.855: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 20:42:14.852: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct  3 20:42:14.852: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 20:42:15.847: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct  3 20:42:15.847: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 10/03/22 20:42:15.847
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 10/03/22 20:42:15.87
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5528, will wait for the garbage collector to delete the pods 10/03/22 20:42:15.87
    Oct  3 20:42:15.973: INFO: Deleting DaemonSet.extensions daemon-set took: 20.112063ms
    Oct  3 20:42:16.073: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.437876ms
    Oct  3 20:42:18.285: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 20:42:18.285: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Oct  3 20:42:18.296: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38539"},"items":null}

    Oct  3 20:42:18.310: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38539"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 20:42:18.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-5528" for this suite. 10/03/22 20:42:18.371
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:42:18.394
Oct  3 20:42:18.394: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 20:42:18.395
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:42:18.426
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:42:18.435
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 10/03/22 20:42:18.445
Oct  3 20:42:18.467: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290" in namespace "downward-api-6026" to be "Succeeded or Failed"
Oct  3 20:42:18.477: INFO: Pod "downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290": Phase="Pending", Reason="", readiness=false. Elapsed: 10.244655ms
Oct  3 20:42:20.489: INFO: Pod "downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021987359s
Oct  3 20:42:22.517: INFO: Pod "downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050259422s
Oct  3 20:42:24.491: INFO: Pod "downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023917775s
STEP: Saw pod success 10/03/22 20:42:24.491
Oct  3 20:42:24.491: INFO: Pod "downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290" satisfied condition "Succeeded or Failed"
Oct  3 20:42:24.504: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290 container client-container: <nil>
STEP: delete the pod 10/03/22 20:42:24.614
Oct  3 20:42:24.646: INFO: Waiting for pod downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290 to disappear
Oct  3 20:42:24.657: INFO: Pod downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Oct  3 20:42:24.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6026" for this suite. 10/03/22 20:42:24.701
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":265,"skipped":5191,"failed":0}
------------------------------
• [SLOW TEST] [6.344 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:42:18.394
    Oct  3 20:42:18.394: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 20:42:18.395
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:42:18.426
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:42:18.435
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 10/03/22 20:42:18.445
    Oct  3 20:42:18.467: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290" in namespace "downward-api-6026" to be "Succeeded or Failed"
    Oct  3 20:42:18.477: INFO: Pod "downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290": Phase="Pending", Reason="", readiness=false. Elapsed: 10.244655ms
    Oct  3 20:42:20.489: INFO: Pod "downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021987359s
    Oct  3 20:42:22.517: INFO: Pod "downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050259422s
    Oct  3 20:42:24.491: INFO: Pod "downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023917775s
    STEP: Saw pod success 10/03/22 20:42:24.491
    Oct  3 20:42:24.491: INFO: Pod "downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290" satisfied condition "Succeeded or Failed"
    Oct  3 20:42:24.504: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290 container client-container: <nil>
    STEP: delete the pod 10/03/22 20:42:24.614
    Oct  3 20:42:24.646: INFO: Waiting for pod downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290 to disappear
    Oct  3 20:42:24.657: INFO: Pod downwardapi-volume-7d3c6ac5-02f6-41dd-a4f7-410ebb1d0290 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Oct  3 20:42:24.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6026" for this suite. 10/03/22 20:42:24.701
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:42:24.741
Oct  3 20:42:24.741: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir 10/03/22 20:42:24.742
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:42:24.773
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:42:24.783
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 10/03/22 20:42:24.792
Oct  3 20:42:24.812: INFO: Waiting up to 5m0s for pod "pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc" in namespace "emptydir-3931" to be "Succeeded or Failed"
Oct  3 20:42:24.822: INFO: Pod "pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.127532ms
Oct  3 20:42:26.836: INFO: Pod "pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024100275s
Oct  3 20:42:28.835: INFO: Pod "pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022202468s
Oct  3 20:42:30.835: INFO: Pod "pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022469851s
STEP: Saw pod success 10/03/22 20:42:30.835
Oct  3 20:42:30.835: INFO: Pod "pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc" satisfied condition "Succeeded or Failed"
Oct  3 20:42:30.846: INFO: Trying to get logs from node 10.63.128.3 pod pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc container test-container: <nil>
STEP: delete the pod 10/03/22 20:42:30.871
Oct  3 20:42:30.905: INFO: Waiting for pod pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc to disappear
Oct  3 20:42:30.916: INFO: Pod pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Oct  3 20:42:30.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3931" for this suite. 10/03/22 20:42:30.934
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":266,"skipped":5199,"failed":0}
------------------------------
• [SLOW TEST] [6.212 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:42:24.741
    Oct  3 20:42:24.741: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir 10/03/22 20:42:24.742
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:42:24.773
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:42:24.783
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 10/03/22 20:42:24.792
    Oct  3 20:42:24.812: INFO: Waiting up to 5m0s for pod "pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc" in namespace "emptydir-3931" to be "Succeeded or Failed"
    Oct  3 20:42:24.822: INFO: Pod "pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.127532ms
    Oct  3 20:42:26.836: INFO: Pod "pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024100275s
    Oct  3 20:42:28.835: INFO: Pod "pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022202468s
    Oct  3 20:42:30.835: INFO: Pod "pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022469851s
    STEP: Saw pod success 10/03/22 20:42:30.835
    Oct  3 20:42:30.835: INFO: Pod "pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc" satisfied condition "Succeeded or Failed"
    Oct  3 20:42:30.846: INFO: Trying to get logs from node 10.63.128.3 pod pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc container test-container: <nil>
    STEP: delete the pod 10/03/22 20:42:30.871
    Oct  3 20:42:30.905: INFO: Waiting for pod pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc to disappear
    Oct  3 20:42:30.916: INFO: Pod pod-677e101a-c367-49ba-8261-7ad6cf6ca0cc no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Oct  3 20:42:30.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3931" for this suite. 10/03/22 20:42:30.934
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:42:30.962
Oct  3 20:42:30.962: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename runtimeclass 10/03/22 20:42:30.963
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:42:31.017
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:42:31.027
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-3436-delete-me 10/03/22 20:42:31.049
STEP: Waiting for the RuntimeClass to disappear 10/03/22 20:42:31.066
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Oct  3 20:42:31.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-3436" for this suite. 10/03/22 20:42:31.113
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":267,"skipped":5242,"failed":0}
------------------------------
• [0.171 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:42:30.962
    Oct  3 20:42:30.962: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename runtimeclass 10/03/22 20:42:30.963
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:42:31.017
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:42:31.027
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-3436-delete-me 10/03/22 20:42:31.049
    STEP: Waiting for the RuntimeClass to disappear 10/03/22 20:42:31.066
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Oct  3 20:42:31.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-3436" for this suite. 10/03/22 20:42:31.113
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:42:31.134
Oct  3 20:42:31.134: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 20:42:31.135
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:42:31.166
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:42:31.178
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-3232 10/03/22 20:42:31.192
STEP: creating service affinity-clusterip-transition in namespace services-3232 10/03/22 20:42:31.193
STEP: creating replication controller affinity-clusterip-transition in namespace services-3232 10/03/22 20:42:31.231
I1003 20:42:31.249285      22 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3232, replica count: 3
I1003 20:42:34.303148      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  3 20:42:34.326: INFO: Creating new exec pod
Oct  3 20:42:34.363: INFO: Waiting up to 5m0s for pod "execpod-affinityh4zdt" in namespace "services-3232" to be "running"
Oct  3 20:42:34.376: INFO: Pod "execpod-affinityh4zdt": Phase="Pending", Reason="", readiness=false. Elapsed: 13.031922ms
Oct  3 20:42:36.392: INFO: Pod "execpod-affinityh4zdt": Phase="Running", Reason="", readiness=true. Elapsed: 2.02854834s
Oct  3 20:42:36.392: INFO: Pod "execpod-affinityh4zdt" satisfied condition "running"
Oct  3 20:42:37.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-3232 exec execpod-affinityh4zdt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Oct  3 20:42:37.731: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Oct  3 20:42:37.731: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:42:37.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-3232 exec execpod-affinityh4zdt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.182.224 80'
Oct  3 20:42:38.044: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.182.224 80\nConnection to 172.21.182.224 80 port [tcp/http] succeeded!\n"
Oct  3 20:42:38.044: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:42:38.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-3232 exec execpod-affinityh4zdt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.182.224:80/ ; done'
Oct  3 20:42:38.549: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n"
Oct  3 20:42:38.549: INFO: stdout: "\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8"
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:08.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-3232 exec execpod-affinityh4zdt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.182.224:80/ ; done'
Oct  3 20:43:09.047: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n"
Oct  3 20:43:09.047: INFO: stdout: "\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-9kkpt\naffinity-clusterip-transition-9kkpt\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-dzrmp\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-9kkpt\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-9kkpt\naffinity-clusterip-transition-9kkpt\naffinity-clusterip-transition-dzrmp"
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-9kkpt
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-9kkpt
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-dzrmp
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-9kkpt
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-9kkpt
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-9kkpt
Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-dzrmp
Oct  3 20:43:09.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-3232 exec execpod-affinityh4zdt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.182.224:80/ ; done'
Oct  3 20:43:09.600: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n"
Oct  3 20:43:09.600: INFO: stdout: "\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8"
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
Oct  3 20:43:09.600: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3232, will wait for the garbage collector to delete the pods 10/03/22 20:43:09.635
Oct  3 20:43:09.713: INFO: Deleting ReplicationController affinity-clusterip-transition took: 17.119712ms
Oct  3 20:43:09.814: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.84942ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 20:43:12.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3232" for this suite. 10/03/22 20:43:12.588
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":268,"skipped":5246,"failed":0}
------------------------------
• [SLOW TEST] [41.478 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:42:31.134
    Oct  3 20:42:31.134: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 20:42:31.135
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:42:31.166
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:42:31.178
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-3232 10/03/22 20:42:31.192
    STEP: creating service affinity-clusterip-transition in namespace services-3232 10/03/22 20:42:31.193
    STEP: creating replication controller affinity-clusterip-transition in namespace services-3232 10/03/22 20:42:31.231
    I1003 20:42:31.249285      22 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3232, replica count: 3
    I1003 20:42:34.303148      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct  3 20:42:34.326: INFO: Creating new exec pod
    Oct  3 20:42:34.363: INFO: Waiting up to 5m0s for pod "execpod-affinityh4zdt" in namespace "services-3232" to be "running"
    Oct  3 20:42:34.376: INFO: Pod "execpod-affinityh4zdt": Phase="Pending", Reason="", readiness=false. Elapsed: 13.031922ms
    Oct  3 20:42:36.392: INFO: Pod "execpod-affinityh4zdt": Phase="Running", Reason="", readiness=true. Elapsed: 2.02854834s
    Oct  3 20:42:36.392: INFO: Pod "execpod-affinityh4zdt" satisfied condition "running"
    Oct  3 20:42:37.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-3232 exec execpod-affinityh4zdt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Oct  3 20:42:37.731: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Oct  3 20:42:37.731: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:42:37.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-3232 exec execpod-affinityh4zdt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.182.224 80'
    Oct  3 20:42:38.044: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.182.224 80\nConnection to 172.21.182.224 80 port [tcp/http] succeeded!\n"
    Oct  3 20:42:38.044: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:42:38.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-3232 exec execpod-affinityh4zdt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.182.224:80/ ; done'
    Oct  3 20:42:38.549: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n"
    Oct  3 20:42:38.549: INFO: stdout: "\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8"
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:42:38.549: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:08.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-3232 exec execpod-affinityh4zdt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.182.224:80/ ; done'
    Oct  3 20:43:09.047: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n"
    Oct  3 20:43:09.047: INFO: stdout: "\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-9kkpt\naffinity-clusterip-transition-9kkpt\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-dzrmp\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-9kkpt\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-9kkpt\naffinity-clusterip-transition-9kkpt\naffinity-clusterip-transition-dzrmp"
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-9kkpt
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-9kkpt
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-dzrmp
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-9kkpt
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-9kkpt
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-9kkpt
    Oct  3 20:43:09.047: INFO: Received response from host: affinity-clusterip-transition-dzrmp
    Oct  3 20:43:09.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-3232 exec execpod-affinityh4zdt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.182.224:80/ ; done'
    Oct  3 20:43:09.600: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.182.224:80/\n"
    Oct  3 20:43:09.600: INFO: stdout: "\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8\naffinity-clusterip-transition-kgzd8"
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Received response from host: affinity-clusterip-transition-kgzd8
    Oct  3 20:43:09.600: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3232, will wait for the garbage collector to delete the pods 10/03/22 20:43:09.635
    Oct  3 20:43:09.713: INFO: Deleting ReplicationController affinity-clusterip-transition took: 17.119712ms
    Oct  3 20:43:09.814: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.84942ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 20:43:12.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3232" for this suite. 10/03/22 20:43:12.588
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:43:12.613
Oct  3 20:43:12.613: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename secrets 10/03/22 20:43:12.614
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:12.662
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:12.673
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-f7516044-9fc1-4c93-985b-aab40807489f 10/03/22 20:43:12.767
STEP: Creating a pod to test consume secrets 10/03/22 20:43:12.782
Oct  3 20:43:12.813: INFO: Waiting up to 5m0s for pod "pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b" in namespace "secrets-5095" to be "Succeeded or Failed"
Oct  3 20:43:12.838: INFO: Pod "pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b": Phase="Pending", Reason="", readiness=false. Elapsed: 25.512466ms
Oct  3 20:43:14.853: INFO: Pod "pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040056279s
Oct  3 20:43:16.854: INFO: Pod "pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041479942s
Oct  3 20:43:18.853: INFO: Pod "pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040167319s
STEP: Saw pod success 10/03/22 20:43:18.853
Oct  3 20:43:18.853: INFO: Pod "pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b" satisfied condition "Succeeded or Failed"
Oct  3 20:43:18.867: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b container secret-volume-test: <nil>
STEP: delete the pod 10/03/22 20:43:18.976
Oct  3 20:43:19.021: INFO: Waiting for pod pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b to disappear
Oct  3 20:43:19.035: INFO: Pod pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Oct  3 20:43:19.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5095" for this suite. 10/03/22 20:43:19.053
STEP: Destroying namespace "secret-namespace-9889" for this suite. 10/03/22 20:43:19.076
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":269,"skipped":5258,"failed":0}
------------------------------
• [SLOW TEST] [6.487 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:43:12.613
    Oct  3 20:43:12.613: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename secrets 10/03/22 20:43:12.614
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:12.662
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:12.673
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-f7516044-9fc1-4c93-985b-aab40807489f 10/03/22 20:43:12.767
    STEP: Creating a pod to test consume secrets 10/03/22 20:43:12.782
    Oct  3 20:43:12.813: INFO: Waiting up to 5m0s for pod "pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b" in namespace "secrets-5095" to be "Succeeded or Failed"
    Oct  3 20:43:12.838: INFO: Pod "pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b": Phase="Pending", Reason="", readiness=false. Elapsed: 25.512466ms
    Oct  3 20:43:14.853: INFO: Pod "pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040056279s
    Oct  3 20:43:16.854: INFO: Pod "pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041479942s
    Oct  3 20:43:18.853: INFO: Pod "pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040167319s
    STEP: Saw pod success 10/03/22 20:43:18.853
    Oct  3 20:43:18.853: INFO: Pod "pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b" satisfied condition "Succeeded or Failed"
    Oct  3 20:43:18.867: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b container secret-volume-test: <nil>
    STEP: delete the pod 10/03/22 20:43:18.976
    Oct  3 20:43:19.021: INFO: Waiting for pod pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b to disappear
    Oct  3 20:43:19.035: INFO: Pod pod-secrets-950b29dd-7d76-439c-a734-54d1928ad61b no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Oct  3 20:43:19.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5095" for this suite. 10/03/22 20:43:19.053
    STEP: Destroying namespace "secret-namespace-9889" for this suite. 10/03/22 20:43:19.076
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:43:19.101
Oct  3 20:43:19.102: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename tables 10/03/22 20:43:19.103
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:19.144
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:19.153
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Oct  3 20:43:19.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-4325" for this suite. 10/03/22 20:43:19.19
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":270,"skipped":5268,"failed":0}
------------------------------
• [0.112 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:43:19.101
    Oct  3 20:43:19.102: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename tables 10/03/22 20:43:19.103
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:19.144
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:19.153
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Oct  3 20:43:19.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-4325" for this suite. 10/03/22 20:43:19.19
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:43:19.222
Oct  3 20:43:19.223: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename custom-resource-definition 10/03/22 20:43:19.224
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:19.269
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:19.281
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Oct  3 20:43:19.304: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:43:20.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1417" for this suite. 10/03/22 20:43:20.397
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":271,"skipped":5302,"failed":0}
------------------------------
• [1.197 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:43:19.222
    Oct  3 20:43:19.223: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename custom-resource-definition 10/03/22 20:43:19.224
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:19.269
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:19.281
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Oct  3 20:43:19.304: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:43:20.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1417" for this suite. 10/03/22 20:43:20.397
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:43:20.422
Oct  3 20:43:20.422: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 20:43:20.423
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:20.466
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:20.477
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 20:43:20.548
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:43:21.158
STEP: Deploying the webhook pod 10/03/22 20:43:21.193
STEP: Wait for the deployment to be ready 10/03/22 20:43:21.249
Oct  3 20:43:21.303: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/03/22 20:43:23.372
STEP: Verifying the service has paired with the endpoint 10/03/22 20:43:23.422
Oct  3 20:43:24.423: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Oct  3 20:43:24.435: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6120-crds.webhook.example.com via the AdmissionRegistration API 10/03/22 20:43:24.978
STEP: Creating a custom resource that should be mutated by the webhook 10/03/22 20:43:25.058
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:43:27.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3376" for this suite. 10/03/22 20:43:27.947
STEP: Destroying namespace "webhook-3376-markers" for this suite. 10/03/22 20:43:27.991
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":272,"skipped":5307,"failed":0}
------------------------------
• [SLOW TEST] [7.772 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:43:20.422
    Oct  3 20:43:20.422: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 20:43:20.423
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:20.466
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:20.477
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 20:43:20.548
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:43:21.158
    STEP: Deploying the webhook pod 10/03/22 20:43:21.193
    STEP: Wait for the deployment to be ready 10/03/22 20:43:21.249
    Oct  3 20:43:21.303: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/03/22 20:43:23.372
    STEP: Verifying the service has paired with the endpoint 10/03/22 20:43:23.422
    Oct  3 20:43:24.423: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Oct  3 20:43:24.435: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6120-crds.webhook.example.com via the AdmissionRegistration API 10/03/22 20:43:24.978
    STEP: Creating a custom resource that should be mutated by the webhook 10/03/22 20:43:25.058
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:43:27.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3376" for this suite. 10/03/22 20:43:27.947
    STEP: Destroying namespace "webhook-3376-markers" for this suite. 10/03/22 20:43:27.991
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:43:28.205
Oct  3 20:43:28.206: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 20:43:28.207
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:28.25
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:28.262
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 10/03/22 20:43:28.274
Oct  3 20:43:28.275: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: mark a version not serverd 10/03/22 20:43:38.489
STEP: check the unserved version gets removed 10/03/22 20:43:38.531
STEP: check the other version is not changed 10/03/22 20:43:43.011
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:43:50.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4582" for this suite. 10/03/22 20:43:50.705
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":273,"skipped":5389,"failed":0}
------------------------------
• [SLOW TEST] [22.519 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:43:28.205
    Oct  3 20:43:28.206: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 20:43:28.207
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:28.25
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:28.262
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 10/03/22 20:43:28.274
    Oct  3 20:43:28.275: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: mark a version not serverd 10/03/22 20:43:38.489
    STEP: check the unserved version gets removed 10/03/22 20:43:38.531
    STEP: check the other version is not changed 10/03/22 20:43:43.011
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:43:50.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4582" for this suite. 10/03/22 20:43:50.705
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:43:50.728
Oct  3 20:43:50.728: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 10/03/22 20:43:50.729
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:50.762
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:50.773
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 10/03/22 20:43:50.782
STEP: Creating hostNetwork=false pod 10/03/22 20:43:50.783
Oct  3 20:43:50.806: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-1296" to be "running and ready"
Oct  3 20:43:50.819: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.855794ms
Oct  3 20:43:50.819: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:43:52.833: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026498174s
Oct  3 20:43:52.833: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:43:54.833: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.026685761s
Oct  3 20:43:54.833: INFO: The phase of Pod test-pod is Running (Ready = true)
Oct  3 20:43:54.833: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 10/03/22 20:43:54.843
Oct  3 20:43:54.859: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-1296" to be "running and ready"
Oct  3 20:43:54.871: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.178077ms
Oct  3 20:43:54.871: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:43:56.883: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.024226734s
Oct  3 20:43:56.883: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Oct  3 20:43:56.883: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 10/03/22 20:43:56.893
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 10/03/22 20:43:56.893
Oct  3 20:43:56.894: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:43:56.894: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:43:56.895: INFO: ExecWithOptions: Clientset creation
Oct  3 20:43:56.895: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Oct  3 20:43:57.127: INFO: Exec stderr: ""
Oct  3 20:43:57.127: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:43:57.127: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:43:57.129: INFO: ExecWithOptions: Clientset creation
Oct  3 20:43:57.129: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Oct  3 20:43:57.355: INFO: Exec stderr: ""
Oct  3 20:43:57.355: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:43:57.355: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:43:57.356: INFO: ExecWithOptions: Clientset creation
Oct  3 20:43:57.357: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Oct  3 20:43:57.590: INFO: Exec stderr: ""
Oct  3 20:43:57.590: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:43:57.590: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:43:57.591: INFO: ExecWithOptions: Clientset creation
Oct  3 20:43:57.591: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Oct  3 20:43:57.804: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 10/03/22 20:43:57.804
Oct  3 20:43:57.804: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:43:57.804: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:43:57.805: INFO: ExecWithOptions: Clientset creation
Oct  3 20:43:57.805: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Oct  3 20:43:57.983: INFO: Exec stderr: ""
Oct  3 20:43:57.983: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:43:57.984: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:43:57.985: INFO: ExecWithOptions: Clientset creation
Oct  3 20:43:57.985: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Oct  3 20:43:58.161: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 10/03/22 20:43:58.161
Oct  3 20:43:58.162: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:43:58.162: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:43:58.164: INFO: ExecWithOptions: Clientset creation
Oct  3 20:43:58.164: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Oct  3 20:43:58.377: INFO: Exec stderr: ""
Oct  3 20:43:58.377: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:43:58.377: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:43:58.378: INFO: ExecWithOptions: Clientset creation
Oct  3 20:43:58.378: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Oct  3 20:43:58.622: INFO: Exec stderr: ""
Oct  3 20:43:58.622: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:43:58.622: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:43:58.624: INFO: ExecWithOptions: Clientset creation
Oct  3 20:43:58.624: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Oct  3 20:43:58.839: INFO: Exec stderr: ""
Oct  3 20:43:58.840: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:43:58.840: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:43:58.841: INFO: ExecWithOptions: Clientset creation
Oct  3 20:43:58.841: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Oct  3 20:43:59.018: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Oct  3 20:43:59.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1296" for this suite. 10/03/22 20:43:59.034
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":274,"skipped":5404,"failed":0}
------------------------------
• [SLOW TEST] [8.327 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:43:50.728
    Oct  3 20:43:50.728: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 10/03/22 20:43:50.729
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:50.762
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:50.773
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 10/03/22 20:43:50.782
    STEP: Creating hostNetwork=false pod 10/03/22 20:43:50.783
    Oct  3 20:43:50.806: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-1296" to be "running and ready"
    Oct  3 20:43:50.819: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.855794ms
    Oct  3 20:43:50.819: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:43:52.833: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026498174s
    Oct  3 20:43:52.833: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:43:54.833: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.026685761s
    Oct  3 20:43:54.833: INFO: The phase of Pod test-pod is Running (Ready = true)
    Oct  3 20:43:54.833: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 10/03/22 20:43:54.843
    Oct  3 20:43:54.859: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-1296" to be "running and ready"
    Oct  3 20:43:54.871: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.178077ms
    Oct  3 20:43:54.871: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:43:56.883: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.024226734s
    Oct  3 20:43:56.883: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Oct  3 20:43:56.883: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 10/03/22 20:43:56.893
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 10/03/22 20:43:56.893
    Oct  3 20:43:56.894: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:43:56.894: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:43:56.895: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:43:56.895: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Oct  3 20:43:57.127: INFO: Exec stderr: ""
    Oct  3 20:43:57.127: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:43:57.127: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:43:57.129: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:43:57.129: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Oct  3 20:43:57.355: INFO: Exec stderr: ""
    Oct  3 20:43:57.355: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:43:57.355: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:43:57.356: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:43:57.357: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Oct  3 20:43:57.590: INFO: Exec stderr: ""
    Oct  3 20:43:57.590: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:43:57.590: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:43:57.591: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:43:57.591: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Oct  3 20:43:57.804: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 10/03/22 20:43:57.804
    Oct  3 20:43:57.804: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:43:57.804: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:43:57.805: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:43:57.805: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Oct  3 20:43:57.983: INFO: Exec stderr: ""
    Oct  3 20:43:57.983: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:43:57.984: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:43:57.985: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:43:57.985: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Oct  3 20:43:58.161: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 10/03/22 20:43:58.161
    Oct  3 20:43:58.162: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:43:58.162: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:43:58.164: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:43:58.164: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Oct  3 20:43:58.377: INFO: Exec stderr: ""
    Oct  3 20:43:58.377: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:43:58.377: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:43:58.378: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:43:58.378: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Oct  3 20:43:58.622: INFO: Exec stderr: ""
    Oct  3 20:43:58.622: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:43:58.622: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:43:58.624: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:43:58.624: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Oct  3 20:43:58.839: INFO: Exec stderr: ""
    Oct  3 20:43:58.840: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1296 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:43:58.840: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:43:58.841: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:43:58.841: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1296/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Oct  3 20:43:59.018: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Oct  3 20:43:59.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-1296" for this suite. 10/03/22 20:43:59.034
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:43:59.056
Oct  3 20:43:59.056: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename namespaces 10/03/22 20:43:59.057
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:59.089
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:59.099
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 10/03/22 20:43:59.109
STEP: patching the Namespace 10/03/22 20:43:59.14
STEP: get the Namespace and ensuring it has the label 10/03/22 20:43:59.154
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Oct  3 20:43:59.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1321" for this suite. 10/03/22 20:43:59.179
STEP: Destroying namespace "nspatchtest-5d41dc88-0cb8-4232-8072-7cbaaea7a2f9-3477" for this suite. 10/03/22 20:43:59.199
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":275,"skipped":5417,"failed":0}
------------------------------
• [0.162 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:43:59.056
    Oct  3 20:43:59.056: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename namespaces 10/03/22 20:43:59.057
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:59.089
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:59.099
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 10/03/22 20:43:59.109
    STEP: patching the Namespace 10/03/22 20:43:59.14
    STEP: get the Namespace and ensuring it has the label 10/03/22 20:43:59.154
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 20:43:59.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-1321" for this suite. 10/03/22 20:43:59.179
    STEP: Destroying namespace "nspatchtest-5d41dc88-0cb8-4232-8072-7cbaaea7a2f9-3477" for this suite. 10/03/22 20:43:59.199
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:43:59.219
Oct  3 20:43:59.219: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 20:43:59.221
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:59.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:59.274
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 10/03/22 20:43:59.286
Oct  3 20:43:59.309: INFO: Waiting up to 5m0s for pod "downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97" in namespace "downward-api-6615" to be "Succeeded or Failed"
Oct  3 20:43:59.320: INFO: Pod "downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97": Phase="Pending", Reason="", readiness=false. Elapsed: 11.209748ms
Oct  3 20:44:01.333: INFO: Pod "downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024353226s
Oct  3 20:44:03.333: INFO: Pod "downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023806913s
Oct  3 20:44:05.333: INFO: Pod "downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023698651s
Oct  3 20:44:07.332: INFO: Pod "downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.022991052s
STEP: Saw pod success 10/03/22 20:44:07.332
Oct  3 20:44:07.332: INFO: Pod "downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97" satisfied condition "Succeeded or Failed"
Oct  3 20:44:07.344: INFO: Trying to get logs from node 10.63.128.13 pod downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97 container dapi-container: <nil>
STEP: delete the pod 10/03/22 20:44:07.441
Oct  3 20:44:07.467: INFO: Waiting for pod downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97 to disappear
Oct  3 20:44:07.479: INFO: Pod downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Oct  3 20:44:07.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6615" for this suite. 10/03/22 20:44:07.494
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":276,"skipped":5423,"failed":0}
------------------------------
• [SLOW TEST] [8.295 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:43:59.219
    Oct  3 20:43:59.219: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 20:43:59.221
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:43:59.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:43:59.274
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 10/03/22 20:43:59.286
    Oct  3 20:43:59.309: INFO: Waiting up to 5m0s for pod "downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97" in namespace "downward-api-6615" to be "Succeeded or Failed"
    Oct  3 20:43:59.320: INFO: Pod "downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97": Phase="Pending", Reason="", readiness=false. Elapsed: 11.209748ms
    Oct  3 20:44:01.333: INFO: Pod "downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024353226s
    Oct  3 20:44:03.333: INFO: Pod "downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023806913s
    Oct  3 20:44:05.333: INFO: Pod "downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023698651s
    Oct  3 20:44:07.332: INFO: Pod "downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.022991052s
    STEP: Saw pod success 10/03/22 20:44:07.332
    Oct  3 20:44:07.332: INFO: Pod "downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97" satisfied condition "Succeeded or Failed"
    Oct  3 20:44:07.344: INFO: Trying to get logs from node 10.63.128.13 pod downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97 container dapi-container: <nil>
    STEP: delete the pod 10/03/22 20:44:07.441
    Oct  3 20:44:07.467: INFO: Waiting for pod downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97 to disappear
    Oct  3 20:44:07.479: INFO: Pod downward-api-db1ea1be-21b0-4105-9168-4ce08b959b97 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Oct  3 20:44:07.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6615" for this suite. 10/03/22 20:44:07.494
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:44:07.52
Oct  3 20:44:07.521: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename var-expansion 10/03/22 20:44:07.521
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:07.555
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:07.564
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Oct  3 20:44:07.597: INFO: Waiting up to 2m0s for pod "var-expansion-225cc380-9741-4d77-8774-b4973ab9ed1d" in namespace "var-expansion-7864" to be "container 0 failed with reason CreateContainerConfigError"
Oct  3 20:44:07.608: INFO: Pod "var-expansion-225cc380-9741-4d77-8774-b4973ab9ed1d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.906327ms
Oct  3 20:44:09.621: INFO: Pod "var-expansion-225cc380-9741-4d77-8774-b4973ab9ed1d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023677111s
Oct  3 20:44:09.621: INFO: Pod "var-expansion-225cc380-9741-4d77-8774-b4973ab9ed1d" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Oct  3 20:44:09.622: INFO: Deleting pod "var-expansion-225cc380-9741-4d77-8774-b4973ab9ed1d" in namespace "var-expansion-7864"
Oct  3 20:44:09.641: INFO: Wait up to 5m0s for pod "var-expansion-225cc380-9741-4d77-8774-b4973ab9ed1d" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Oct  3 20:44:13.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7864" for this suite. 10/03/22 20:44:13.68
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":277,"skipped":5460,"failed":0}
------------------------------
• [SLOW TEST] [6.179 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:44:07.52
    Oct  3 20:44:07.521: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename var-expansion 10/03/22 20:44:07.521
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:07.555
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:07.564
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Oct  3 20:44:07.597: INFO: Waiting up to 2m0s for pod "var-expansion-225cc380-9741-4d77-8774-b4973ab9ed1d" in namespace "var-expansion-7864" to be "container 0 failed with reason CreateContainerConfigError"
    Oct  3 20:44:07.608: INFO: Pod "var-expansion-225cc380-9741-4d77-8774-b4973ab9ed1d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.906327ms
    Oct  3 20:44:09.621: INFO: Pod "var-expansion-225cc380-9741-4d77-8774-b4973ab9ed1d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023677111s
    Oct  3 20:44:09.621: INFO: Pod "var-expansion-225cc380-9741-4d77-8774-b4973ab9ed1d" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Oct  3 20:44:09.622: INFO: Deleting pod "var-expansion-225cc380-9741-4d77-8774-b4973ab9ed1d" in namespace "var-expansion-7864"
    Oct  3 20:44:09.641: INFO: Wait up to 5m0s for pod "var-expansion-225cc380-9741-4d77-8774-b4973ab9ed1d" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Oct  3 20:44:13.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7864" for this suite. 10/03/22 20:44:13.68
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:44:13.702
Oct  3 20:44:13.703: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename configmap 10/03/22 20:44:13.704
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:13.737
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:13.746
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-3e686649-b5af-4e84-956b-6258ff500cac 10/03/22 20:44:13.756
STEP: Creating a pod to test consume configMaps 10/03/22 20:44:13.77
Oct  3 20:44:13.792: INFO: Waiting up to 5m0s for pod "pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538" in namespace "configmap-2744" to be "Succeeded or Failed"
Oct  3 20:44:13.804: INFO: Pod "pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538": Phase="Pending", Reason="", readiness=false. Elapsed: 11.61704ms
Oct  3 20:44:15.816: INFO: Pod "pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538": Phase="Running", Reason="", readiness=true. Elapsed: 2.023544895s
Oct  3 20:44:17.815: INFO: Pod "pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538": Phase="Running", Reason="", readiness=false. Elapsed: 4.022216092s
Oct  3 20:44:19.818: INFO: Pod "pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025249228s
STEP: Saw pod success 10/03/22 20:44:19.818
Oct  3 20:44:19.818: INFO: Pod "pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538" satisfied condition "Succeeded or Failed"
Oct  3 20:44:19.829: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538 container agnhost-container: <nil>
STEP: delete the pod 10/03/22 20:44:19.893
Oct  3 20:44:19.926: INFO: Waiting for pod pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538 to disappear
Oct  3 20:44:19.937: INFO: Pod pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Oct  3 20:44:19.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2744" for this suite. 10/03/22 20:44:19.95
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":278,"skipped":5475,"failed":0}
------------------------------
• [SLOW TEST] [6.275 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:44:13.702
    Oct  3 20:44:13.703: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename configmap 10/03/22 20:44:13.704
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:13.737
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:13.746
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-3e686649-b5af-4e84-956b-6258ff500cac 10/03/22 20:44:13.756
    STEP: Creating a pod to test consume configMaps 10/03/22 20:44:13.77
    Oct  3 20:44:13.792: INFO: Waiting up to 5m0s for pod "pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538" in namespace "configmap-2744" to be "Succeeded or Failed"
    Oct  3 20:44:13.804: INFO: Pod "pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538": Phase="Pending", Reason="", readiness=false. Elapsed: 11.61704ms
    Oct  3 20:44:15.816: INFO: Pod "pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538": Phase="Running", Reason="", readiness=true. Elapsed: 2.023544895s
    Oct  3 20:44:17.815: INFO: Pod "pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538": Phase="Running", Reason="", readiness=false. Elapsed: 4.022216092s
    Oct  3 20:44:19.818: INFO: Pod "pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025249228s
    STEP: Saw pod success 10/03/22 20:44:19.818
    Oct  3 20:44:19.818: INFO: Pod "pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538" satisfied condition "Succeeded or Failed"
    Oct  3 20:44:19.829: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538 container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 20:44:19.893
    Oct  3 20:44:19.926: INFO: Waiting for pod pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538 to disappear
    Oct  3 20:44:19.937: INFO: Pod pod-configmaps-7d5f21f2-aef7-4b5e-8753-9b0e81ecc538 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Oct  3 20:44:19.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2744" for this suite. 10/03/22 20:44:19.95
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:44:19.981
Oct  3 20:44:19.981: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 20:44:19.983
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:20.014
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:20.024
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-2843ca93-6fbc-40a5-aa86-7848a53758a2 10/03/22 20:44:20.034
STEP: Creating a pod to test consume secrets 10/03/22 20:44:20.047
Oct  3 20:44:20.072: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d" in namespace "projected-6346" to be "Succeeded or Failed"
Oct  3 20:44:20.084: INFO: Pod "pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.07817ms
Oct  3 20:44:22.096: INFO: Pod "pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023721585s
Oct  3 20:44:24.097: INFO: Pod "pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024179565s
Oct  3 20:44:26.099: INFO: Pod "pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026661896s
STEP: Saw pod success 10/03/22 20:44:26.099
Oct  3 20:44:26.100: INFO: Pod "pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d" satisfied condition "Succeeded or Failed"
Oct  3 20:44:26.114: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d container projected-secret-volume-test: <nil>
STEP: delete the pod 10/03/22 20:44:26.141
Oct  3 20:44:26.173: INFO: Waiting for pod pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d to disappear
Oct  3 20:44:26.184: INFO: Pod pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Oct  3 20:44:26.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6346" for this suite. 10/03/22 20:44:26.198
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":279,"skipped":5488,"failed":0}
------------------------------
• [SLOW TEST] [6.259 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:44:19.981
    Oct  3 20:44:19.981: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 20:44:19.983
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:20.014
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:20.024
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-2843ca93-6fbc-40a5-aa86-7848a53758a2 10/03/22 20:44:20.034
    STEP: Creating a pod to test consume secrets 10/03/22 20:44:20.047
    Oct  3 20:44:20.072: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d" in namespace "projected-6346" to be "Succeeded or Failed"
    Oct  3 20:44:20.084: INFO: Pod "pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.07817ms
    Oct  3 20:44:22.096: INFO: Pod "pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023721585s
    Oct  3 20:44:24.097: INFO: Pod "pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024179565s
    Oct  3 20:44:26.099: INFO: Pod "pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026661896s
    STEP: Saw pod success 10/03/22 20:44:26.099
    Oct  3 20:44:26.100: INFO: Pod "pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d" satisfied condition "Succeeded or Failed"
    Oct  3 20:44:26.114: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d container projected-secret-volume-test: <nil>
    STEP: delete the pod 10/03/22 20:44:26.141
    Oct  3 20:44:26.173: INFO: Waiting for pod pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d to disappear
    Oct  3 20:44:26.184: INFO: Pod pod-projected-secrets-ad382cbc-3433-456e-8ef4-f74b66bb7f1d no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Oct  3 20:44:26.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6346" for this suite. 10/03/22 20:44:26.198
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:44:26.241
Oct  3 20:44:26.241: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename namespaces 10/03/22 20:44:26.243
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:26.277
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:26.286
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 10/03/22 20:44:26.298
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:26.33
STEP: Creating a pod in the namespace 10/03/22 20:44:26.339
STEP: Waiting for the pod to have running status 10/03/22 20:44:26.361
Oct  3 20:44:26.361: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-1629" to be "running"
Oct  3 20:44:26.372: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.059947ms
Oct  3 20:44:28.384: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023738419s
Oct  3 20:44:30.384: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.023406775s
Oct  3 20:44:30.384: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 10/03/22 20:44:30.384
STEP: Waiting for the namespace to be removed. 10/03/22 20:44:30.405
STEP: Recreating the namespace 10/03/22 20:44:42.418
STEP: Verifying there are no pods in the namespace 10/03/22 20:44:42.45
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Oct  3 20:44:42.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7314" for this suite. 10/03/22 20:44:42.475
STEP: Destroying namespace "nsdeletetest-1629" for this suite. 10/03/22 20:44:42.495
Oct  3 20:44:42.507: INFO: Namespace nsdeletetest-1629 was already deleted
STEP: Destroying namespace "nsdeletetest-9449" for this suite. 10/03/22 20:44:42.507
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":280,"skipped":5489,"failed":0}
------------------------------
• [SLOW TEST] [16.296 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:44:26.241
    Oct  3 20:44:26.241: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename namespaces 10/03/22 20:44:26.243
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:26.277
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:26.286
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 10/03/22 20:44:26.298
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:26.33
    STEP: Creating a pod in the namespace 10/03/22 20:44:26.339
    STEP: Waiting for the pod to have running status 10/03/22 20:44:26.361
    Oct  3 20:44:26.361: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-1629" to be "running"
    Oct  3 20:44:26.372: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.059947ms
    Oct  3 20:44:28.384: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023738419s
    Oct  3 20:44:30.384: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.023406775s
    Oct  3 20:44:30.384: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 10/03/22 20:44:30.384
    STEP: Waiting for the namespace to be removed. 10/03/22 20:44:30.405
    STEP: Recreating the namespace 10/03/22 20:44:42.418
    STEP: Verifying there are no pods in the namespace 10/03/22 20:44:42.45
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 20:44:42.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-7314" for this suite. 10/03/22 20:44:42.475
    STEP: Destroying namespace "nsdeletetest-1629" for this suite. 10/03/22 20:44:42.495
    Oct  3 20:44:42.507: INFO: Namespace nsdeletetest-1629 was already deleted
    STEP: Destroying namespace "nsdeletetest-9449" for this suite. 10/03/22 20:44:42.507
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:44:42.538
Oct  3 20:44:42.538: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename resourcequota 10/03/22 20:44:42.54
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:42.577
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:42.587
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 10/03/22 20:44:42.596
STEP: Getting a ResourceQuota 10/03/22 20:44:42.61
STEP: Listing all ResourceQuotas with LabelSelector 10/03/22 20:44:42.623
STEP: Patching the ResourceQuota 10/03/22 20:44:42.635
STEP: Deleting a Collection of ResourceQuotas 10/03/22 20:44:42.654
STEP: Verifying the deleted ResourceQuota 10/03/22 20:44:42.684
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Oct  3 20:44:42.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3969" for this suite. 10/03/22 20:44:42.708
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":281,"skipped":5501,"failed":0}
------------------------------
• [0.189 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:44:42.538
    Oct  3 20:44:42.538: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename resourcequota 10/03/22 20:44:42.54
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:42.577
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:42.587
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 10/03/22 20:44:42.596
    STEP: Getting a ResourceQuota 10/03/22 20:44:42.61
    STEP: Listing all ResourceQuotas with LabelSelector 10/03/22 20:44:42.623
    STEP: Patching the ResourceQuota 10/03/22 20:44:42.635
    STEP: Deleting a Collection of ResourceQuotas 10/03/22 20:44:42.654
    STEP: Verifying the deleted ResourceQuota 10/03/22 20:44:42.684
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Oct  3 20:44:42.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3969" for this suite. 10/03/22 20:44:42.708
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:44:42.728
Oct  3 20:44:42.728: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 20:44:42.729
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:42.763
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:42.773
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 10/03/22 20:44:42.783
Oct  3 20:44:42.806: INFO: Waiting up to 5m0s for pod "downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb" in namespace "downward-api-6268" to be "Succeeded or Failed"
Oct  3 20:44:42.820: INFO: Pod "downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.426725ms
Oct  3 20:44:44.833: INFO: Pod "downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027056478s
Oct  3 20:44:46.832: INFO: Pod "downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026021634s
STEP: Saw pod success 10/03/22 20:44:46.832
Oct  3 20:44:46.832: INFO: Pod "downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb" satisfied condition "Succeeded or Failed"
Oct  3 20:44:46.843: INFO: Trying to get logs from node 10.63.128.3 pod downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb container dapi-container: <nil>
STEP: delete the pod 10/03/22 20:44:46.868
Oct  3 20:44:46.902: INFO: Waiting for pod downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb to disappear
Oct  3 20:44:46.914: INFO: Pod downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Oct  3 20:44:46.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6268" for this suite. 10/03/22 20:44:46.929
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":282,"skipped":5502,"failed":0}
------------------------------
• [4.220 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:44:42.728
    Oct  3 20:44:42.728: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 20:44:42.729
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:42.763
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:42.773
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 10/03/22 20:44:42.783
    Oct  3 20:44:42.806: INFO: Waiting up to 5m0s for pod "downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb" in namespace "downward-api-6268" to be "Succeeded or Failed"
    Oct  3 20:44:42.820: INFO: Pod "downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.426725ms
    Oct  3 20:44:44.833: INFO: Pod "downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027056478s
    Oct  3 20:44:46.832: INFO: Pod "downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026021634s
    STEP: Saw pod success 10/03/22 20:44:46.832
    Oct  3 20:44:46.832: INFO: Pod "downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb" satisfied condition "Succeeded or Failed"
    Oct  3 20:44:46.843: INFO: Trying to get logs from node 10.63.128.3 pod downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb container dapi-container: <nil>
    STEP: delete the pod 10/03/22 20:44:46.868
    Oct  3 20:44:46.902: INFO: Waiting for pod downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb to disappear
    Oct  3 20:44:46.914: INFO: Pod downward-api-32167b68-4670-48cf-ba55-012d4c4c6fbb no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Oct  3 20:44:46.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6268" for this suite. 10/03/22 20:44:46.929
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:44:46.961
Oct  3 20:44:46.961: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename pods 10/03/22 20:44:46.962
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:47.022
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:47.033
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 10/03/22 20:44:47.042
Oct  3 20:44:47.065: INFO: Waiting up to 5m0s for pod "pod-qhkfr" in namespace "pods-8642" to be "running"
Oct  3 20:44:47.076: INFO: Pod "pod-qhkfr": Phase="Pending", Reason="", readiness=false. Elapsed: 10.881312ms
Oct  3 20:44:49.088: INFO: Pod "pod-qhkfr": Phase="Running", Reason="", readiness=true. Elapsed: 2.022972156s
Oct  3 20:44:49.088: INFO: Pod "pod-qhkfr" satisfied condition "running"
STEP: patching /status 10/03/22 20:44:49.088
Oct  3 20:44:49.105: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Oct  3 20:44:49.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8642" for this suite. 10/03/22 20:44:49.119
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":283,"skipped":5542,"failed":0}
------------------------------
• [2.176 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:44:46.961
    Oct  3 20:44:46.961: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename pods 10/03/22 20:44:46.962
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:47.022
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:47.033
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 10/03/22 20:44:47.042
    Oct  3 20:44:47.065: INFO: Waiting up to 5m0s for pod "pod-qhkfr" in namespace "pods-8642" to be "running"
    Oct  3 20:44:47.076: INFO: Pod "pod-qhkfr": Phase="Pending", Reason="", readiness=false. Elapsed: 10.881312ms
    Oct  3 20:44:49.088: INFO: Pod "pod-qhkfr": Phase="Running", Reason="", readiness=true. Elapsed: 2.022972156s
    Oct  3 20:44:49.088: INFO: Pod "pod-qhkfr" satisfied condition "running"
    STEP: patching /status 10/03/22 20:44:49.088
    Oct  3 20:44:49.105: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Oct  3 20:44:49.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8642" for this suite. 10/03/22 20:44:49.119
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:44:49.137
Oct  3 20:44:49.137: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 20:44:49.139
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:49.171
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:49.18
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 20:44:49.229
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:44:49.886
STEP: Deploying the webhook pod 10/03/22 20:44:49.908
STEP: Wait for the deployment to be ready 10/03/22 20:44:49.936
Oct  3 20:44:49.967: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/03/22 20:44:52.008
STEP: Verifying the service has paired with the endpoint 10/03/22 20:44:52.07
Oct  3 20:44:53.071: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 10/03/22 20:44:53.093
STEP: Creating a custom resource definition that should be denied by the webhook 10/03/22 20:44:53.191
Oct  3 20:44:53.191: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:44:53.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3714" for this suite. 10/03/22 20:44:53.332
STEP: Destroying namespace "webhook-3714-markers" for this suite. 10/03/22 20:44:53.351
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":284,"skipped":5543,"failed":0}
------------------------------
• [4.345 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:44:49.137
    Oct  3 20:44:49.137: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 20:44:49.139
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:49.171
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:49.18
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 20:44:49.229
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:44:49.886
    STEP: Deploying the webhook pod 10/03/22 20:44:49.908
    STEP: Wait for the deployment to be ready 10/03/22 20:44:49.936
    Oct  3 20:44:49.967: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/03/22 20:44:52.008
    STEP: Verifying the service has paired with the endpoint 10/03/22 20:44:52.07
    Oct  3 20:44:53.071: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 10/03/22 20:44:53.093
    STEP: Creating a custom resource definition that should be denied by the webhook 10/03/22 20:44:53.191
    Oct  3 20:44:53.191: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:44:53.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3714" for this suite. 10/03/22 20:44:53.332
    STEP: Destroying namespace "webhook-3714-markers" for this suite. 10/03/22 20:44:53.351
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:44:53.484
Oct  3 20:44:53.484: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 20:44:53.486
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:53.517
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:53.527
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 10/03/22 20:44:53.537
Oct  3 20:44:53.560: INFO: Waiting up to 5m0s for pod "downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a" in namespace "downward-api-1884" to be "Succeeded or Failed"
Oct  3 20:44:53.571: INFO: Pod "downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.88919ms
Oct  3 20:44:55.583: INFO: Pod "downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023658342s
Oct  3 20:44:57.584: INFO: Pod "downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023876491s
Oct  3 20:44:59.583: INFO: Pod "downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023251024s
STEP: Saw pod success 10/03/22 20:44:59.583
Oct  3 20:44:59.583: INFO: Pod "downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a" satisfied condition "Succeeded or Failed"
Oct  3 20:44:59.594: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a container client-container: <nil>
STEP: delete the pod 10/03/22 20:44:59.622
Oct  3 20:44:59.655: INFO: Waiting for pod downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a to disappear
Oct  3 20:44:59.666: INFO: Pod downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Oct  3 20:44:59.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1884" for this suite. 10/03/22 20:44:59.679
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":285,"skipped":5549,"failed":0}
------------------------------
• [SLOW TEST] [6.235 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:44:53.484
    Oct  3 20:44:53.484: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 20:44:53.486
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:53.517
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:53.527
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 10/03/22 20:44:53.537
    Oct  3 20:44:53.560: INFO: Waiting up to 5m0s for pod "downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a" in namespace "downward-api-1884" to be "Succeeded or Failed"
    Oct  3 20:44:53.571: INFO: Pod "downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.88919ms
    Oct  3 20:44:55.583: INFO: Pod "downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023658342s
    Oct  3 20:44:57.584: INFO: Pod "downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023876491s
    Oct  3 20:44:59.583: INFO: Pod "downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023251024s
    STEP: Saw pod success 10/03/22 20:44:59.583
    Oct  3 20:44:59.583: INFO: Pod "downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a" satisfied condition "Succeeded or Failed"
    Oct  3 20:44:59.594: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a container client-container: <nil>
    STEP: delete the pod 10/03/22 20:44:59.622
    Oct  3 20:44:59.655: INFO: Waiting for pod downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a to disappear
    Oct  3 20:44:59.666: INFO: Pod downwardapi-volume-13d37587-f00c-4db5-aafd-feda5cd17c6a no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Oct  3 20:44:59.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1884" for this suite. 10/03/22 20:44:59.679
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:44:59.72
Oct  3 20:44:59.720: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename configmap 10/03/22 20:44:59.722
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:59.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:59.769
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-8dadcaf6-247a-4bf9-92eb-117556145f96 10/03/22 20:44:59.779
STEP: Creating a pod to test consume configMaps 10/03/22 20:44:59.793
Oct  3 20:44:59.815: INFO: Waiting up to 5m0s for pod "pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd" in namespace "configmap-727" to be "Succeeded or Failed"
Oct  3 20:44:59.826: INFO: Pod "pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.593998ms
Oct  3 20:45:01.841: INFO: Pod "pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026032959s
Oct  3 20:45:03.841: INFO: Pod "pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025281611s
Oct  3 20:45:05.839: INFO: Pod "pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023641712s
STEP: Saw pod success 10/03/22 20:45:05.839
Oct  3 20:45:05.839: INFO: Pod "pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd" satisfied condition "Succeeded or Failed"
Oct  3 20:45:05.850: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd container agnhost-container: <nil>
STEP: delete the pod 10/03/22 20:45:05.874
Oct  3 20:45:05.904: INFO: Waiting for pod pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd to disappear
Oct  3 20:45:05.914: INFO: Pod pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Oct  3 20:45:05.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-727" for this suite. 10/03/22 20:45:05.935
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":286,"skipped":5559,"failed":0}
------------------------------
• [SLOW TEST] [6.235 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:44:59.72
    Oct  3 20:44:59.720: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename configmap 10/03/22 20:44:59.722
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:44:59.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:44:59.769
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-8dadcaf6-247a-4bf9-92eb-117556145f96 10/03/22 20:44:59.779
    STEP: Creating a pod to test consume configMaps 10/03/22 20:44:59.793
    Oct  3 20:44:59.815: INFO: Waiting up to 5m0s for pod "pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd" in namespace "configmap-727" to be "Succeeded or Failed"
    Oct  3 20:44:59.826: INFO: Pod "pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.593998ms
    Oct  3 20:45:01.841: INFO: Pod "pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026032959s
    Oct  3 20:45:03.841: INFO: Pod "pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025281611s
    Oct  3 20:45:05.839: INFO: Pod "pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023641712s
    STEP: Saw pod success 10/03/22 20:45:05.839
    Oct  3 20:45:05.839: INFO: Pod "pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd" satisfied condition "Succeeded or Failed"
    Oct  3 20:45:05.850: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 20:45:05.874
    Oct  3 20:45:05.904: INFO: Waiting for pod pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd to disappear
    Oct  3 20:45:05.914: INFO: Pod pod-configmaps-9f391864-80ec-4383-ae4f-d4ef282069cd no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Oct  3 20:45:05.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-727" for this suite. 10/03/22 20:45:05.935
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:45:05.957
Oct  3 20:45:05.957: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 20:45:05.958
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:45:05.995
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:45:06.005
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 10/03/22 20:45:06.015
Oct  3 20:45:06.015: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-6159 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 10/03/22 20:45:06.076
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 20:45:06.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6159" for this suite. 10/03/22 20:45:06.101
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":287,"skipped":5560,"failed":0}
------------------------------
• [0.163 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:45:05.957
    Oct  3 20:45:05.957: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 20:45:05.958
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:45:05.995
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:45:06.005
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 10/03/22 20:45:06.015
    Oct  3 20:45:06.015: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-6159 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 10/03/22 20:45:06.076
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 20:45:06.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6159" for this suite. 10/03/22 20:45:06.101
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:45:06.122
Oct  3 20:45:06.122: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 20:45:06.123
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:45:06.176
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:45:06.186
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Oct  3 20:45:06.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8564 create -f -'
Oct  3 20:45:06.837: INFO: stderr: ""
Oct  3 20:45:06.837: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Oct  3 20:45:06.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8564 create -f -'
Oct  3 20:45:07.172: INFO: stderr: ""
Oct  3 20:45:07.172: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 10/03/22 20:45:07.172
Oct  3 20:45:08.183: INFO: Selector matched 1 pods for map[app:agnhost]
Oct  3 20:45:08.183: INFO: Found 0 / 1
Oct  3 20:45:09.185: INFO: Selector matched 1 pods for map[app:agnhost]
Oct  3 20:45:09.185: INFO: Found 1 / 1
Oct  3 20:45:09.185: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct  3 20:45:09.196: INFO: Selector matched 1 pods for map[app:agnhost]
Oct  3 20:45:09.196: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct  3 20:45:09.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8564 describe pod agnhost-primary-crp4h'
Oct  3 20:45:09.371: INFO: stderr: ""
Oct  3 20:45:09.371: INFO: stdout: "Name:             agnhost-primary-crp4h\nNamespace:        kubectl-8564\nPriority:         0\nService Account:  default\nNode:             10.63.128.3/10.63.128.3\nStart Time:       Mon, 03 Oct 2022 20:45:06 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 900482774cd084f7b8b30f211409b67e39c11a275dd3d79f17fd7a78b221b1ea\n                  cni.projectcalico.org/podIP: 172.30.49.62/32\n                  cni.projectcalico.org/podIPs: 172.30.49.62/32\nStatus:           Running\nIP:               172.30.49.62\nIPs:\n  IP:           172.30.49.62\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://7be6654d048f3eafc3375473930cc3928baccd4413e83200bf627533d2e0fdc6\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 03 Oct 2022 20:45:08 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-6vtpn (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-6vtpn:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 600s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 600s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-8564/agnhost-primary-crp4h to 10.63.128.3\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Oct  3 20:45:09.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8564 describe rc agnhost-primary'
Oct  3 20:45:09.518: INFO: stderr: ""
Oct  3 20:45:09.518: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-8564\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-crp4h\n"
Oct  3 20:45:09.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8564 describe service agnhost-primary'
Oct  3 20:45:09.661: INFO: stderr: ""
Oct  3 20:45:09.661: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-8564\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                172.21.27.111\nIPs:               172.21.27.111\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.30.49.62:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct  3 20:45:09.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8564 describe node 10.63.128.13'
Oct  3 20:45:09.903: INFO: stderr: ""
Oct  3 20:45:09.903: INFO: stdout: "Name:               10.63.128.13\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=au-syd\n                    failure-domain.beta.kubernetes.io/zone=syd04\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=130.198.101.139\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.63.128.13\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=au-syd\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-ccth7mps0r4bub83p85g-kubee2epvgm-default-0000033e\n                    ibm-cloud.kubernetes.io/worker-pool-id=ccth7mps0r4bub83p85g-34c1681\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.25.2_1516\n                    ibm-cloud.kubernetes.io/zone=syd04\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.63.128.13\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    privateVLAN=2723070\n                    publicVLAN=2723068\n                    topology.kubernetes.io/region=au-syd\n                    topology.kubernetes.io/zone=syd04\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.63.128.13/26\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.30.35.192\nCreationTimestamp:  Mon, 03 Oct 2022 17:10:57 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  10.63.128.13\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 03 Oct 2022 20:45:07 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 03 Oct 2022 17:11:29 +0000   Mon, 03 Oct 2022 17:11:29 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Mon, 03 Oct 2022 20:44:31 +0000   Mon, 03 Oct 2022 17:10:57 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 03 Oct 2022 20:44:31 +0000   Mon, 03 Oct 2022 17:10:57 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 03 Oct 2022 20:44:31 +0000   Mon, 03 Oct 2022 17:10:57 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 03 Oct 2022 20:44:31 +0000   Mon, 03 Oct 2022 17:11:18 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.63.128.13\n  ExternalIP:  130.198.101.139\n  Hostname:    10.63.128.13\nCapacity:\n  cpu:                4\n  ephemeral-storage:  102624184Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16212372Ki\n  pods:               110\nAllocatable:\n  cpu:                3910m\n  ephemeral-storage:  93927226085\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             13440404Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 f1d821fae0454b7f82f66f637e034b7e\n  System UUID:                3BA316AD-99B1-43FF-F362-1DF4A90FA171\n  Boot ID:                    273111d3-b120-408c-886c-b7fd3e6658c9\n  Kernel Version:             4.15.0-193-generic\n  OS Image:                   Ubuntu 18.04.6 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.25.2+IKS\n  Kube-Proxy Version:         v1.25.2+IKS\nProviderID:                   ibm://fee034388aa6435883a1f720010ab3a2///ccth7mps0r4bub83p85g/kube-ccth7mps0r4bub83p85g-kubee2epvgm-default-0000033e\nNon-terminated Pods:          (13 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  ibm-system                  ibm-cloud-provider-ip-130-198-66-222-b8894768-5lm6l        5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         3h29m\n  kube-system                 calico-node-zpr9s                                          250m (6%)     0 (0%)      90Mi (0%)        0 (0%)         3h34m\n  kube-system                 calico-typha-644fdcd5f-w67fp                               250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         3h40m\n  kube-system                 coredns-6754846f95-bl2wt                                   100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     3h25m\n  kube-system                 ibm-keepalived-watcher-nw2l6                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         3h34m\n  kube-system                 ibm-master-proxy-static-10.63.128.13                       25m (0%)      300m (7%)   32M (0%)         512M (3%)      3h34m\n  kube-system                 ibmcloud-block-storage-driver-f5thb                        50m (1%)      300m (7%)   100Mi (0%)       300Mi (2%)     3h34m\n  kube-system                 ingress-cluster-healthcheck-6dbd7f8d47-vx87x               10m (0%)      0 (0%)      50Mi (0%)        0 (0%)         120m\n  kube-system                 konnectivity-agent-qv9fn                                   10m (0%)      0 (0%)      10Mi (0%)        500Mi (3%)     3h25m\n  kube-system                 metrics-server-668b4d7ddd-7glct                            126m (3%)     266m (6%)   191Mi (1%)       536Mi (4%)     169m\n  kube-system                 public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-7vk57        10m (0%)      0 (0%)      100Mi (0%)       0 (0%)         52m\n  sonobuoy                    sonobuoy-e2e-job-2c5abccdc00d487c                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         91m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-cwlqc    0 (0%)        0 (0%)      0 (0%)           0 (0%)         91m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                841m (21%)     866m (22%)\n  memory             759314Ki (5%)  2277664Ki (16%)\n  ephemeral-storage  0 (0%)         0 (0%)\n  hugepages-1Gi      0 (0%)         0 (0%)\n  hugepages-2Mi      0 (0%)         0 (0%)\nEvents:              <none>\n"
Oct  3 20:45:09.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8564 describe namespace kubectl-8564'
Oct  3 20:45:10.058: INFO: stderr: ""
Oct  3 20:45:10.058: INFO: stdout: "Name:         kubectl-8564\nLabels:       e2e-framework=kubectl\n              e2e-run=c016e225-6064-4d03-943e-dc46bcf079b7\n              kubernetes.io/metadata.name=kubectl-8564\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 20:45:10.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8564" for this suite. 10/03/22 20:45:10.072
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":288,"skipped":5578,"failed":0}
------------------------------
• [3.970 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:45:06.122
    Oct  3 20:45:06.122: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 20:45:06.123
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:45:06.176
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:45:06.186
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Oct  3 20:45:06.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8564 create -f -'
    Oct  3 20:45:06.837: INFO: stderr: ""
    Oct  3 20:45:06.837: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Oct  3 20:45:06.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8564 create -f -'
    Oct  3 20:45:07.172: INFO: stderr: ""
    Oct  3 20:45:07.172: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 10/03/22 20:45:07.172
    Oct  3 20:45:08.183: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct  3 20:45:08.183: INFO: Found 0 / 1
    Oct  3 20:45:09.185: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct  3 20:45:09.185: INFO: Found 1 / 1
    Oct  3 20:45:09.185: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Oct  3 20:45:09.196: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct  3 20:45:09.196: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Oct  3 20:45:09.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8564 describe pod agnhost-primary-crp4h'
    Oct  3 20:45:09.371: INFO: stderr: ""
    Oct  3 20:45:09.371: INFO: stdout: "Name:             agnhost-primary-crp4h\nNamespace:        kubectl-8564\nPriority:         0\nService Account:  default\nNode:             10.63.128.3/10.63.128.3\nStart Time:       Mon, 03 Oct 2022 20:45:06 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 900482774cd084f7b8b30f211409b67e39c11a275dd3d79f17fd7a78b221b1ea\n                  cni.projectcalico.org/podIP: 172.30.49.62/32\n                  cni.projectcalico.org/podIPs: 172.30.49.62/32\nStatus:           Running\nIP:               172.30.49.62\nIPs:\n  IP:           172.30.49.62\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://7be6654d048f3eafc3375473930cc3928baccd4413e83200bf627533d2e0fdc6\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 03 Oct 2022 20:45:08 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-6vtpn (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-6vtpn:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 600s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 600s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-8564/agnhost-primary-crp4h to 10.63.128.3\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
    Oct  3 20:45:09.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8564 describe rc agnhost-primary'
    Oct  3 20:45:09.518: INFO: stderr: ""
    Oct  3 20:45:09.518: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-8564\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-crp4h\n"
    Oct  3 20:45:09.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8564 describe service agnhost-primary'
    Oct  3 20:45:09.661: INFO: stderr: ""
    Oct  3 20:45:09.661: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-8564\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                172.21.27.111\nIPs:               172.21.27.111\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.30.49.62:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Oct  3 20:45:09.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8564 describe node 10.63.128.13'
    Oct  3 20:45:09.903: INFO: stderr: ""
    Oct  3 20:45:09.903: INFO: stdout: "Name:               10.63.128.13\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=au-syd\n                    failure-domain.beta.kubernetes.io/zone=syd04\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=130.198.101.139\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.63.128.13\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=au-syd\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-ccth7mps0r4bub83p85g-kubee2epvgm-default-0000033e\n                    ibm-cloud.kubernetes.io/worker-pool-id=ccth7mps0r4bub83p85g-34c1681\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.25.2_1516\n                    ibm-cloud.kubernetes.io/zone=syd04\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.63.128.13\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    privateVLAN=2723070\n                    publicVLAN=2723068\n                    topology.kubernetes.io/region=au-syd\n                    topology.kubernetes.io/zone=syd04\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.63.128.13/26\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.30.35.192\nCreationTimestamp:  Mon, 03 Oct 2022 17:10:57 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  10.63.128.13\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 03 Oct 2022 20:45:07 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 03 Oct 2022 17:11:29 +0000   Mon, 03 Oct 2022 17:11:29 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Mon, 03 Oct 2022 20:44:31 +0000   Mon, 03 Oct 2022 17:10:57 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 03 Oct 2022 20:44:31 +0000   Mon, 03 Oct 2022 17:10:57 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 03 Oct 2022 20:44:31 +0000   Mon, 03 Oct 2022 17:10:57 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 03 Oct 2022 20:44:31 +0000   Mon, 03 Oct 2022 17:11:18 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.63.128.13\n  ExternalIP:  130.198.101.139\n  Hostname:    10.63.128.13\nCapacity:\n  cpu:                4\n  ephemeral-storage:  102624184Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16212372Ki\n  pods:               110\nAllocatable:\n  cpu:                3910m\n  ephemeral-storage:  93927226085\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             13440404Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 f1d821fae0454b7f82f66f637e034b7e\n  System UUID:                3BA316AD-99B1-43FF-F362-1DF4A90FA171\n  Boot ID:                    273111d3-b120-408c-886c-b7fd3e6658c9\n  Kernel Version:             4.15.0-193-generic\n  OS Image:                   Ubuntu 18.04.6 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.25.2+IKS\n  Kube-Proxy Version:         v1.25.2+IKS\nProviderID:                   ibm://fee034388aa6435883a1f720010ab3a2///ccth7mps0r4bub83p85g/kube-ccth7mps0r4bub83p85g-kubee2epvgm-default-0000033e\nNon-terminated Pods:          (13 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  ibm-system                  ibm-cloud-provider-ip-130-198-66-222-b8894768-5lm6l        5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         3h29m\n  kube-system                 calico-node-zpr9s                                          250m (6%)     0 (0%)      90Mi (0%)        0 (0%)         3h34m\n  kube-system                 calico-typha-644fdcd5f-w67fp                               250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         3h40m\n  kube-system                 coredns-6754846f95-bl2wt                                   100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     3h25m\n  kube-system                 ibm-keepalived-watcher-nw2l6                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         3h34m\n  kube-system                 ibm-master-proxy-static-10.63.128.13                       25m (0%)      300m (7%)   32M (0%)         512M (3%)      3h34m\n  kube-system                 ibmcloud-block-storage-driver-f5thb                        50m (1%)      300m (7%)   100Mi (0%)       300Mi (2%)     3h34m\n  kube-system                 ingress-cluster-healthcheck-6dbd7f8d47-vx87x               10m (0%)      0 (0%)      50Mi (0%)        0 (0%)         120m\n  kube-system                 konnectivity-agent-qv9fn                                   10m (0%)      0 (0%)      10Mi (0%)        500Mi (3%)     3h25m\n  kube-system                 metrics-server-668b4d7ddd-7glct                            126m (3%)     266m (6%)   191Mi (1%)       536Mi (4%)     169m\n  kube-system                 public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-7vk57        10m (0%)      0 (0%)      100Mi (0%)       0 (0%)         52m\n  sonobuoy                    sonobuoy-e2e-job-2c5abccdc00d487c                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         91m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-cwlqc    0 (0%)        0 (0%)      0 (0%)           0 (0%)         91m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                841m (21%)     866m (22%)\n  memory             759314Ki (5%)  2277664Ki (16%)\n  ephemeral-storage  0 (0%)         0 (0%)\n  hugepages-1Gi      0 (0%)         0 (0%)\n  hugepages-2Mi      0 (0%)         0 (0%)\nEvents:              <none>\n"
    Oct  3 20:45:09.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8564 describe namespace kubectl-8564'
    Oct  3 20:45:10.058: INFO: stderr: ""
    Oct  3 20:45:10.058: INFO: stdout: "Name:         kubectl-8564\nLabels:       e2e-framework=kubectl\n              e2e-run=c016e225-6064-4d03-943e-dc46bcf079b7\n              kubernetes.io/metadata.name=kubectl-8564\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 20:45:10.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8564" for this suite. 10/03/22 20:45:10.072
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:45:10.095
Oct  3 20:45:10.095: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename server-version 10/03/22 20:45:10.097
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:45:10.135
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:45:10.144
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 10/03/22 20:45:10.154
STEP: Confirm major version 10/03/22 20:45:10.159
Oct  3 20:45:10.159: INFO: Major version: 1
STEP: Confirm minor version 10/03/22 20:45:10.159
Oct  3 20:45:10.160: INFO: cleanMinorVersion: 25
Oct  3 20:45:10.160: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Oct  3 20:45:10.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-687" for this suite. 10/03/22 20:45:10.174
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":289,"skipped":5582,"failed":0}
------------------------------
• [0.098 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:45:10.095
    Oct  3 20:45:10.095: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename server-version 10/03/22 20:45:10.097
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:45:10.135
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:45:10.144
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 10/03/22 20:45:10.154
    STEP: Confirm major version 10/03/22 20:45:10.159
    Oct  3 20:45:10.159: INFO: Major version: 1
    STEP: Confirm minor version 10/03/22 20:45:10.159
    Oct  3 20:45:10.160: INFO: cleanMinorVersion: 25
    Oct  3 20:45:10.160: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Oct  3 20:45:10.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-687" for this suite. 10/03/22 20:45:10.174
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:45:10.197
Oct  3 20:45:10.197: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 20:45:10.199
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:45:10.23
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:45:10.24
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-5745 10/03/22 20:45:10.249
STEP: creating service affinity-nodeport in namespace services-5745 10/03/22 20:45:10.249
STEP: creating replication controller affinity-nodeport in namespace services-5745 10/03/22 20:45:10.298
I1003 20:45:10.316595      22 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-5745, replica count: 3
I1003 20:45:13.367923      22 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  3 20:45:13.403: INFO: Creating new exec pod
Oct  3 20:45:13.417: INFO: Waiting up to 5m0s for pod "execpod-affinityfmdxj" in namespace "services-5745" to be "running"
Oct  3 20:45:13.429: INFO: Pod "execpod-affinityfmdxj": Phase="Pending", Reason="", readiness=false. Elapsed: 12.032905ms
Oct  3 20:45:15.440: INFO: Pod "execpod-affinityfmdxj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023552224s
Oct  3 20:45:17.442: INFO: Pod "execpod-affinityfmdxj": Phase="Running", Reason="", readiness=true. Elapsed: 4.02549128s
Oct  3 20:45:17.442: INFO: Pod "execpod-affinityfmdxj" satisfied condition "running"
Oct  3 20:45:18.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5745 exec execpod-affinityfmdxj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Oct  3 20:45:18.777: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Oct  3 20:45:18.777: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:45:18.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5745 exec execpod-affinityfmdxj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.190.93 80'
Oct  3 20:45:19.128: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.190.93 80\nConnection to 172.21.190.93 80 port [tcp/http] succeeded!\n"
Oct  3 20:45:19.128: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:45:19.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5745 exec execpod-affinityfmdxj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.3 30369'
Oct  3 20:45:19.431: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.3 30369\nConnection to 10.63.128.3 30369 port [tcp/*] succeeded!\n"
Oct  3 20:45:19.431: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:45:19.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5745 exec execpod-affinityfmdxj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.51 30369'
Oct  3 20:45:19.717: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.51 30369\nConnection to 10.63.128.51 30369 port [tcp/*] succeeded!\n"
Oct  3 20:45:19.717: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:45:19.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5745 exec execpod-affinityfmdxj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.63.128.13:30369/ ; done'
Oct  3 20:45:20.204: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n"
Oct  3 20:45:20.204: INFO: stdout: "\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h"
Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.205: INFO: Received response from host: affinity-nodeport-nv74h
Oct  3 20:45:20.205: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-5745, will wait for the garbage collector to delete the pods 10/03/22 20:45:20.231
Oct  3 20:45:20.314: INFO: Deleting ReplicationController affinity-nodeport took: 20.524118ms
Oct  3 20:45:20.415: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.38761ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 20:45:23.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5745" for this suite. 10/03/22 20:45:23.093
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":290,"skipped":5596,"failed":0}
------------------------------
• [SLOW TEST] [12.914 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:45:10.197
    Oct  3 20:45:10.197: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 20:45:10.199
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:45:10.23
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:45:10.24
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-5745 10/03/22 20:45:10.249
    STEP: creating service affinity-nodeport in namespace services-5745 10/03/22 20:45:10.249
    STEP: creating replication controller affinity-nodeport in namespace services-5745 10/03/22 20:45:10.298
    I1003 20:45:10.316595      22 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-5745, replica count: 3
    I1003 20:45:13.367923      22 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct  3 20:45:13.403: INFO: Creating new exec pod
    Oct  3 20:45:13.417: INFO: Waiting up to 5m0s for pod "execpod-affinityfmdxj" in namespace "services-5745" to be "running"
    Oct  3 20:45:13.429: INFO: Pod "execpod-affinityfmdxj": Phase="Pending", Reason="", readiness=false. Elapsed: 12.032905ms
    Oct  3 20:45:15.440: INFO: Pod "execpod-affinityfmdxj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023552224s
    Oct  3 20:45:17.442: INFO: Pod "execpod-affinityfmdxj": Phase="Running", Reason="", readiness=true. Elapsed: 4.02549128s
    Oct  3 20:45:17.442: INFO: Pod "execpod-affinityfmdxj" satisfied condition "running"
    Oct  3 20:45:18.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5745 exec execpod-affinityfmdxj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Oct  3 20:45:18.777: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Oct  3 20:45:18.777: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:45:18.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5745 exec execpod-affinityfmdxj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.190.93 80'
    Oct  3 20:45:19.128: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.190.93 80\nConnection to 172.21.190.93 80 port [tcp/http] succeeded!\n"
    Oct  3 20:45:19.128: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:45:19.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5745 exec execpod-affinityfmdxj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.3 30369'
    Oct  3 20:45:19.431: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.3 30369\nConnection to 10.63.128.3 30369 port [tcp/*] succeeded!\n"
    Oct  3 20:45:19.431: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:45:19.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5745 exec execpod-affinityfmdxj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.63.128.51 30369'
    Oct  3 20:45:19.717: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.63.128.51 30369\nConnection to 10.63.128.51 30369 port [tcp/*] succeeded!\n"
    Oct  3 20:45:19.717: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:45:19.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-5745 exec execpod-affinityfmdxj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.63.128.13:30369/ ; done'
    Oct  3 20:45:20.204: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.63.128.13:30369/\n"
    Oct  3 20:45:20.204: INFO: stdout: "\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h\naffinity-nodeport-nv74h"
    Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.204: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.205: INFO: Received response from host: affinity-nodeport-nv74h
    Oct  3 20:45:20.205: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-5745, will wait for the garbage collector to delete the pods 10/03/22 20:45:20.231
    Oct  3 20:45:20.314: INFO: Deleting ReplicationController affinity-nodeport took: 20.524118ms
    Oct  3 20:45:20.415: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.38761ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 20:45:23.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5745" for this suite. 10/03/22 20:45:23.093
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:45:23.114
Oct  3 20:45:23.114: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename deployment 10/03/22 20:45:23.115
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:45:23.148
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:45:23.157
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 10/03/22 20:45:23.195
STEP: waiting for Deployment to be created 10/03/22 20:45:23.208
STEP: waiting for all Replicas to be Ready 10/03/22 20:45:23.213
Oct  3 20:45:23.218: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct  3 20:45:23.218: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct  3 20:45:23.229: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct  3 20:45:23.229: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct  3 20:45:23.259: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct  3 20:45:23.259: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct  3 20:45:23.283: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct  3 20:45:23.283: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct  3 20:45:24.965: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Oct  3 20:45:24.965: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Oct  3 20:45:25.006: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 10/03/22 20:45:25.006
W1003 20:45:25.020818      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Oct  3 20:45:25.026: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 10/03/22 20:45:25.026
Oct  3 20:45:25.031: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
Oct  3 20:45:25.031: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
Oct  3 20:45:25.031: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
Oct  3 20:45:25.031: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
Oct  3 20:45:25.031: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
Oct  3 20:45:25.031: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
Oct  3 20:45:25.042: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
Oct  3 20:45:25.042: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
Oct  3 20:45:25.066: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
Oct  3 20:45:25.066: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
Oct  3 20:45:25.086: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
Oct  3 20:45:25.086: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
Oct  3 20:45:25.101: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
Oct  3 20:45:25.101: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
Oct  3 20:45:27.048: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
Oct  3 20:45:27.048: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
Oct  3 20:45:27.084: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
STEP: listing Deployments 10/03/22 20:45:27.084
Oct  3 20:45:27.108: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 10/03/22 20:45:27.108
Oct  3 20:45:27.146: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 10/03/22 20:45:27.146
Oct  3 20:45:27.166: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Oct  3 20:45:27.166: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Oct  3 20:45:27.212: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Oct  3 20:45:27.238: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Oct  3 20:45:27.264: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Oct  3 20:45:28.985: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Oct  3 20:45:29.086: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Oct  3 20:45:29.192: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Oct  3 20:45:29.221: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Oct  3 20:45:31.005: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 10/03/22 20:45:31.054
STEP: fetching the DeploymentStatus 10/03/22 20:45:31.073
Oct  3 20:45:31.091: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
Oct  3 20:45:31.091: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
Oct  3 20:45:31.091: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
Oct  3 20:45:31.092: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
Oct  3 20:45:31.092: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
Oct  3 20:45:31.092: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
Oct  3 20:45:31.092: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 3
Oct  3 20:45:31.092: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
Oct  3 20:45:31.092: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
Oct  3 20:45:31.092: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 3
STEP: deleting the Deployment 10/03/22 20:45:31.092
Oct  3 20:45:31.123: INFO: observed event type MODIFIED
Oct  3 20:45:31.123: INFO: observed event type MODIFIED
Oct  3 20:45:31.123: INFO: observed event type MODIFIED
Oct  3 20:45:31.123: INFO: observed event type MODIFIED
Oct  3 20:45:31.123: INFO: observed event type MODIFIED
Oct  3 20:45:31.128: INFO: observed event type MODIFIED
Oct  3 20:45:31.128: INFO: observed event type MODIFIED
Oct  3 20:45:31.128: INFO: observed event type MODIFIED
Oct  3 20:45:31.129: INFO: observed event type MODIFIED
Oct  3 20:45:31.130: INFO: observed event type MODIFIED
Oct  3 20:45:31.130: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct  3 20:45:31.141: INFO: Log out all the ReplicaSets if there is no deployment created
Oct  3 20:45:31.182: INFO: ReplicaSet "test-deployment-54cc775c4b":
&ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-5632  68a02e3b-58f6-42a3-8bda-4481293f8753 39991 4 2022-10-03 20:45:25 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment f42909c2-725a-4438-aecb-f6e2cb3a08ea 0xc004caed47 0xc004caed48}] [] [{kube-controller-manager Update apps/v1 2022-10-03 20:45:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f42909c2-725a-4438-aecb-f6e2cb3a08ea\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:45:31 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004caedd0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Oct  3 20:45:31.196: INFO: pod: "test-deployment-54cc775c4b-wqw64":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-wqw64 test-deployment-54cc775c4b- deployment-5632  43840b2e-4395-4e13-a395-dd7b81e1f3d0 39987 0 2022-10-03 20:45:27 +0000 UTC 2022-10-03 20:45:31 +0000 UTC 0xc003e1c838 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:d433aace9ceed972faf7d12444909e42b6611b2d6d77e1592181d3ccac4a72ce cni.projectcalico.org/podIP:172.30.35.206/32 cni.projectcalico.org/podIPs:172.30.35.206/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 68a02e3b-58f6-42a3-8bda-4481293f8753 0xc003e1c9e7 0xc003e1c9e8}] [] [{kube-controller-manager Update v1 2022-10-03 20:45:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"68a02e3b-58f6-42a3-8bda-4481293f8753\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 20:45:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 20:45:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.35.206\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d2ps5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d2ps5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:172.30.35.206,StartTime:2022-10-03 20:45:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 20:45:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://924bfa54685714ee8b6caa70c1bacc4383fd4f93e36b21df8a24a8eb71aa1133,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.35.206,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Oct  3 20:45:31.197: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
&ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-5632  e41fb1db-dfac-4579-9910-0186482f51b9 39983 2 2022-10-03 20:45:27 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment f42909c2-725a-4438-aecb-f6e2cb3a08ea 0xc004caee37 0xc004caee38}] [] [{kube-controller-manager Update apps/v1 2022-10-03 20:45:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f42909c2-725a-4438-aecb-f6e2cb3a08ea\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:45:30 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004caeec0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Oct  3 20:45:31.215: INFO: pod: "test-deployment-7c7d8d58c8-55nkr":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-55nkr test-deployment-7c7d8d58c8- deployment-5632  2c28ea4a-39d3-4b01-8bb2-b4e889fe861e 39997 0 2022-10-03 20:45:27 +0000 UTC 2022-10-03 20:45:32 +0000 UTC 0xc004caf268 map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:fa9159aa0ba38847f046dde3965b6e661192cf8fc9a6262c1031311445da88d3 cni.projectcalico.org/podIP:172.30.49.10/32 cni.projectcalico.org/podIPs:172.30.49.10/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 e41fb1db-dfac-4579-9910-0186482f51b9 0xc004caf2b7 0xc004caf2b8}] [] [{kube-controller-manager Update v1 2022-10-03 20:45:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e41fb1db-dfac-4579-9910-0186482f51b9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 20:45:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 20:45:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.10\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k8jjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k8jjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.10,StartTime:2022-10-03 20:45:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 20:45:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://12c8d5fd3e284d9fc4d24de171e16bd0719c6e4601100fba1a8c0a2f41d80c65,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.10,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Oct  3 20:45:31.215: INFO: pod: "test-deployment-7c7d8d58c8-bvl7h":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-bvl7h test-deployment-7c7d8d58c8- deployment-5632  9a3735bc-8ef7-47b6-a401-aa095f5cdf80 39998 0 2022-10-03 20:45:29 +0000 UTC 2022-10-03 20:45:32 +0000 UTC 0xc004caf4a0 map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:7329a98269ffe864529d8bebd627cf307482774b5e460b8f905fc5cfd3f93838 cni.projectcalico.org/podIP:172.30.35.207/32 cni.projectcalico.org/podIPs:172.30.35.207/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 e41fb1db-dfac-4579-9910-0186482f51b9 0xc004caf4f7 0xc004caf4f8}] [] [{kube-controller-manager Update v1 2022-10-03 20:45:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e41fb1db-dfac-4579-9910-0186482f51b9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 20:45:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 20:45:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.35.207\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-27hd9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-27hd9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:172.30.35.207,StartTime:2022-10-03 20:45:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 20:45:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://9760cc969eee5ba370c3b39fdc4f5c3d0460acb150567d6910747aa723b4d6b2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.35.207,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Oct  3 20:45:31.215: INFO: ReplicaSet "test-deployment-8594bb6fdd":
&ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-5632  f87f0b37-b8ba-4331-8270-25ae2002fd54 39861 3 2022-10-03 20:45:23 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment f42909c2-725a-4438-aecb-f6e2cb3a08ea 0xc004caef27 0xc004caef28}] [] [{kube-controller-manager Update apps/v1 2022-10-03 20:45:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f42909c2-725a-4438-aecb-f6e2cb3a08ea\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:45:27 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004caefb0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Oct  3 20:45:31.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5632" for this suite. 10/03/22 20:45:31.245
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":291,"skipped":5616,"failed":0}
------------------------------
• [SLOW TEST] [8.153 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:45:23.114
    Oct  3 20:45:23.114: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename deployment 10/03/22 20:45:23.115
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:45:23.148
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:45:23.157
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 10/03/22 20:45:23.195
    STEP: waiting for Deployment to be created 10/03/22 20:45:23.208
    STEP: waiting for all Replicas to be Ready 10/03/22 20:45:23.213
    Oct  3 20:45:23.218: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct  3 20:45:23.218: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct  3 20:45:23.229: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct  3 20:45:23.229: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct  3 20:45:23.259: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct  3 20:45:23.259: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct  3 20:45:23.283: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct  3 20:45:23.283: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct  3 20:45:24.965: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Oct  3 20:45:24.965: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Oct  3 20:45:25.006: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 10/03/22 20:45:25.006
    W1003 20:45:25.020818      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Oct  3 20:45:25.026: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 10/03/22 20:45:25.026
    Oct  3 20:45:25.031: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
    Oct  3 20:45:25.031: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
    Oct  3 20:45:25.031: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
    Oct  3 20:45:25.031: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
    Oct  3 20:45:25.031: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
    Oct  3 20:45:25.031: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
    Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
    Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 0
    Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
    Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
    Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
    Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
    Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
    Oct  3 20:45:25.032: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
    Oct  3 20:45:25.042: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
    Oct  3 20:45:25.042: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
    Oct  3 20:45:25.066: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
    Oct  3 20:45:25.066: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
    Oct  3 20:45:25.086: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
    Oct  3 20:45:25.086: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
    Oct  3 20:45:25.101: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
    Oct  3 20:45:25.101: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
    Oct  3 20:45:27.048: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
    Oct  3 20:45:27.048: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
    Oct  3 20:45:27.084: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
    STEP: listing Deployments 10/03/22 20:45:27.084
    Oct  3 20:45:27.108: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 10/03/22 20:45:27.108
    Oct  3 20:45:27.146: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 10/03/22 20:45:27.146
    Oct  3 20:45:27.166: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Oct  3 20:45:27.166: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Oct  3 20:45:27.212: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Oct  3 20:45:27.238: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Oct  3 20:45:27.264: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Oct  3 20:45:28.985: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Oct  3 20:45:29.086: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    Oct  3 20:45:29.192: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Oct  3 20:45:29.221: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Oct  3 20:45:31.005: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 10/03/22 20:45:31.054
    STEP: fetching the DeploymentStatus 10/03/22 20:45:31.073
    Oct  3 20:45:31.091: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
    Oct  3 20:45:31.091: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
    Oct  3 20:45:31.091: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
    Oct  3 20:45:31.092: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
    Oct  3 20:45:31.092: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 1
    Oct  3 20:45:31.092: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
    Oct  3 20:45:31.092: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 3
    Oct  3 20:45:31.092: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
    Oct  3 20:45:31.092: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 2
    Oct  3 20:45:31.092: INFO: observed Deployment test-deployment in namespace deployment-5632 with ReadyReplicas 3
    STEP: deleting the Deployment 10/03/22 20:45:31.092
    Oct  3 20:45:31.123: INFO: observed event type MODIFIED
    Oct  3 20:45:31.123: INFO: observed event type MODIFIED
    Oct  3 20:45:31.123: INFO: observed event type MODIFIED
    Oct  3 20:45:31.123: INFO: observed event type MODIFIED
    Oct  3 20:45:31.123: INFO: observed event type MODIFIED
    Oct  3 20:45:31.128: INFO: observed event type MODIFIED
    Oct  3 20:45:31.128: INFO: observed event type MODIFIED
    Oct  3 20:45:31.128: INFO: observed event type MODIFIED
    Oct  3 20:45:31.129: INFO: observed event type MODIFIED
    Oct  3 20:45:31.130: INFO: observed event type MODIFIED
    Oct  3 20:45:31.130: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct  3 20:45:31.141: INFO: Log out all the ReplicaSets if there is no deployment created
    Oct  3 20:45:31.182: INFO: ReplicaSet "test-deployment-54cc775c4b":
    &ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-5632  68a02e3b-58f6-42a3-8bda-4481293f8753 39991 4 2022-10-03 20:45:25 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment f42909c2-725a-4438-aecb-f6e2cb3a08ea 0xc004caed47 0xc004caed48}] [] [{kube-controller-manager Update apps/v1 2022-10-03 20:45:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f42909c2-725a-4438-aecb-f6e2cb3a08ea\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:45:31 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004caedd0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Oct  3 20:45:31.196: INFO: pod: "test-deployment-54cc775c4b-wqw64":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-wqw64 test-deployment-54cc775c4b- deployment-5632  43840b2e-4395-4e13-a395-dd7b81e1f3d0 39987 0 2022-10-03 20:45:27 +0000 UTC 2022-10-03 20:45:31 +0000 UTC 0xc003e1c838 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:d433aace9ceed972faf7d12444909e42b6611b2d6d77e1592181d3ccac4a72ce cni.projectcalico.org/podIP:172.30.35.206/32 cni.projectcalico.org/podIPs:172.30.35.206/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 68a02e3b-58f6-42a3-8bda-4481293f8753 0xc003e1c9e7 0xc003e1c9e8}] [] [{kube-controller-manager Update v1 2022-10-03 20:45:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"68a02e3b-58f6-42a3-8bda-4481293f8753\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 20:45:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 20:45:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.35.206\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d2ps5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d2ps5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:172.30.35.206,StartTime:2022-10-03 20:45:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 20:45:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://924bfa54685714ee8b6caa70c1bacc4383fd4f93e36b21df8a24a8eb71aa1133,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.35.206,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Oct  3 20:45:31.197: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
    &ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-5632  e41fb1db-dfac-4579-9910-0186482f51b9 39983 2 2022-10-03 20:45:27 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment f42909c2-725a-4438-aecb-f6e2cb3a08ea 0xc004caee37 0xc004caee38}] [] [{kube-controller-manager Update apps/v1 2022-10-03 20:45:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f42909c2-725a-4438-aecb-f6e2cb3a08ea\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:45:30 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004caeec0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

    Oct  3 20:45:31.215: INFO: pod: "test-deployment-7c7d8d58c8-55nkr":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-55nkr test-deployment-7c7d8d58c8- deployment-5632  2c28ea4a-39d3-4b01-8bb2-b4e889fe861e 39997 0 2022-10-03 20:45:27 +0000 UTC 2022-10-03 20:45:32 +0000 UTC 0xc004caf268 map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:fa9159aa0ba38847f046dde3965b6e661192cf8fc9a6262c1031311445da88d3 cni.projectcalico.org/podIP:172.30.49.10/32 cni.projectcalico.org/podIPs:172.30.49.10/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 e41fb1db-dfac-4579-9910-0186482f51b9 0xc004caf2b7 0xc004caf2b8}] [] [{kube-controller-manager Update v1 2022-10-03 20:45:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e41fb1db-dfac-4579-9910-0186482f51b9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 20:45:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 20:45:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.10\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k8jjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k8jjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.10,StartTime:2022-10-03 20:45:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 20:45:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://12c8d5fd3e284d9fc4d24de171e16bd0719c6e4601100fba1a8c0a2f41d80c65,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.10,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Oct  3 20:45:31.215: INFO: pod: "test-deployment-7c7d8d58c8-bvl7h":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-bvl7h test-deployment-7c7d8d58c8- deployment-5632  9a3735bc-8ef7-47b6-a401-aa095f5cdf80 39998 0 2022-10-03 20:45:29 +0000 UTC 2022-10-03 20:45:32 +0000 UTC 0xc004caf4a0 map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:7329a98269ffe864529d8bebd627cf307482774b5e460b8f905fc5cfd3f93838 cni.projectcalico.org/podIP:172.30.35.207/32 cni.projectcalico.org/podIPs:172.30.35.207/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 e41fb1db-dfac-4579-9910-0186482f51b9 0xc004caf4f7 0xc004caf4f8}] [] [{kube-controller-manager Update v1 2022-10-03 20:45:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e41fb1db-dfac-4579-9910-0186482f51b9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 20:45:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 20:45:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.35.207\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-27hd9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-27hd9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:45:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.13,PodIP:172.30.35.207,StartTime:2022-10-03 20:45:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 20:45:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://9760cc969eee5ba370c3b39fdc4f5c3d0460acb150567d6910747aa723b4d6b2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.35.207,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Oct  3 20:45:31.215: INFO: ReplicaSet "test-deployment-8594bb6fdd":
    &ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-5632  f87f0b37-b8ba-4331-8270-25ae2002fd54 39861 3 2022-10-03 20:45:23 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment f42909c2-725a-4438-aecb-f6e2cb3a08ea 0xc004caef27 0xc004caef28}] [] [{kube-controller-manager Update apps/v1 2022-10-03 20:45:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f42909c2-725a-4438-aecb-f6e2cb3a08ea\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:45:27 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004caefb0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Oct  3 20:45:31.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-5632" for this suite. 10/03/22 20:45:31.245
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:45:31.268
Oct  3 20:45:31.268: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename statefulset 10/03/22 20:45:31.269
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:45:31.314
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:45:31.324
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6410 10/03/22 20:45:31.333
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 10/03/22 20:45:31.345
STEP: Creating stateful set ss in namespace statefulset-6410 10/03/22 20:45:31.359
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6410 10/03/22 20:45:31.371
Oct  3 20:45:31.382: INFO: Found 0 stateful pods, waiting for 1
Oct  3 20:45:41.396: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 10/03/22 20:45:41.396
Oct  3 20:45:41.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  3 20:45:41.749: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  3 20:45:41.750: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  3 20:45:41.750: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  3 20:45:41.761: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct  3 20:45:51.785: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  3 20:45:51.785: INFO: Waiting for statefulset status.replicas updated to 0
Oct  3 20:45:51.834: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998236s
Oct  3 20:45:52.847: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.984606172s
Oct  3 20:45:53.860: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.971280113s
Oct  3 20:45:54.872: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.958687915s
Oct  3 20:45:55.884: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.946293615s
Oct  3 20:45:56.897: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.934784121s
Oct  3 20:45:57.909: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.921548319s
Oct  3 20:45:58.921: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.909822302s
Oct  3 20:45:59.933: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.897759881s
Oct  3 20:46:00.944: INFO: Verifying statefulset ss doesn't scale past 1 for another 885.679066ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6410 10/03/22 20:46:01.944
Oct  3 20:46:01.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:46:02.280: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  3 20:46:02.280: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  3 20:46:02.280: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  3 20:46:02.298: INFO: Found 1 stateful pods, waiting for 3
Oct  3 20:46:12.313: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  3 20:46:12.313: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  3 20:46:12.313: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 10/03/22 20:46:12.313
STEP: Scale down will halt with unhealthy stateful pod 10/03/22 20:46:12.313
Oct  3 20:46:12.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  3 20:46:12.627: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  3 20:46:12.627: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  3 20:46:12.627: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  3 20:46:12.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  3 20:46:12.910: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  3 20:46:12.910: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  3 20:46:12.910: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  3 20:46:12.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  3 20:46:13.257: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  3 20:46:13.257: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  3 20:46:13.257: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  3 20:46:13.257: INFO: Waiting for statefulset status.replicas updated to 0
Oct  3 20:46:13.268: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Oct  3 20:46:23.294: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  3 20:46:23.294: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct  3 20:46:23.294: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct  3 20:46:23.329: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998137s
Oct  3 20:46:24.342: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.98834734s
Oct  3 20:46:25.355: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.975643307s
Oct  3 20:46:26.367: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.962558164s
Oct  3 20:46:27.385: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.950476025s
Oct  3 20:46:28.398: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.933076914s
Oct  3 20:46:29.410: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.919701223s
Oct  3 20:46:30.423: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.906531049s
Oct  3 20:46:31.437: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.894421679s
Oct  3 20:46:32.449: INFO: Verifying statefulset ss doesn't scale past 3 for another 880.559608ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6410 10/03/22 20:46:33.45
Oct  3 20:46:33.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:46:33.754: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  3 20:46:33.754: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  3 20:46:33.754: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  3 20:46:33.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:46:34.017: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  3 20:46:34.017: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  3 20:46:34.017: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  3 20:46:34.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:46:34.300: INFO: rc: 1
Oct  3 20:46:34.300: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: failed to exec in container: failed to start exec "011f9e2af79702017ccf297b3173ba1fa122c6650244d662fea30ee07010f9f2": OCI runtime exec failed: exec failed: cannot exec in a stopped container: unknown

error:
exit status 1
Oct  3 20:46:44.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:46:44.417: INFO: rc: 1
Oct  3 20:46:44.417: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:46:54.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:46:54.530: INFO: rc: 1
Oct  3 20:46:54.530: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:47:04.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:47:04.650: INFO: rc: 1
Oct  3 20:47:04.650: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:47:14.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:47:14.755: INFO: rc: 1
Oct  3 20:47:14.755: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:47:24.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:47:24.894: INFO: rc: 1
Oct  3 20:47:24.894: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:47:34.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:47:35.054: INFO: rc: 1
Oct  3 20:47:35.054: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:47:45.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:47:45.174: INFO: rc: 1
Oct  3 20:47:45.174: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:47:55.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:47:55.300: INFO: rc: 1
Oct  3 20:47:55.300: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:48:05.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:48:05.426: INFO: rc: 1
Oct  3 20:48:05.426: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:48:15.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:48:15.538: INFO: rc: 1
Oct  3 20:48:15.538: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:48:25.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:48:25.649: INFO: rc: 1
Oct  3 20:48:25.649: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:48:35.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:48:35.771: INFO: rc: 1
Oct  3 20:48:35.771: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:48:45.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:48:45.881: INFO: rc: 1
Oct  3 20:48:45.881: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:48:55.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:48:56.004: INFO: rc: 1
Oct  3 20:48:56.004: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:49:06.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:49:06.115: INFO: rc: 1
Oct  3 20:49:06.115: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:49:16.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:49:16.229: INFO: rc: 1
Oct  3 20:49:16.229: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:49:26.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:49:26.341: INFO: rc: 1
Oct  3 20:49:26.341: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:49:36.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:49:36.470: INFO: rc: 1
Oct  3 20:49:36.470: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:49:46.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:49:46.585: INFO: rc: 1
Oct  3 20:49:46.585: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:49:56.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:49:56.699: INFO: rc: 1
Oct  3 20:49:56.699: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:50:06.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:50:06.807: INFO: rc: 1
Oct  3 20:50:06.807: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:50:16.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:50:16.920: INFO: rc: 1
Oct  3 20:50:16.920: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:50:26.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:50:27.035: INFO: rc: 1
Oct  3 20:50:27.035: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:50:37.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:50:37.159: INFO: rc: 1
Oct  3 20:50:37.159: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:50:47.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:50:47.272: INFO: rc: 1
Oct  3 20:50:47.272: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:50:57.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:50:57.395: INFO: rc: 1
Oct  3 20:50:57.395: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:51:07.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:51:07.518: INFO: rc: 1
Oct  3 20:51:07.518: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:51:17.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:51:17.640: INFO: rc: 1
Oct  3 20:51:17.640: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:51:27.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:51:27.758: INFO: rc: 1
Oct  3 20:51:27.758: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Oct  3 20:51:37.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:51:37.864: INFO: rc: 1
Oct  3 20:51:37.864: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Oct  3 20:51:37.864: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 10/03/22 20:51:37.901
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct  3 20:51:37.901: INFO: Deleting all statefulset in ns statefulset-6410
Oct  3 20:51:37.912: INFO: Scaling statefulset ss to 0
Oct  3 20:51:37.946: INFO: Waiting for statefulset status.replicas updated to 0
Oct  3 20:51:37.956: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Oct  3 20:51:37.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6410" for this suite. 10/03/22 20:51:38.014
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":292,"skipped":5620,"failed":0}
------------------------------
• [SLOW TEST] [366.778 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:45:31.268
    Oct  3 20:45:31.268: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename statefulset 10/03/22 20:45:31.269
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:45:31.314
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:45:31.324
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6410 10/03/22 20:45:31.333
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 10/03/22 20:45:31.345
    STEP: Creating stateful set ss in namespace statefulset-6410 10/03/22 20:45:31.359
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6410 10/03/22 20:45:31.371
    Oct  3 20:45:31.382: INFO: Found 0 stateful pods, waiting for 1
    Oct  3 20:45:41.396: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 10/03/22 20:45:41.396
    Oct  3 20:45:41.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct  3 20:45:41.749: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct  3 20:45:41.750: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct  3 20:45:41.750: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct  3 20:45:41.761: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Oct  3 20:45:51.785: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Oct  3 20:45:51.785: INFO: Waiting for statefulset status.replicas updated to 0
    Oct  3 20:45:51.834: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998236s
    Oct  3 20:45:52.847: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.984606172s
    Oct  3 20:45:53.860: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.971280113s
    Oct  3 20:45:54.872: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.958687915s
    Oct  3 20:45:55.884: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.946293615s
    Oct  3 20:45:56.897: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.934784121s
    Oct  3 20:45:57.909: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.921548319s
    Oct  3 20:45:58.921: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.909822302s
    Oct  3 20:45:59.933: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.897759881s
    Oct  3 20:46:00.944: INFO: Verifying statefulset ss doesn't scale past 1 for another 885.679066ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6410 10/03/22 20:46:01.944
    Oct  3 20:46:01.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:46:02.280: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Oct  3 20:46:02.280: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct  3 20:46:02.280: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Oct  3 20:46:02.298: INFO: Found 1 stateful pods, waiting for 3
    Oct  3 20:46:12.313: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Oct  3 20:46:12.313: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Oct  3 20:46:12.313: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 10/03/22 20:46:12.313
    STEP: Scale down will halt with unhealthy stateful pod 10/03/22 20:46:12.313
    Oct  3 20:46:12.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct  3 20:46:12.627: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct  3 20:46:12.627: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct  3 20:46:12.627: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct  3 20:46:12.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct  3 20:46:12.910: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct  3 20:46:12.910: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct  3 20:46:12.910: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct  3 20:46:12.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct  3 20:46:13.257: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct  3 20:46:13.257: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct  3 20:46:13.257: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct  3 20:46:13.257: INFO: Waiting for statefulset status.replicas updated to 0
    Oct  3 20:46:13.268: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
    Oct  3 20:46:23.294: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Oct  3 20:46:23.294: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Oct  3 20:46:23.294: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Oct  3 20:46:23.329: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998137s
    Oct  3 20:46:24.342: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.98834734s
    Oct  3 20:46:25.355: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.975643307s
    Oct  3 20:46:26.367: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.962558164s
    Oct  3 20:46:27.385: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.950476025s
    Oct  3 20:46:28.398: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.933076914s
    Oct  3 20:46:29.410: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.919701223s
    Oct  3 20:46:30.423: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.906531049s
    Oct  3 20:46:31.437: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.894421679s
    Oct  3 20:46:32.449: INFO: Verifying statefulset ss doesn't scale past 3 for another 880.559608ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6410 10/03/22 20:46:33.45
    Oct  3 20:46:33.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:46:33.754: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Oct  3 20:46:33.754: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct  3 20:46:33.754: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Oct  3 20:46:33.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:46:34.017: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Oct  3 20:46:34.017: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct  3 20:46:34.017: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Oct  3 20:46:34.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:46:34.300: INFO: rc: 1
    Oct  3 20:46:34.300: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    error: Internal error occurred: error executing command in container: failed to exec in container: failed to start exec "011f9e2af79702017ccf297b3173ba1fa122c6650244d662fea30ee07010f9f2": OCI runtime exec failed: exec failed: cannot exec in a stopped container: unknown

    error:
    exit status 1
    Oct  3 20:46:44.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:46:44.417: INFO: rc: 1
    Oct  3 20:46:44.417: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:46:54.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:46:54.530: INFO: rc: 1
    Oct  3 20:46:54.530: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:47:04.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:47:04.650: INFO: rc: 1
    Oct  3 20:47:04.650: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:47:14.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:47:14.755: INFO: rc: 1
    Oct  3 20:47:14.755: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:47:24.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:47:24.894: INFO: rc: 1
    Oct  3 20:47:24.894: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:47:34.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:47:35.054: INFO: rc: 1
    Oct  3 20:47:35.054: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:47:45.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:47:45.174: INFO: rc: 1
    Oct  3 20:47:45.174: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:47:55.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:47:55.300: INFO: rc: 1
    Oct  3 20:47:55.300: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:48:05.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:48:05.426: INFO: rc: 1
    Oct  3 20:48:05.426: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:48:15.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:48:15.538: INFO: rc: 1
    Oct  3 20:48:15.538: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:48:25.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:48:25.649: INFO: rc: 1
    Oct  3 20:48:25.649: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:48:35.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:48:35.771: INFO: rc: 1
    Oct  3 20:48:35.771: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:48:45.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:48:45.881: INFO: rc: 1
    Oct  3 20:48:45.881: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:48:55.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:48:56.004: INFO: rc: 1
    Oct  3 20:48:56.004: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:49:06.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:49:06.115: INFO: rc: 1
    Oct  3 20:49:06.115: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:49:16.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:49:16.229: INFO: rc: 1
    Oct  3 20:49:16.229: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:49:26.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:49:26.341: INFO: rc: 1
    Oct  3 20:49:26.341: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:49:36.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:49:36.470: INFO: rc: 1
    Oct  3 20:49:36.470: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:49:46.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:49:46.585: INFO: rc: 1
    Oct  3 20:49:46.585: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:49:56.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:49:56.699: INFO: rc: 1
    Oct  3 20:49:56.699: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:50:06.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:50:06.807: INFO: rc: 1
    Oct  3 20:50:06.807: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:50:16.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:50:16.920: INFO: rc: 1
    Oct  3 20:50:16.920: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:50:26.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:50:27.035: INFO: rc: 1
    Oct  3 20:50:27.035: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:50:37.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:50:37.159: INFO: rc: 1
    Oct  3 20:50:37.159: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:50:47.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:50:47.272: INFO: rc: 1
    Oct  3 20:50:47.272: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:50:57.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:50:57.395: INFO: rc: 1
    Oct  3 20:50:57.395: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:51:07.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:51:07.518: INFO: rc: 1
    Oct  3 20:51:07.518: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:51:17.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:51:17.640: INFO: rc: 1
    Oct  3 20:51:17.640: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:51:27.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:51:27.758: INFO: rc: 1
    Oct  3 20:51:27.758: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    Oct  3 20:51:37.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-6410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:51:37.864: INFO: rc: 1
    Oct  3 20:51:37.864: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
    Oct  3 20:51:37.864: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 10/03/22 20:51:37.901
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Oct  3 20:51:37.901: INFO: Deleting all statefulset in ns statefulset-6410
    Oct  3 20:51:37.912: INFO: Scaling statefulset ss to 0
    Oct  3 20:51:37.946: INFO: Waiting for statefulset status.replicas updated to 0
    Oct  3 20:51:37.956: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Oct  3 20:51:37.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6410" for this suite. 10/03/22 20:51:38.014
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:51:38.049
Oct  3 20:51:38.049: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename secrets 10/03/22 20:51:38.05
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:51:38.085
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:51:38.094
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Oct  3 20:51:38.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8379" for this suite. 10/03/22 20:51:38.239
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":293,"skipped":5647,"failed":0}
------------------------------
• [0.210 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:51:38.049
    Oct  3 20:51:38.049: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename secrets 10/03/22 20:51:38.05
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:51:38.085
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:51:38.094
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Oct  3 20:51:38.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8379" for this suite. 10/03/22 20:51:38.239
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:51:38.26
Oct  3 20:51:38.260: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 20:51:38.261
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:51:38.295
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:51:38.305
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 10/03/22 20:51:38.314
Oct  3 20:51:38.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Oct  3 20:51:38.461: INFO: stderr: ""
Oct  3 20:51:38.461: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 10/03/22 20:51:38.461
Oct  3 20:51:38.461: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Oct  3 20:51:38.461: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1048" to be "running and ready, or succeeded"
Oct  3 20:51:38.473: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 12.182435ms
Oct  3 20:51:38.473: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '10.63.128.3' to be 'Running' but was 'Pending'
Oct  3 20:51:40.486: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025344547s
Oct  3 20:51:40.486: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '10.63.128.3' to be 'Running' but was 'Pending'
Oct  3 20:51:42.487: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.025768025s
Oct  3 20:51:42.487: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Oct  3 20:51:42.487: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 10/03/22 20:51:42.487
Oct  3 20:51:42.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 logs logs-generator logs-generator'
Oct  3 20:51:42.653: INFO: stderr: ""
Oct  3 20:51:42.654: INFO: stdout: "I1003 20:51:40.109293       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/tw9 398\nI1003 20:51:40.309648       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/2vx7 477\nI1003 20:51:40.510391       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/nv9 475\nI1003 20:51:40.709911       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/hg7 546\nI1003 20:51:40.910398       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/lg4 405\nI1003 20:51:41.110012       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/mlr7 391\nI1003 20:51:41.309492       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/r5x 416\nI1003 20:51:41.509918       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/9dnj 522\nI1003 20:51:41.709461       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/fxk 592\nI1003 20:51:41.910124       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/67sk 306\nI1003 20:51:42.109703       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/m2vb 415\nI1003 20:51:42.310183       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/bgvf 448\nI1003 20:51:42.509579       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/4m5 402\n"
STEP: limiting log lines 10/03/22 20:51:42.654
Oct  3 20:51:42.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 logs logs-generator logs-generator --tail=1'
Oct  3 20:51:42.851: INFO: stderr: ""
Oct  3 20:51:42.852: INFO: stdout: "I1003 20:51:42.710275       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/lsg 445\n"
Oct  3 20:51:42.852: INFO: got output "I1003 20:51:42.710275       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/lsg 445\n"
STEP: limiting log bytes 10/03/22 20:51:42.852
Oct  3 20:51:42.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 logs logs-generator logs-generator --limit-bytes=1'
Oct  3 20:51:42.996: INFO: stderr: ""
Oct  3 20:51:42.996: INFO: stdout: "I"
Oct  3 20:51:42.996: INFO: got output "I"
STEP: exposing timestamps 10/03/22 20:51:42.996
Oct  3 20:51:42.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 logs logs-generator logs-generator --tail=1 --timestamps'
Oct  3 20:51:43.111: INFO: stderr: ""
Oct  3 20:51:43.111: INFO: stdout: "2022-10-03T20:51:42.910126374Z I1003 20:51:42.909785       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/lqm 536\n"
Oct  3 20:51:43.111: INFO: got output "2022-10-03T20:51:42.910126374Z I1003 20:51:42.909785       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/lqm 536\n"
STEP: restricting to a time range 10/03/22 20:51:43.111
Oct  3 20:51:45.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 logs logs-generator logs-generator --since=1s'
Oct  3 20:51:45.755: INFO: stderr: ""
Oct  3 20:51:45.755: INFO: stdout: "I1003 20:51:44.910154       1 logs_generator.go:76] 24 GET /api/v1/namespaces/kube-system/pods/2zr 256\nI1003 20:51:45.109627       1 logs_generator.go:76] 25 GET /api/v1/namespaces/ns/pods/ljln 534\nI1003 20:51:45.310065       1 logs_generator.go:76] 26 GET /api/v1/namespaces/default/pods/jqrp 394\nI1003 20:51:45.509561       1 logs_generator.go:76] 27 GET /api/v1/namespaces/kube-system/pods/trwk 391\nI1003 20:51:45.710174       1 logs_generator.go:76] 28 POST /api/v1/namespaces/kube-system/pods/4hv 453\n"
Oct  3 20:51:45.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 logs logs-generator logs-generator --since=24h'
Oct  3 20:51:45.885: INFO: stderr: ""
Oct  3 20:51:45.885: INFO: stdout: "I1003 20:51:40.109293       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/tw9 398\nI1003 20:51:40.309648       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/2vx7 477\nI1003 20:51:40.510391       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/nv9 475\nI1003 20:51:40.709911       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/hg7 546\nI1003 20:51:40.910398       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/lg4 405\nI1003 20:51:41.110012       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/mlr7 391\nI1003 20:51:41.309492       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/r5x 416\nI1003 20:51:41.509918       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/9dnj 522\nI1003 20:51:41.709461       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/fxk 592\nI1003 20:51:41.910124       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/67sk 306\nI1003 20:51:42.109703       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/m2vb 415\nI1003 20:51:42.310183       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/bgvf 448\nI1003 20:51:42.509579       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/4m5 402\nI1003 20:51:42.710275       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/lsg 445\nI1003 20:51:42.909785       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/lqm 536\nI1003 20:51:43.110363       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/ns/pods/kvw8 563\nI1003 20:51:43.309796       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/f2s 392\nI1003 20:51:43.510567       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/96z 404\nI1003 20:51:43.710121       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/dnwt 517\nI1003 20:51:43.909542       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/vvm 286\nI1003 20:51:44.110142       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/96r 598\nI1003 20:51:44.309577       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/clzw 394\nI1003 20:51:44.510146       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/7nk 550\nI1003 20:51:44.710684       1 logs_generator.go:76] 23 GET /api/v1/namespaces/kube-system/pods/q79 451\nI1003 20:51:44.910154       1 logs_generator.go:76] 24 GET /api/v1/namespaces/kube-system/pods/2zr 256\nI1003 20:51:45.109627       1 logs_generator.go:76] 25 GET /api/v1/namespaces/ns/pods/ljln 534\nI1003 20:51:45.310065       1 logs_generator.go:76] 26 GET /api/v1/namespaces/default/pods/jqrp 394\nI1003 20:51:45.509561       1 logs_generator.go:76] 27 GET /api/v1/namespaces/kube-system/pods/trwk 391\nI1003 20:51:45.710174       1 logs_generator.go:76] 28 POST /api/v1/namespaces/kube-system/pods/4hv 453\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Oct  3 20:51:45.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 delete pod logs-generator'
Oct  3 20:51:47.682: INFO: stderr: ""
Oct  3 20:51:47.682: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 20:51:47.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1048" for this suite. 10/03/22 20:51:47.697
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":294,"skipped":5649,"failed":0}
------------------------------
• [SLOW TEST] [9.459 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:51:38.26
    Oct  3 20:51:38.260: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 20:51:38.261
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:51:38.295
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:51:38.305
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 10/03/22 20:51:38.314
    Oct  3 20:51:38.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Oct  3 20:51:38.461: INFO: stderr: ""
    Oct  3 20:51:38.461: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 10/03/22 20:51:38.461
    Oct  3 20:51:38.461: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Oct  3 20:51:38.461: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1048" to be "running and ready, or succeeded"
    Oct  3 20:51:38.473: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 12.182435ms
    Oct  3 20:51:38.473: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '10.63.128.3' to be 'Running' but was 'Pending'
    Oct  3 20:51:40.486: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025344547s
    Oct  3 20:51:40.486: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '10.63.128.3' to be 'Running' but was 'Pending'
    Oct  3 20:51:42.487: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.025768025s
    Oct  3 20:51:42.487: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Oct  3 20:51:42.487: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 10/03/22 20:51:42.487
    Oct  3 20:51:42.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 logs logs-generator logs-generator'
    Oct  3 20:51:42.653: INFO: stderr: ""
    Oct  3 20:51:42.654: INFO: stdout: "I1003 20:51:40.109293       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/tw9 398\nI1003 20:51:40.309648       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/2vx7 477\nI1003 20:51:40.510391       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/nv9 475\nI1003 20:51:40.709911       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/hg7 546\nI1003 20:51:40.910398       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/lg4 405\nI1003 20:51:41.110012       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/mlr7 391\nI1003 20:51:41.309492       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/r5x 416\nI1003 20:51:41.509918       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/9dnj 522\nI1003 20:51:41.709461       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/fxk 592\nI1003 20:51:41.910124       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/67sk 306\nI1003 20:51:42.109703       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/m2vb 415\nI1003 20:51:42.310183       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/bgvf 448\nI1003 20:51:42.509579       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/4m5 402\n"
    STEP: limiting log lines 10/03/22 20:51:42.654
    Oct  3 20:51:42.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 logs logs-generator logs-generator --tail=1'
    Oct  3 20:51:42.851: INFO: stderr: ""
    Oct  3 20:51:42.852: INFO: stdout: "I1003 20:51:42.710275       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/lsg 445\n"
    Oct  3 20:51:42.852: INFO: got output "I1003 20:51:42.710275       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/lsg 445\n"
    STEP: limiting log bytes 10/03/22 20:51:42.852
    Oct  3 20:51:42.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 logs logs-generator logs-generator --limit-bytes=1'
    Oct  3 20:51:42.996: INFO: stderr: ""
    Oct  3 20:51:42.996: INFO: stdout: "I"
    Oct  3 20:51:42.996: INFO: got output "I"
    STEP: exposing timestamps 10/03/22 20:51:42.996
    Oct  3 20:51:42.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 logs logs-generator logs-generator --tail=1 --timestamps'
    Oct  3 20:51:43.111: INFO: stderr: ""
    Oct  3 20:51:43.111: INFO: stdout: "2022-10-03T20:51:42.910126374Z I1003 20:51:42.909785       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/lqm 536\n"
    Oct  3 20:51:43.111: INFO: got output "2022-10-03T20:51:42.910126374Z I1003 20:51:42.909785       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/lqm 536\n"
    STEP: restricting to a time range 10/03/22 20:51:43.111
    Oct  3 20:51:45.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 logs logs-generator logs-generator --since=1s'
    Oct  3 20:51:45.755: INFO: stderr: ""
    Oct  3 20:51:45.755: INFO: stdout: "I1003 20:51:44.910154       1 logs_generator.go:76] 24 GET /api/v1/namespaces/kube-system/pods/2zr 256\nI1003 20:51:45.109627       1 logs_generator.go:76] 25 GET /api/v1/namespaces/ns/pods/ljln 534\nI1003 20:51:45.310065       1 logs_generator.go:76] 26 GET /api/v1/namespaces/default/pods/jqrp 394\nI1003 20:51:45.509561       1 logs_generator.go:76] 27 GET /api/v1/namespaces/kube-system/pods/trwk 391\nI1003 20:51:45.710174       1 logs_generator.go:76] 28 POST /api/v1/namespaces/kube-system/pods/4hv 453\n"
    Oct  3 20:51:45.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 logs logs-generator logs-generator --since=24h'
    Oct  3 20:51:45.885: INFO: stderr: ""
    Oct  3 20:51:45.885: INFO: stdout: "I1003 20:51:40.109293       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/tw9 398\nI1003 20:51:40.309648       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/2vx7 477\nI1003 20:51:40.510391       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/nv9 475\nI1003 20:51:40.709911       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/hg7 546\nI1003 20:51:40.910398       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/lg4 405\nI1003 20:51:41.110012       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/mlr7 391\nI1003 20:51:41.309492       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/r5x 416\nI1003 20:51:41.509918       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/9dnj 522\nI1003 20:51:41.709461       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/fxk 592\nI1003 20:51:41.910124       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/67sk 306\nI1003 20:51:42.109703       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/m2vb 415\nI1003 20:51:42.310183       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/bgvf 448\nI1003 20:51:42.509579       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/4m5 402\nI1003 20:51:42.710275       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/lsg 445\nI1003 20:51:42.909785       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/lqm 536\nI1003 20:51:43.110363       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/ns/pods/kvw8 563\nI1003 20:51:43.309796       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/f2s 392\nI1003 20:51:43.510567       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/96z 404\nI1003 20:51:43.710121       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/dnwt 517\nI1003 20:51:43.909542       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/vvm 286\nI1003 20:51:44.110142       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/96r 598\nI1003 20:51:44.309577       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/clzw 394\nI1003 20:51:44.510146       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/7nk 550\nI1003 20:51:44.710684       1 logs_generator.go:76] 23 GET /api/v1/namespaces/kube-system/pods/q79 451\nI1003 20:51:44.910154       1 logs_generator.go:76] 24 GET /api/v1/namespaces/kube-system/pods/2zr 256\nI1003 20:51:45.109627       1 logs_generator.go:76] 25 GET /api/v1/namespaces/ns/pods/ljln 534\nI1003 20:51:45.310065       1 logs_generator.go:76] 26 GET /api/v1/namespaces/default/pods/jqrp 394\nI1003 20:51:45.509561       1 logs_generator.go:76] 27 GET /api/v1/namespaces/kube-system/pods/trwk 391\nI1003 20:51:45.710174       1 logs_generator.go:76] 28 POST /api/v1/namespaces/kube-system/pods/4hv 453\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Oct  3 20:51:45.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-1048 delete pod logs-generator'
    Oct  3 20:51:47.682: INFO: stderr: ""
    Oct  3 20:51:47.682: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 20:51:47.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1048" for this suite. 10/03/22 20:51:47.697
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:51:47.72
Oct  3 20:51:47.721: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir 10/03/22 20:51:47.722
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:51:47.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:51:47.765
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 10/03/22 20:51:47.775
Oct  3 20:51:47.798: INFO: Waiting up to 5m0s for pod "pod-16cb4291-1410-4ff0-a699-28fa8611577f" in namespace "emptydir-3561" to be "Succeeded or Failed"
Oct  3 20:51:47.809: INFO: Pod "pod-16cb4291-1410-4ff0-a699-28fa8611577f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.387202ms
Oct  3 20:51:49.822: INFO: Pod "pod-16cb4291-1410-4ff0-a699-28fa8611577f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024248838s
Oct  3 20:51:51.820: INFO: Pod "pod-16cb4291-1410-4ff0-a699-28fa8611577f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022588705s
STEP: Saw pod success 10/03/22 20:51:51.82
Oct  3 20:51:51.820: INFO: Pod "pod-16cb4291-1410-4ff0-a699-28fa8611577f" satisfied condition "Succeeded or Failed"
Oct  3 20:51:51.829: INFO: Trying to get logs from node 10.63.128.3 pod pod-16cb4291-1410-4ff0-a699-28fa8611577f container test-container: <nil>
STEP: delete the pod 10/03/22 20:51:51.854
Oct  3 20:51:51.887: INFO: Waiting for pod pod-16cb4291-1410-4ff0-a699-28fa8611577f to disappear
Oct  3 20:51:51.898: INFO: Pod pod-16cb4291-1410-4ff0-a699-28fa8611577f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Oct  3 20:51:51.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3561" for this suite. 10/03/22 20:51:51.912
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":295,"skipped":5652,"failed":0}
------------------------------
• [4.211 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:51:47.72
    Oct  3 20:51:47.721: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir 10/03/22 20:51:47.722
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:51:47.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:51:47.765
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 10/03/22 20:51:47.775
    Oct  3 20:51:47.798: INFO: Waiting up to 5m0s for pod "pod-16cb4291-1410-4ff0-a699-28fa8611577f" in namespace "emptydir-3561" to be "Succeeded or Failed"
    Oct  3 20:51:47.809: INFO: Pod "pod-16cb4291-1410-4ff0-a699-28fa8611577f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.387202ms
    Oct  3 20:51:49.822: INFO: Pod "pod-16cb4291-1410-4ff0-a699-28fa8611577f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024248838s
    Oct  3 20:51:51.820: INFO: Pod "pod-16cb4291-1410-4ff0-a699-28fa8611577f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022588705s
    STEP: Saw pod success 10/03/22 20:51:51.82
    Oct  3 20:51:51.820: INFO: Pod "pod-16cb4291-1410-4ff0-a699-28fa8611577f" satisfied condition "Succeeded or Failed"
    Oct  3 20:51:51.829: INFO: Trying to get logs from node 10.63.128.3 pod pod-16cb4291-1410-4ff0-a699-28fa8611577f container test-container: <nil>
    STEP: delete the pod 10/03/22 20:51:51.854
    Oct  3 20:51:51.887: INFO: Waiting for pod pod-16cb4291-1410-4ff0-a699-28fa8611577f to disappear
    Oct  3 20:51:51.898: INFO: Pod pod-16cb4291-1410-4ff0-a699-28fa8611577f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Oct  3 20:51:51.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3561" for this suite. 10/03/22 20:51:51.912
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:51:51.934
Oct  3 20:51:51.934: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename job 10/03/22 20:51:51.936
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:51:51.973
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:51:51.983
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 10/03/22 20:51:51.992
STEP: Ensuring active pods == parallelism 10/03/22 20:51:52.013
STEP: Orphaning one of the Job's Pods 10/03/22 20:51:56.025
Oct  3 20:51:56.566: INFO: Successfully updated pod "adopt-release-cldzz"
STEP: Checking that the Job readopts the Pod 10/03/22 20:51:56.566
Oct  3 20:51:56.566: INFO: Waiting up to 15m0s for pod "adopt-release-cldzz" in namespace "job-9828" to be "adopted"
Oct  3 20:51:56.586: INFO: Pod "adopt-release-cldzz": Phase="Running", Reason="", readiness=true. Elapsed: 20.191935ms
Oct  3 20:51:58.598: INFO: Pod "adopt-release-cldzz": Phase="Running", Reason="", readiness=true. Elapsed: 2.032322555s
Oct  3 20:51:58.598: INFO: Pod "adopt-release-cldzz" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 10/03/22 20:51:58.598
Oct  3 20:51:59.127: INFO: Successfully updated pod "adopt-release-cldzz"
STEP: Checking that the Job releases the Pod 10/03/22 20:51:59.127
Oct  3 20:51:59.127: INFO: Waiting up to 15m0s for pod "adopt-release-cldzz" in namespace "job-9828" to be "released"
Oct  3 20:51:59.139: INFO: Pod "adopt-release-cldzz": Phase="Running", Reason="", readiness=true. Elapsed: 12.07669ms
Oct  3 20:52:01.152: INFO: Pod "adopt-release-cldzz": Phase="Running", Reason="", readiness=true. Elapsed: 2.025049823s
Oct  3 20:52:01.152: INFO: Pod "adopt-release-cldzz" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Oct  3 20:52:01.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9828" for this suite. 10/03/22 20:52:01.168
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":296,"skipped":5659,"failed":0}
------------------------------
• [SLOW TEST] [9.253 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:51:51.934
    Oct  3 20:51:51.934: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename job 10/03/22 20:51:51.936
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:51:51.973
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:51:51.983
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 10/03/22 20:51:51.992
    STEP: Ensuring active pods == parallelism 10/03/22 20:51:52.013
    STEP: Orphaning one of the Job's Pods 10/03/22 20:51:56.025
    Oct  3 20:51:56.566: INFO: Successfully updated pod "adopt-release-cldzz"
    STEP: Checking that the Job readopts the Pod 10/03/22 20:51:56.566
    Oct  3 20:51:56.566: INFO: Waiting up to 15m0s for pod "adopt-release-cldzz" in namespace "job-9828" to be "adopted"
    Oct  3 20:51:56.586: INFO: Pod "adopt-release-cldzz": Phase="Running", Reason="", readiness=true. Elapsed: 20.191935ms
    Oct  3 20:51:58.598: INFO: Pod "adopt-release-cldzz": Phase="Running", Reason="", readiness=true. Elapsed: 2.032322555s
    Oct  3 20:51:58.598: INFO: Pod "adopt-release-cldzz" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 10/03/22 20:51:58.598
    Oct  3 20:51:59.127: INFO: Successfully updated pod "adopt-release-cldzz"
    STEP: Checking that the Job releases the Pod 10/03/22 20:51:59.127
    Oct  3 20:51:59.127: INFO: Waiting up to 15m0s for pod "adopt-release-cldzz" in namespace "job-9828" to be "released"
    Oct  3 20:51:59.139: INFO: Pod "adopt-release-cldzz": Phase="Running", Reason="", readiness=true. Elapsed: 12.07669ms
    Oct  3 20:52:01.152: INFO: Pod "adopt-release-cldzz": Phase="Running", Reason="", readiness=true. Elapsed: 2.025049823s
    Oct  3 20:52:01.152: INFO: Pod "adopt-release-cldzz" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Oct  3 20:52:01.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9828" for this suite. 10/03/22 20:52:01.168
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:52:01.188
Oct  3 20:52:01.188: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename runtimeclass 10/03/22 20:52:01.189
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:52:01.226
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:52:01.235
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 10/03/22 20:52:01.245
STEP: getting /apis/node.k8s.io 10/03/22 20:52:01.254
STEP: getting /apis/node.k8s.io/v1 10/03/22 20:52:01.258
STEP: creating 10/03/22 20:52:01.262
STEP: watching 10/03/22 20:52:01.304
Oct  3 20:52:01.304: INFO: starting watch
STEP: getting 10/03/22 20:52:01.321
STEP: listing 10/03/22 20:52:01.333
STEP: patching 10/03/22 20:52:01.344
STEP: updating 10/03/22 20:52:01.356
Oct  3 20:52:01.369: INFO: waiting for watch events with expected annotations
STEP: deleting 10/03/22 20:52:01.369
STEP: deleting a collection 10/03/22 20:52:01.408
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Oct  3 20:52:01.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-3637" for this suite. 10/03/22 20:52:01.468
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":297,"skipped":5667,"failed":0}
------------------------------
• [0.300 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:52:01.188
    Oct  3 20:52:01.188: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename runtimeclass 10/03/22 20:52:01.189
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:52:01.226
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:52:01.235
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 10/03/22 20:52:01.245
    STEP: getting /apis/node.k8s.io 10/03/22 20:52:01.254
    STEP: getting /apis/node.k8s.io/v1 10/03/22 20:52:01.258
    STEP: creating 10/03/22 20:52:01.262
    STEP: watching 10/03/22 20:52:01.304
    Oct  3 20:52:01.304: INFO: starting watch
    STEP: getting 10/03/22 20:52:01.321
    STEP: listing 10/03/22 20:52:01.333
    STEP: patching 10/03/22 20:52:01.344
    STEP: updating 10/03/22 20:52:01.356
    Oct  3 20:52:01.369: INFO: waiting for watch events with expected annotations
    STEP: deleting 10/03/22 20:52:01.369
    STEP: deleting a collection 10/03/22 20:52:01.408
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Oct  3 20:52:01.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-3637" for this suite. 10/03/22 20:52:01.468
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:52:01.488
Oct  3 20:52:01.489: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename proxy 10/03/22 20:52:01.489
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:52:01.525
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:52:01.535
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Oct  3 20:52:01.545: INFO: Creating pod...
Oct  3 20:52:01.567: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-2435" to be "running"
Oct  3 20:52:01.577: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 10.259641ms
Oct  3 20:52:03.590: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023480863s
Oct  3 20:52:05.589: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.022299656s
Oct  3 20:52:05.589: INFO: Pod "agnhost" satisfied condition "running"
Oct  3 20:52:05.589: INFO: Creating service...
Oct  3 20:52:05.624: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/pods/agnhost/proxy?method=DELETE
Oct  3 20:52:05.665: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Oct  3 20:52:05.665: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/pods/agnhost/proxy?method=OPTIONS
Oct  3 20:52:05.682: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Oct  3 20:52:05.682: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/pods/agnhost/proxy?method=PATCH
Oct  3 20:52:05.698: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Oct  3 20:52:05.698: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/pods/agnhost/proxy?method=POST
Oct  3 20:52:05.715: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Oct  3 20:52:05.715: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/pods/agnhost/proxy?method=PUT
Oct  3 20:52:05.731: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Oct  3 20:52:05.731: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/services/e2e-proxy-test-service/proxy?method=DELETE
Oct  3 20:52:05.754: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Oct  3 20:52:05.754: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/services/e2e-proxy-test-service/proxy?method=OPTIONS
Oct  3 20:52:05.777: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Oct  3 20:52:05.777: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/services/e2e-proxy-test-service/proxy?method=PATCH
Oct  3 20:52:05.800: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Oct  3 20:52:05.800: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/services/e2e-proxy-test-service/proxy?method=POST
Oct  3 20:52:05.823: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Oct  3 20:52:05.823: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/services/e2e-proxy-test-service/proxy?method=PUT
Oct  3 20:52:05.848: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Oct  3 20:52:05.848: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/pods/agnhost/proxy?method=GET
Oct  3 20:52:05.858: INFO: http.Client request:GET StatusCode:301
Oct  3 20:52:05.858: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/services/e2e-proxy-test-service/proxy?method=GET
Oct  3 20:52:05.874: INFO: http.Client request:GET StatusCode:301
Oct  3 20:52:05.874: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/pods/agnhost/proxy?method=HEAD
Oct  3 20:52:05.883: INFO: http.Client request:HEAD StatusCode:301
Oct  3 20:52:05.883: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/services/e2e-proxy-test-service/proxy?method=HEAD
Oct  3 20:52:05.899: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Oct  3 20:52:05.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2435" for this suite. 10/03/22 20:52:05.914
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":298,"skipped":5679,"failed":0}
------------------------------
• [4.445 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:52:01.488
    Oct  3 20:52:01.489: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename proxy 10/03/22 20:52:01.489
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:52:01.525
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:52:01.535
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Oct  3 20:52:01.545: INFO: Creating pod...
    Oct  3 20:52:01.567: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-2435" to be "running"
    Oct  3 20:52:01.577: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 10.259641ms
    Oct  3 20:52:03.590: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023480863s
    Oct  3 20:52:05.589: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.022299656s
    Oct  3 20:52:05.589: INFO: Pod "agnhost" satisfied condition "running"
    Oct  3 20:52:05.589: INFO: Creating service...
    Oct  3 20:52:05.624: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/pods/agnhost/proxy?method=DELETE
    Oct  3 20:52:05.665: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Oct  3 20:52:05.665: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/pods/agnhost/proxy?method=OPTIONS
    Oct  3 20:52:05.682: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Oct  3 20:52:05.682: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/pods/agnhost/proxy?method=PATCH
    Oct  3 20:52:05.698: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Oct  3 20:52:05.698: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/pods/agnhost/proxy?method=POST
    Oct  3 20:52:05.715: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Oct  3 20:52:05.715: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/pods/agnhost/proxy?method=PUT
    Oct  3 20:52:05.731: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Oct  3 20:52:05.731: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/services/e2e-proxy-test-service/proxy?method=DELETE
    Oct  3 20:52:05.754: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Oct  3 20:52:05.754: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Oct  3 20:52:05.777: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Oct  3 20:52:05.777: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/services/e2e-proxy-test-service/proxy?method=PATCH
    Oct  3 20:52:05.800: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Oct  3 20:52:05.800: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/services/e2e-proxy-test-service/proxy?method=POST
    Oct  3 20:52:05.823: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Oct  3 20:52:05.823: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/services/e2e-proxy-test-service/proxy?method=PUT
    Oct  3 20:52:05.848: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Oct  3 20:52:05.848: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/pods/agnhost/proxy?method=GET
    Oct  3 20:52:05.858: INFO: http.Client request:GET StatusCode:301
    Oct  3 20:52:05.858: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/services/e2e-proxy-test-service/proxy?method=GET
    Oct  3 20:52:05.874: INFO: http.Client request:GET StatusCode:301
    Oct  3 20:52:05.874: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/pods/agnhost/proxy?method=HEAD
    Oct  3 20:52:05.883: INFO: http.Client request:HEAD StatusCode:301
    Oct  3 20:52:05.883: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-2435/services/e2e-proxy-test-service/proxy?method=HEAD
    Oct  3 20:52:05.899: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Oct  3 20:52:05.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-2435" for this suite. 10/03/22 20:52:05.914
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:52:05.937
Oct  3 20:52:05.937: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 20:52:05.939
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:52:05.974
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:52:05.983
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-5f72a83d-9628-45b0-920b-4fe0752f7737 10/03/22 20:52:05.992
STEP: Creating a pod to test consume secrets 10/03/22 20:52:06.005
Oct  3 20:52:06.027: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37" in namespace "projected-8845" to be "Succeeded or Failed"
Oct  3 20:52:06.038: INFO: Pod "pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37": Phase="Pending", Reason="", readiness=false. Elapsed: 10.837486ms
Oct  3 20:52:08.052: INFO: Pod "pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37": Phase="Running", Reason="", readiness=true. Elapsed: 2.024946524s
Oct  3 20:52:10.048: INFO: Pod "pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37": Phase="Running", Reason="", readiness=false. Elapsed: 4.021804869s
Oct  3 20:52:12.051: INFO: Pod "pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0239564s
STEP: Saw pod success 10/03/22 20:52:12.051
Oct  3 20:52:12.051: INFO: Pod "pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37" satisfied condition "Succeeded or Failed"
Oct  3 20:52:12.062: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37 container projected-secret-volume-test: <nil>
STEP: delete the pod 10/03/22 20:52:12.091
Oct  3 20:52:12.123: INFO: Waiting for pod pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37 to disappear
Oct  3 20:52:12.132: INFO: Pod pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Oct  3 20:52:12.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8845" for this suite. 10/03/22 20:52:12.146
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":299,"skipped":5707,"failed":0}
------------------------------
• [SLOW TEST] [6.244 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:52:05.937
    Oct  3 20:52:05.937: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 20:52:05.939
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:52:05.974
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:52:05.983
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-5f72a83d-9628-45b0-920b-4fe0752f7737 10/03/22 20:52:05.992
    STEP: Creating a pod to test consume secrets 10/03/22 20:52:06.005
    Oct  3 20:52:06.027: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37" in namespace "projected-8845" to be "Succeeded or Failed"
    Oct  3 20:52:06.038: INFO: Pod "pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37": Phase="Pending", Reason="", readiness=false. Elapsed: 10.837486ms
    Oct  3 20:52:08.052: INFO: Pod "pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37": Phase="Running", Reason="", readiness=true. Elapsed: 2.024946524s
    Oct  3 20:52:10.048: INFO: Pod "pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37": Phase="Running", Reason="", readiness=false. Elapsed: 4.021804869s
    Oct  3 20:52:12.051: INFO: Pod "pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0239564s
    STEP: Saw pod success 10/03/22 20:52:12.051
    Oct  3 20:52:12.051: INFO: Pod "pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37" satisfied condition "Succeeded or Failed"
    Oct  3 20:52:12.062: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37 container projected-secret-volume-test: <nil>
    STEP: delete the pod 10/03/22 20:52:12.091
    Oct  3 20:52:12.123: INFO: Waiting for pod pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37 to disappear
    Oct  3 20:52:12.132: INFO: Pod pod-projected-secrets-57d7c4dd-9a1e-4ae7-88df-344522bdec37 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Oct  3 20:52:12.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8845" for this suite. 10/03/22 20:52:12.146
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:52:12.182
Oct  3 20:52:12.182: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 20:52:12.184
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:52:12.22
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:52:12.232
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 10/03/22 20:52:12.242
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 20:52:12.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-170" for this suite. 10/03/22 20:52:12.265
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":300,"skipped":5708,"failed":0}
------------------------------
• [0.105 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:52:12.182
    Oct  3 20:52:12.182: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 20:52:12.184
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:52:12.22
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:52:12.232
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 10/03/22 20:52:12.242
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 20:52:12.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-170" for this suite. 10/03/22 20:52:12.265
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:52:12.289
Oct  3 20:52:12.289: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubelet-test 10/03/22 20:52:12.29
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:52:12.33
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:52:12.339
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 10/03/22 20:52:12.384
Oct  3 20:52:12.384: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases012d8c5b-5e95-4611-a7e1-e5681b435a47" in namespace "kubelet-test-8952" to be "completed"
Oct  3 20:52:12.419: INFO: Pod "agnhost-host-aliases012d8c5b-5e95-4611-a7e1-e5681b435a47": Phase="Pending", Reason="", readiness=false. Elapsed: 35.219411ms
Oct  3 20:52:14.432: INFO: Pod "agnhost-host-aliases012d8c5b-5e95-4611-a7e1-e5681b435a47": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047722371s
Oct  3 20:52:16.432: INFO: Pod "agnhost-host-aliases012d8c5b-5e95-4611-a7e1-e5681b435a47": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048299388s
Oct  3 20:52:18.433: INFO: Pod "agnhost-host-aliases012d8c5b-5e95-4611-a7e1-e5681b435a47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.048883142s
Oct  3 20:52:18.433: INFO: Pod "agnhost-host-aliases012d8c5b-5e95-4611-a7e1-e5681b435a47" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Oct  3 20:52:18.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8952" for this suite. 10/03/22 20:52:18.478
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":301,"skipped":5713,"failed":0}
------------------------------
• [SLOW TEST] [6.209 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:52:12.289
    Oct  3 20:52:12.289: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubelet-test 10/03/22 20:52:12.29
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:52:12.33
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:52:12.339
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 10/03/22 20:52:12.384
    Oct  3 20:52:12.384: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases012d8c5b-5e95-4611-a7e1-e5681b435a47" in namespace "kubelet-test-8952" to be "completed"
    Oct  3 20:52:12.419: INFO: Pod "agnhost-host-aliases012d8c5b-5e95-4611-a7e1-e5681b435a47": Phase="Pending", Reason="", readiness=false. Elapsed: 35.219411ms
    Oct  3 20:52:14.432: INFO: Pod "agnhost-host-aliases012d8c5b-5e95-4611-a7e1-e5681b435a47": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047722371s
    Oct  3 20:52:16.432: INFO: Pod "agnhost-host-aliases012d8c5b-5e95-4611-a7e1-e5681b435a47": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048299388s
    Oct  3 20:52:18.433: INFO: Pod "agnhost-host-aliases012d8c5b-5e95-4611-a7e1-e5681b435a47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.048883142s
    Oct  3 20:52:18.433: INFO: Pod "agnhost-host-aliases012d8c5b-5e95-4611-a7e1-e5681b435a47" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Oct  3 20:52:18.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-8952" for this suite. 10/03/22 20:52:18.478
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:52:18.498
Oct  3 20:52:18.498: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename statefulset 10/03/22 20:52:18.499
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:52:18.533
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:52:18.544
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5507 10/03/22 20:52:18.555
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 10/03/22 20:52:18.569
Oct  3 20:52:18.592: INFO: Found 0 stateful pods, waiting for 3
Oct  3 20:52:28.604: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  3 20:52:28.605: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  3 20:52:28.605: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct  3 20:52:28.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-5507 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  3 20:52:28.923: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  3 20:52:28.923: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  3 20:52:28.923: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 10/03/22 20:52:38.97
Oct  3 20:52:39.009: INFO: Updating stateful set ss2
STEP: Creating a new revision 10/03/22 20:52:39.009
STEP: Updating Pods in reverse ordinal order 10/03/22 20:52:49.063
Oct  3 20:52:49.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-5507 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:52:49.360: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  3 20:52:49.360: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  3 20:52:49.360: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  3 20:52:59.430: INFO: Waiting for StatefulSet statefulset-5507/ss2 to complete update
Oct  3 20:52:59.430: INFO: Waiting for Pod statefulset-5507/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Oct  3 20:52:59.430: INFO: Waiting for Pod statefulset-5507/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Oct  3 20:53:09.457: INFO: Waiting for StatefulSet statefulset-5507/ss2 to complete update
Oct  3 20:53:09.457: INFO: Waiting for Pod statefulset-5507/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Oct  3 20:53:19.457: INFO: Waiting for StatefulSet statefulset-5507/ss2 to complete update
STEP: Rolling back to a previous revision 10/03/22 20:53:29.456
Oct  3 20:53:29.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-5507 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  3 20:53:29.745: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  3 20:53:29.745: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  3 20:53:29.745: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  3 20:53:39.825: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 10/03/22 20:53:49.874
Oct  3 20:53:49.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-5507 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  3 20:53:50.161: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  3 20:53:50.161: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  3 20:53:50.161: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  3 20:54:00.239: INFO: Waiting for StatefulSet statefulset-5507/ss2 to complete update
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct  3 20:54:10.266: INFO: Deleting all statefulset in ns statefulset-5507
Oct  3 20:54:10.276: INFO: Scaling statefulset ss2 to 0
Oct  3 20:54:20.327: INFO: Waiting for statefulset status.replicas updated to 0
Oct  3 20:54:20.338: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Oct  3 20:54:20.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5507" for this suite. 10/03/22 20:54:20.398
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":302,"skipped":5719,"failed":0}
------------------------------
• [SLOW TEST] [121.922 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:52:18.498
    Oct  3 20:52:18.498: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename statefulset 10/03/22 20:52:18.499
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:52:18.533
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:52:18.544
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-5507 10/03/22 20:52:18.555
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 10/03/22 20:52:18.569
    Oct  3 20:52:18.592: INFO: Found 0 stateful pods, waiting for 3
    Oct  3 20:52:28.604: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Oct  3 20:52:28.605: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Oct  3 20:52:28.605: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Oct  3 20:52:28.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-5507 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct  3 20:52:28.923: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct  3 20:52:28.923: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct  3 20:52:28.923: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 10/03/22 20:52:38.97
    Oct  3 20:52:39.009: INFO: Updating stateful set ss2
    STEP: Creating a new revision 10/03/22 20:52:39.009
    STEP: Updating Pods in reverse ordinal order 10/03/22 20:52:49.063
    Oct  3 20:52:49.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-5507 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:52:49.360: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Oct  3 20:52:49.360: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct  3 20:52:49.360: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Oct  3 20:52:59.430: INFO: Waiting for StatefulSet statefulset-5507/ss2 to complete update
    Oct  3 20:52:59.430: INFO: Waiting for Pod statefulset-5507/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Oct  3 20:52:59.430: INFO: Waiting for Pod statefulset-5507/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Oct  3 20:53:09.457: INFO: Waiting for StatefulSet statefulset-5507/ss2 to complete update
    Oct  3 20:53:09.457: INFO: Waiting for Pod statefulset-5507/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Oct  3 20:53:19.457: INFO: Waiting for StatefulSet statefulset-5507/ss2 to complete update
    STEP: Rolling back to a previous revision 10/03/22 20:53:29.456
    Oct  3 20:53:29.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-5507 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct  3 20:53:29.745: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct  3 20:53:29.745: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct  3 20:53:29.745: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct  3 20:53:39.825: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 10/03/22 20:53:49.874
    Oct  3 20:53:49.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=statefulset-5507 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct  3 20:53:50.161: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Oct  3 20:53:50.161: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct  3 20:53:50.161: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Oct  3 20:54:00.239: INFO: Waiting for StatefulSet statefulset-5507/ss2 to complete update
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Oct  3 20:54:10.266: INFO: Deleting all statefulset in ns statefulset-5507
    Oct  3 20:54:10.276: INFO: Scaling statefulset ss2 to 0
    Oct  3 20:54:20.327: INFO: Waiting for statefulset status.replicas updated to 0
    Oct  3 20:54:20.338: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Oct  3 20:54:20.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-5507" for this suite. 10/03/22 20:54:20.398
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:54:20.423
Oct  3 20:54:20.424: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename secrets 10/03/22 20:54:20.425
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:54:20.461
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:54:20.472
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-90346167-ec3d-469a-ac3d-2fda8e4908d3 10/03/22 20:54:20.482
STEP: Creating a pod to test consume secrets 10/03/22 20:54:20.495
Oct  3 20:54:20.517: INFO: Waiting up to 5m0s for pod "pod-secrets-410b628c-1416-478b-9f94-f49424c42775" in namespace "secrets-1668" to be "Succeeded or Failed"
Oct  3 20:54:20.529: INFO: Pod "pod-secrets-410b628c-1416-478b-9f94-f49424c42775": Phase="Pending", Reason="", readiness=false. Elapsed: 11.946204ms
Oct  3 20:54:22.549: INFO: Pod "pod-secrets-410b628c-1416-478b-9f94-f49424c42775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031988828s
Oct  3 20:54:24.542: INFO: Pod "pod-secrets-410b628c-1416-478b-9f94-f49424c42775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025232005s
STEP: Saw pod success 10/03/22 20:54:24.542
Oct  3 20:54:24.543: INFO: Pod "pod-secrets-410b628c-1416-478b-9f94-f49424c42775" satisfied condition "Succeeded or Failed"
Oct  3 20:54:24.556: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-410b628c-1416-478b-9f94-f49424c42775 container secret-volume-test: <nil>
STEP: delete the pod 10/03/22 20:54:24.634
Oct  3 20:54:24.666: INFO: Waiting for pod pod-secrets-410b628c-1416-478b-9f94-f49424c42775 to disappear
Oct  3 20:54:24.679: INFO: Pod pod-secrets-410b628c-1416-478b-9f94-f49424c42775 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Oct  3 20:54:24.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1668" for this suite. 10/03/22 20:54:24.715
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":303,"skipped":5754,"failed":0}
------------------------------
• [4.311 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:54:20.423
    Oct  3 20:54:20.424: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename secrets 10/03/22 20:54:20.425
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:54:20.461
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:54:20.472
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-90346167-ec3d-469a-ac3d-2fda8e4908d3 10/03/22 20:54:20.482
    STEP: Creating a pod to test consume secrets 10/03/22 20:54:20.495
    Oct  3 20:54:20.517: INFO: Waiting up to 5m0s for pod "pod-secrets-410b628c-1416-478b-9f94-f49424c42775" in namespace "secrets-1668" to be "Succeeded or Failed"
    Oct  3 20:54:20.529: INFO: Pod "pod-secrets-410b628c-1416-478b-9f94-f49424c42775": Phase="Pending", Reason="", readiness=false. Elapsed: 11.946204ms
    Oct  3 20:54:22.549: INFO: Pod "pod-secrets-410b628c-1416-478b-9f94-f49424c42775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031988828s
    Oct  3 20:54:24.542: INFO: Pod "pod-secrets-410b628c-1416-478b-9f94-f49424c42775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025232005s
    STEP: Saw pod success 10/03/22 20:54:24.542
    Oct  3 20:54:24.543: INFO: Pod "pod-secrets-410b628c-1416-478b-9f94-f49424c42775" satisfied condition "Succeeded or Failed"
    Oct  3 20:54:24.556: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-410b628c-1416-478b-9f94-f49424c42775 container secret-volume-test: <nil>
    STEP: delete the pod 10/03/22 20:54:24.634
    Oct  3 20:54:24.666: INFO: Waiting for pod pod-secrets-410b628c-1416-478b-9f94-f49424c42775 to disappear
    Oct  3 20:54:24.679: INFO: Pod pod-secrets-410b628c-1416-478b-9f94-f49424c42775 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Oct  3 20:54:24.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1668" for this suite. 10/03/22 20:54:24.715
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:54:24.739
Oct  3 20:54:24.739: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 20:54:24.741
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:54:24.775
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:54:24.784
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 20:54:24.835
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:54:25.646
STEP: Deploying the webhook pod 10/03/22 20:54:25.659
STEP: Wait for the deployment to be ready 10/03/22 20:54:25.72
Oct  3 20:54:25.749: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/03/22 20:54:27.787
STEP: Verifying the service has paired with the endpoint 10/03/22 20:54:27.819
Oct  3 20:54:28.819: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Oct  3 20:54:28.832: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Registering the custom resource webhook via the AdmissionRegistration API 10/03/22 20:54:29.36
STEP: Creating a custom resource that should be denied by the webhook 10/03/22 20:54:29.42
STEP: Creating a custom resource whose deletion would be denied by the webhook 10/03/22 20:54:31.515
STEP: Updating the custom resource with disallowed data should be denied 10/03/22 20:54:31.563
STEP: Deleting the custom resource should be denied 10/03/22 20:54:31.596
STEP: Remove the offending key and value from the custom resource data 10/03/22 20:54:31.624
STEP: Deleting the updated custom resource should be successful 10/03/22 20:54:31.658
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:54:32.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6289" for this suite. 10/03/22 20:54:32.264
STEP: Destroying namespace "webhook-6289-markers" for this suite. 10/03/22 20:54:32.296
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":304,"skipped":5780,"failed":0}
------------------------------
• [SLOW TEST] [7.801 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:54:24.739
    Oct  3 20:54:24.739: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 20:54:24.741
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:54:24.775
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:54:24.784
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 20:54:24.835
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:54:25.646
    STEP: Deploying the webhook pod 10/03/22 20:54:25.659
    STEP: Wait for the deployment to be ready 10/03/22 20:54:25.72
    Oct  3 20:54:25.749: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/03/22 20:54:27.787
    STEP: Verifying the service has paired with the endpoint 10/03/22 20:54:27.819
    Oct  3 20:54:28.819: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Oct  3 20:54:28.832: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 10/03/22 20:54:29.36
    STEP: Creating a custom resource that should be denied by the webhook 10/03/22 20:54:29.42
    STEP: Creating a custom resource whose deletion would be denied by the webhook 10/03/22 20:54:31.515
    STEP: Updating the custom resource with disallowed data should be denied 10/03/22 20:54:31.563
    STEP: Deleting the custom resource should be denied 10/03/22 20:54:31.596
    STEP: Remove the offending key and value from the custom resource data 10/03/22 20:54:31.624
    STEP: Deleting the updated custom resource should be successful 10/03/22 20:54:31.658
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:54:32.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6289" for this suite. 10/03/22 20:54:32.264
    STEP: Destroying namespace "webhook-6289-markers" for this suite. 10/03/22 20:54:32.296
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:54:32.543
Oct  3 20:54:32.543: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 20:54:32.544
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:54:32.582
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:54:32.592
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 10/03/22 20:54:32.602
Oct  3 20:54:32.603: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 10/03/22 20:54:51.736
Oct  3 20:54:51.737: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:54:56.526: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:55:12.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7880" for this suite. 10/03/22 20:55:12.642
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":305,"skipped":5809,"failed":0}
------------------------------
• [SLOW TEST] [40.124 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:54:32.543
    Oct  3 20:54:32.543: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename crd-publish-openapi 10/03/22 20:54:32.544
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:54:32.582
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:54:32.592
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 10/03/22 20:54:32.602
    Oct  3 20:54:32.603: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 10/03/22 20:54:51.736
    Oct  3 20:54:51.737: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:54:56.526: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:55:12.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7880" for this suite. 10/03/22 20:55:12.642
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:55:12.668
Oct  3 20:55:12.668: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename container-lifecycle-hook 10/03/22 20:55:12.67
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:55:12.718
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:55:12.729
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 10/03/22 20:55:12.761
Oct  3 20:55:12.792: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7965" to be "running and ready"
Oct  3 20:55:12.805: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 12.457127ms
Oct  3 20:55:12.805: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:55:14.823: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.030393664s
Oct  3 20:55:14.823: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Oct  3 20:55:14.823: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 10/03/22 20:55:14.838
Oct  3 20:55:14.857: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-7965" to be "running and ready"
Oct  3 20:55:14.871: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 14.171784ms
Oct  3 20:55:14.871: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:55:16.885: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.028196188s
Oct  3 20:55:16.885: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Oct  3 20:55:16.885: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 10/03/22 20:55:16.897
Oct  3 20:55:16.922: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  3 20:55:16.936: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  3 20:55:18.938: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  3 20:55:18.953: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  3 20:55:20.937: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  3 20:55:20.952: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 10/03/22 20:55:20.952
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Oct  3 20:55:21.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7965" for this suite. 10/03/22 20:55:21.039
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":306,"skipped":5829,"failed":0}
------------------------------
• [SLOW TEST] [8.394 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:55:12.668
    Oct  3 20:55:12.668: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename container-lifecycle-hook 10/03/22 20:55:12.67
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:55:12.718
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:55:12.729
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 10/03/22 20:55:12.761
    Oct  3 20:55:12.792: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7965" to be "running and ready"
    Oct  3 20:55:12.805: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 12.457127ms
    Oct  3 20:55:12.805: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:55:14.823: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.030393664s
    Oct  3 20:55:14.823: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Oct  3 20:55:14.823: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 10/03/22 20:55:14.838
    Oct  3 20:55:14.857: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-7965" to be "running and ready"
    Oct  3 20:55:14.871: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 14.171784ms
    Oct  3 20:55:14.871: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:55:16.885: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.028196188s
    Oct  3 20:55:16.885: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Oct  3 20:55:16.885: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 10/03/22 20:55:16.897
    Oct  3 20:55:16.922: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Oct  3 20:55:16.936: INFO: Pod pod-with-prestop-exec-hook still exists
    Oct  3 20:55:18.938: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Oct  3 20:55:18.953: INFO: Pod pod-with-prestop-exec-hook still exists
    Oct  3 20:55:20.937: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Oct  3 20:55:20.952: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 10/03/22 20:55:20.952
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Oct  3 20:55:21.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-7965" for this suite. 10/03/22 20:55:21.039
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:55:21.07
Oct  3 20:55:21.071: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename endpointslice 10/03/22 20:55:21.073
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:55:21.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:55:21.134
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 10/03/22 20:55:21.146
STEP: getting /apis/discovery.k8s.io 10/03/22 20:55:21.156
STEP: getting /apis/discovery.k8s.iov1 10/03/22 20:55:21.161
STEP: creating 10/03/22 20:55:21.166
STEP: getting 10/03/22 20:55:21.24
STEP: listing 10/03/22 20:55:21.253
STEP: watching 10/03/22 20:55:21.267
Oct  3 20:55:21.267: INFO: starting watch
STEP: cluster-wide listing 10/03/22 20:55:21.273
STEP: cluster-wide watching 10/03/22 20:55:21.288
Oct  3 20:55:21.288: INFO: starting watch
STEP: patching 10/03/22 20:55:21.293
STEP: updating 10/03/22 20:55:21.312
Oct  3 20:55:21.342: INFO: waiting for watch events with expected annotations
Oct  3 20:55:21.342: INFO: saw patched and updated annotations
STEP: deleting 10/03/22 20:55:21.342
STEP: deleting a collection 10/03/22 20:55:21.392
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Oct  3 20:55:21.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9238" for this suite. 10/03/22 20:55:21.476
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":307,"skipped":5862,"failed":0}
------------------------------
• [0.429 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:55:21.07
    Oct  3 20:55:21.071: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename endpointslice 10/03/22 20:55:21.073
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:55:21.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:55:21.134
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 10/03/22 20:55:21.146
    STEP: getting /apis/discovery.k8s.io 10/03/22 20:55:21.156
    STEP: getting /apis/discovery.k8s.iov1 10/03/22 20:55:21.161
    STEP: creating 10/03/22 20:55:21.166
    STEP: getting 10/03/22 20:55:21.24
    STEP: listing 10/03/22 20:55:21.253
    STEP: watching 10/03/22 20:55:21.267
    Oct  3 20:55:21.267: INFO: starting watch
    STEP: cluster-wide listing 10/03/22 20:55:21.273
    STEP: cluster-wide watching 10/03/22 20:55:21.288
    Oct  3 20:55:21.288: INFO: starting watch
    STEP: patching 10/03/22 20:55:21.293
    STEP: updating 10/03/22 20:55:21.312
    Oct  3 20:55:21.342: INFO: waiting for watch events with expected annotations
    Oct  3 20:55:21.342: INFO: saw patched and updated annotations
    STEP: deleting 10/03/22 20:55:21.342
    STEP: deleting a collection 10/03/22 20:55:21.392
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Oct  3 20:55:21.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-9238" for this suite. 10/03/22 20:55:21.476
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:55:21.507
Oct  3 20:55:21.507: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename secrets 10/03/22 20:55:21.508
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:55:21.554
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:55:21.568
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-f99482d1-43d7-4ce5-abc7-ddc6df6a4bba 10/03/22 20:55:21.579
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Oct  3 20:55:21.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3009" for this suite. 10/03/22 20:55:21.604
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":308,"skipped":5884,"failed":0}
------------------------------
• [0.121 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:55:21.507
    Oct  3 20:55:21.507: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename secrets 10/03/22 20:55:21.508
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:55:21.554
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:55:21.568
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-f99482d1-43d7-4ce5-abc7-ddc6df6a4bba 10/03/22 20:55:21.579
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Oct  3 20:55:21.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3009" for this suite. 10/03/22 20:55:21.604
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:55:21.629
Oct  3 20:55:21.629: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 20:55:21.63
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:55:21.675
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:55:21.687
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 10/03/22 20:55:21.7
Oct  3 20:55:21.728: INFO: Waiting up to 5m0s for pod "labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2" in namespace "downward-api-6940" to be "running and ready"
Oct  3 20:55:21.741: INFO: Pod "labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.513818ms
Oct  3 20:55:21.741: INFO: The phase of Pod labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:55:23.757: INFO: Pod "labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028976311s
Oct  3 20:55:23.757: INFO: The phase of Pod labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:55:25.758: INFO: Pod "labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2": Phase="Running", Reason="", readiness=true. Elapsed: 4.030093751s
Oct  3 20:55:25.758: INFO: The phase of Pod labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2 is Running (Ready = true)
Oct  3 20:55:25.758: INFO: Pod "labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2" satisfied condition "running and ready"
Oct  3 20:55:26.350: INFO: Successfully updated pod "labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Oct  3 20:55:28.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6940" for this suite. 10/03/22 20:55:28.433
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":309,"skipped":5886,"failed":0}
------------------------------
• [SLOW TEST] [6.832 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:55:21.629
    Oct  3 20:55:21.629: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 20:55:21.63
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:55:21.675
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:55:21.687
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 10/03/22 20:55:21.7
    Oct  3 20:55:21.728: INFO: Waiting up to 5m0s for pod "labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2" in namespace "downward-api-6940" to be "running and ready"
    Oct  3 20:55:21.741: INFO: Pod "labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.513818ms
    Oct  3 20:55:21.741: INFO: The phase of Pod labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:55:23.757: INFO: Pod "labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028976311s
    Oct  3 20:55:23.757: INFO: The phase of Pod labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:55:25.758: INFO: Pod "labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2": Phase="Running", Reason="", readiness=true. Elapsed: 4.030093751s
    Oct  3 20:55:25.758: INFO: The phase of Pod labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2 is Running (Ready = true)
    Oct  3 20:55:25.758: INFO: Pod "labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2" satisfied condition "running and ready"
    Oct  3 20:55:26.350: INFO: Successfully updated pod "labelsupdate4e51095c-c2fb-4adb-9ef9-1dae27788ea2"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Oct  3 20:55:28.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6940" for this suite. 10/03/22 20:55:28.433
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:55:28.463
Oct  3 20:55:28.464: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename containers 10/03/22 20:55:28.465
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:55:28.509
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:55:28.519
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 10/03/22 20:55:28.53
Oct  3 20:55:28.559: INFO: Waiting up to 5m0s for pod "client-containers-555f6581-58d3-4105-963e-85e027d67936" in namespace "containers-3459" to be "Succeeded or Failed"
Oct  3 20:55:28.573: INFO: Pod "client-containers-555f6581-58d3-4105-963e-85e027d67936": Phase="Pending", Reason="", readiness=false. Elapsed: 13.169833ms
Oct  3 20:55:30.588: INFO: Pod "client-containers-555f6581-58d3-4105-963e-85e027d67936": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028123925s
Oct  3 20:55:32.587: INFO: Pod "client-containers-555f6581-58d3-4105-963e-85e027d67936": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027953081s
Oct  3 20:55:34.589: INFO: Pod "client-containers-555f6581-58d3-4105-963e-85e027d67936": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029585759s
STEP: Saw pod success 10/03/22 20:55:34.589
Oct  3 20:55:34.589: INFO: Pod "client-containers-555f6581-58d3-4105-963e-85e027d67936" satisfied condition "Succeeded or Failed"
Oct  3 20:55:34.603: INFO: Trying to get logs from node 10.63.128.3 pod client-containers-555f6581-58d3-4105-963e-85e027d67936 container agnhost-container: <nil>
STEP: delete the pod 10/03/22 20:55:34.635
Oct  3 20:55:34.669: INFO: Waiting for pod client-containers-555f6581-58d3-4105-963e-85e027d67936 to disappear
Oct  3 20:55:34.683: INFO: Pod client-containers-555f6581-58d3-4105-963e-85e027d67936 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Oct  3 20:55:34.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3459" for this suite. 10/03/22 20:55:34.701
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":310,"skipped":5911,"failed":0}
------------------------------
• [SLOW TEST] [6.267 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:55:28.463
    Oct  3 20:55:28.464: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename containers 10/03/22 20:55:28.465
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:55:28.509
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:55:28.519
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 10/03/22 20:55:28.53
    Oct  3 20:55:28.559: INFO: Waiting up to 5m0s for pod "client-containers-555f6581-58d3-4105-963e-85e027d67936" in namespace "containers-3459" to be "Succeeded or Failed"
    Oct  3 20:55:28.573: INFO: Pod "client-containers-555f6581-58d3-4105-963e-85e027d67936": Phase="Pending", Reason="", readiness=false. Elapsed: 13.169833ms
    Oct  3 20:55:30.588: INFO: Pod "client-containers-555f6581-58d3-4105-963e-85e027d67936": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028123925s
    Oct  3 20:55:32.587: INFO: Pod "client-containers-555f6581-58d3-4105-963e-85e027d67936": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027953081s
    Oct  3 20:55:34.589: INFO: Pod "client-containers-555f6581-58d3-4105-963e-85e027d67936": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029585759s
    STEP: Saw pod success 10/03/22 20:55:34.589
    Oct  3 20:55:34.589: INFO: Pod "client-containers-555f6581-58d3-4105-963e-85e027d67936" satisfied condition "Succeeded or Failed"
    Oct  3 20:55:34.603: INFO: Trying to get logs from node 10.63.128.3 pod client-containers-555f6581-58d3-4105-963e-85e027d67936 container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 20:55:34.635
    Oct  3 20:55:34.669: INFO: Waiting for pod client-containers-555f6581-58d3-4105-963e-85e027d67936 to disappear
    Oct  3 20:55:34.683: INFO: Pod client-containers-555f6581-58d3-4105-963e-85e027d67936 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Oct  3 20:55:34.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-3459" for this suite. 10/03/22 20:55:34.701
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:55:34.735
Oct  3 20:55:34.736: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename subpath 10/03/22 20:55:34.737
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:55:34.847
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:55:34.859
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 10/03/22 20:55:34.87
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-7zdz 10/03/22 20:55:34.899
STEP: Creating a pod to test atomic-volume-subpath 10/03/22 20:55:34.899
Oct  3 20:55:34.925: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-7zdz" in namespace "subpath-2302" to be "Succeeded or Failed"
Oct  3 20:55:34.938: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Pending", Reason="", readiness=false. Elapsed: 12.788495ms
Oct  3 20:55:36.953: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 2.028575643s
Oct  3 20:55:38.952: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 4.027393426s
Oct  3 20:55:40.953: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 6.027743123s
Oct  3 20:55:42.954: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 8.029170134s
Oct  3 20:55:44.953: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 10.027766838s
Oct  3 20:55:46.951: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 12.026130942s
Oct  3 20:55:48.953: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 14.028359065s
Oct  3 20:55:50.953: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 16.028221164s
Oct  3 20:55:52.953: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 18.027650266s
Oct  3 20:55:54.954: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 20.02879196s
Oct  3 20:55:56.954: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 22.028986195s
Oct  3 20:55:58.952: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=false. Elapsed: 24.027049987s
Oct  3 20:56:00.951: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.025790059s
STEP: Saw pod success 10/03/22 20:56:00.951
Oct  3 20:56:00.951: INFO: Pod "pod-subpath-test-secret-7zdz" satisfied condition "Succeeded or Failed"
Oct  3 20:56:00.966: INFO: Trying to get logs from node 10.63.128.3 pod pod-subpath-test-secret-7zdz container test-container-subpath-secret-7zdz: <nil>
STEP: delete the pod 10/03/22 20:56:00.994
Oct  3 20:56:01.043: INFO: Waiting for pod pod-subpath-test-secret-7zdz to disappear
Oct  3 20:56:01.058: INFO: Pod pod-subpath-test-secret-7zdz no longer exists
STEP: Deleting pod pod-subpath-test-secret-7zdz 10/03/22 20:56:01.058
Oct  3 20:56:01.058: INFO: Deleting pod "pod-subpath-test-secret-7zdz" in namespace "subpath-2302"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Oct  3 20:56:01.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2302" for this suite. 10/03/22 20:56:01.093
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":311,"skipped":5914,"failed":0}
------------------------------
• [SLOW TEST] [26.383 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:55:34.735
    Oct  3 20:55:34.736: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename subpath 10/03/22 20:55:34.737
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:55:34.847
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:55:34.859
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 10/03/22 20:55:34.87
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-7zdz 10/03/22 20:55:34.899
    STEP: Creating a pod to test atomic-volume-subpath 10/03/22 20:55:34.899
    Oct  3 20:55:34.925: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-7zdz" in namespace "subpath-2302" to be "Succeeded or Failed"
    Oct  3 20:55:34.938: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Pending", Reason="", readiness=false. Elapsed: 12.788495ms
    Oct  3 20:55:36.953: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 2.028575643s
    Oct  3 20:55:38.952: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 4.027393426s
    Oct  3 20:55:40.953: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 6.027743123s
    Oct  3 20:55:42.954: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 8.029170134s
    Oct  3 20:55:44.953: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 10.027766838s
    Oct  3 20:55:46.951: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 12.026130942s
    Oct  3 20:55:48.953: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 14.028359065s
    Oct  3 20:55:50.953: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 16.028221164s
    Oct  3 20:55:52.953: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 18.027650266s
    Oct  3 20:55:54.954: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 20.02879196s
    Oct  3 20:55:56.954: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=true. Elapsed: 22.028986195s
    Oct  3 20:55:58.952: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Running", Reason="", readiness=false. Elapsed: 24.027049987s
    Oct  3 20:56:00.951: INFO: Pod "pod-subpath-test-secret-7zdz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.025790059s
    STEP: Saw pod success 10/03/22 20:56:00.951
    Oct  3 20:56:00.951: INFO: Pod "pod-subpath-test-secret-7zdz" satisfied condition "Succeeded or Failed"
    Oct  3 20:56:00.966: INFO: Trying to get logs from node 10.63.128.3 pod pod-subpath-test-secret-7zdz container test-container-subpath-secret-7zdz: <nil>
    STEP: delete the pod 10/03/22 20:56:00.994
    Oct  3 20:56:01.043: INFO: Waiting for pod pod-subpath-test-secret-7zdz to disappear
    Oct  3 20:56:01.058: INFO: Pod pod-subpath-test-secret-7zdz no longer exists
    STEP: Deleting pod pod-subpath-test-secret-7zdz 10/03/22 20:56:01.058
    Oct  3 20:56:01.058: INFO: Deleting pod "pod-subpath-test-secret-7zdz" in namespace "subpath-2302"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Oct  3 20:56:01.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-2302" for this suite. 10/03/22 20:56:01.093
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:56:01.119
Oct  3 20:56:01.119: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename disruption 10/03/22 20:56:01.12
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:56:01.169
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:56:01.178
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 10/03/22 20:56:01.204
STEP: Updating PodDisruptionBudget status 10/03/22 20:56:01.215
STEP: Waiting for all pods to be running 10/03/22 20:56:01.244
Oct  3 20:56:01.259: INFO: running pods: 0 < 1
STEP: locating a running pod 10/03/22 20:56:03.275
STEP: Waiting for the pdb to be processed 10/03/22 20:56:03.315
STEP: Patching PodDisruptionBudget status 10/03/22 20:56:03.338
STEP: Waiting for the pdb to be processed 10/03/22 20:56:03.364
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Oct  3 20:56:03.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4624" for this suite. 10/03/22 20:56:03.393
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":312,"skipped":5927,"failed":0}
------------------------------
• [2.300 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:56:01.119
    Oct  3 20:56:01.119: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename disruption 10/03/22 20:56:01.12
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:56:01.169
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:56:01.178
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 10/03/22 20:56:01.204
    STEP: Updating PodDisruptionBudget status 10/03/22 20:56:01.215
    STEP: Waiting for all pods to be running 10/03/22 20:56:01.244
    Oct  3 20:56:01.259: INFO: running pods: 0 < 1
    STEP: locating a running pod 10/03/22 20:56:03.275
    STEP: Waiting for the pdb to be processed 10/03/22 20:56:03.315
    STEP: Patching PodDisruptionBudget status 10/03/22 20:56:03.338
    STEP: Waiting for the pdb to be processed 10/03/22 20:56:03.364
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Oct  3 20:56:03.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-4624" for this suite. 10/03/22 20:56:03.393
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:56:03.422
Oct  3 20:56:03.422: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename var-expansion 10/03/22 20:56:03.423
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:56:03.47
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:56:03.481
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Oct  3 20:56:03.524: INFO: Waiting up to 2m0s for pod "var-expansion-3881d5cc-f1f9-4c38-a497-bc37f1ffef68" in namespace "var-expansion-7672" to be "container 0 failed with reason CreateContainerConfigError"
Oct  3 20:56:03.539: INFO: Pod "var-expansion-3881d5cc-f1f9-4c38-a497-bc37f1ffef68": Phase="Pending", Reason="", readiness=false. Elapsed: 15.673099ms
Oct  3 20:56:05.555: INFO: Pod "var-expansion-3881d5cc-f1f9-4c38-a497-bc37f1ffef68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03127803s
Oct  3 20:56:05.555: INFO: Pod "var-expansion-3881d5cc-f1f9-4c38-a497-bc37f1ffef68" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Oct  3 20:56:05.555: INFO: Deleting pod "var-expansion-3881d5cc-f1f9-4c38-a497-bc37f1ffef68" in namespace "var-expansion-7672"
Oct  3 20:56:05.581: INFO: Wait up to 5m0s for pod "var-expansion-3881d5cc-f1f9-4c38-a497-bc37f1ffef68" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Oct  3 20:56:09.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7672" for this suite. 10/03/22 20:56:09.639
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":313,"skipped":5937,"failed":0}
------------------------------
• [SLOW TEST] [6.242 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:56:03.422
    Oct  3 20:56:03.422: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename var-expansion 10/03/22 20:56:03.423
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:56:03.47
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:56:03.481
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Oct  3 20:56:03.524: INFO: Waiting up to 2m0s for pod "var-expansion-3881d5cc-f1f9-4c38-a497-bc37f1ffef68" in namespace "var-expansion-7672" to be "container 0 failed with reason CreateContainerConfigError"
    Oct  3 20:56:03.539: INFO: Pod "var-expansion-3881d5cc-f1f9-4c38-a497-bc37f1ffef68": Phase="Pending", Reason="", readiness=false. Elapsed: 15.673099ms
    Oct  3 20:56:05.555: INFO: Pod "var-expansion-3881d5cc-f1f9-4c38-a497-bc37f1ffef68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03127803s
    Oct  3 20:56:05.555: INFO: Pod "var-expansion-3881d5cc-f1f9-4c38-a497-bc37f1ffef68" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Oct  3 20:56:05.555: INFO: Deleting pod "var-expansion-3881d5cc-f1f9-4c38-a497-bc37f1ffef68" in namespace "var-expansion-7672"
    Oct  3 20:56:05.581: INFO: Wait up to 5m0s for pod "var-expansion-3881d5cc-f1f9-4c38-a497-bc37f1ffef68" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Oct  3 20:56:09.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7672" for this suite. 10/03/22 20:56:09.639
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:56:09.667
Oct  3 20:56:09.667: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename replicaset 10/03/22 20:56:09.668
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:56:09.71
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:56:09.721
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Oct  3 20:56:09.780: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct  3 20:56:14.794: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 10/03/22 20:56:14.794
STEP: Scaling up "test-rs" replicaset  10/03/22 20:56:14.795
Oct  3 20:56:14.832: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 10/03/22 20:56:14.832
W1003 20:56:14.883861      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Oct  3 20:56:14.888: INFO: observed ReplicaSet test-rs in namespace replicaset-9987 with ReadyReplicas 1, AvailableReplicas 1
Oct  3 20:56:14.904: INFO: observed ReplicaSet test-rs in namespace replicaset-9987 with ReadyReplicas 1, AvailableReplicas 1
Oct  3 20:56:14.914: INFO: observed ReplicaSet test-rs in namespace replicaset-9987 with ReadyReplicas 1, AvailableReplicas 1
Oct  3 20:56:17.088: INFO: observed ReplicaSet test-rs in namespace replicaset-9987 with ReadyReplicas 2, AvailableReplicas 2
Oct  3 20:56:17.227: INFO: observed Replicaset test-rs in namespace replicaset-9987 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Oct  3 20:56:17.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9987" for this suite. 10/03/22 20:56:17.244
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":314,"skipped":5940,"failed":0}
------------------------------
• [SLOW TEST] [7.602 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:56:09.667
    Oct  3 20:56:09.667: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename replicaset 10/03/22 20:56:09.668
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:56:09.71
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:56:09.721
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Oct  3 20:56:09.780: INFO: Pod name sample-pod: Found 0 pods out of 1
    Oct  3 20:56:14.794: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 10/03/22 20:56:14.794
    STEP: Scaling up "test-rs" replicaset  10/03/22 20:56:14.795
    Oct  3 20:56:14.832: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 10/03/22 20:56:14.832
    W1003 20:56:14.883861      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Oct  3 20:56:14.888: INFO: observed ReplicaSet test-rs in namespace replicaset-9987 with ReadyReplicas 1, AvailableReplicas 1
    Oct  3 20:56:14.904: INFO: observed ReplicaSet test-rs in namespace replicaset-9987 with ReadyReplicas 1, AvailableReplicas 1
    Oct  3 20:56:14.914: INFO: observed ReplicaSet test-rs in namespace replicaset-9987 with ReadyReplicas 1, AvailableReplicas 1
    Oct  3 20:56:17.088: INFO: observed ReplicaSet test-rs in namespace replicaset-9987 with ReadyReplicas 2, AvailableReplicas 2
    Oct  3 20:56:17.227: INFO: observed Replicaset test-rs in namespace replicaset-9987 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Oct  3 20:56:17.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9987" for this suite. 10/03/22 20:56:17.244
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:56:17.273
Oct  3 20:56:17.273: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename gc 10/03/22 20:56:17.274
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:56:17.324
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:56:17.334
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 10/03/22 20:56:17.364
STEP: create the rc2 10/03/22 20:56:17.379
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 10/03/22 20:56:22.412
STEP: delete the rc simpletest-rc-to-be-deleted 10/03/22 20:56:23.834
STEP: wait for the rc to be deleted 10/03/22 20:56:23.86
STEP: Gathering metrics 10/03/22 20:56:28.958
W1003 20:56:29.083697      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Oct  3 20:56:29.083: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Oct  3 20:56:29.084: INFO: Deleting pod "simpletest-rc-to-be-deleted-25m2r" in namespace "gc-5123"
Oct  3 20:56:29.144: INFO: Deleting pod "simpletest-rc-to-be-deleted-2bjt4" in namespace "gc-5123"
Oct  3 20:56:29.183: INFO: Deleting pod "simpletest-rc-to-be-deleted-2lfdc" in namespace "gc-5123"
Oct  3 20:56:29.318: INFO: Deleting pod "simpletest-rc-to-be-deleted-2lp9q" in namespace "gc-5123"
Oct  3 20:56:29.382: INFO: Deleting pod "simpletest-rc-to-be-deleted-2ls49" in namespace "gc-5123"
Oct  3 20:56:29.432: INFO: Deleting pod "simpletest-rc-to-be-deleted-2nq9z" in namespace "gc-5123"
Oct  3 20:56:29.505: INFO: Deleting pod "simpletest-rc-to-be-deleted-2vcsn" in namespace "gc-5123"
Oct  3 20:56:29.544: INFO: Deleting pod "simpletest-rc-to-be-deleted-2zh4n" in namespace "gc-5123"
Oct  3 20:56:29.581: INFO: Deleting pod "simpletest-rc-to-be-deleted-48xnd" in namespace "gc-5123"
Oct  3 20:56:29.634: INFO: Deleting pod "simpletest-rc-to-be-deleted-4f5s4" in namespace "gc-5123"
Oct  3 20:56:29.761: INFO: Deleting pod "simpletest-rc-to-be-deleted-4zq9k" in namespace "gc-5123"
Oct  3 20:56:29.812: INFO: Deleting pod "simpletest-rc-to-be-deleted-5dnxx" in namespace "gc-5123"
Oct  3 20:56:29.864: INFO: Deleting pod "simpletest-rc-to-be-deleted-5s9nv" in namespace "gc-5123"
Oct  3 20:56:29.902: INFO: Deleting pod "simpletest-rc-to-be-deleted-5vkr8" in namespace "gc-5123"
Oct  3 20:56:29.947: INFO: Deleting pod "simpletest-rc-to-be-deleted-5zpdf" in namespace "gc-5123"
Oct  3 20:56:30.040: INFO: Deleting pod "simpletest-rc-to-be-deleted-6kvz8" in namespace "gc-5123"
Oct  3 20:56:30.085: INFO: Deleting pod "simpletest-rc-to-be-deleted-6mnkv" in namespace "gc-5123"
Oct  3 20:56:30.161: INFO: Deleting pod "simpletest-rc-to-be-deleted-6rk6r" in namespace "gc-5123"
Oct  3 20:56:30.229: INFO: Deleting pod "simpletest-rc-to-be-deleted-6swfp" in namespace "gc-5123"
Oct  3 20:56:30.305: INFO: Deleting pod "simpletest-rc-to-be-deleted-6tkvp" in namespace "gc-5123"
Oct  3 20:56:30.373: INFO: Deleting pod "simpletest-rc-to-be-deleted-6tkxp" in namespace "gc-5123"
Oct  3 20:56:30.424: INFO: Deleting pod "simpletest-rc-to-be-deleted-6v95l" in namespace "gc-5123"
Oct  3 20:56:30.511: INFO: Deleting pod "simpletest-rc-to-be-deleted-74j87" in namespace "gc-5123"
Oct  3 20:56:30.558: INFO: Deleting pod "simpletest-rc-to-be-deleted-78ggt" in namespace "gc-5123"
Oct  3 20:56:30.601: INFO: Deleting pod "simpletest-rc-to-be-deleted-7lqlk" in namespace "gc-5123"
Oct  3 20:56:30.638: INFO: Deleting pod "simpletest-rc-to-be-deleted-89prt" in namespace "gc-5123"
Oct  3 20:56:30.714: INFO: Deleting pod "simpletest-rc-to-be-deleted-8gbtq" in namespace "gc-5123"
Oct  3 20:56:30.814: INFO: Deleting pod "simpletest-rc-to-be-deleted-9brjl" in namespace "gc-5123"
Oct  3 20:56:30.881: INFO: Deleting pod "simpletest-rc-to-be-deleted-9c2xs" in namespace "gc-5123"
Oct  3 20:56:30.964: INFO: Deleting pod "simpletest-rc-to-be-deleted-9kfcs" in namespace "gc-5123"
Oct  3 20:56:31.033: INFO: Deleting pod "simpletest-rc-to-be-deleted-9mw8w" in namespace "gc-5123"
Oct  3 20:56:31.089: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qfhk" in namespace "gc-5123"
Oct  3 20:56:31.128: INFO: Deleting pod "simpletest-rc-to-be-deleted-9r7qx" in namespace "gc-5123"
Oct  3 20:56:31.186: INFO: Deleting pod "simpletest-rc-to-be-deleted-bcmc5" in namespace "gc-5123"
Oct  3 20:56:31.232: INFO: Deleting pod "simpletest-rc-to-be-deleted-bj86s" in namespace "gc-5123"
Oct  3 20:56:31.274: INFO: Deleting pod "simpletest-rc-to-be-deleted-bjnj4" in namespace "gc-5123"
Oct  3 20:56:31.318: INFO: Deleting pod "simpletest-rc-to-be-deleted-bl9ct" in namespace "gc-5123"
Oct  3 20:56:31.388: INFO: Deleting pod "simpletest-rc-to-be-deleted-c2pj2" in namespace "gc-5123"
Oct  3 20:56:31.437: INFO: Deleting pod "simpletest-rc-to-be-deleted-c4hgx" in namespace "gc-5123"
Oct  3 20:56:31.506: INFO: Deleting pod "simpletest-rc-to-be-deleted-c92pp" in namespace "gc-5123"
Oct  3 20:56:31.573: INFO: Deleting pod "simpletest-rc-to-be-deleted-cdw4n" in namespace "gc-5123"
Oct  3 20:56:31.625: INFO: Deleting pod "simpletest-rc-to-be-deleted-cjrnt" in namespace "gc-5123"
Oct  3 20:56:31.714: INFO: Deleting pod "simpletest-rc-to-be-deleted-d225d" in namespace "gc-5123"
Oct  3 20:56:31.761: INFO: Deleting pod "simpletest-rc-to-be-deleted-f9lpb" in namespace "gc-5123"
Oct  3 20:56:31.801: INFO: Deleting pod "simpletest-rc-to-be-deleted-fx7mg" in namespace "gc-5123"
Oct  3 20:56:31.854: INFO: Deleting pod "simpletest-rc-to-be-deleted-g2fkk" in namespace "gc-5123"
Oct  3 20:56:31.907: INFO: Deleting pod "simpletest-rc-to-be-deleted-g57dh" in namespace "gc-5123"
Oct  3 20:56:31.945: INFO: Deleting pod "simpletest-rc-to-be-deleted-g84zt" in namespace "gc-5123"
Oct  3 20:56:31.993: INFO: Deleting pod "simpletest-rc-to-be-deleted-g9wld" in namespace "gc-5123"
Oct  3 20:56:32.031: INFO: Deleting pod "simpletest-rc-to-be-deleted-gcsn7" in namespace "gc-5123"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Oct  3 20:56:32.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5123" for this suite. 10/03/22 20:56:32.143
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":315,"skipped":5960,"failed":0}
------------------------------
• [SLOW TEST] [14.899 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:56:17.273
    Oct  3 20:56:17.273: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename gc 10/03/22 20:56:17.274
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:56:17.324
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:56:17.334
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 10/03/22 20:56:17.364
    STEP: create the rc2 10/03/22 20:56:17.379
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 10/03/22 20:56:22.412
    STEP: delete the rc simpletest-rc-to-be-deleted 10/03/22 20:56:23.834
    STEP: wait for the rc to be deleted 10/03/22 20:56:23.86
    STEP: Gathering metrics 10/03/22 20:56:28.958
    W1003 20:56:29.083697      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Oct  3 20:56:29.083: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Oct  3 20:56:29.084: INFO: Deleting pod "simpletest-rc-to-be-deleted-25m2r" in namespace "gc-5123"
    Oct  3 20:56:29.144: INFO: Deleting pod "simpletest-rc-to-be-deleted-2bjt4" in namespace "gc-5123"
    Oct  3 20:56:29.183: INFO: Deleting pod "simpletest-rc-to-be-deleted-2lfdc" in namespace "gc-5123"
    Oct  3 20:56:29.318: INFO: Deleting pod "simpletest-rc-to-be-deleted-2lp9q" in namespace "gc-5123"
    Oct  3 20:56:29.382: INFO: Deleting pod "simpletest-rc-to-be-deleted-2ls49" in namespace "gc-5123"
    Oct  3 20:56:29.432: INFO: Deleting pod "simpletest-rc-to-be-deleted-2nq9z" in namespace "gc-5123"
    Oct  3 20:56:29.505: INFO: Deleting pod "simpletest-rc-to-be-deleted-2vcsn" in namespace "gc-5123"
    Oct  3 20:56:29.544: INFO: Deleting pod "simpletest-rc-to-be-deleted-2zh4n" in namespace "gc-5123"
    Oct  3 20:56:29.581: INFO: Deleting pod "simpletest-rc-to-be-deleted-48xnd" in namespace "gc-5123"
    Oct  3 20:56:29.634: INFO: Deleting pod "simpletest-rc-to-be-deleted-4f5s4" in namespace "gc-5123"
    Oct  3 20:56:29.761: INFO: Deleting pod "simpletest-rc-to-be-deleted-4zq9k" in namespace "gc-5123"
    Oct  3 20:56:29.812: INFO: Deleting pod "simpletest-rc-to-be-deleted-5dnxx" in namespace "gc-5123"
    Oct  3 20:56:29.864: INFO: Deleting pod "simpletest-rc-to-be-deleted-5s9nv" in namespace "gc-5123"
    Oct  3 20:56:29.902: INFO: Deleting pod "simpletest-rc-to-be-deleted-5vkr8" in namespace "gc-5123"
    Oct  3 20:56:29.947: INFO: Deleting pod "simpletest-rc-to-be-deleted-5zpdf" in namespace "gc-5123"
    Oct  3 20:56:30.040: INFO: Deleting pod "simpletest-rc-to-be-deleted-6kvz8" in namespace "gc-5123"
    Oct  3 20:56:30.085: INFO: Deleting pod "simpletest-rc-to-be-deleted-6mnkv" in namespace "gc-5123"
    Oct  3 20:56:30.161: INFO: Deleting pod "simpletest-rc-to-be-deleted-6rk6r" in namespace "gc-5123"
    Oct  3 20:56:30.229: INFO: Deleting pod "simpletest-rc-to-be-deleted-6swfp" in namespace "gc-5123"
    Oct  3 20:56:30.305: INFO: Deleting pod "simpletest-rc-to-be-deleted-6tkvp" in namespace "gc-5123"
    Oct  3 20:56:30.373: INFO: Deleting pod "simpletest-rc-to-be-deleted-6tkxp" in namespace "gc-5123"
    Oct  3 20:56:30.424: INFO: Deleting pod "simpletest-rc-to-be-deleted-6v95l" in namespace "gc-5123"
    Oct  3 20:56:30.511: INFO: Deleting pod "simpletest-rc-to-be-deleted-74j87" in namespace "gc-5123"
    Oct  3 20:56:30.558: INFO: Deleting pod "simpletest-rc-to-be-deleted-78ggt" in namespace "gc-5123"
    Oct  3 20:56:30.601: INFO: Deleting pod "simpletest-rc-to-be-deleted-7lqlk" in namespace "gc-5123"
    Oct  3 20:56:30.638: INFO: Deleting pod "simpletest-rc-to-be-deleted-89prt" in namespace "gc-5123"
    Oct  3 20:56:30.714: INFO: Deleting pod "simpletest-rc-to-be-deleted-8gbtq" in namespace "gc-5123"
    Oct  3 20:56:30.814: INFO: Deleting pod "simpletest-rc-to-be-deleted-9brjl" in namespace "gc-5123"
    Oct  3 20:56:30.881: INFO: Deleting pod "simpletest-rc-to-be-deleted-9c2xs" in namespace "gc-5123"
    Oct  3 20:56:30.964: INFO: Deleting pod "simpletest-rc-to-be-deleted-9kfcs" in namespace "gc-5123"
    Oct  3 20:56:31.033: INFO: Deleting pod "simpletest-rc-to-be-deleted-9mw8w" in namespace "gc-5123"
    Oct  3 20:56:31.089: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qfhk" in namespace "gc-5123"
    Oct  3 20:56:31.128: INFO: Deleting pod "simpletest-rc-to-be-deleted-9r7qx" in namespace "gc-5123"
    Oct  3 20:56:31.186: INFO: Deleting pod "simpletest-rc-to-be-deleted-bcmc5" in namespace "gc-5123"
    Oct  3 20:56:31.232: INFO: Deleting pod "simpletest-rc-to-be-deleted-bj86s" in namespace "gc-5123"
    Oct  3 20:56:31.274: INFO: Deleting pod "simpletest-rc-to-be-deleted-bjnj4" in namespace "gc-5123"
    Oct  3 20:56:31.318: INFO: Deleting pod "simpletest-rc-to-be-deleted-bl9ct" in namespace "gc-5123"
    Oct  3 20:56:31.388: INFO: Deleting pod "simpletest-rc-to-be-deleted-c2pj2" in namespace "gc-5123"
    Oct  3 20:56:31.437: INFO: Deleting pod "simpletest-rc-to-be-deleted-c4hgx" in namespace "gc-5123"
    Oct  3 20:56:31.506: INFO: Deleting pod "simpletest-rc-to-be-deleted-c92pp" in namespace "gc-5123"
    Oct  3 20:56:31.573: INFO: Deleting pod "simpletest-rc-to-be-deleted-cdw4n" in namespace "gc-5123"
    Oct  3 20:56:31.625: INFO: Deleting pod "simpletest-rc-to-be-deleted-cjrnt" in namespace "gc-5123"
    Oct  3 20:56:31.714: INFO: Deleting pod "simpletest-rc-to-be-deleted-d225d" in namespace "gc-5123"
    Oct  3 20:56:31.761: INFO: Deleting pod "simpletest-rc-to-be-deleted-f9lpb" in namespace "gc-5123"
    Oct  3 20:56:31.801: INFO: Deleting pod "simpletest-rc-to-be-deleted-fx7mg" in namespace "gc-5123"
    Oct  3 20:56:31.854: INFO: Deleting pod "simpletest-rc-to-be-deleted-g2fkk" in namespace "gc-5123"
    Oct  3 20:56:31.907: INFO: Deleting pod "simpletest-rc-to-be-deleted-g57dh" in namespace "gc-5123"
    Oct  3 20:56:31.945: INFO: Deleting pod "simpletest-rc-to-be-deleted-g84zt" in namespace "gc-5123"
    Oct  3 20:56:31.993: INFO: Deleting pod "simpletest-rc-to-be-deleted-g9wld" in namespace "gc-5123"
    Oct  3 20:56:32.031: INFO: Deleting pod "simpletest-rc-to-be-deleted-gcsn7" in namespace "gc-5123"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Oct  3 20:56:32.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5123" for this suite. 10/03/22 20:56:32.143
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:56:32.178
Oct  3 20:56:32.178: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename hostport 10/03/22 20:56:32.18
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:56:32.232
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:56:32.252
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 10/03/22 20:56:32.285
Oct  3 20:56:32.315: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-8230" to be "running and ready"
Oct  3 20:56:32.332: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.599923ms
Oct  3 20:56:32.332: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:56:34.359: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044472298s
Oct  3 20:56:34.359: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:56:36.351: INFO: Pod "pod1": Phase="Running", Reason="", readiness=false. Elapsed: 4.036637044s
Oct  3 20:56:36.351: INFO: The phase of Pod pod1 is Running (Ready = false)
Oct  3 20:56:38.348: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 6.033662677s
Oct  3 20:56:38.348: INFO: The phase of Pod pod1 is Running (Ready = true)
Oct  3 20:56:38.348: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.63.128.13 on the node which pod1 resides and expect scheduled 10/03/22 20:56:38.348
Oct  3 20:56:38.364: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-8230" to be "running and ready"
Oct  3 20:56:38.437: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 73.29602ms
Oct  3 20:56:38.438: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:56:40.453: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0892699s
Oct  3 20:56:40.453: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:56:42.456: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.091967616s
Oct  3 20:56:42.456: INFO: The phase of Pod pod2 is Running (Ready = true)
Oct  3 20:56:42.456: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.63.128.13 but use UDP protocol on the node which pod2 resides 10/03/22 20:56:42.456
Oct  3 20:56:42.478: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-8230" to be "running and ready"
Oct  3 20:56:42.518: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 39.929304ms
Oct  3 20:56:42.518: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:56:44.533: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.055152687s
Oct  3 20:56:44.533: INFO: The phase of Pod pod3 is Running (Ready = true)
Oct  3 20:56:44.533: INFO: Pod "pod3" satisfied condition "running and ready"
Oct  3 20:56:44.552: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-8230" to be "running and ready"
Oct  3 20:56:44.566: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 14.634203ms
Oct  3 20:56:44.566: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:56:46.582: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.030398291s
Oct  3 20:56:46.582: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Oct  3 20:56:46.582: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 10/03/22 20:56:46.596
Oct  3 20:56:46.596: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.63.128.13 http://127.0.0.1:54323/hostname] Namespace:hostport-8230 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:56:46.596: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:56:46.597: INFO: ExecWithOptions: Clientset creation
Oct  3 20:56:46.597: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-8230/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.63.128.13+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.63.128.13, port: 54323 10/03/22 20:56:46.784
Oct  3 20:56:46.785: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.63.128.13:54323/hostname] Namespace:hostport-8230 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:56:46.785: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:56:46.786: INFO: ExecWithOptions: Clientset creation
Oct  3 20:56:46.787: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-8230/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.63.128.13%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.63.128.13, port: 54323 UDP 10/03/22 20:56:46.95
Oct  3 20:56:46.950: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.63.128.13 54323] Namespace:hostport-8230 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct  3 20:56:46.951: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
Oct  3 20:56:46.952: INFO: ExecWithOptions: Clientset creation
Oct  3 20:56:46.952: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-8230/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.63.128.13+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Oct  3 20:56:52.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-8230" for this suite. 10/03/22 20:56:52.15
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":316,"skipped":5967,"failed":0}
------------------------------
• [SLOW TEST] [19.995 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:56:32.178
    Oct  3 20:56:32.178: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename hostport 10/03/22 20:56:32.18
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:56:32.232
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:56:32.252
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 10/03/22 20:56:32.285
    Oct  3 20:56:32.315: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-8230" to be "running and ready"
    Oct  3 20:56:32.332: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.599923ms
    Oct  3 20:56:32.332: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:56:34.359: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044472298s
    Oct  3 20:56:34.359: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:56:36.351: INFO: Pod "pod1": Phase="Running", Reason="", readiness=false. Elapsed: 4.036637044s
    Oct  3 20:56:36.351: INFO: The phase of Pod pod1 is Running (Ready = false)
    Oct  3 20:56:38.348: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 6.033662677s
    Oct  3 20:56:38.348: INFO: The phase of Pod pod1 is Running (Ready = true)
    Oct  3 20:56:38.348: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.63.128.13 on the node which pod1 resides and expect scheduled 10/03/22 20:56:38.348
    Oct  3 20:56:38.364: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-8230" to be "running and ready"
    Oct  3 20:56:38.437: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 73.29602ms
    Oct  3 20:56:38.438: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:56:40.453: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0892699s
    Oct  3 20:56:40.453: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:56:42.456: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.091967616s
    Oct  3 20:56:42.456: INFO: The phase of Pod pod2 is Running (Ready = true)
    Oct  3 20:56:42.456: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.63.128.13 but use UDP protocol on the node which pod2 resides 10/03/22 20:56:42.456
    Oct  3 20:56:42.478: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-8230" to be "running and ready"
    Oct  3 20:56:42.518: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 39.929304ms
    Oct  3 20:56:42.518: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:56:44.533: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.055152687s
    Oct  3 20:56:44.533: INFO: The phase of Pod pod3 is Running (Ready = true)
    Oct  3 20:56:44.533: INFO: Pod "pod3" satisfied condition "running and ready"
    Oct  3 20:56:44.552: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-8230" to be "running and ready"
    Oct  3 20:56:44.566: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 14.634203ms
    Oct  3 20:56:44.566: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:56:46.582: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.030398291s
    Oct  3 20:56:46.582: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Oct  3 20:56:46.582: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 10/03/22 20:56:46.596
    Oct  3 20:56:46.596: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.63.128.13 http://127.0.0.1:54323/hostname] Namespace:hostport-8230 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:56:46.596: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:56:46.597: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:56:46.597: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-8230/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.63.128.13+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.63.128.13, port: 54323 10/03/22 20:56:46.784
    Oct  3 20:56:46.785: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.63.128.13:54323/hostname] Namespace:hostport-8230 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:56:46.785: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:56:46.786: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:56:46.787: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-8230/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.63.128.13%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.63.128.13, port: 54323 UDP 10/03/22 20:56:46.95
    Oct  3 20:56:46.950: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.63.128.13 54323] Namespace:hostport-8230 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct  3 20:56:46.951: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    Oct  3 20:56:46.952: INFO: ExecWithOptions: Clientset creation
    Oct  3 20:56:46.952: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-8230/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.63.128.13+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Oct  3 20:56:52.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-8230" for this suite. 10/03/22 20:56:52.15
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:56:52.176
Oct  3 20:56:52.176: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename sched-pred 10/03/22 20:56:52.178
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:56:52.227
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:56:52.238
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Oct  3 20:56:52.249: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  3 20:56:52.318: INFO: Waiting for terminating namespaces to be deleted...
Oct  3 20:56:52.334: INFO: 
Logging pods the apiserver thinks is on node 10.63.128.13 before test
Oct  3 20:56:52.379: INFO: e2e-host-exec from hostport-8230 started at 2022-10-03 20:56:44 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.379: INFO: 	Container e2e-host-exec ready: true, restart count 0
Oct  3 20:56:52.379: INFO: pod1 from hostport-8230 started at 2022-10-03 20:56:32 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.379: INFO: 	Container agnhost ready: true, restart count 0
Oct  3 20:56:52.379: INFO: pod2 from hostport-8230 started at 2022-10-03 20:56:38 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.379: INFO: 	Container agnhost ready: true, restart count 0
Oct  3 20:56:52.379: INFO: pod3 from hostport-8230 started at 2022-10-03 20:56:42 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.379: INFO: 	Container agnhost ready: true, restart count 0
Oct  3 20:56:52.379: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-5lm6l from ibm-system started at 2022-10-03 17:16:04 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.379: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
Oct  3 20:56:52.379: INFO: calico-node-zpr9s from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.379: INFO: 	Container calico-node ready: true, restart count 0
Oct  3 20:56:52.379: INFO: calico-typha-644fdcd5f-w67fp from kube-system started at 2022-10-03 17:11:18 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.379: INFO: 	Container calico-typha ready: true, restart count 0
Oct  3 20:56:52.379: INFO: coredns-6754846f95-bl2wt from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.379: INFO: 	Container coredns ready: true, restart count 0
Oct  3 20:56:52.379: INFO: ibm-keepalived-watcher-nw2l6 from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.379: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  3 20:56:52.379: INFO: ibm-master-proxy-static-10.63.128.13 from kube-system started at 2022-10-03 17:10:55 +0000 UTC (2 container statuses recorded)
Oct  3 20:56:52.379: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct  3 20:56:52.379: INFO: 	Container pause ready: true, restart count 0
Oct  3 20:56:52.379: INFO: ibmcloud-block-storage-driver-f5thb from kube-system started at 2022-10-03 17:11:06 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.379: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct  3 20:56:52.379: INFO: ingress-cluster-healthcheck-6dbd7f8d47-vx87x from kube-system started at 2022-10-03 18:44:30 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.379: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Oct  3 20:56:52.379: INFO: konnectivity-agent-qv9fn from kube-system started at 2022-10-03 17:19:11 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.379: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct  3 20:56:52.379: INFO: metrics-server-668b4d7ddd-7glct from kube-system started at 2022-10-03 17:55:22 +0000 UTC (3 container statuses recorded)
Oct  3 20:56:52.379: INFO: 	Container config-watcher ready: true, restart count 0
Oct  3 20:56:52.379: INFO: 	Container metrics-server ready: true, restart count 0
Oct  3 20:56:52.379: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct  3 20:56:52.379: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-7vk57 from kube-system started at 2022-10-03 19:52:24 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.379: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct  3 20:56:52.379: INFO: sonobuoy-e2e-job-2c5abccdc00d487c from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 20:56:52.380: INFO: 	Container e2e ready: true, restart count 0
Oct  3 20:56:52.380: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 20:56:52.380: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-cwlqc from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 20:56:52.380: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 20:56:52.380: INFO: 	Container systemd-logs ready: true, restart count 0
Oct  3 20:56:52.380: INFO: 
Logging pods the apiserver thinks is on node 10.63.128.3 before test
Oct  3 20:56:52.420: INFO: calico-node-zrfj4 from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.420: INFO: 	Container calico-node ready: true, restart count 0
Oct  3 20:56:52.420: INFO: calico-typha-644fdcd5f-rskkx from kube-system started at 2022-10-03 20:20:28 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.420: INFO: 	Container calico-typha ready: true, restart count 0
Oct  3 20:56:52.420: INFO: ibm-keepalived-watcher-jr7cc from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.420: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  3 20:56:52.420: INFO: ibm-master-proxy-static-10.63.128.3 from kube-system started at 2022-10-03 17:10:52 +0000 UTC (2 container statuses recorded)
Oct  3 20:56:52.420: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct  3 20:56:52.420: INFO: 	Container pause ready: true, restart count 0
Oct  3 20:56:52.420: INFO: ibmcloud-block-storage-driver-j765w from kube-system started at 2022-10-03 17:11:13 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.420: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct  3 20:56:52.420: INFO: konnectivity-agent-n5jcf from kube-system started at 2022-10-03 17:19:17 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.420: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct  3 20:56:52.420: INFO: sonobuoy from sonobuoy started at 2022-10-03 19:13:32 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.420: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  3 20:56:52.420: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-lpx2r from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 20:56:52.420: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 20:56:52.420: INFO: 	Container systemd-logs ready: true, restart count 0
Oct  3 20:56:52.420: INFO: 
Logging pods the apiserver thinks is on node 10.63.128.51 before test
Oct  3 20:56:52.469: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-6mpp7 from ibm-system started at 2022-10-03 19:20:52 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
Oct  3 20:56:52.469: INFO: calico-kube-controllers-5ccfdf4b6d-qxssd from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct  3 20:56:52.469: INFO: calico-node-zfv55 from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container calico-node ready: true, restart count 0
Oct  3 20:56:52.469: INFO: calico-typha-644fdcd5f-7qcns from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container calico-typha ready: true, restart count 0
Oct  3 20:56:52.469: INFO: coredns-6754846f95-9q5kh from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container coredns ready: true, restart count 0
Oct  3 20:56:52.469: INFO: coredns-6754846f95-c7x4x from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container coredns ready: true, restart count 0
Oct  3 20:56:52.469: INFO: coredns-autoscaler-669cf746f6-wwqwh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container autoscaler ready: true, restart count 0
Oct  3 20:56:52.469: INFO: dashboard-metrics-scraper-c964d5594-bvc48 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Oct  3 20:56:52.469: INFO: ibm-file-plugin-bdf4f476-5nc82 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct  3 20:56:52.469: INFO: ibm-keepalived-watcher-8t2hv from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  3 20:56:52.469: INFO: ibm-master-proxy-static-10.63.128.51 from kube-system started at 2022-10-03 17:10:31 +0000 UTC (2 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct  3 20:56:52.469: INFO: 	Container pause ready: true, restart count 0
Oct  3 20:56:52.469: INFO: ibm-storage-watcher-64fb9cdcfc-bsg7k from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct  3 20:56:52.469: INFO: ibmcloud-block-storage-driver-fdv2t from kube-system started at 2022-10-03 17:10:51 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct  3 20:56:52.469: INFO: ibmcloud-block-storage-plugin-7c4cfb55cb-72zmh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Oct  3 20:56:52.469: INFO: konnectivity-agent-lc67p from kube-system started at 2022-10-03 17:19:14 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct  3 20:56:52.469: INFO: kubernetes-dashboard-55c4d56798-qwrbg from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct  3 20:56:52.469: INFO: metrics-server-668b4d7ddd-mpnsv from kube-system started at 2022-10-03 19:20:52 +0000 UTC (3 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container config-watcher ready: true, restart count 0
Oct  3 20:56:52.469: INFO: 	Container metrics-server ready: true, restart count 0
Oct  3 20:56:52.469: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct  3 20:56:52.469: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-cc7hf from kube-system started at 2022-10-03 20:20:26 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct  3 20:56:52.469: INFO: snapshot-controller-c5c6dddff-2mxr6 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct  3 20:56:52.469: INFO: snapshot-controller-c5c6dddff-m6kpt from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct  3 20:56:52.469: INFO: snapshot-controller-c5c6dddff-wjxf9 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct  3 20:56:52.469: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-z8psd from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 20:56:52.469: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 20:56:52.469: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 10/03/22 20:56:52.469
Oct  3 20:56:52.499: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-6733" to be "running"
Oct  3 20:56:52.513: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 13.538767ms
Oct  3 20:56:54.529: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029268756s
Oct  3 20:56:56.527: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.027480214s
Oct  3 20:56:56.527: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 10/03/22 20:56:56.54
STEP: Trying to apply a random label on the found node. 10/03/22 20:56:56.583
STEP: verifying the node has the label kubernetes.io/e2e-4bad413b-5f79-49f6-bc20-77706cec3a8e 42 10/03/22 20:56:56.617
STEP: Trying to relaunch the pod, now with labels. 10/03/22 20:56:56.66
Oct  3 20:56:56.677: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-6733" to be "not pending"
Oct  3 20:56:56.688: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 10.906499ms
Oct  3 20:56:58.710: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.032405046s
Oct  3 20:56:58.710: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-4bad413b-5f79-49f6-bc20-77706cec3a8e off the node 10.63.128.3 10/03/22 20:56:58.729
STEP: verifying the node doesn't have the label kubernetes.io/e2e-4bad413b-5f79-49f6-bc20-77706cec3a8e 10/03/22 20:56:58.796
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Oct  3 20:56:58.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6733" for this suite. 10/03/22 20:56:58.849
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":317,"skipped":5977,"failed":0}
------------------------------
• [SLOW TEST] [6.698 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:56:52.176
    Oct  3 20:56:52.176: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename sched-pred 10/03/22 20:56:52.178
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:56:52.227
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:56:52.238
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Oct  3 20:56:52.249: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Oct  3 20:56:52.318: INFO: Waiting for terminating namespaces to be deleted...
    Oct  3 20:56:52.334: INFO: 
    Logging pods the apiserver thinks is on node 10.63.128.13 before test
    Oct  3 20:56:52.379: INFO: e2e-host-exec from hostport-8230 started at 2022-10-03 20:56:44 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.379: INFO: 	Container e2e-host-exec ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: pod1 from hostport-8230 started at 2022-10-03 20:56:32 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.379: INFO: 	Container agnhost ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: pod2 from hostport-8230 started at 2022-10-03 20:56:38 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.379: INFO: 	Container agnhost ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: pod3 from hostport-8230 started at 2022-10-03 20:56:42 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.379: INFO: 	Container agnhost ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-5lm6l from ibm-system started at 2022-10-03 17:16:04 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.379: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: calico-node-zpr9s from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.379: INFO: 	Container calico-node ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: calico-typha-644fdcd5f-w67fp from kube-system started at 2022-10-03 17:11:18 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.379: INFO: 	Container calico-typha ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: coredns-6754846f95-bl2wt from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.379: INFO: 	Container coredns ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: ibm-keepalived-watcher-nw2l6 from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.379: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: ibm-master-proxy-static-10.63.128.13 from kube-system started at 2022-10-03 17:10:55 +0000 UTC (2 container statuses recorded)
    Oct  3 20:56:52.379: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: 	Container pause ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: ibmcloud-block-storage-driver-f5thb from kube-system started at 2022-10-03 17:11:06 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.379: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: ingress-cluster-healthcheck-6dbd7f8d47-vx87x from kube-system started at 2022-10-03 18:44:30 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.379: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: konnectivity-agent-qv9fn from kube-system started at 2022-10-03 17:19:11 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.379: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: metrics-server-668b4d7ddd-7glct from kube-system started at 2022-10-03 17:55:22 +0000 UTC (3 container statuses recorded)
    Oct  3 20:56:52.379: INFO: 	Container config-watcher ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: 	Container metrics-server ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-7vk57 from kube-system started at 2022-10-03 19:52:24 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.379: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct  3 20:56:52.379: INFO: sonobuoy-e2e-job-2c5abccdc00d487c from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 20:56:52.380: INFO: 	Container e2e ready: true, restart count 0
    Oct  3 20:56:52.380: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 20:56:52.380: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-cwlqc from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 20:56:52.380: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 20:56:52.380: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct  3 20:56:52.380: INFO: 
    Logging pods the apiserver thinks is on node 10.63.128.3 before test
    Oct  3 20:56:52.420: INFO: calico-node-zrfj4 from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.420: INFO: 	Container calico-node ready: true, restart count 0
    Oct  3 20:56:52.420: INFO: calico-typha-644fdcd5f-rskkx from kube-system started at 2022-10-03 20:20:28 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.420: INFO: 	Container calico-typha ready: true, restart count 0
    Oct  3 20:56:52.420: INFO: ibm-keepalived-watcher-jr7cc from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.420: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct  3 20:56:52.420: INFO: ibm-master-proxy-static-10.63.128.3 from kube-system started at 2022-10-03 17:10:52 +0000 UTC (2 container statuses recorded)
    Oct  3 20:56:52.420: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct  3 20:56:52.420: INFO: 	Container pause ready: true, restart count 0
    Oct  3 20:56:52.420: INFO: ibmcloud-block-storage-driver-j765w from kube-system started at 2022-10-03 17:11:13 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.420: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct  3 20:56:52.420: INFO: konnectivity-agent-n5jcf from kube-system started at 2022-10-03 17:19:17 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.420: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct  3 20:56:52.420: INFO: sonobuoy from sonobuoy started at 2022-10-03 19:13:32 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.420: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Oct  3 20:56:52.420: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-lpx2r from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 20:56:52.420: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 20:56:52.420: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct  3 20:56:52.420: INFO: 
    Logging pods the apiserver thinks is on node 10.63.128.51 before test
    Oct  3 20:56:52.469: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-6mpp7 from ibm-system started at 2022-10-03 19:20:52 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: calico-kube-controllers-5ccfdf4b6d-qxssd from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: calico-node-zfv55 from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container calico-node ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: calico-typha-644fdcd5f-7qcns from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container calico-typha ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: coredns-6754846f95-9q5kh from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container coredns ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: coredns-6754846f95-c7x4x from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container coredns ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: coredns-autoscaler-669cf746f6-wwqwh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container autoscaler ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: dashboard-metrics-scraper-c964d5594-bvc48 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: ibm-file-plugin-bdf4f476-5nc82 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: ibm-keepalived-watcher-8t2hv from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: ibm-master-proxy-static-10.63.128.51 from kube-system started at 2022-10-03 17:10:31 +0000 UTC (2 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: 	Container pause ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: ibm-storage-watcher-64fb9cdcfc-bsg7k from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: ibmcloud-block-storage-driver-fdv2t from kube-system started at 2022-10-03 17:10:51 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: ibmcloud-block-storage-plugin-7c4cfb55cb-72zmh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: konnectivity-agent-lc67p from kube-system started at 2022-10-03 17:19:14 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: kubernetes-dashboard-55c4d56798-qwrbg from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: metrics-server-668b4d7ddd-mpnsv from kube-system started at 2022-10-03 19:20:52 +0000 UTC (3 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container config-watcher ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: 	Container metrics-server ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-cc7hf from kube-system started at 2022-10-03 20:20:26 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: snapshot-controller-c5c6dddff-2mxr6 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: snapshot-controller-c5c6dddff-m6kpt from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: snapshot-controller-c5c6dddff-wjxf9 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-z8psd from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 20:56:52.469: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 20:56:52.469: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 10/03/22 20:56:52.469
    Oct  3 20:56:52.499: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-6733" to be "running"
    Oct  3 20:56:52.513: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 13.538767ms
    Oct  3 20:56:54.529: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029268756s
    Oct  3 20:56:56.527: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.027480214s
    Oct  3 20:56:56.527: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 10/03/22 20:56:56.54
    STEP: Trying to apply a random label on the found node. 10/03/22 20:56:56.583
    STEP: verifying the node has the label kubernetes.io/e2e-4bad413b-5f79-49f6-bc20-77706cec3a8e 42 10/03/22 20:56:56.617
    STEP: Trying to relaunch the pod, now with labels. 10/03/22 20:56:56.66
    Oct  3 20:56:56.677: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-6733" to be "not pending"
    Oct  3 20:56:56.688: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 10.906499ms
    Oct  3 20:56:58.710: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.032405046s
    Oct  3 20:56:58.710: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-4bad413b-5f79-49f6-bc20-77706cec3a8e off the node 10.63.128.3 10/03/22 20:56:58.729
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-4bad413b-5f79-49f6-bc20-77706cec3a8e 10/03/22 20:56:58.796
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 20:56:58.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-6733" for this suite. 10/03/22 20:56:58.849
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:56:58.877
Oct  3 20:56:58.877: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename deployment 10/03/22 20:56:58.879
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:56:58.925
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:56:58.936
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Oct  3 20:56:58.976: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct  3 20:57:03.995: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 10/03/22 20:57:03.995
Oct  3 20:57:03.995: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 10/03/22 20:57:04.031
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct  3 20:57:08.103: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-7070  cd0456f8-99ce-49b4-a955-4fde27d95131 44419 1 2022-10-03 20:57:04 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-10-03 20:57:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:57:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004928988 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-10-03 20:57:04 +0000 UTC,LastTransitionTime:2022-10-03 20:57:04 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2022-10-03 20:57:06 +0000 UTC,LastTransitionTime:2022-10-03 20:57:04 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct  3 20:57:08.116: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-7070  629650d9-aab8-4b7c-9152-5a6ddb6d248c 44409 1 2022-10-03 20:57:04 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment cd0456f8-99ce-49b4-a955-4fde27d95131 0xc004928ef7 0xc004928ef8}] [] [{kube-controller-manager Update apps/v1 2022-10-03 20:57:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cd0456f8-99ce-49b4-a955-4fde27d95131\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:57:06 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004928fe8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct  3 20:57:08.130: INFO: Pod "test-cleanup-deployment-69cb9c5497-pqkzk" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-pqkzk test-cleanup-deployment-69cb9c5497- deployment-7070  e43f0219-19b2-4d38-86e9-bdd0a10eaab9 44408 0 2022-10-03 20:57:04 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:c7b52a6f169179f31d0701b87118c17e0a5881ec018efff3a66344188b480a1b cni.projectcalico.org/podIP:172.30.49.14/32 cni.projectcalico.org/podIPs:172.30.49.14/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 629650d9-aab8-4b7c-9152-5a6ddb6d248c 0xc0042589d7 0xc0042589d8}] [] [{kube-controller-manager Update v1 2022-10-03 20:57:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"629650d9-aab8-4b7c-9152-5a6ddb6d248c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 20:57:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 20:57:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.14\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rwf2w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rwf2w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:57:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:57:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:57:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:57:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.14,StartTime:2022-10-03 20:57:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 20:57:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://566c784d90e2875e75827c0c105f06741c1a8d5464acbc952f4c3dace7350475,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.14,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Oct  3 20:57:08.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7070" for this suite. 10/03/22 20:57:08.179
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":318,"skipped":5979,"failed":0}
------------------------------
• [SLOW TEST] [9.328 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:56:58.877
    Oct  3 20:56:58.877: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename deployment 10/03/22 20:56:58.879
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:56:58.925
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:56:58.936
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Oct  3 20:56:58.976: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Oct  3 20:57:03.995: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 10/03/22 20:57:03.995
    Oct  3 20:57:03.995: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 10/03/22 20:57:04.031
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct  3 20:57:08.103: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-7070  cd0456f8-99ce-49b4-a955-4fde27d95131 44419 1 2022-10-03 20:57:04 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-10-03 20:57:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:57:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004928988 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-10-03 20:57:04 +0000 UTC,LastTransitionTime:2022-10-03 20:57:04 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2022-10-03 20:57:06 +0000 UTC,LastTransitionTime:2022-10-03 20:57:04 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Oct  3 20:57:08.116: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-7070  629650d9-aab8-4b7c-9152-5a6ddb6d248c 44409 1 2022-10-03 20:57:04 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment cd0456f8-99ce-49b4-a955-4fde27d95131 0xc004928ef7 0xc004928ef8}] [] [{kube-controller-manager Update apps/v1 2022-10-03 20:57:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cd0456f8-99ce-49b4-a955-4fde27d95131\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 20:57:06 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004928fe8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Oct  3 20:57:08.130: INFO: Pod "test-cleanup-deployment-69cb9c5497-pqkzk" is available:
    &Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-pqkzk test-cleanup-deployment-69cb9c5497- deployment-7070  e43f0219-19b2-4d38-86e9-bdd0a10eaab9 44408 0 2022-10-03 20:57:04 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:c7b52a6f169179f31d0701b87118c17e0a5881ec018efff3a66344188b480a1b cni.projectcalico.org/podIP:172.30.49.14/32 cni.projectcalico.org/podIPs:172.30.49.14/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 629650d9-aab8-4b7c-9152-5a6ddb6d248c 0xc0042589d7 0xc0042589d8}] [] [{kube-controller-manager Update v1 2022-10-03 20:57:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"629650d9-aab8-4b7c-9152-5a6ddb6d248c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-10-03 20:57:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-03 20:57:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.49.14\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rwf2w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rwf2w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:57:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:57:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:57:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 20:57:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:172.30.49.14,StartTime:2022-10-03 20:57:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-03 20:57:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://566c784d90e2875e75827c0c105f06741c1a8d5464acbc952f4c3dace7350475,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.49.14,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Oct  3 20:57:08.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7070" for this suite. 10/03/22 20:57:08.179
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:57:08.207
Oct  3 20:57:08.207: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 20:57:08.208
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:57:08.256
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:57:08.267
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 10/03/22 20:57:08.279
Oct  3 20:57:08.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9890 api-versions'
Oct  3 20:57:08.377: INFO: stderr: ""
Oct  3 20:57:08.377: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nibm.com/v1alpha1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 20:57:08.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9890" for this suite. 10/03/22 20:57:08.4
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":319,"skipped":5993,"failed":0}
------------------------------
• [0.218 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:57:08.207
    Oct  3 20:57:08.207: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 20:57:08.208
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:57:08.256
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:57:08.267
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 10/03/22 20:57:08.279
    Oct  3 20:57:08.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-9890 api-versions'
    Oct  3 20:57:08.377: INFO: stderr: ""
    Oct  3 20:57:08.377: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nibm.com/v1alpha1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 20:57:08.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9890" for this suite. 10/03/22 20:57:08.4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:57:08.432
Oct  3 20:57:08.433: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename resourcequota 10/03/22 20:57:08.434
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:57:08.479
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:57:08.491
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 10/03/22 20:57:08.5
STEP: Creating a ResourceQuota 10/03/22 20:57:13.514
STEP: Ensuring resource quota status is calculated 10/03/22 20:57:13.531
STEP: Creating a ReplicationController 10/03/22 20:57:15.548
STEP: Ensuring resource quota status captures replication controller creation 10/03/22 20:57:15.58
STEP: Deleting a ReplicationController 10/03/22 20:57:17.594
STEP: Ensuring resource quota status released usage 10/03/22 20:57:17.611
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Oct  3 20:57:19.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2001" for this suite. 10/03/22 20:57:19.647
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":320,"skipped":6051,"failed":0}
------------------------------
• [SLOW TEST] [11.240 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:57:08.432
    Oct  3 20:57:08.433: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename resourcequota 10/03/22 20:57:08.434
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:57:08.479
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:57:08.491
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 10/03/22 20:57:08.5
    STEP: Creating a ResourceQuota 10/03/22 20:57:13.514
    STEP: Ensuring resource quota status is calculated 10/03/22 20:57:13.531
    STEP: Creating a ReplicationController 10/03/22 20:57:15.548
    STEP: Ensuring resource quota status captures replication controller creation 10/03/22 20:57:15.58
    STEP: Deleting a ReplicationController 10/03/22 20:57:17.594
    STEP: Ensuring resource quota status released usage 10/03/22 20:57:17.611
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Oct  3 20:57:19.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2001" for this suite. 10/03/22 20:57:19.647
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:57:19.675
Oct  3 20:57:19.675: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 20:57:19.676
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:57:19.737
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:57:19.748
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 20:57:19.803
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:57:20.36
STEP: Deploying the webhook pod 10/03/22 20:57:20.388
STEP: Wait for the deployment to be ready 10/03/22 20:57:20.422
Oct  3 20:57:20.447: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Oct  3 20:57:22.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 20, 57, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 57, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 20, 57, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 57, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 10/03/22 20:57:24.501
STEP: Verifying the service has paired with the endpoint 10/03/22 20:57:24.531
Oct  3 20:57:25.532: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 10/03/22 20:57:25.543
STEP: create a pod 10/03/22 20:57:25.64
Oct  3 20:57:25.670: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-247" to be "running"
Oct  3 20:57:25.682: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.451377ms
Oct  3 20:57:27.703: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033477082s
Oct  3 20:57:29.698: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.028276247s
Oct  3 20:57:29.698: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 10/03/22 20:57:29.698
Oct  3 20:57:29.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=webhook-247 attach --namespace=webhook-247 to-be-attached-pod -i -c=container1'
Oct  3 20:57:29.853: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 20:57:29.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-247" for this suite. 10/03/22 20:57:29.889
STEP: Destroying namespace "webhook-247-markers" for this suite. 10/03/22 20:57:29.912
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":321,"skipped":6072,"failed":0}
------------------------------
• [SLOW TEST] [10.394 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:57:19.675
    Oct  3 20:57:19.675: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 20:57:19.676
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:57:19.737
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:57:19.748
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 20:57:19.803
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 20:57:20.36
    STEP: Deploying the webhook pod 10/03/22 20:57:20.388
    STEP: Wait for the deployment to be ready 10/03/22 20:57:20.422
    Oct  3 20:57:20.447: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Oct  3 20:57:22.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 20, 57, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 57, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 20, 57, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 20, 57, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 10/03/22 20:57:24.501
    STEP: Verifying the service has paired with the endpoint 10/03/22 20:57:24.531
    Oct  3 20:57:25.532: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 10/03/22 20:57:25.543
    STEP: create a pod 10/03/22 20:57:25.64
    Oct  3 20:57:25.670: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-247" to be "running"
    Oct  3 20:57:25.682: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.451377ms
    Oct  3 20:57:27.703: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033477082s
    Oct  3 20:57:29.698: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.028276247s
    Oct  3 20:57:29.698: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 10/03/22 20:57:29.698
    Oct  3 20:57:29.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=webhook-247 attach --namespace=webhook-247 to-be-attached-pod -i -c=container1'
    Oct  3 20:57:29.853: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 20:57:29.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-247" for this suite. 10/03/22 20:57:29.889
    STEP: Destroying namespace "webhook-247-markers" for this suite. 10/03/22 20:57:29.912
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:57:30.071
Oct  3 20:57:30.071: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename configmap 10/03/22 20:57:30.072
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:57:30.129
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:57:30.14
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-2720/configmap-test-34615820-939d-4b15-b11f-94bb11f2ff0d 10/03/22 20:57:30.151
STEP: Creating a pod to test consume configMaps 10/03/22 20:57:30.163
Oct  3 20:57:30.191: INFO: Waiting up to 5m0s for pod "pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8" in namespace "configmap-2720" to be "Succeeded or Failed"
Oct  3 20:57:30.203: INFO: Pod "pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.549728ms
Oct  3 20:57:32.218: INFO: Pod "pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8": Phase="Running", Reason="", readiness=true. Elapsed: 2.026957467s
Oct  3 20:57:34.220: INFO: Pod "pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8": Phase="Running", Reason="", readiness=false. Elapsed: 4.029529552s
Oct  3 20:57:36.218: INFO: Pod "pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027490225s
STEP: Saw pod success 10/03/22 20:57:36.218
Oct  3 20:57:36.219: INFO: Pod "pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8" satisfied condition "Succeeded or Failed"
Oct  3 20:57:36.234: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8 container env-test: <nil>
STEP: delete the pod 10/03/22 20:57:36.317
Oct  3 20:57:36.360: INFO: Waiting for pod pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8 to disappear
Oct  3 20:57:36.373: INFO: Pod pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Oct  3 20:57:36.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2720" for this suite. 10/03/22 20:57:36.389
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":322,"skipped":6105,"failed":0}
------------------------------
• [SLOW TEST] [6.341 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:57:30.071
    Oct  3 20:57:30.071: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename configmap 10/03/22 20:57:30.072
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:57:30.129
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:57:30.14
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-2720/configmap-test-34615820-939d-4b15-b11f-94bb11f2ff0d 10/03/22 20:57:30.151
    STEP: Creating a pod to test consume configMaps 10/03/22 20:57:30.163
    Oct  3 20:57:30.191: INFO: Waiting up to 5m0s for pod "pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8" in namespace "configmap-2720" to be "Succeeded or Failed"
    Oct  3 20:57:30.203: INFO: Pod "pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.549728ms
    Oct  3 20:57:32.218: INFO: Pod "pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8": Phase="Running", Reason="", readiness=true. Elapsed: 2.026957467s
    Oct  3 20:57:34.220: INFO: Pod "pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8": Phase="Running", Reason="", readiness=false. Elapsed: 4.029529552s
    Oct  3 20:57:36.218: INFO: Pod "pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027490225s
    STEP: Saw pod success 10/03/22 20:57:36.218
    Oct  3 20:57:36.219: INFO: Pod "pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8" satisfied condition "Succeeded or Failed"
    Oct  3 20:57:36.234: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8 container env-test: <nil>
    STEP: delete the pod 10/03/22 20:57:36.317
    Oct  3 20:57:36.360: INFO: Waiting for pod pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8 to disappear
    Oct  3 20:57:36.373: INFO: Pod pod-configmaps-1afd2210-66b7-49cd-b899-2c771d4603b8 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Oct  3 20:57:36.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2720" for this suite. 10/03/22 20:57:36.389
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:57:36.415
Oct  3 20:57:36.415: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename replication-controller 10/03/22 20:57:36.417
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:57:36.46
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:57:36.476
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 10/03/22 20:57:36.488
STEP: When the matched label of one of its pods change 10/03/22 20:57:36.503
Oct  3 20:57:36.515: INFO: Pod name pod-release: Found 0 pods out of 1
Oct  3 20:57:41.530: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 10/03/22 20:57:41.562
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Oct  3 20:57:41.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8126" for this suite. 10/03/22 20:57:41.593
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":323,"skipped":6112,"failed":0}
------------------------------
• [SLOW TEST] [5.200 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:57:36.415
    Oct  3 20:57:36.415: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename replication-controller 10/03/22 20:57:36.417
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:57:36.46
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:57:36.476
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 10/03/22 20:57:36.488
    STEP: When the matched label of one of its pods change 10/03/22 20:57:36.503
    Oct  3 20:57:36.515: INFO: Pod name pod-release: Found 0 pods out of 1
    Oct  3 20:57:41.530: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 10/03/22 20:57:41.562
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Oct  3 20:57:41.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-8126" for this suite. 10/03/22 20:57:41.593
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:57:41.616
Oct  3 20:57:41.617: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename gc 10/03/22 20:57:41.619
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:57:41.659
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:57:41.671
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 10/03/22 20:57:41.703
STEP: delete the rc 10/03/22 20:57:46.731
STEP: wait for the rc to be deleted 10/03/22 20:57:46.748
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 10/03/22 20:57:51.764
STEP: Gathering metrics 10/03/22 20:58:21.808
W1003 20:58:21.875077      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Oct  3 20:58:21.875: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Oct  3 20:58:21.875: INFO: Deleting pod "simpletest.rc-29nxh" in namespace "gc-7613"
Oct  3 20:58:21.913: INFO: Deleting pod "simpletest.rc-2b2nl" in namespace "gc-7613"
Oct  3 20:58:21.948: INFO: Deleting pod "simpletest.rc-2k8f6" in namespace "gc-7613"
Oct  3 20:58:22.045: INFO: Deleting pod "simpletest.rc-49r5p" in namespace "gc-7613"
Oct  3 20:58:22.085: INFO: Deleting pod "simpletest.rc-4cwht" in namespace "gc-7613"
Oct  3 20:58:22.137: INFO: Deleting pod "simpletest.rc-4lfgb" in namespace "gc-7613"
Oct  3 20:58:22.171: INFO: Deleting pod "simpletest.rc-4r7gm" in namespace "gc-7613"
Oct  3 20:58:22.215: INFO: Deleting pod "simpletest.rc-58gr9" in namespace "gc-7613"
Oct  3 20:58:22.252: INFO: Deleting pod "simpletest.rc-59zqr" in namespace "gc-7613"
Oct  3 20:58:22.285: INFO: Deleting pod "simpletest.rc-5b9cv" in namespace "gc-7613"
Oct  3 20:58:22.318: INFO: Deleting pod "simpletest.rc-5dnd5" in namespace "gc-7613"
Oct  3 20:58:22.359: INFO: Deleting pod "simpletest.rc-5rshg" in namespace "gc-7613"
Oct  3 20:58:22.414: INFO: Deleting pod "simpletest.rc-699bh" in namespace "gc-7613"
Oct  3 20:58:22.448: INFO: Deleting pod "simpletest.rc-75q9v" in namespace "gc-7613"
Oct  3 20:58:22.510: INFO: Deleting pod "simpletest.rc-7d4pw" in namespace "gc-7613"
Oct  3 20:58:22.563: INFO: Deleting pod "simpletest.rc-7dpr9" in namespace "gc-7613"
Oct  3 20:58:22.597: INFO: Deleting pod "simpletest.rc-7gsmz" in namespace "gc-7613"
Oct  3 20:58:22.672: INFO: Deleting pod "simpletest.rc-7zwsp" in namespace "gc-7613"
Oct  3 20:58:22.715: INFO: Deleting pod "simpletest.rc-846gj" in namespace "gc-7613"
Oct  3 20:58:22.759: INFO: Deleting pod "simpletest.rc-8c77d" in namespace "gc-7613"
Oct  3 20:58:22.792: INFO: Deleting pod "simpletest.rc-8d2w6" in namespace "gc-7613"
Oct  3 20:58:22.842: INFO: Deleting pod "simpletest.rc-8mtzj" in namespace "gc-7613"
Oct  3 20:58:22.891: INFO: Deleting pod "simpletest.rc-97t9p" in namespace "gc-7613"
Oct  3 20:58:22.930: INFO: Deleting pod "simpletest.rc-9n4kv" in namespace "gc-7613"
Oct  3 20:58:22.995: INFO: Deleting pod "simpletest.rc-9njxx" in namespace "gc-7613"
Oct  3 20:58:23.051: INFO: Deleting pod "simpletest.rc-9npq5" in namespace "gc-7613"
Oct  3 20:58:23.092: INFO: Deleting pod "simpletest.rc-9nt5n" in namespace "gc-7613"
Oct  3 20:58:23.130: INFO: Deleting pod "simpletest.rc-9zf4d" in namespace "gc-7613"
Oct  3 20:58:23.187: INFO: Deleting pod "simpletest.rc-b768s" in namespace "gc-7613"
Oct  3 20:58:23.230: INFO: Deleting pod "simpletest.rc-b9fb4" in namespace "gc-7613"
Oct  3 20:58:23.267: INFO: Deleting pod "simpletest.rc-bc26b" in namespace "gc-7613"
Oct  3 20:58:23.315: INFO: Deleting pod "simpletest.rc-bm95g" in namespace "gc-7613"
Oct  3 20:58:23.366: INFO: Deleting pod "simpletest.rc-bmd8v" in namespace "gc-7613"
Oct  3 20:58:23.414: INFO: Deleting pod "simpletest.rc-cflzt" in namespace "gc-7613"
Oct  3 20:58:23.456: INFO: Deleting pod "simpletest.rc-clg47" in namespace "gc-7613"
Oct  3 20:58:23.511: INFO: Deleting pod "simpletest.rc-cnhrn" in namespace "gc-7613"
Oct  3 20:58:23.561: INFO: Deleting pod "simpletest.rc-d96dx" in namespace "gc-7613"
Oct  3 20:58:23.594: INFO: Deleting pod "simpletest.rc-drjhp" in namespace "gc-7613"
Oct  3 20:58:23.651: INFO: Deleting pod "simpletest.rc-f4jg7" in namespace "gc-7613"
Oct  3 20:58:23.691: INFO: Deleting pod "simpletest.rc-fdgcn" in namespace "gc-7613"
Oct  3 20:58:23.734: INFO: Deleting pod "simpletest.rc-fjljr" in namespace "gc-7613"
Oct  3 20:58:23.774: INFO: Deleting pod "simpletest.rc-fmgbf" in namespace "gc-7613"
Oct  3 20:58:23.810: INFO: Deleting pod "simpletest.rc-fp6b9" in namespace "gc-7613"
Oct  3 20:58:23.880: INFO: Deleting pod "simpletest.rc-g82dw" in namespace "gc-7613"
Oct  3 20:58:23.931: INFO: Deleting pod "simpletest.rc-gngfq" in namespace "gc-7613"
Oct  3 20:58:23.978: INFO: Deleting pod "simpletest.rc-gtd6t" in namespace "gc-7613"
Oct  3 20:58:24.017: INFO: Deleting pod "simpletest.rc-gttx5" in namespace "gc-7613"
Oct  3 20:58:24.065: INFO: Deleting pod "simpletest.rc-hrstp" in namespace "gc-7613"
Oct  3 20:58:24.114: INFO: Deleting pod "simpletest.rc-j58f5" in namespace "gc-7613"
Oct  3 20:58:24.155: INFO: Deleting pod "simpletest.rc-j5kjv" in namespace "gc-7613"
Oct  3 20:58:24.187: INFO: Deleting pod "simpletest.rc-k8wfq" in namespace "gc-7613"
Oct  3 20:58:24.227: INFO: Deleting pod "simpletest.rc-ktwks" in namespace "gc-7613"
Oct  3 20:58:24.272: INFO: Deleting pod "simpletest.rc-kxpfw" in namespace "gc-7613"
Oct  3 20:58:24.321: INFO: Deleting pod "simpletest.rc-kzmrp" in namespace "gc-7613"
Oct  3 20:58:24.360: INFO: Deleting pod "simpletest.rc-m6s6n" in namespace "gc-7613"
Oct  3 20:58:24.428: INFO: Deleting pod "simpletest.rc-m7z7w" in namespace "gc-7613"
Oct  3 20:58:24.474: INFO: Deleting pod "simpletest.rc-mhthw" in namespace "gc-7613"
Oct  3 20:58:24.515: INFO: Deleting pod "simpletest.rc-mn75n" in namespace "gc-7613"
Oct  3 20:58:24.550: INFO: Deleting pod "simpletest.rc-n5gd2" in namespace "gc-7613"
Oct  3 20:58:24.632: INFO: Deleting pod "simpletest.rc-n7kcv" in namespace "gc-7613"
Oct  3 20:58:24.677: INFO: Deleting pod "simpletest.rc-n7vmj" in namespace "gc-7613"
Oct  3 20:58:24.727: INFO: Deleting pod "simpletest.rc-n9j8t" in namespace "gc-7613"
Oct  3 20:58:24.775: INFO: Deleting pod "simpletest.rc-nbrtt" in namespace "gc-7613"
Oct  3 20:58:24.822: INFO: Deleting pod "simpletest.rc-ngjhm" in namespace "gc-7613"
Oct  3 20:58:24.891: INFO: Deleting pod "simpletest.rc-nlztd" in namespace "gc-7613"
Oct  3 20:58:25.005: INFO: Deleting pod "simpletest.rc-nmsz6" in namespace "gc-7613"
Oct  3 20:58:25.051: INFO: Deleting pod "simpletest.rc-nr5jr" in namespace "gc-7613"
Oct  3 20:58:25.110: INFO: Deleting pod "simpletest.rc-p5rbt" in namespace "gc-7613"
Oct  3 20:58:25.153: INFO: Deleting pod "simpletest.rc-pjgn9" in namespace "gc-7613"
Oct  3 20:58:25.210: INFO: Deleting pod "simpletest.rc-pjmst" in namespace "gc-7613"
Oct  3 20:58:25.249: INFO: Deleting pod "simpletest.rc-ptwht" in namespace "gc-7613"
Oct  3 20:58:25.293: INFO: Deleting pod "simpletest.rc-qp9f7" in namespace "gc-7613"
Oct  3 20:58:25.348: INFO: Deleting pod "simpletest.rc-qxvfl" in namespace "gc-7613"
Oct  3 20:58:25.409: INFO: Deleting pod "simpletest.rc-r6gdp" in namespace "gc-7613"
Oct  3 20:58:25.450: INFO: Deleting pod "simpletest.rc-rd6km" in namespace "gc-7613"
Oct  3 20:58:25.485: INFO: Deleting pod "simpletest.rc-rjpr8" in namespace "gc-7613"
Oct  3 20:58:25.521: INFO: Deleting pod "simpletest.rc-rzlxx" in namespace "gc-7613"
Oct  3 20:58:25.578: INFO: Deleting pod "simpletest.rc-skl88" in namespace "gc-7613"
Oct  3 20:58:25.642: INFO: Deleting pod "simpletest.rc-sxpwt" in namespace "gc-7613"
Oct  3 20:58:25.697: INFO: Deleting pod "simpletest.rc-t6rh7" in namespace "gc-7613"
Oct  3 20:58:25.765: INFO: Deleting pod "simpletest.rc-t7ltt" in namespace "gc-7613"
Oct  3 20:58:25.802: INFO: Deleting pod "simpletest.rc-tfs9q" in namespace "gc-7613"
Oct  3 20:58:25.845: INFO: Deleting pod "simpletest.rc-tv42s" in namespace "gc-7613"
Oct  3 20:58:25.877: INFO: Deleting pod "simpletest.rc-tw4ts" in namespace "gc-7613"
Oct  3 20:58:25.918: INFO: Deleting pod "simpletest.rc-v59jz" in namespace "gc-7613"
Oct  3 20:58:25.964: INFO: Deleting pod "simpletest.rc-vb644" in namespace "gc-7613"
Oct  3 20:58:26.007: INFO: Deleting pod "simpletest.rc-vz2vt" in namespace "gc-7613"
Oct  3 20:58:26.057: INFO: Deleting pod "simpletest.rc-wfnkh" in namespace "gc-7613"
Oct  3 20:58:26.095: INFO: Deleting pod "simpletest.rc-wvtbz" in namespace "gc-7613"
Oct  3 20:58:26.143: INFO: Deleting pod "simpletest.rc-wwzqx" in namespace "gc-7613"
Oct  3 20:58:26.189: INFO: Deleting pod "simpletest.rc-x274d" in namespace "gc-7613"
Oct  3 20:58:26.254: INFO: Deleting pod "simpletest.rc-xmp2v" in namespace "gc-7613"
Oct  3 20:58:26.348: INFO: Deleting pod "simpletest.rc-xwzkg" in namespace "gc-7613"
Oct  3 20:58:26.390: INFO: Deleting pod "simpletest.rc-z9lp8" in namespace "gc-7613"
Oct  3 20:58:26.432: INFO: Deleting pod "simpletest.rc-zd72r" in namespace "gc-7613"
Oct  3 20:58:26.479: INFO: Deleting pod "simpletest.rc-zjg27" in namespace "gc-7613"
Oct  3 20:58:26.560: INFO: Deleting pod "simpletest.rc-zl45f" in namespace "gc-7613"
Oct  3 20:58:26.636: INFO: Deleting pod "simpletest.rc-zqb86" in namespace "gc-7613"
Oct  3 20:58:26.688: INFO: Deleting pod "simpletest.rc-zsrgq" in namespace "gc-7613"
Oct  3 20:58:26.741: INFO: Deleting pod "simpletest.rc-zwpmh" in namespace "gc-7613"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Oct  3 20:58:26.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7613" for this suite. 10/03/22 20:58:26.805
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":324,"skipped":6115,"failed":0}
------------------------------
• [SLOW TEST] [45.227 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:57:41.616
    Oct  3 20:57:41.617: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename gc 10/03/22 20:57:41.619
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:57:41.659
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:57:41.671
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 10/03/22 20:57:41.703
    STEP: delete the rc 10/03/22 20:57:46.731
    STEP: wait for the rc to be deleted 10/03/22 20:57:46.748
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 10/03/22 20:57:51.764
    STEP: Gathering metrics 10/03/22 20:58:21.808
    W1003 20:58:21.875077      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Oct  3 20:58:21.875: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Oct  3 20:58:21.875: INFO: Deleting pod "simpletest.rc-29nxh" in namespace "gc-7613"
    Oct  3 20:58:21.913: INFO: Deleting pod "simpletest.rc-2b2nl" in namespace "gc-7613"
    Oct  3 20:58:21.948: INFO: Deleting pod "simpletest.rc-2k8f6" in namespace "gc-7613"
    Oct  3 20:58:22.045: INFO: Deleting pod "simpletest.rc-49r5p" in namespace "gc-7613"
    Oct  3 20:58:22.085: INFO: Deleting pod "simpletest.rc-4cwht" in namespace "gc-7613"
    Oct  3 20:58:22.137: INFO: Deleting pod "simpletest.rc-4lfgb" in namespace "gc-7613"
    Oct  3 20:58:22.171: INFO: Deleting pod "simpletest.rc-4r7gm" in namespace "gc-7613"
    Oct  3 20:58:22.215: INFO: Deleting pod "simpletest.rc-58gr9" in namespace "gc-7613"
    Oct  3 20:58:22.252: INFO: Deleting pod "simpletest.rc-59zqr" in namespace "gc-7613"
    Oct  3 20:58:22.285: INFO: Deleting pod "simpletest.rc-5b9cv" in namespace "gc-7613"
    Oct  3 20:58:22.318: INFO: Deleting pod "simpletest.rc-5dnd5" in namespace "gc-7613"
    Oct  3 20:58:22.359: INFO: Deleting pod "simpletest.rc-5rshg" in namespace "gc-7613"
    Oct  3 20:58:22.414: INFO: Deleting pod "simpletest.rc-699bh" in namespace "gc-7613"
    Oct  3 20:58:22.448: INFO: Deleting pod "simpletest.rc-75q9v" in namespace "gc-7613"
    Oct  3 20:58:22.510: INFO: Deleting pod "simpletest.rc-7d4pw" in namespace "gc-7613"
    Oct  3 20:58:22.563: INFO: Deleting pod "simpletest.rc-7dpr9" in namespace "gc-7613"
    Oct  3 20:58:22.597: INFO: Deleting pod "simpletest.rc-7gsmz" in namespace "gc-7613"
    Oct  3 20:58:22.672: INFO: Deleting pod "simpletest.rc-7zwsp" in namespace "gc-7613"
    Oct  3 20:58:22.715: INFO: Deleting pod "simpletest.rc-846gj" in namespace "gc-7613"
    Oct  3 20:58:22.759: INFO: Deleting pod "simpletest.rc-8c77d" in namespace "gc-7613"
    Oct  3 20:58:22.792: INFO: Deleting pod "simpletest.rc-8d2w6" in namespace "gc-7613"
    Oct  3 20:58:22.842: INFO: Deleting pod "simpletest.rc-8mtzj" in namespace "gc-7613"
    Oct  3 20:58:22.891: INFO: Deleting pod "simpletest.rc-97t9p" in namespace "gc-7613"
    Oct  3 20:58:22.930: INFO: Deleting pod "simpletest.rc-9n4kv" in namespace "gc-7613"
    Oct  3 20:58:22.995: INFO: Deleting pod "simpletest.rc-9njxx" in namespace "gc-7613"
    Oct  3 20:58:23.051: INFO: Deleting pod "simpletest.rc-9npq5" in namespace "gc-7613"
    Oct  3 20:58:23.092: INFO: Deleting pod "simpletest.rc-9nt5n" in namespace "gc-7613"
    Oct  3 20:58:23.130: INFO: Deleting pod "simpletest.rc-9zf4d" in namespace "gc-7613"
    Oct  3 20:58:23.187: INFO: Deleting pod "simpletest.rc-b768s" in namespace "gc-7613"
    Oct  3 20:58:23.230: INFO: Deleting pod "simpletest.rc-b9fb4" in namespace "gc-7613"
    Oct  3 20:58:23.267: INFO: Deleting pod "simpletest.rc-bc26b" in namespace "gc-7613"
    Oct  3 20:58:23.315: INFO: Deleting pod "simpletest.rc-bm95g" in namespace "gc-7613"
    Oct  3 20:58:23.366: INFO: Deleting pod "simpletest.rc-bmd8v" in namespace "gc-7613"
    Oct  3 20:58:23.414: INFO: Deleting pod "simpletest.rc-cflzt" in namespace "gc-7613"
    Oct  3 20:58:23.456: INFO: Deleting pod "simpletest.rc-clg47" in namespace "gc-7613"
    Oct  3 20:58:23.511: INFO: Deleting pod "simpletest.rc-cnhrn" in namespace "gc-7613"
    Oct  3 20:58:23.561: INFO: Deleting pod "simpletest.rc-d96dx" in namespace "gc-7613"
    Oct  3 20:58:23.594: INFO: Deleting pod "simpletest.rc-drjhp" in namespace "gc-7613"
    Oct  3 20:58:23.651: INFO: Deleting pod "simpletest.rc-f4jg7" in namespace "gc-7613"
    Oct  3 20:58:23.691: INFO: Deleting pod "simpletest.rc-fdgcn" in namespace "gc-7613"
    Oct  3 20:58:23.734: INFO: Deleting pod "simpletest.rc-fjljr" in namespace "gc-7613"
    Oct  3 20:58:23.774: INFO: Deleting pod "simpletest.rc-fmgbf" in namespace "gc-7613"
    Oct  3 20:58:23.810: INFO: Deleting pod "simpletest.rc-fp6b9" in namespace "gc-7613"
    Oct  3 20:58:23.880: INFO: Deleting pod "simpletest.rc-g82dw" in namespace "gc-7613"
    Oct  3 20:58:23.931: INFO: Deleting pod "simpletest.rc-gngfq" in namespace "gc-7613"
    Oct  3 20:58:23.978: INFO: Deleting pod "simpletest.rc-gtd6t" in namespace "gc-7613"
    Oct  3 20:58:24.017: INFO: Deleting pod "simpletest.rc-gttx5" in namespace "gc-7613"
    Oct  3 20:58:24.065: INFO: Deleting pod "simpletest.rc-hrstp" in namespace "gc-7613"
    Oct  3 20:58:24.114: INFO: Deleting pod "simpletest.rc-j58f5" in namespace "gc-7613"
    Oct  3 20:58:24.155: INFO: Deleting pod "simpletest.rc-j5kjv" in namespace "gc-7613"
    Oct  3 20:58:24.187: INFO: Deleting pod "simpletest.rc-k8wfq" in namespace "gc-7613"
    Oct  3 20:58:24.227: INFO: Deleting pod "simpletest.rc-ktwks" in namespace "gc-7613"
    Oct  3 20:58:24.272: INFO: Deleting pod "simpletest.rc-kxpfw" in namespace "gc-7613"
    Oct  3 20:58:24.321: INFO: Deleting pod "simpletest.rc-kzmrp" in namespace "gc-7613"
    Oct  3 20:58:24.360: INFO: Deleting pod "simpletest.rc-m6s6n" in namespace "gc-7613"
    Oct  3 20:58:24.428: INFO: Deleting pod "simpletest.rc-m7z7w" in namespace "gc-7613"
    Oct  3 20:58:24.474: INFO: Deleting pod "simpletest.rc-mhthw" in namespace "gc-7613"
    Oct  3 20:58:24.515: INFO: Deleting pod "simpletest.rc-mn75n" in namespace "gc-7613"
    Oct  3 20:58:24.550: INFO: Deleting pod "simpletest.rc-n5gd2" in namespace "gc-7613"
    Oct  3 20:58:24.632: INFO: Deleting pod "simpletest.rc-n7kcv" in namespace "gc-7613"
    Oct  3 20:58:24.677: INFO: Deleting pod "simpletest.rc-n7vmj" in namespace "gc-7613"
    Oct  3 20:58:24.727: INFO: Deleting pod "simpletest.rc-n9j8t" in namespace "gc-7613"
    Oct  3 20:58:24.775: INFO: Deleting pod "simpletest.rc-nbrtt" in namespace "gc-7613"
    Oct  3 20:58:24.822: INFO: Deleting pod "simpletest.rc-ngjhm" in namespace "gc-7613"
    Oct  3 20:58:24.891: INFO: Deleting pod "simpletest.rc-nlztd" in namespace "gc-7613"
    Oct  3 20:58:25.005: INFO: Deleting pod "simpletest.rc-nmsz6" in namespace "gc-7613"
    Oct  3 20:58:25.051: INFO: Deleting pod "simpletest.rc-nr5jr" in namespace "gc-7613"
    Oct  3 20:58:25.110: INFO: Deleting pod "simpletest.rc-p5rbt" in namespace "gc-7613"
    Oct  3 20:58:25.153: INFO: Deleting pod "simpletest.rc-pjgn9" in namespace "gc-7613"
    Oct  3 20:58:25.210: INFO: Deleting pod "simpletest.rc-pjmst" in namespace "gc-7613"
    Oct  3 20:58:25.249: INFO: Deleting pod "simpletest.rc-ptwht" in namespace "gc-7613"
    Oct  3 20:58:25.293: INFO: Deleting pod "simpletest.rc-qp9f7" in namespace "gc-7613"
    Oct  3 20:58:25.348: INFO: Deleting pod "simpletest.rc-qxvfl" in namespace "gc-7613"
    Oct  3 20:58:25.409: INFO: Deleting pod "simpletest.rc-r6gdp" in namespace "gc-7613"
    Oct  3 20:58:25.450: INFO: Deleting pod "simpletest.rc-rd6km" in namespace "gc-7613"
    Oct  3 20:58:25.485: INFO: Deleting pod "simpletest.rc-rjpr8" in namespace "gc-7613"
    Oct  3 20:58:25.521: INFO: Deleting pod "simpletest.rc-rzlxx" in namespace "gc-7613"
    Oct  3 20:58:25.578: INFO: Deleting pod "simpletest.rc-skl88" in namespace "gc-7613"
    Oct  3 20:58:25.642: INFO: Deleting pod "simpletest.rc-sxpwt" in namespace "gc-7613"
    Oct  3 20:58:25.697: INFO: Deleting pod "simpletest.rc-t6rh7" in namespace "gc-7613"
    Oct  3 20:58:25.765: INFO: Deleting pod "simpletest.rc-t7ltt" in namespace "gc-7613"
    Oct  3 20:58:25.802: INFO: Deleting pod "simpletest.rc-tfs9q" in namespace "gc-7613"
    Oct  3 20:58:25.845: INFO: Deleting pod "simpletest.rc-tv42s" in namespace "gc-7613"
    Oct  3 20:58:25.877: INFO: Deleting pod "simpletest.rc-tw4ts" in namespace "gc-7613"
    Oct  3 20:58:25.918: INFO: Deleting pod "simpletest.rc-v59jz" in namespace "gc-7613"
    Oct  3 20:58:25.964: INFO: Deleting pod "simpletest.rc-vb644" in namespace "gc-7613"
    Oct  3 20:58:26.007: INFO: Deleting pod "simpletest.rc-vz2vt" in namespace "gc-7613"
    Oct  3 20:58:26.057: INFO: Deleting pod "simpletest.rc-wfnkh" in namespace "gc-7613"
    Oct  3 20:58:26.095: INFO: Deleting pod "simpletest.rc-wvtbz" in namespace "gc-7613"
    Oct  3 20:58:26.143: INFO: Deleting pod "simpletest.rc-wwzqx" in namespace "gc-7613"
    Oct  3 20:58:26.189: INFO: Deleting pod "simpletest.rc-x274d" in namespace "gc-7613"
    Oct  3 20:58:26.254: INFO: Deleting pod "simpletest.rc-xmp2v" in namespace "gc-7613"
    Oct  3 20:58:26.348: INFO: Deleting pod "simpletest.rc-xwzkg" in namespace "gc-7613"
    Oct  3 20:58:26.390: INFO: Deleting pod "simpletest.rc-z9lp8" in namespace "gc-7613"
    Oct  3 20:58:26.432: INFO: Deleting pod "simpletest.rc-zd72r" in namespace "gc-7613"
    Oct  3 20:58:26.479: INFO: Deleting pod "simpletest.rc-zjg27" in namespace "gc-7613"
    Oct  3 20:58:26.560: INFO: Deleting pod "simpletest.rc-zl45f" in namespace "gc-7613"
    Oct  3 20:58:26.636: INFO: Deleting pod "simpletest.rc-zqb86" in namespace "gc-7613"
    Oct  3 20:58:26.688: INFO: Deleting pod "simpletest.rc-zsrgq" in namespace "gc-7613"
    Oct  3 20:58:26.741: INFO: Deleting pod "simpletest.rc-zwpmh" in namespace "gc-7613"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Oct  3 20:58:26.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7613" for this suite. 10/03/22 20:58:26.805
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:58:26.845
Oct  3 20:58:26.846: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename resourcequota 10/03/22 20:58:26.848
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:58:26.905
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:58:26.917
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 10/03/22 20:58:26.933
STEP: Creating a ResourceQuota 10/03/22 20:58:31.947
STEP: Ensuring resource quota status is calculated 10/03/22 20:58:31.967
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Oct  3 20:58:33.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5152" for this suite. 10/03/22 20:58:34.003
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":325,"skipped":6126,"failed":0}
------------------------------
• [SLOW TEST] [7.181 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:58:26.845
    Oct  3 20:58:26.846: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename resourcequota 10/03/22 20:58:26.848
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:58:26.905
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:58:26.917
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 10/03/22 20:58:26.933
    STEP: Creating a ResourceQuota 10/03/22 20:58:31.947
    STEP: Ensuring resource quota status is calculated 10/03/22 20:58:31.967
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Oct  3 20:58:33.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5152" for this suite. 10/03/22 20:58:34.003
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:58:34.031
Oct  3 20:58:34.031: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename dns 10/03/22 20:58:34.032
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:58:34.077
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:58:34.088
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 10/03/22 20:58:34.1
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7816.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7816.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7816.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7816.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 46.9.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.9.46_udp@PTR;check="$$(dig +tcp +noall +answer +search 46.9.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.9.46_tcp@PTR;sleep 1; done
 10/03/22 20:58:34.149
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7816.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7816.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7816.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7816.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 46.9.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.9.46_udp@PTR;check="$$(dig +tcp +noall +answer +search 46.9.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.9.46_tcp@PTR;sleep 1; done
 10/03/22 20:58:34.149
STEP: creating a pod to probe DNS 10/03/22 20:58:34.149
STEP: submitting the pod to kubernetes 10/03/22 20:58:34.149
Oct  3 20:58:34.180: INFO: Waiting up to 15m0s for pod "dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5" in namespace "dns-7816" to be "running"
Oct  3 20:58:34.195: INFO: Pod "dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.70881ms
Oct  3 20:58:36.211: INFO: Pod "dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030301809s
Oct  3 20:58:38.210: INFO: Pod "dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5": Phase="Running", Reason="", readiness=true. Elapsed: 4.029364853s
Oct  3 20:58:38.210: INFO: Pod "dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5" satisfied condition "running"
STEP: retrieving the pod 10/03/22 20:58:38.21
STEP: looking for the results for each expected name from probers 10/03/22 20:58:38.224
Oct  3 20:58:38.296: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7816.svc.cluster.local from pod dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5: the server could not find the requested resource (get pods dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5)
Oct  3 20:58:38.316: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local from pod dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5: the server could not find the requested resource (get pods dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5)
Oct  3 20:58:38.431: INFO: Unable to read jessie_udp@dns-test-service.dns-7816.svc.cluster.local from pod dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5: the server could not find the requested resource (get pods dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5)
Oct  3 20:58:38.452: INFO: Unable to read jessie_tcp@dns-test-service.dns-7816.svc.cluster.local from pod dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5: the server could not find the requested resource (get pods dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5)
Oct  3 20:58:38.494: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local from pod dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5: the server could not find the requested resource (get pods dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5)
Oct  3 20:58:38.574: INFO: Lookups using dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5 failed for: [wheezy_tcp@dns-test-service.dns-7816.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local jessie_udp@dns-test-service.dns-7816.svc.cluster.local jessie_tcp@dns-test-service.dns-7816.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local]

Oct  3 20:58:43.639: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local from pod dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5: the server could not find the requested resource (get pods dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5)
Oct  3 20:58:43.936: INFO: Lookups using dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local]

Oct  3 20:58:48.882: INFO: DNS probes using dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5 succeeded

STEP: deleting the pod 10/03/22 20:58:48.883
STEP: deleting the test service 10/03/22 20:58:48.923
STEP: deleting the test headless service 10/03/22 20:58:48.97
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Oct  3 20:58:48.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7816" for this suite. 10/03/22 20:58:49.013
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":326,"skipped":6168,"failed":0}
------------------------------
• [SLOW TEST] [15.004 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:58:34.031
    Oct  3 20:58:34.031: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename dns 10/03/22 20:58:34.032
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:58:34.077
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:58:34.088
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 10/03/22 20:58:34.1
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7816.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7816.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7816.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7816.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 46.9.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.9.46_udp@PTR;check="$$(dig +tcp +noall +answer +search 46.9.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.9.46_tcp@PTR;sleep 1; done
     10/03/22 20:58:34.149
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7816.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7816.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7816.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7816.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7816.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 46.9.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.9.46_udp@PTR;check="$$(dig +tcp +noall +answer +search 46.9.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.9.46_tcp@PTR;sleep 1; done
     10/03/22 20:58:34.149
    STEP: creating a pod to probe DNS 10/03/22 20:58:34.149
    STEP: submitting the pod to kubernetes 10/03/22 20:58:34.149
    Oct  3 20:58:34.180: INFO: Waiting up to 15m0s for pod "dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5" in namespace "dns-7816" to be "running"
    Oct  3 20:58:34.195: INFO: Pod "dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.70881ms
    Oct  3 20:58:36.211: INFO: Pod "dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030301809s
    Oct  3 20:58:38.210: INFO: Pod "dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5": Phase="Running", Reason="", readiness=true. Elapsed: 4.029364853s
    Oct  3 20:58:38.210: INFO: Pod "dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5" satisfied condition "running"
    STEP: retrieving the pod 10/03/22 20:58:38.21
    STEP: looking for the results for each expected name from probers 10/03/22 20:58:38.224
    Oct  3 20:58:38.296: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7816.svc.cluster.local from pod dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5: the server could not find the requested resource (get pods dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5)
    Oct  3 20:58:38.316: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local from pod dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5: the server could not find the requested resource (get pods dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5)
    Oct  3 20:58:38.431: INFO: Unable to read jessie_udp@dns-test-service.dns-7816.svc.cluster.local from pod dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5: the server could not find the requested resource (get pods dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5)
    Oct  3 20:58:38.452: INFO: Unable to read jessie_tcp@dns-test-service.dns-7816.svc.cluster.local from pod dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5: the server could not find the requested resource (get pods dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5)
    Oct  3 20:58:38.494: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local from pod dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5: the server could not find the requested resource (get pods dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5)
    Oct  3 20:58:38.574: INFO: Lookups using dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5 failed for: [wheezy_tcp@dns-test-service.dns-7816.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local jessie_udp@dns-test-service.dns-7816.svc.cluster.local jessie_tcp@dns-test-service.dns-7816.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local]

    Oct  3 20:58:43.639: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local from pod dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5: the server could not find the requested resource (get pods dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5)
    Oct  3 20:58:43.936: INFO: Lookups using dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-7816.svc.cluster.local]

    Oct  3 20:58:48.882: INFO: DNS probes using dns-7816/dns-test-7f6b8ec1-8580-4469-9f25-804941306cf5 succeeded

    STEP: deleting the pod 10/03/22 20:58:48.883
    STEP: deleting the test service 10/03/22 20:58:48.923
    STEP: deleting the test headless service 10/03/22 20:58:48.97
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Oct  3 20:58:48.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7816" for this suite. 10/03/22 20:58:49.013
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:58:49.035
Oct  3 20:58:49.035: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename dns 10/03/22 20:58:49.037
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:58:49.077
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:58:49.086
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 10/03/22 20:58:49.097
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 10/03/22 20:58:49.097
STEP: creating a pod to probe DNS 10/03/22 20:58:49.098
STEP: submitting the pod to kubernetes 10/03/22 20:58:49.098
Oct  3 20:58:49.125: INFO: Waiting up to 15m0s for pod "dns-test-d275d146-aaaa-40bb-baad-ee7aa791fe66" in namespace "dns-3585" to be "running"
Oct  3 20:58:49.139: INFO: Pod "dns-test-d275d146-aaaa-40bb-baad-ee7aa791fe66": Phase="Pending", Reason="", readiness=false. Elapsed: 13.814154ms
Oct  3 20:58:51.158: INFO: Pod "dns-test-d275d146-aaaa-40bb-baad-ee7aa791fe66": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032388548s
Oct  3 20:58:53.155: INFO: Pod "dns-test-d275d146-aaaa-40bb-baad-ee7aa791fe66": Phase="Running", Reason="", readiness=true. Elapsed: 4.029702301s
Oct  3 20:58:53.155: INFO: Pod "dns-test-d275d146-aaaa-40bb-baad-ee7aa791fe66" satisfied condition "running"
STEP: retrieving the pod 10/03/22 20:58:53.155
STEP: looking for the results for each expected name from probers 10/03/22 20:58:53.17
Oct  3 20:58:53.272: INFO: DNS probes using dns-3585/dns-test-d275d146-aaaa-40bb-baad-ee7aa791fe66 succeeded

STEP: deleting the pod 10/03/22 20:58:53.272
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Oct  3 20:58:53.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3585" for this suite. 10/03/22 20:58:53.335
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":327,"skipped":6172,"failed":0}
------------------------------
• [4.324 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:58:49.035
    Oct  3 20:58:49.035: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename dns 10/03/22 20:58:49.037
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:58:49.077
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:58:49.086
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     10/03/22 20:58:49.097
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     10/03/22 20:58:49.097
    STEP: creating a pod to probe DNS 10/03/22 20:58:49.098
    STEP: submitting the pod to kubernetes 10/03/22 20:58:49.098
    Oct  3 20:58:49.125: INFO: Waiting up to 15m0s for pod "dns-test-d275d146-aaaa-40bb-baad-ee7aa791fe66" in namespace "dns-3585" to be "running"
    Oct  3 20:58:49.139: INFO: Pod "dns-test-d275d146-aaaa-40bb-baad-ee7aa791fe66": Phase="Pending", Reason="", readiness=false. Elapsed: 13.814154ms
    Oct  3 20:58:51.158: INFO: Pod "dns-test-d275d146-aaaa-40bb-baad-ee7aa791fe66": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032388548s
    Oct  3 20:58:53.155: INFO: Pod "dns-test-d275d146-aaaa-40bb-baad-ee7aa791fe66": Phase="Running", Reason="", readiness=true. Elapsed: 4.029702301s
    Oct  3 20:58:53.155: INFO: Pod "dns-test-d275d146-aaaa-40bb-baad-ee7aa791fe66" satisfied condition "running"
    STEP: retrieving the pod 10/03/22 20:58:53.155
    STEP: looking for the results for each expected name from probers 10/03/22 20:58:53.17
    Oct  3 20:58:53.272: INFO: DNS probes using dns-3585/dns-test-d275d146-aaaa-40bb-baad-ee7aa791fe66 succeeded

    STEP: deleting the pod 10/03/22 20:58:53.272
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Oct  3 20:58:53.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3585" for this suite. 10/03/22 20:58:53.335
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:58:53.363
Oct  3 20:58:53.363: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename resourcequota 10/03/22 20:58:53.364
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:58:53.407
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:58:53.418
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 10/03/22 20:58:53.431
STEP: Creating a ResourceQuota 10/03/22 20:58:58.446
STEP: Ensuring resource quota status is calculated 10/03/22 20:58:58.464
STEP: Creating a ReplicaSet 10/03/22 20:59:00.478
STEP: Ensuring resource quota status captures replicaset creation 10/03/22 20:59:00.514
STEP: Deleting a ReplicaSet 10/03/22 20:59:02.527
STEP: Ensuring resource quota status released usage 10/03/22 20:59:02.568
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Oct  3 20:59:04.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9939" for this suite. 10/03/22 20:59:04.602
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":328,"skipped":6183,"failed":0}
------------------------------
• [SLOW TEST] [11.264 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:58:53.363
    Oct  3 20:58:53.363: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename resourcequota 10/03/22 20:58:53.364
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:58:53.407
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:58:53.418
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 10/03/22 20:58:53.431
    STEP: Creating a ResourceQuota 10/03/22 20:58:58.446
    STEP: Ensuring resource quota status is calculated 10/03/22 20:58:58.464
    STEP: Creating a ReplicaSet 10/03/22 20:59:00.478
    STEP: Ensuring resource quota status captures replicaset creation 10/03/22 20:59:00.514
    STEP: Deleting a ReplicaSet 10/03/22 20:59:02.527
    STEP: Ensuring resource quota status released usage 10/03/22 20:59:02.568
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Oct  3 20:59:04.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9939" for this suite. 10/03/22 20:59:04.602
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:59:04.637
Oct  3 20:59:04.637: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename daemonsets 10/03/22 20:59:04.638
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:04.684
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:04.695
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Oct  3 20:59:04.817: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 10/03/22 20:59:04.834
Oct  3 20:59:04.868: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 20:59:04.868: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 20:59:05.910: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 20:59:05.910: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 20:59:06.910: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Oct  3 20:59:06.911: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
Oct  3 20:59:07.907: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct  3 20:59:07.907: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 10/03/22 20:59:07.967
STEP: Check that daemon pods images are updated. 10/03/22 20:59:08.006
Oct  3 20:59:08.019: INFO: Wrong image for pod: daemon-set-c6qr8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Oct  3 20:59:08.019: INFO: Wrong image for pod: daemon-set-mvlhp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Oct  3 20:59:09.073: INFO: Wrong image for pod: daemon-set-c6qr8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Oct  3 20:59:09.073: INFO: Wrong image for pod: daemon-set-mvlhp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Oct  3 20:59:10.073: INFO: Wrong image for pod: daemon-set-c6qr8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Oct  3 20:59:10.073: INFO: Wrong image for pod: daemon-set-mvlhp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Oct  3 20:59:10.073: INFO: Pod daemon-set-pzdhx is not available
Oct  3 20:59:11.073: INFO: Wrong image for pod: daemon-set-c6qr8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Oct  3 20:59:11.073: INFO: Wrong image for pod: daemon-set-mvlhp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Oct  3 20:59:11.073: INFO: Pod daemon-set-pzdhx is not available
Oct  3 20:59:12.074: INFO: Wrong image for pod: daemon-set-c6qr8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Oct  3 20:59:13.074: INFO: Wrong image for pod: daemon-set-c6qr8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Oct  3 20:59:13.074: INFO: Pod daemon-set-ndzqn is not available
Oct  3 20:59:14.074: INFO: Wrong image for pod: daemon-set-c6qr8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Oct  3 20:59:14.074: INFO: Pod daemon-set-ndzqn is not available
Oct  3 20:59:17.073: INFO: Pod daemon-set-lqbs7 is not available
STEP: Check that daemon pods are still running on every node of the cluster. 10/03/22 20:59:17.094
Oct  3 20:59:17.129: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct  3 20:59:17.129: INFO: Node 10.63.128.3 is running 0 daemon pod, expected 1
Oct  3 20:59:18.166: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct  3 20:59:18.166: INFO: Node 10.63.128.3 is running 0 daemon pod, expected 1
Oct  3 20:59:19.166: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct  3 20:59:19.166: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 10/03/22 20:59:19.234
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8033, will wait for the garbage collector to delete the pods 10/03/22 20:59:19.234
Oct  3 20:59:19.320: INFO: Deleting DaemonSet.extensions daemon-set took: 21.967807ms
Oct  3 20:59:19.421: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.608689ms
Oct  3 20:59:22.747: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct  3 20:59:22.747: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct  3 20:59:22.760: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"47445"},"items":null}

Oct  3 20:59:22.776: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"47445"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Oct  3 20:59:22.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8033" for this suite. 10/03/22 20:59:22.866
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":329,"skipped":6243,"failed":0}
------------------------------
• [SLOW TEST] [18.261 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:59:04.637
    Oct  3 20:59:04.637: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename daemonsets 10/03/22 20:59:04.638
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:04.684
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:04.695
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Oct  3 20:59:04.817: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 10/03/22 20:59:04.834
    Oct  3 20:59:04.868: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 20:59:04.868: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 20:59:05.910: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 20:59:05.910: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 20:59:06.910: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Oct  3 20:59:06.911: INFO: Node 10.63.128.13 is running 0 daemon pod, expected 1
    Oct  3 20:59:07.907: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct  3 20:59:07.907: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 10/03/22 20:59:07.967
    STEP: Check that daemon pods images are updated. 10/03/22 20:59:08.006
    Oct  3 20:59:08.019: INFO: Wrong image for pod: daemon-set-c6qr8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Oct  3 20:59:08.019: INFO: Wrong image for pod: daemon-set-mvlhp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Oct  3 20:59:09.073: INFO: Wrong image for pod: daemon-set-c6qr8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Oct  3 20:59:09.073: INFO: Wrong image for pod: daemon-set-mvlhp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Oct  3 20:59:10.073: INFO: Wrong image for pod: daemon-set-c6qr8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Oct  3 20:59:10.073: INFO: Wrong image for pod: daemon-set-mvlhp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Oct  3 20:59:10.073: INFO: Pod daemon-set-pzdhx is not available
    Oct  3 20:59:11.073: INFO: Wrong image for pod: daemon-set-c6qr8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Oct  3 20:59:11.073: INFO: Wrong image for pod: daemon-set-mvlhp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Oct  3 20:59:11.073: INFO: Pod daemon-set-pzdhx is not available
    Oct  3 20:59:12.074: INFO: Wrong image for pod: daemon-set-c6qr8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Oct  3 20:59:13.074: INFO: Wrong image for pod: daemon-set-c6qr8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Oct  3 20:59:13.074: INFO: Pod daemon-set-ndzqn is not available
    Oct  3 20:59:14.074: INFO: Wrong image for pod: daemon-set-c6qr8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Oct  3 20:59:14.074: INFO: Pod daemon-set-ndzqn is not available
    Oct  3 20:59:17.073: INFO: Pod daemon-set-lqbs7 is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 10/03/22 20:59:17.094
    Oct  3 20:59:17.129: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct  3 20:59:17.129: INFO: Node 10.63.128.3 is running 0 daemon pod, expected 1
    Oct  3 20:59:18.166: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct  3 20:59:18.166: INFO: Node 10.63.128.3 is running 0 daemon pod, expected 1
    Oct  3 20:59:19.166: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct  3 20:59:19.166: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 10/03/22 20:59:19.234
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8033, will wait for the garbage collector to delete the pods 10/03/22 20:59:19.234
    Oct  3 20:59:19.320: INFO: Deleting DaemonSet.extensions daemon-set took: 21.967807ms
    Oct  3 20:59:19.421: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.608689ms
    Oct  3 20:59:22.747: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct  3 20:59:22.747: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Oct  3 20:59:22.760: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"47445"},"items":null}

    Oct  3 20:59:22.776: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"47445"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 20:59:22.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8033" for this suite. 10/03/22 20:59:22.866
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:59:22.899
Oct  3 20:59:22.899: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 20:59:22.9
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:22.954
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:22.964
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 10/03/22 20:59:22.975
Oct  3 20:59:22.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-591 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Oct  3 20:59:23.099: INFO: stderr: ""
Oct  3 20:59:23.099: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 10/03/22 20:59:23.099
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Oct  3 20:59:23.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-591 delete pods e2e-test-httpd-pod'
Oct  3 20:59:26.421: INFO: stderr: ""
Oct  3 20:59:26.421: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 20:59:26.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-591" for this suite. 10/03/22 20:59:26.44
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":330,"skipped":6243,"failed":0}
------------------------------
• [3.574 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:59:22.899
    Oct  3 20:59:22.899: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 20:59:22.9
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:22.954
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:22.964
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 10/03/22 20:59:22.975
    Oct  3 20:59:22.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-591 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Oct  3 20:59:23.099: INFO: stderr: ""
    Oct  3 20:59:23.099: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 10/03/22 20:59:23.099
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Oct  3 20:59:23.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-591 delete pods e2e-test-httpd-pod'
    Oct  3 20:59:26.421: INFO: stderr: ""
    Oct  3 20:59:26.421: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 20:59:26.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-591" for this suite. 10/03/22 20:59:26.44
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:59:26.476
Oct  3 20:59:26.476: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename var-expansion 10/03/22 20:59:26.478
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:26.523
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:26.551
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 10/03/22 20:59:26.563
Oct  3 20:59:26.592: INFO: Waiting up to 5m0s for pod "var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb" in namespace "var-expansion-780" to be "Succeeded or Failed"
Oct  3 20:59:26.605: INFO: Pod "var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb": Phase="Pending", Reason="", readiness=false. Elapsed: 13.603393ms
Oct  3 20:59:28.630: INFO: Pod "var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037816657s
Oct  3 20:59:30.620: INFO: Pod "var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028683918s
STEP: Saw pod success 10/03/22 20:59:30.62
Oct  3 20:59:30.621: INFO: Pod "var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb" satisfied condition "Succeeded or Failed"
Oct  3 20:59:30.636: INFO: Trying to get logs from node 10.63.128.3 pod var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb container dapi-container: <nil>
STEP: delete the pod 10/03/22 20:59:30.719
Oct  3 20:59:30.751: INFO: Waiting for pod var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb to disappear
Oct  3 20:59:30.765: INFO: Pod var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Oct  3 20:59:30.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-780" for this suite. 10/03/22 20:59:30.784
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":331,"skipped":6252,"failed":0}
------------------------------
• [4.335 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:59:26.476
    Oct  3 20:59:26.476: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename var-expansion 10/03/22 20:59:26.478
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:26.523
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:26.551
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 10/03/22 20:59:26.563
    Oct  3 20:59:26.592: INFO: Waiting up to 5m0s for pod "var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb" in namespace "var-expansion-780" to be "Succeeded or Failed"
    Oct  3 20:59:26.605: INFO: Pod "var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb": Phase="Pending", Reason="", readiness=false. Elapsed: 13.603393ms
    Oct  3 20:59:28.630: INFO: Pod "var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037816657s
    Oct  3 20:59:30.620: INFO: Pod "var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028683918s
    STEP: Saw pod success 10/03/22 20:59:30.62
    Oct  3 20:59:30.621: INFO: Pod "var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb" satisfied condition "Succeeded or Failed"
    Oct  3 20:59:30.636: INFO: Trying to get logs from node 10.63.128.3 pod var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb container dapi-container: <nil>
    STEP: delete the pod 10/03/22 20:59:30.719
    Oct  3 20:59:30.751: INFO: Waiting for pod var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb to disappear
    Oct  3 20:59:30.765: INFO: Pod var-expansion-b508df84-4a67-4226-9239-c4b8ea91a2bb no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Oct  3 20:59:30.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-780" for this suite. 10/03/22 20:59:30.784
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:59:30.812
Oct  3 20:59:30.812: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubelet-test 10/03/22 20:59:30.813
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:30.855
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:30.866
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Oct  3 20:59:34.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8235" for this suite. 10/03/22 20:59:34.957
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":332,"skipped":6268,"failed":0}
------------------------------
• [4.167 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:59:30.812
    Oct  3 20:59:30.812: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubelet-test 10/03/22 20:59:30.813
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:30.855
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:30.866
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Oct  3 20:59:34.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-8235" for this suite. 10/03/22 20:59:34.957
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:59:34.979
Oct  3 20:59:34.979: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename services 10/03/22 20:59:34.981
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:35.021
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:35.032
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-4880 10/03/22 20:59:35.044
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4880 to expose endpoints map[] 10/03/22 20:59:35.076
Oct  3 20:59:35.106: INFO: successfully validated that service endpoint-test2 in namespace services-4880 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-4880 10/03/22 20:59:35.106
Oct  3 20:59:35.133: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4880" to be "running and ready"
Oct  3 20:59:35.147: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 13.368915ms
Oct  3 20:59:35.147: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:59:37.161: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027801535s
Oct  3 20:59:37.161: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:59:39.163: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.029815341s
Oct  3 20:59:39.163: INFO: The phase of Pod pod1 is Running (Ready = true)
Oct  3 20:59:39.163: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4880 to expose endpoints map[pod1:[80]] 10/03/22 20:59:39.177
Oct  3 20:59:39.218: INFO: successfully validated that service endpoint-test2 in namespace services-4880 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 10/03/22 20:59:39.218
Oct  3 20:59:39.219: INFO: Creating new exec pod
Oct  3 20:59:39.233: INFO: Waiting up to 5m0s for pod "execpod82jnx" in namespace "services-4880" to be "running"
Oct  3 20:59:39.246: INFO: Pod "execpod82jnx": Phase="Pending", Reason="", readiness=false. Elapsed: 13.645984ms
Oct  3 20:59:41.270: INFO: Pod "execpod82jnx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037341978s
Oct  3 20:59:43.260: INFO: Pod "execpod82jnx": Phase="Running", Reason="", readiness=true. Elapsed: 4.027342262s
Oct  3 20:59:43.260: INFO: Pod "execpod82jnx" satisfied condition "running"
Oct  3 20:59:44.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-4880 exec execpod82jnx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Oct  3 20:59:44.607: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2+  80\necho hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Oct  3 20:59:44.607: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:59:44.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-4880 exec execpod82jnx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.255.217 80'
Oct  3 20:59:44.897: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.255.217 80\nConnection to 172.21.255.217 80 port [tcp/http] succeeded!\n"
Oct  3 20:59:44.897: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-4880 10/03/22 20:59:44.897
Oct  3 20:59:44.915: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4880" to be "running and ready"
Oct  3 20:59:44.929: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 14.708405ms
Oct  3 20:59:44.929: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 20:59:46.945: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.030742105s
Oct  3 20:59:46.945: INFO: The phase of Pod pod2 is Running (Ready = true)
Oct  3 20:59:46.945: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4880 to expose endpoints map[pod1:[80] pod2:[80]] 10/03/22 20:59:46.959
Oct  3 20:59:47.014: INFO: successfully validated that service endpoint-test2 in namespace services-4880 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 10/03/22 20:59:47.014
Oct  3 20:59:48.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-4880 exec execpod82jnx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Oct  3 20:59:48.361: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Oct  3 20:59:48.361: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:59:48.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-4880 exec execpod82jnx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.255.217 80'
Oct  3 20:59:48.637: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.255.217 80\nConnection to 172.21.255.217 80 port [tcp/http] succeeded!\n"
Oct  3 20:59:48.637: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-4880 10/03/22 20:59:48.637
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4880 to expose endpoints map[pod2:[80]] 10/03/22 20:59:48.682
Oct  3 20:59:48.726: INFO: successfully validated that service endpoint-test2 in namespace services-4880 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 10/03/22 20:59:48.726
Oct  3 20:59:49.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-4880 exec execpod82jnx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Oct  3 20:59:51.061: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Oct  3 20:59:51.061: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct  3 20:59:51.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-4880 exec execpod82jnx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.255.217 80'
Oct  3 20:59:51.355: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.255.217 80\nConnection to 172.21.255.217 80 port [tcp/http] succeeded!\n"
Oct  3 20:59:51.355: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-4880 10/03/22 20:59:51.355
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4880 to expose endpoints map[] 10/03/22 20:59:51.391
Oct  3 20:59:51.428: INFO: successfully validated that service endpoint-test2 in namespace services-4880 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Oct  3 20:59:51.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4880" for this suite. 10/03/22 20:59:51.553
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":333,"skipped":6271,"failed":0}
------------------------------
• [SLOW TEST] [16.604 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:59:34.979
    Oct  3 20:59:34.979: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename services 10/03/22 20:59:34.981
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:35.021
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:35.032
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-4880 10/03/22 20:59:35.044
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4880 to expose endpoints map[] 10/03/22 20:59:35.076
    Oct  3 20:59:35.106: INFO: successfully validated that service endpoint-test2 in namespace services-4880 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-4880 10/03/22 20:59:35.106
    Oct  3 20:59:35.133: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4880" to be "running and ready"
    Oct  3 20:59:35.147: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 13.368915ms
    Oct  3 20:59:35.147: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:59:37.161: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027801535s
    Oct  3 20:59:37.161: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:59:39.163: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.029815341s
    Oct  3 20:59:39.163: INFO: The phase of Pod pod1 is Running (Ready = true)
    Oct  3 20:59:39.163: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4880 to expose endpoints map[pod1:[80]] 10/03/22 20:59:39.177
    Oct  3 20:59:39.218: INFO: successfully validated that service endpoint-test2 in namespace services-4880 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 10/03/22 20:59:39.218
    Oct  3 20:59:39.219: INFO: Creating new exec pod
    Oct  3 20:59:39.233: INFO: Waiting up to 5m0s for pod "execpod82jnx" in namespace "services-4880" to be "running"
    Oct  3 20:59:39.246: INFO: Pod "execpod82jnx": Phase="Pending", Reason="", readiness=false. Elapsed: 13.645984ms
    Oct  3 20:59:41.270: INFO: Pod "execpod82jnx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037341978s
    Oct  3 20:59:43.260: INFO: Pod "execpod82jnx": Phase="Running", Reason="", readiness=true. Elapsed: 4.027342262s
    Oct  3 20:59:43.260: INFO: Pod "execpod82jnx" satisfied condition "running"
    Oct  3 20:59:44.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-4880 exec execpod82jnx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Oct  3 20:59:44.607: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2+  80\necho hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Oct  3 20:59:44.607: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:59:44.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-4880 exec execpod82jnx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.255.217 80'
    Oct  3 20:59:44.897: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.255.217 80\nConnection to 172.21.255.217 80 port [tcp/http] succeeded!\n"
    Oct  3 20:59:44.897: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-4880 10/03/22 20:59:44.897
    Oct  3 20:59:44.915: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4880" to be "running and ready"
    Oct  3 20:59:44.929: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 14.708405ms
    Oct  3 20:59:44.929: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 20:59:46.945: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.030742105s
    Oct  3 20:59:46.945: INFO: The phase of Pod pod2 is Running (Ready = true)
    Oct  3 20:59:46.945: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4880 to expose endpoints map[pod1:[80] pod2:[80]] 10/03/22 20:59:46.959
    Oct  3 20:59:47.014: INFO: successfully validated that service endpoint-test2 in namespace services-4880 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 10/03/22 20:59:47.014
    Oct  3 20:59:48.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-4880 exec execpod82jnx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Oct  3 20:59:48.361: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Oct  3 20:59:48.361: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:59:48.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-4880 exec execpod82jnx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.255.217 80'
    Oct  3 20:59:48.637: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.255.217 80\nConnection to 172.21.255.217 80 port [tcp/http] succeeded!\n"
    Oct  3 20:59:48.637: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-4880 10/03/22 20:59:48.637
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4880 to expose endpoints map[pod2:[80]] 10/03/22 20:59:48.682
    Oct  3 20:59:48.726: INFO: successfully validated that service endpoint-test2 in namespace services-4880 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 10/03/22 20:59:48.726
    Oct  3 20:59:49.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-4880 exec execpod82jnx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Oct  3 20:59:51.061: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Oct  3 20:59:51.061: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Oct  3 20:59:51.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=services-4880 exec execpod82jnx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.255.217 80'
    Oct  3 20:59:51.355: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.255.217 80\nConnection to 172.21.255.217 80 port [tcp/http] succeeded!\n"
    Oct  3 20:59:51.355: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-4880 10/03/22 20:59:51.355
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4880 to expose endpoints map[] 10/03/22 20:59:51.391
    Oct  3 20:59:51.428: INFO: successfully validated that service endpoint-test2 in namespace services-4880 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Oct  3 20:59:51.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4880" for this suite. 10/03/22 20:59:51.553
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:59:51.584
Oct  3 20:59:51.584: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename secrets 10/03/22 20:59:51.585
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:51.666
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:51.678
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 10/03/22 20:59:51.69
STEP: listing secrets in all namespaces to ensure that there are more than zero 10/03/22 20:59:51.705
STEP: patching the secret 10/03/22 20:59:51.726
STEP: deleting the secret using a LabelSelector 10/03/22 20:59:51.768
STEP: listing secrets in all namespaces, searching for label name and value in patch 10/03/22 20:59:51.844
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Oct  3 20:59:51.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7975" for this suite. 10/03/22 20:59:51.888
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":334,"skipped":6288,"failed":0}
------------------------------
• [0.333 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:59:51.584
    Oct  3 20:59:51.584: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename secrets 10/03/22 20:59:51.585
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:51.666
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:51.678
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 10/03/22 20:59:51.69
    STEP: listing secrets in all namespaces to ensure that there are more than zero 10/03/22 20:59:51.705
    STEP: patching the secret 10/03/22 20:59:51.726
    STEP: deleting the secret using a LabelSelector 10/03/22 20:59:51.768
    STEP: listing secrets in all namespaces, searching for label name and value in patch 10/03/22 20:59:51.844
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Oct  3 20:59:51.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7975" for this suite. 10/03/22 20:59:51.888
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:59:51.918
Oct  3 20:59:51.918: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename secrets 10/03/22 20:59:51.919
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:52.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:52.012
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-3582/secret-test-297c56de-08d9-420d-b67a-d49511e30712 10/03/22 20:59:52.024
STEP: Creating a pod to test consume secrets 10/03/22 20:59:52.042
Oct  3 20:59:52.074: INFO: Waiting up to 5m0s for pod "pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3" in namespace "secrets-3582" to be "Succeeded or Failed"
Oct  3 20:59:52.087: INFO: Pod "pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.634771ms
Oct  3 20:59:54.104: INFO: Pod "pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029781447s
Oct  3 20:59:56.101: INFO: Pod "pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026765503s
Oct  3 20:59:58.103: INFO: Pod "pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028343218s
STEP: Saw pod success 10/03/22 20:59:58.103
Oct  3 20:59:58.103: INFO: Pod "pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3" satisfied condition "Succeeded or Failed"
Oct  3 20:59:58.117: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3 container env-test: <nil>
STEP: delete the pod 10/03/22 20:59:58.149
Oct  3 20:59:58.183: INFO: Waiting for pod pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3 to disappear
Oct  3 20:59:58.196: INFO: Pod pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Oct  3 20:59:58.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3582" for this suite. 10/03/22 20:59:58.215
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":335,"skipped":6292,"failed":0}
------------------------------
• [SLOW TEST] [6.320 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:59:51.918
    Oct  3 20:59:51.918: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename secrets 10/03/22 20:59:51.919
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:52.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:52.012
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-3582/secret-test-297c56de-08d9-420d-b67a-d49511e30712 10/03/22 20:59:52.024
    STEP: Creating a pod to test consume secrets 10/03/22 20:59:52.042
    Oct  3 20:59:52.074: INFO: Waiting up to 5m0s for pod "pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3" in namespace "secrets-3582" to be "Succeeded or Failed"
    Oct  3 20:59:52.087: INFO: Pod "pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.634771ms
    Oct  3 20:59:54.104: INFO: Pod "pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029781447s
    Oct  3 20:59:56.101: INFO: Pod "pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026765503s
    Oct  3 20:59:58.103: INFO: Pod "pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028343218s
    STEP: Saw pod success 10/03/22 20:59:58.103
    Oct  3 20:59:58.103: INFO: Pod "pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3" satisfied condition "Succeeded or Failed"
    Oct  3 20:59:58.117: INFO: Trying to get logs from node 10.63.128.3 pod pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3 container env-test: <nil>
    STEP: delete the pod 10/03/22 20:59:58.149
    Oct  3 20:59:58.183: INFO: Waiting for pod pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3 to disappear
    Oct  3 20:59:58.196: INFO: Pod pod-configmaps-c7e1b2ae-b1db-4e3c-8b3d-92d8c8ceb2e3 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Oct  3 20:59:58.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3582" for this suite. 10/03/22 20:59:58.215
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:59:58.243
Oct  3 20:59:58.243: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename pods 10/03/22 20:59:58.245
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:58.296
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:58.308
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 10/03/22 20:59:58.319
STEP: submitting the pod to kubernetes 10/03/22 20:59:58.32
STEP: verifying QOS class is set on the pod 10/03/22 20:59:58.347
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Oct  3 20:59:58.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3381" for this suite. 10/03/22 20:59:58.384
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":336,"skipped":6312,"failed":0}
------------------------------
• [0.215 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:59:58.243
    Oct  3 20:59:58.243: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename pods 10/03/22 20:59:58.245
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:58.296
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:58.308
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 10/03/22 20:59:58.319
    STEP: submitting the pod to kubernetes 10/03/22 20:59:58.32
    STEP: verifying QOS class is set on the pod 10/03/22 20:59:58.347
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Oct  3 20:59:58.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3381" for this suite. 10/03/22 20:59:58.384
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 20:59:58.463
Oct  3 20:59:58.463: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 20:59:58.465
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:58.508
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:58.518
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 10/03/22 20:59:58.529
Oct  3 20:59:58.558: INFO: Waiting up to 5m0s for pod "annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1" in namespace "projected-1636" to be "running and ready"
Oct  3 20:59:58.571: INFO: Pod "annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1": Phase="Pending", Reason="", readiness=false. Elapsed: 13.418202ms
Oct  3 20:59:58.571: INFO: The phase of Pod annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 21:00:00.589: INFO: Pod "annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030798179s
Oct  3 21:00:00.589: INFO: The phase of Pod annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 21:00:02.586: INFO: Pod "annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1": Phase="Running", Reason="", readiness=true. Elapsed: 4.028278375s
Oct  3 21:00:02.586: INFO: The phase of Pod annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1 is Running (Ready = true)
Oct  3 21:00:02.587: INFO: Pod "annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1" satisfied condition "running and ready"
Oct  3 21:00:03.166: INFO: Successfully updated pod "annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Oct  3 21:00:05.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1636" for this suite. 10/03/22 21:00:05.249
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":337,"skipped":6324,"failed":0}
------------------------------
• [SLOW TEST] [6.810 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 20:59:58.463
    Oct  3 20:59:58.463: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 20:59:58.465
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 20:59:58.508
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 20:59:58.518
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 10/03/22 20:59:58.529
    Oct  3 20:59:58.558: INFO: Waiting up to 5m0s for pod "annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1" in namespace "projected-1636" to be "running and ready"
    Oct  3 20:59:58.571: INFO: Pod "annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1": Phase="Pending", Reason="", readiness=false. Elapsed: 13.418202ms
    Oct  3 20:59:58.571: INFO: The phase of Pod annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 21:00:00.589: INFO: Pod "annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030798179s
    Oct  3 21:00:00.589: INFO: The phase of Pod annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 21:00:02.586: INFO: Pod "annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1": Phase="Running", Reason="", readiness=true. Elapsed: 4.028278375s
    Oct  3 21:00:02.586: INFO: The phase of Pod annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1 is Running (Ready = true)
    Oct  3 21:00:02.587: INFO: Pod "annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1" satisfied condition "running and ready"
    Oct  3 21:00:03.166: INFO: Successfully updated pod "annotationupdate8ff20e6a-d087-4ea9-bdf7-4d3f20d246c1"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Oct  3 21:00:05.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1636" for this suite. 10/03/22 21:00:05.249
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:00:05.272
Oct  3 21:00:05.273: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 21:00:05.274
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:05.321
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:05.332
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-3e38fe2a-672e-490e-b73f-38ca270d69e6 10/03/22 21:00:05.348
STEP: Creating a pod to test consume configMaps 10/03/22 21:00:05.376
Oct  3 21:00:05.405: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3" in namespace "projected-5882" to be "Succeeded or Failed"
Oct  3 21:00:05.421: INFO: Pod "pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3": Phase="Pending", Reason="", readiness=false. Elapsed: 15.742028ms
Oct  3 21:00:07.439: INFO: Pod "pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034341906s
Oct  3 21:00:09.437: INFO: Pod "pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031880408s
Oct  3 21:00:11.437: INFO: Pod "pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031579318s
STEP: Saw pod success 10/03/22 21:00:11.437
Oct  3 21:00:11.437: INFO: Pod "pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3" satisfied condition "Succeeded or Failed"
Oct  3 21:00:11.450: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3 container projected-configmap-volume-test: <nil>
STEP: delete the pod 10/03/22 21:00:11.485
Oct  3 21:00:11.529: INFO: Waiting for pod pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3 to disappear
Oct  3 21:00:11.543: INFO: Pod pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Oct  3 21:00:11.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5882" for this suite. 10/03/22 21:00:11.562
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":338,"skipped":6324,"failed":0}
------------------------------
• [SLOW TEST] [6.313 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:00:05.272
    Oct  3 21:00:05.273: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 21:00:05.274
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:05.321
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:05.332
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-3e38fe2a-672e-490e-b73f-38ca270d69e6 10/03/22 21:00:05.348
    STEP: Creating a pod to test consume configMaps 10/03/22 21:00:05.376
    Oct  3 21:00:05.405: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3" in namespace "projected-5882" to be "Succeeded or Failed"
    Oct  3 21:00:05.421: INFO: Pod "pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3": Phase="Pending", Reason="", readiness=false. Elapsed: 15.742028ms
    Oct  3 21:00:07.439: INFO: Pod "pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034341906s
    Oct  3 21:00:09.437: INFO: Pod "pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031880408s
    Oct  3 21:00:11.437: INFO: Pod "pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031579318s
    STEP: Saw pod success 10/03/22 21:00:11.437
    Oct  3 21:00:11.437: INFO: Pod "pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3" satisfied condition "Succeeded or Failed"
    Oct  3 21:00:11.450: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 10/03/22 21:00:11.485
    Oct  3 21:00:11.529: INFO: Waiting for pod pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3 to disappear
    Oct  3 21:00:11.543: INFO: Pod pod-projected-configmaps-0eea4d06-58a5-49fe-9798-1c22887522d3 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Oct  3 21:00:11.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5882" for this suite. 10/03/22 21:00:11.562
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:00:11.587
Oct  3 21:00:11.587: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename namespaces 10/03/22 21:00:11.589
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:11.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:11.699
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 10/03/22 21:00:11.709
Oct  3 21:00:11.722: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 10/03/22 21:00:11.722
Oct  3 21:00:11.736: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 10/03/22 21:00:11.736
Oct  3 21:00:11.768: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Oct  3 21:00:11.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2900" for this suite. 10/03/22 21:00:11.787
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":339,"skipped":6333,"failed":0}
------------------------------
• [0.225 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:00:11.587
    Oct  3 21:00:11.587: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename namespaces 10/03/22 21:00:11.589
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:11.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:11.699
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 10/03/22 21:00:11.709
    Oct  3 21:00:11.722: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 10/03/22 21:00:11.722
    Oct  3 21:00:11.736: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 10/03/22 21:00:11.736
    Oct  3 21:00:11.768: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 21:00:11.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-2900" for this suite. 10/03/22 21:00:11.787
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:00:11.817
Oct  3 21:00:11.817: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename configmap 10/03/22 21:00:11.818
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:11.866
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:11.877
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 10/03/22 21:00:11.89
STEP: fetching the ConfigMap 10/03/22 21:00:11.903
STEP: patching the ConfigMap 10/03/22 21:00:11.916
STEP: listing all ConfigMaps in all namespaces with a label selector 10/03/22 21:00:11.94
STEP: deleting the ConfigMap by collection with a label selector 10/03/22 21:00:11.951
STEP: listing all ConfigMaps in test namespace 10/03/22 21:00:11.973
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Oct  3 21:00:11.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7814" for this suite. 10/03/22 21:00:12
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":340,"skipped":6389,"failed":0}
------------------------------
• [0.205 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:00:11.817
    Oct  3 21:00:11.817: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename configmap 10/03/22 21:00:11.818
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:11.866
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:11.877
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 10/03/22 21:00:11.89
    STEP: fetching the ConfigMap 10/03/22 21:00:11.903
    STEP: patching the ConfigMap 10/03/22 21:00:11.916
    STEP: listing all ConfigMaps in all namespaces with a label selector 10/03/22 21:00:11.94
    STEP: deleting the ConfigMap by collection with a label selector 10/03/22 21:00:11.951
    STEP: listing all ConfigMaps in test namespace 10/03/22 21:00:11.973
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Oct  3 21:00:11.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7814" for this suite. 10/03/22 21:00:12
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:00:12.023
Oct  3 21:00:12.024: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename custom-resource-definition 10/03/22 21:00:12.025
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:12.096
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:12.109
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Oct  3 21:00:12.120: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 21:00:15.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7328" for this suite. 10/03/22 21:00:15.061
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":341,"skipped":6394,"failed":0}
------------------------------
• [3.064 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:00:12.023
    Oct  3 21:00:12.024: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename custom-resource-definition 10/03/22 21:00:12.025
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:12.096
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:12.109
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Oct  3 21:00:12.120: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 21:00:15.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-7328" for this suite. 10/03/22 21:00:15.061
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:00:15.097
Oct  3 21:00:15.098: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir-wrapper 10/03/22 21:00:15.099
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:15.162
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:15.174
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Oct  3 21:00:15.255: INFO: Waiting up to 5m0s for pod "pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700" in namespace "emptydir-wrapper-716" to be "running and ready"
Oct  3 21:00:15.267: INFO: Pod "pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700": Phase="Pending", Reason="", readiness=false. Elapsed: 12.596175ms
Oct  3 21:00:15.267: INFO: The phase of Pod pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 21:00:17.283: INFO: Pod "pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028603826s
Oct  3 21:00:17.284: INFO: The phase of Pod pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 21:00:19.283: INFO: Pod "pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700": Phase="Running", Reason="", readiness=true. Elapsed: 4.028110418s
Oct  3 21:00:19.283: INFO: The phase of Pod pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700 is Running (Ready = true)
Oct  3 21:00:19.283: INFO: Pod "pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700" satisfied condition "running and ready"
STEP: Cleaning up the secret 10/03/22 21:00:19.298
STEP: Cleaning up the configmap 10/03/22 21:00:19.32
STEP: Cleaning up the pod 10/03/22 21:00:19.338
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Oct  3 21:00:19.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-716" for this suite. 10/03/22 21:00:19.4
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":342,"skipped":6429,"failed":0}
------------------------------
• [4.325 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:00:15.097
    Oct  3 21:00:15.098: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir-wrapper 10/03/22 21:00:15.099
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:15.162
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:15.174
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Oct  3 21:00:15.255: INFO: Waiting up to 5m0s for pod "pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700" in namespace "emptydir-wrapper-716" to be "running and ready"
    Oct  3 21:00:15.267: INFO: Pod "pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700": Phase="Pending", Reason="", readiness=false. Elapsed: 12.596175ms
    Oct  3 21:00:15.267: INFO: The phase of Pod pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 21:00:17.283: INFO: Pod "pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028603826s
    Oct  3 21:00:17.284: INFO: The phase of Pod pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 21:00:19.283: INFO: Pod "pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700": Phase="Running", Reason="", readiness=true. Elapsed: 4.028110418s
    Oct  3 21:00:19.283: INFO: The phase of Pod pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700 is Running (Ready = true)
    Oct  3 21:00:19.283: INFO: Pod "pod-secrets-21265711-cca7-46bb-9294-572e5a3f3700" satisfied condition "running and ready"
    STEP: Cleaning up the secret 10/03/22 21:00:19.298
    STEP: Cleaning up the configmap 10/03/22 21:00:19.32
    STEP: Cleaning up the pod 10/03/22 21:00:19.338
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Oct  3 21:00:19.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-716" for this suite. 10/03/22 21:00:19.4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:00:19.425
Oct  3 21:00:19.425: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename lease-test 10/03/22 21:00:19.427
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:19.471
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:19.483
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Oct  3 21:00:19.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-5453" for this suite. 10/03/22 21:00:19.845
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":343,"skipped":6440,"failed":0}
------------------------------
• [0.442 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:00:19.425
    Oct  3 21:00:19.425: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename lease-test 10/03/22 21:00:19.427
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:19.471
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:19.483
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Oct  3 21:00:19.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-5453" for this suite. 10/03/22 21:00:19.845
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:00:19.87
Oct  3 21:00:19.870: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename endpointslice 10/03/22 21:00:19.871
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:19.94
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:19.952
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Oct  3 21:00:22.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-253" for this suite. 10/03/22 21:00:22.146
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":344,"skipped":6454,"failed":0}
------------------------------
• [2.299 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:00:19.87
    Oct  3 21:00:19.870: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename endpointslice 10/03/22 21:00:19.871
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:19.94
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:19.952
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Oct  3 21:00:22.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-253" for this suite. 10/03/22 21:00:22.146
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:00:22.179
Oct  3 21:00:22.179: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename kubectl 10/03/22 21:00:22.18
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:22.264
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:22.275
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 10/03/22 21:00:22.285
Oct  3 21:00:22.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8784 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Oct  3 21:00:22.406: INFO: stderr: ""
Oct  3 21:00:22.406: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 10/03/22 21:00:22.406
Oct  3 21:00:22.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8784 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Oct  3 21:00:23.362: INFO: stderr: ""
Oct  3 21:00:23.362: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 10/03/22 21:00:23.362
Oct  3 21:00:23.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8784 delete pods e2e-test-httpd-pod'
Oct  3 21:00:25.806: INFO: stderr: ""
Oct  3 21:00:25.806: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Oct  3 21:00:25.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8784" for this suite. 10/03/22 21:00:25.825
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":345,"skipped":6473,"failed":0}
------------------------------
• [3.672 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:00:22.179
    Oct  3 21:00:22.179: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename kubectl 10/03/22 21:00:22.18
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:22.264
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:22.275
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 10/03/22 21:00:22.285
    Oct  3 21:00:22.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8784 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Oct  3 21:00:22.406: INFO: stderr: ""
    Oct  3 21:00:22.406: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 10/03/22 21:00:22.406
    Oct  3 21:00:22.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8784 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Oct  3 21:00:23.362: INFO: stderr: ""
    Oct  3 21:00:23.362: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 10/03/22 21:00:23.362
    Oct  3 21:00:23.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4105927341 --namespace=kubectl-8784 delete pods e2e-test-httpd-pod'
    Oct  3 21:00:25.806: INFO: stderr: ""
    Oct  3 21:00:25.806: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Oct  3 21:00:25.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8784" for this suite. 10/03/22 21:00:25.825
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:00:25.855
Oct  3 21:00:25.855: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename secrets 10/03/22 21:00:25.856
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:25.911
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:25.924
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-9d6cc3f3-9e53-48e4-a461-b3b531288a17 10/03/22 21:00:25.935
STEP: Creating a pod to test consume secrets 10/03/22 21:00:25.978
Oct  3 21:00:26.008: INFO: Waiting up to 5m0s for pod "pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f" in namespace "secrets-8023" to be "Succeeded or Failed"
Oct  3 21:00:26.022: INFO: Pod "pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.831446ms
Oct  3 21:00:28.038: INFO: Pod "pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02942829s
Oct  3 21:00:30.038: INFO: Pod "pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030203754s
STEP: Saw pod success 10/03/22 21:00:30.038
Oct  3 21:00:30.039: INFO: Pod "pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f" satisfied condition "Succeeded or Failed"
Oct  3 21:00:30.052: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f container secret-volume-test: <nil>
STEP: delete the pod 10/03/22 21:00:30.083
Oct  3 21:00:30.132: INFO: Waiting for pod pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f to disappear
Oct  3 21:00:30.145: INFO: Pod pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Oct  3 21:00:30.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8023" for this suite. 10/03/22 21:00:30.166
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":346,"skipped":6501,"failed":0}
------------------------------
• [4.334 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:00:25.855
    Oct  3 21:00:25.855: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename secrets 10/03/22 21:00:25.856
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:25.911
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:25.924
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-9d6cc3f3-9e53-48e4-a461-b3b531288a17 10/03/22 21:00:25.935
    STEP: Creating a pod to test consume secrets 10/03/22 21:00:25.978
    Oct  3 21:00:26.008: INFO: Waiting up to 5m0s for pod "pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f" in namespace "secrets-8023" to be "Succeeded or Failed"
    Oct  3 21:00:26.022: INFO: Pod "pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.831446ms
    Oct  3 21:00:28.038: INFO: Pod "pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02942829s
    Oct  3 21:00:30.038: INFO: Pod "pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030203754s
    STEP: Saw pod success 10/03/22 21:00:30.038
    Oct  3 21:00:30.039: INFO: Pod "pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f" satisfied condition "Succeeded or Failed"
    Oct  3 21:00:30.052: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f container secret-volume-test: <nil>
    STEP: delete the pod 10/03/22 21:00:30.083
    Oct  3 21:00:30.132: INFO: Waiting for pod pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f to disappear
    Oct  3 21:00:30.145: INFO: Pod pod-secrets-547b73ea-bc42-40e1-a4ca-077b4b10d97f no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Oct  3 21:00:30.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8023" for this suite. 10/03/22 21:00:30.166
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:00:30.192
Oct  3 21:00:30.193: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename subpath 10/03/22 21:00:30.194
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:30.241
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:30.252
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 10/03/22 21:00:30.27
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-k626 10/03/22 21:00:30.313
STEP: Creating a pod to test atomic-volume-subpath 10/03/22 21:00:30.313
Oct  3 21:00:30.341: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-k626" in namespace "subpath-8725" to be "Succeeded or Failed"
Oct  3 21:00:30.356: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Pending", Reason="", readiness=false. Elapsed: 15.051058ms
Oct  3 21:00:32.378: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037183141s
Oct  3 21:00:34.380: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 4.038494341s
Oct  3 21:00:36.371: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 6.0297028s
Oct  3 21:00:38.370: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 8.028564398s
Oct  3 21:00:40.377: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 10.03595709s
Oct  3 21:00:42.376: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 12.035127927s
Oct  3 21:00:44.373: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 14.031809701s
Oct  3 21:00:46.372: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 16.031340376s
Oct  3 21:00:48.373: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 18.03201973s
Oct  3 21:00:50.372: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 20.030734303s
Oct  3 21:00:52.373: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 22.031516186s
Oct  3 21:00:54.374: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=false. Elapsed: 24.03322164s
Oct  3 21:00:56.371: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.029453652s
STEP: Saw pod success 10/03/22 21:00:56.371
Oct  3 21:00:56.371: INFO: Pod "pod-subpath-test-configmap-k626" satisfied condition "Succeeded or Failed"
Oct  3 21:00:56.385: INFO: Trying to get logs from node 10.63.128.3 pod pod-subpath-test-configmap-k626 container test-container-subpath-configmap-k626: <nil>
STEP: delete the pod 10/03/22 21:00:56.417
Oct  3 21:00:56.449: INFO: Waiting for pod pod-subpath-test-configmap-k626 to disappear
Oct  3 21:00:56.463: INFO: Pod pod-subpath-test-configmap-k626 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-k626 10/03/22 21:00:56.463
Oct  3 21:00:56.463: INFO: Deleting pod "pod-subpath-test-configmap-k626" in namespace "subpath-8725"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Oct  3 21:00:56.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8725" for this suite. 10/03/22 21:00:56.495
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":347,"skipped":6504,"failed":0}
------------------------------
• [SLOW TEST] [26.326 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:00:30.192
    Oct  3 21:00:30.193: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename subpath 10/03/22 21:00:30.194
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:30.241
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:30.252
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 10/03/22 21:00:30.27
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-k626 10/03/22 21:00:30.313
    STEP: Creating a pod to test atomic-volume-subpath 10/03/22 21:00:30.313
    Oct  3 21:00:30.341: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-k626" in namespace "subpath-8725" to be "Succeeded or Failed"
    Oct  3 21:00:30.356: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Pending", Reason="", readiness=false. Elapsed: 15.051058ms
    Oct  3 21:00:32.378: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037183141s
    Oct  3 21:00:34.380: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 4.038494341s
    Oct  3 21:00:36.371: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 6.0297028s
    Oct  3 21:00:38.370: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 8.028564398s
    Oct  3 21:00:40.377: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 10.03595709s
    Oct  3 21:00:42.376: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 12.035127927s
    Oct  3 21:00:44.373: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 14.031809701s
    Oct  3 21:00:46.372: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 16.031340376s
    Oct  3 21:00:48.373: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 18.03201973s
    Oct  3 21:00:50.372: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 20.030734303s
    Oct  3 21:00:52.373: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=true. Elapsed: 22.031516186s
    Oct  3 21:00:54.374: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Running", Reason="", readiness=false. Elapsed: 24.03322164s
    Oct  3 21:00:56.371: INFO: Pod "pod-subpath-test-configmap-k626": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.029453652s
    STEP: Saw pod success 10/03/22 21:00:56.371
    Oct  3 21:00:56.371: INFO: Pod "pod-subpath-test-configmap-k626" satisfied condition "Succeeded or Failed"
    Oct  3 21:00:56.385: INFO: Trying to get logs from node 10.63.128.3 pod pod-subpath-test-configmap-k626 container test-container-subpath-configmap-k626: <nil>
    STEP: delete the pod 10/03/22 21:00:56.417
    Oct  3 21:00:56.449: INFO: Waiting for pod pod-subpath-test-configmap-k626 to disappear
    Oct  3 21:00:56.463: INFO: Pod pod-subpath-test-configmap-k626 no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-k626 10/03/22 21:00:56.463
    Oct  3 21:00:56.463: INFO: Deleting pod "pod-subpath-test-configmap-k626" in namespace "subpath-8725"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Oct  3 21:00:56.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-8725" for this suite. 10/03/22 21:00:56.495
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:00:56.521
Oct  3 21:00:56.521: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename security-context-test 10/03/22 21:00:56.522
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:56.587
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:56.598
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Oct  3 21:00:56.638: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-ad461d9e-52ea-4a66-b2c7-419457c65c70" in namespace "security-context-test-4067" to be "Succeeded or Failed"
Oct  3 21:00:56.651: INFO: Pod "busybox-privileged-false-ad461d9e-52ea-4a66-b2c7-419457c65c70": Phase="Pending", Reason="", readiness=false. Elapsed: 13.208497ms
Oct  3 21:00:58.667: INFO: Pod "busybox-privileged-false-ad461d9e-52ea-4a66-b2c7-419457c65c70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028869083s
Oct  3 21:01:00.667: INFO: Pod "busybox-privileged-false-ad461d9e-52ea-4a66-b2c7-419457c65c70": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029601074s
Oct  3 21:01:02.666: INFO: Pod "busybox-privileged-false-ad461d9e-52ea-4a66-b2c7-419457c65c70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02830076s
Oct  3 21:01:02.666: INFO: Pod "busybox-privileged-false-ad461d9e-52ea-4a66-b2c7-419457c65c70" satisfied condition "Succeeded or Failed"
Oct  3 21:01:02.712: INFO: Got logs for pod "busybox-privileged-false-ad461d9e-52ea-4a66-b2c7-419457c65c70": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Oct  3 21:01:02.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4067" for this suite. 10/03/22 21:01:02.735
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":348,"skipped":6534,"failed":0}
------------------------------
• [SLOW TEST] [6.259 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:00:56.521
    Oct  3 21:00:56.521: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename security-context-test 10/03/22 21:00:56.522
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:00:56.587
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:00:56.598
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Oct  3 21:00:56.638: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-ad461d9e-52ea-4a66-b2c7-419457c65c70" in namespace "security-context-test-4067" to be "Succeeded or Failed"
    Oct  3 21:00:56.651: INFO: Pod "busybox-privileged-false-ad461d9e-52ea-4a66-b2c7-419457c65c70": Phase="Pending", Reason="", readiness=false. Elapsed: 13.208497ms
    Oct  3 21:00:58.667: INFO: Pod "busybox-privileged-false-ad461d9e-52ea-4a66-b2c7-419457c65c70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028869083s
    Oct  3 21:01:00.667: INFO: Pod "busybox-privileged-false-ad461d9e-52ea-4a66-b2c7-419457c65c70": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029601074s
    Oct  3 21:01:02.666: INFO: Pod "busybox-privileged-false-ad461d9e-52ea-4a66-b2c7-419457c65c70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02830076s
    Oct  3 21:01:02.666: INFO: Pod "busybox-privileged-false-ad461d9e-52ea-4a66-b2c7-419457c65c70" satisfied condition "Succeeded or Failed"
    Oct  3 21:01:02.712: INFO: Got logs for pod "busybox-privileged-false-ad461d9e-52ea-4a66-b2c7-419457c65c70": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Oct  3 21:01:02.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-4067" for this suite. 10/03/22 21:01:02.735
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:01:02.784
Oct  3 21:01:02.785: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename webhook 10/03/22 21:01:02.785
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:01:02.873
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:01:02.885
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 10/03/22 21:01:02.94
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 21:01:04.023
STEP: Deploying the webhook pod 10/03/22 21:01:04.057
STEP: Wait for the deployment to be ready 10/03/22 21:01:04.098
Oct  3 21:01:04.127: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  3 21:01:06.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 21, 1, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 21, 1, 4, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 21, 1, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 21, 1, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 10/03/22 21:01:08.183
STEP: Verifying the service has paired with the endpoint 10/03/22 21:01:08.234
Oct  3 21:01:09.235: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 10/03/22 21:01:09.247
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 10/03/22 21:01:09.32
STEP: Creating a dummy validating-webhook-configuration object 10/03/22 21:01:09.388
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 10/03/22 21:01:09.416
STEP: Creating a dummy mutating-webhook-configuration object 10/03/22 21:01:09.431
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 10/03/22 21:01:09.458
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Oct  3 21:01:09.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5493" for this suite. 10/03/22 21:01:09.53
STEP: Destroying namespace "webhook-5493-markers" for this suite. 10/03/22 21:01:09.555
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":349,"skipped":6546,"failed":0}
------------------------------
• [SLOW TEST] [6.936 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:01:02.784
    Oct  3 21:01:02.785: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename webhook 10/03/22 21:01:02.785
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:01:02.873
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:01:02.885
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 10/03/22 21:01:02.94
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/03/22 21:01:04.023
    STEP: Deploying the webhook pod 10/03/22 21:01:04.057
    STEP: Wait for the deployment to be ready 10/03/22 21:01:04.098
    Oct  3 21:01:04.127: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Oct  3 21:01:06.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 21, 1, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 21, 1, 4, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 21, 1, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 21, 1, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 10/03/22 21:01:08.183
    STEP: Verifying the service has paired with the endpoint 10/03/22 21:01:08.234
    Oct  3 21:01:09.235: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 10/03/22 21:01:09.247
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 10/03/22 21:01:09.32
    STEP: Creating a dummy validating-webhook-configuration object 10/03/22 21:01:09.388
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 10/03/22 21:01:09.416
    STEP: Creating a dummy mutating-webhook-configuration object 10/03/22 21:01:09.431
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 10/03/22 21:01:09.458
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Oct  3 21:01:09.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5493" for this suite. 10/03/22 21:01:09.53
    STEP: Destroying namespace "webhook-5493-markers" for this suite. 10/03/22 21:01:09.555
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:01:09.721
Oct  3 21:01:09.722: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 21:01:09.723
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:01:09.767
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:01:09.779
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-c70203d2-f1e3-4b75-8c9b-6c51678cba44 10/03/22 21:01:09.79
STEP: Creating a pod to test consume configMaps 10/03/22 21:01:09.804
Oct  3 21:01:09.830: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac" in namespace "projected-4337" to be "Succeeded or Failed"
Oct  3 21:01:09.843: INFO: Pod "pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac": Phase="Pending", Reason="", readiness=false. Elapsed: 12.720571ms
Oct  3 21:01:11.858: INFO: Pod "pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027981712s
Oct  3 21:01:13.856: INFO: Pod "pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026411147s
Oct  3 21:01:15.858: INFO: Pod "pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027690665s
STEP: Saw pod success 10/03/22 21:01:15.858
Oct  3 21:01:15.858: INFO: Pod "pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac" satisfied condition "Succeeded or Failed"
Oct  3 21:01:15.872: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac container agnhost-container: <nil>
STEP: delete the pod 10/03/22 21:01:15.909
Oct  3 21:01:16.003: INFO: Waiting for pod pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac to disappear
Oct  3 21:01:16.016: INFO: Pod pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Oct  3 21:01:16.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4337" for this suite. 10/03/22 21:01:16.035
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":350,"skipped":6556,"failed":0}
------------------------------
• [SLOW TEST] [6.337 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:01:09.721
    Oct  3 21:01:09.722: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 21:01:09.723
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:01:09.767
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:01:09.779
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-c70203d2-f1e3-4b75-8c9b-6c51678cba44 10/03/22 21:01:09.79
    STEP: Creating a pod to test consume configMaps 10/03/22 21:01:09.804
    Oct  3 21:01:09.830: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac" in namespace "projected-4337" to be "Succeeded or Failed"
    Oct  3 21:01:09.843: INFO: Pod "pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac": Phase="Pending", Reason="", readiness=false. Elapsed: 12.720571ms
    Oct  3 21:01:11.858: INFO: Pod "pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027981712s
    Oct  3 21:01:13.856: INFO: Pod "pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026411147s
    Oct  3 21:01:15.858: INFO: Pod "pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027690665s
    STEP: Saw pod success 10/03/22 21:01:15.858
    Oct  3 21:01:15.858: INFO: Pod "pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac" satisfied condition "Succeeded or Failed"
    Oct  3 21:01:15.872: INFO: Trying to get logs from node 10.63.128.3 pod pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac container agnhost-container: <nil>
    STEP: delete the pod 10/03/22 21:01:15.909
    Oct  3 21:01:16.003: INFO: Waiting for pod pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac to disappear
    Oct  3 21:01:16.016: INFO: Pod pod-projected-configmaps-79ea32c8-5fcd-4f80-a02b-cc34d54417ac no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Oct  3 21:01:16.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4337" for this suite. 10/03/22 21:01:16.035
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:01:16.064
Oct  3 21:01:16.065: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 21:01:16.066
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:01:16.201
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:01:16.213
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 10/03/22 21:01:16.224
Oct  3 21:01:16.254: INFO: Waiting up to 5m0s for pod "downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3" in namespace "downward-api-9446" to be "Succeeded or Failed"
Oct  3 21:01:16.267: INFO: Pod "downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.819167ms
Oct  3 21:01:18.281: INFO: Pod "downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026331448s
Oct  3 21:01:20.282: INFO: Pod "downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027690517s
STEP: Saw pod success 10/03/22 21:01:20.282
Oct  3 21:01:20.282: INFO: Pod "downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3" satisfied condition "Succeeded or Failed"
Oct  3 21:01:20.296: INFO: Trying to get logs from node 10.63.128.3 pod downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3 container dapi-container: <nil>
STEP: delete the pod 10/03/22 21:01:20.327
Oct  3 21:01:20.370: INFO: Waiting for pod downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3 to disappear
Oct  3 21:01:20.382: INFO: Pod downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Oct  3 21:01:20.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9446" for this suite. 10/03/22 21:01:20.406
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":351,"skipped":6586,"failed":0}
------------------------------
• [4.366 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:01:16.064
    Oct  3 21:01:16.065: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 21:01:16.066
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:01:16.201
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:01:16.213
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 10/03/22 21:01:16.224
    Oct  3 21:01:16.254: INFO: Waiting up to 5m0s for pod "downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3" in namespace "downward-api-9446" to be "Succeeded or Failed"
    Oct  3 21:01:16.267: INFO: Pod "downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.819167ms
    Oct  3 21:01:18.281: INFO: Pod "downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026331448s
    Oct  3 21:01:20.282: INFO: Pod "downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027690517s
    STEP: Saw pod success 10/03/22 21:01:20.282
    Oct  3 21:01:20.282: INFO: Pod "downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3" satisfied condition "Succeeded or Failed"
    Oct  3 21:01:20.296: INFO: Trying to get logs from node 10.63.128.3 pod downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3 container dapi-container: <nil>
    STEP: delete the pod 10/03/22 21:01:20.327
    Oct  3 21:01:20.370: INFO: Waiting for pod downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3 to disappear
    Oct  3 21:01:20.382: INFO: Pod downward-api-313cc6fc-2e8b-4f27-9850-8d271b2949f3 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Oct  3 21:01:20.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9446" for this suite. 10/03/22 21:01:20.406
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:01:20.436
Oct  3 21:01:20.436: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename security-context 10/03/22 21:01:20.438
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:01:20.483
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:01:20.495
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 10/03/22 21:01:20.507
Oct  3 21:01:20.535: INFO: Waiting up to 5m0s for pod "security-context-f4662591-12d2-413f-a449-7146d51fc222" in namespace "security-context-5495" to be "Succeeded or Failed"
Oct  3 21:01:20.549: INFO: Pod "security-context-f4662591-12d2-413f-a449-7146d51fc222": Phase="Pending", Reason="", readiness=false. Elapsed: 14.144925ms
Oct  3 21:01:22.564: INFO: Pod "security-context-f4662591-12d2-413f-a449-7146d51fc222": Phase="Running", Reason="", readiness=true. Elapsed: 2.029642984s
Oct  3 21:01:24.562: INFO: Pod "security-context-f4662591-12d2-413f-a449-7146d51fc222": Phase="Running", Reason="", readiness=false. Elapsed: 4.027852424s
Oct  3 21:01:26.563: INFO: Pod "security-context-f4662591-12d2-413f-a449-7146d51fc222": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028163783s
STEP: Saw pod success 10/03/22 21:01:26.563
Oct  3 21:01:26.563: INFO: Pod "security-context-f4662591-12d2-413f-a449-7146d51fc222" satisfied condition "Succeeded or Failed"
Oct  3 21:01:26.576: INFO: Trying to get logs from node 10.63.128.3 pod security-context-f4662591-12d2-413f-a449-7146d51fc222 container test-container: <nil>
STEP: delete the pod 10/03/22 21:01:26.605
Oct  3 21:01:26.638: INFO: Waiting for pod security-context-f4662591-12d2-413f-a449-7146d51fc222 to disappear
Oct  3 21:01:26.651: INFO: Pod security-context-f4662591-12d2-413f-a449-7146d51fc222 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Oct  3 21:01:26.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-5495" for this suite. 10/03/22 21:01:26.671
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":352,"skipped":6611,"failed":0}
------------------------------
• [SLOW TEST] [6.259 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:01:20.436
    Oct  3 21:01:20.436: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename security-context 10/03/22 21:01:20.438
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:01:20.483
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:01:20.495
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 10/03/22 21:01:20.507
    Oct  3 21:01:20.535: INFO: Waiting up to 5m0s for pod "security-context-f4662591-12d2-413f-a449-7146d51fc222" in namespace "security-context-5495" to be "Succeeded or Failed"
    Oct  3 21:01:20.549: INFO: Pod "security-context-f4662591-12d2-413f-a449-7146d51fc222": Phase="Pending", Reason="", readiness=false. Elapsed: 14.144925ms
    Oct  3 21:01:22.564: INFO: Pod "security-context-f4662591-12d2-413f-a449-7146d51fc222": Phase="Running", Reason="", readiness=true. Elapsed: 2.029642984s
    Oct  3 21:01:24.562: INFO: Pod "security-context-f4662591-12d2-413f-a449-7146d51fc222": Phase="Running", Reason="", readiness=false. Elapsed: 4.027852424s
    Oct  3 21:01:26.563: INFO: Pod "security-context-f4662591-12d2-413f-a449-7146d51fc222": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028163783s
    STEP: Saw pod success 10/03/22 21:01:26.563
    Oct  3 21:01:26.563: INFO: Pod "security-context-f4662591-12d2-413f-a449-7146d51fc222" satisfied condition "Succeeded or Failed"
    Oct  3 21:01:26.576: INFO: Trying to get logs from node 10.63.128.3 pod security-context-f4662591-12d2-413f-a449-7146d51fc222 container test-container: <nil>
    STEP: delete the pod 10/03/22 21:01:26.605
    Oct  3 21:01:26.638: INFO: Waiting for pod security-context-f4662591-12d2-413f-a449-7146d51fc222 to disappear
    Oct  3 21:01:26.651: INFO: Pod security-context-f4662591-12d2-413f-a449-7146d51fc222 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Oct  3 21:01:26.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-5495" for this suite. 10/03/22 21:01:26.671
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:01:26.696
Oct  3 21:01:26.696: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename secrets 10/03/22 21:01:26.697
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:01:26.741
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:01:26.75
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-bc625bec-370c-488c-8be2-b31e89c3e966 10/03/22 21:01:26.761
STEP: Creating a pod to test consume secrets 10/03/22 21:01:26.776
Oct  3 21:01:26.804: INFO: Waiting up to 5m0s for pod "pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df" in namespace "secrets-1396" to be "Succeeded or Failed"
Oct  3 21:01:26.817: INFO: Pod "pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df": Phase="Pending", Reason="", readiness=false. Elapsed: 13.255451ms
Oct  3 21:01:28.832: INFO: Pod "pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028100987s
Oct  3 21:01:30.833: INFO: Pod "pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028796203s
Oct  3 21:01:32.831: INFO: Pod "pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027263834s
STEP: Saw pod success 10/03/22 21:01:32.832
Oct  3 21:01:32.832: INFO: Pod "pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df" satisfied condition "Succeeded or Failed"
Oct  3 21:01:32.846: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df container secret-volume-test: <nil>
STEP: delete the pod 10/03/22 21:01:32.877
Oct  3 21:01:32.918: INFO: Waiting for pod pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df to disappear
Oct  3 21:01:32.931: INFO: Pod pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Oct  3 21:01:32.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1396" for this suite. 10/03/22 21:01:32.95
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":353,"skipped":6615,"failed":0}
------------------------------
• [SLOW TEST] [6.277 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:01:26.696
    Oct  3 21:01:26.696: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename secrets 10/03/22 21:01:26.697
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:01:26.741
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:01:26.75
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-bc625bec-370c-488c-8be2-b31e89c3e966 10/03/22 21:01:26.761
    STEP: Creating a pod to test consume secrets 10/03/22 21:01:26.776
    Oct  3 21:01:26.804: INFO: Waiting up to 5m0s for pod "pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df" in namespace "secrets-1396" to be "Succeeded or Failed"
    Oct  3 21:01:26.817: INFO: Pod "pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df": Phase="Pending", Reason="", readiness=false. Elapsed: 13.255451ms
    Oct  3 21:01:28.832: INFO: Pod "pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028100987s
    Oct  3 21:01:30.833: INFO: Pod "pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028796203s
    Oct  3 21:01:32.831: INFO: Pod "pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027263834s
    STEP: Saw pod success 10/03/22 21:01:32.832
    Oct  3 21:01:32.832: INFO: Pod "pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df" satisfied condition "Succeeded or Failed"
    Oct  3 21:01:32.846: INFO: Trying to get logs from node 10.63.128.3 pod pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df container secret-volume-test: <nil>
    STEP: delete the pod 10/03/22 21:01:32.877
    Oct  3 21:01:32.918: INFO: Waiting for pod pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df to disappear
    Oct  3 21:01:32.931: INFO: Pod pod-secrets-05d71af8-d50b-4143-9d3a-ede5d04170df no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Oct  3 21:01:32.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1396" for this suite. 10/03/22 21:01:32.95
  << End Captured GinkgoWriter Output
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:01:32.974
Oct  3 21:01:32.974: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename sched-preemption 10/03/22 21:01:32.976
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:01:33.017
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:01:33.026
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Oct  3 21:01:33.084: INFO: Waiting up to 1m0s for all nodes to be ready
Oct  3 21:02:33.325: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 10/03/22 21:02:33.341
Oct  3 21:02:33.415: INFO: Created pod: pod0-0-sched-preemption-low-priority
Oct  3 21:02:33.453: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Oct  3 21:02:33.519: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Oct  3 21:02:33.536: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Oct  3 21:02:33.586: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Oct  3 21:02:33.604: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 10/03/22 21:02:33.604
Oct  3 21:02:33.605: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8640" to be "running"
Oct  3 21:02:33.631: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 26.468315ms
Oct  3 21:02:35.645: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040806387s
Oct  3 21:02:37.645: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039980551s
Oct  3 21:02:39.646: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.041253552s
Oct  3 21:02:39.646: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Oct  3 21:02:39.646: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8640" to be "running"
Oct  3 21:02:39.659: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 13.3573ms
Oct  3 21:02:39.659: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Oct  3 21:02:39.660: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8640" to be "running"
Oct  3 21:02:39.675: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 15.047086ms
Oct  3 21:02:41.688: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.028432014s
Oct  3 21:02:41.688: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Oct  3 21:02:41.689: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8640" to be "running"
Oct  3 21:02:41.701: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.760392ms
Oct  3 21:02:41.701: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Oct  3 21:02:41.701: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8640" to be "running"
Oct  3 21:02:41.715: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 13.01232ms
Oct  3 21:02:41.715: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Oct  3 21:02:41.715: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8640" to be "running"
Oct  3 21:02:41.728: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 13.094376ms
Oct  3 21:02:41.728: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 10/03/22 21:02:41.728
Oct  3 21:02:41.761: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Oct  3 21:02:41.774: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.945403ms
Oct  3 21:02:43.789: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027024071s
Oct  3 21:02:45.789: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.027076177s
Oct  3 21:02:45.789: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Oct  3 21:02:45.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8640" for this suite. 10/03/22 21:02:45.97
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":354,"skipped":6615,"failed":0}
------------------------------
• [SLOW TEST] [73.187 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:01:32.974
    Oct  3 21:01:32.974: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename sched-preemption 10/03/22 21:01:32.976
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:01:33.017
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:01:33.026
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Oct  3 21:01:33.084: INFO: Waiting up to 1m0s for all nodes to be ready
    Oct  3 21:02:33.325: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 10/03/22 21:02:33.341
    Oct  3 21:02:33.415: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Oct  3 21:02:33.453: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Oct  3 21:02:33.519: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Oct  3 21:02:33.536: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Oct  3 21:02:33.586: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Oct  3 21:02:33.604: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 10/03/22 21:02:33.604
    Oct  3 21:02:33.605: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8640" to be "running"
    Oct  3 21:02:33.631: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 26.468315ms
    Oct  3 21:02:35.645: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040806387s
    Oct  3 21:02:37.645: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039980551s
    Oct  3 21:02:39.646: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.041253552s
    Oct  3 21:02:39.646: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Oct  3 21:02:39.646: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8640" to be "running"
    Oct  3 21:02:39.659: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 13.3573ms
    Oct  3 21:02:39.659: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Oct  3 21:02:39.660: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8640" to be "running"
    Oct  3 21:02:39.675: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 15.047086ms
    Oct  3 21:02:41.688: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.028432014s
    Oct  3 21:02:41.688: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Oct  3 21:02:41.689: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8640" to be "running"
    Oct  3 21:02:41.701: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.760392ms
    Oct  3 21:02:41.701: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Oct  3 21:02:41.701: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8640" to be "running"
    Oct  3 21:02:41.715: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 13.01232ms
    Oct  3 21:02:41.715: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Oct  3 21:02:41.715: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8640" to be "running"
    Oct  3 21:02:41.728: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 13.094376ms
    Oct  3 21:02:41.728: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 10/03/22 21:02:41.728
    Oct  3 21:02:41.761: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Oct  3 21:02:41.774: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.945403ms
    Oct  3 21:02:43.789: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027024071s
    Oct  3 21:02:45.789: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.027076177s
    Oct  3 21:02:45.789: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 21:02:45.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8640" for this suite. 10/03/22 21:02:45.97
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:02:46.163
Oct  3 21:02:46.163: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename deployment 10/03/22 21:02:46.165
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:02:46.208
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:02:46.217
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Oct  3 21:02:46.231: INFO: Creating deployment "test-recreate-deployment"
Oct  3 21:02:46.247: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct  3 21:02:46.271: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Oct  3 21:02:48.297: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct  3 21:02:48.310: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 21, 2, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 21, 2, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 21, 2, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 21, 2, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  3 21:02:50.324: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct  3 21:02:50.352: INFO: Updating deployment test-recreate-deployment
Oct  3 21:02:50.352: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct  3 21:02:50.511: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-5877  b4ee8623-91d9-4f97-b8b4-fd5e2884fadd 48604 2 2022-10-03 21:02:46 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003bb24e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-10-03 21:02:50 +0000 UTC,LastTransitionTime:2022-10-03 21:02:50 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-10-03 21:02:50 +0000 UTC,LastTransitionTime:2022-10-03 21:02:46 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Oct  3 21:02:50.524: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-5877  d247fc7e-2d7e-4885-8105-ed675b0e54ab 48600 1 2022-10-03 21:02:50 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment b4ee8623-91d9-4f97-b8b4-fd5e2884fadd 0xc003183ab0 0xc003183ab1}] [] [{kube-controller-manager Update apps/v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4ee8623-91d9-4f97-b8b4-fd5e2884fadd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003183b48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  3 21:02:50.524: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct  3 21:02:50.524: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-5877  24f6013b-f8a4-4f28-86ba-fd3d5c5a1a6c 48592 2 2022-10-03 21:02:46 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment b4ee8623-91d9-4f97-b8b4-fd5e2884fadd 0xc003183997 0xc003183998}] [] [{kube-controller-manager Update apps/v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4ee8623-91d9-4f97-b8b4-fd5e2884fadd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003183a48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  3 21:02:50.538: INFO: Pod "test-recreate-deployment-9d58999df-w44lq" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-w44lq test-recreate-deployment-9d58999df- deployment-5877  547e3c89-25ae-4acc-b8d3-742a57212d8f 48605 0 2022-10-03 21:02:50 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df d247fc7e-2d7e-4885-8105-ed675b0e54ab 0xc003183fe0 0xc003183fe1}] [] [{kube-controller-manager Update v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d247fc7e-2d7e-4885-8105-ed675b0e54ab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f8x7w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f8x7w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 21:02:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 21:02:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 21:02:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 21:02:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:,StartTime:2022-10-03 21:02:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Oct  3 21:02:50.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5877" for this suite. 10/03/22 21:02:50.557
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":355,"skipped":6619,"failed":0}
------------------------------
• [4.417 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:02:46.163
    Oct  3 21:02:46.163: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename deployment 10/03/22 21:02:46.165
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:02:46.208
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:02:46.217
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Oct  3 21:02:46.231: INFO: Creating deployment "test-recreate-deployment"
    Oct  3 21:02:46.247: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Oct  3 21:02:46.271: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Oct  3 21:02:48.297: INFO: Waiting deployment "test-recreate-deployment" to complete
    Oct  3 21:02:48.310: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 3, 21, 2, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 21, 2, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 3, 21, 2, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 3, 21, 2, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct  3 21:02:50.324: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Oct  3 21:02:50.352: INFO: Updating deployment test-recreate-deployment
    Oct  3 21:02:50.352: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct  3 21:02:50.511: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-5877  b4ee8623-91d9-4f97-b8b4-fd5e2884fadd 48604 2 2022-10-03 21:02:46 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003bb24e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-10-03 21:02:50 +0000 UTC,LastTransitionTime:2022-10-03 21:02:50 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-10-03 21:02:50 +0000 UTC,LastTransitionTime:2022-10-03 21:02:46 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Oct  3 21:02:50.524: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-5877  d247fc7e-2d7e-4885-8105-ed675b0e54ab 48600 1 2022-10-03 21:02:50 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment b4ee8623-91d9-4f97-b8b4-fd5e2884fadd 0xc003183ab0 0xc003183ab1}] [] [{kube-controller-manager Update apps/v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4ee8623-91d9-4f97-b8b4-fd5e2884fadd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003183b48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Oct  3 21:02:50.524: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Oct  3 21:02:50.524: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-5877  24f6013b-f8a4-4f28-86ba-fd3d5c5a1a6c 48592 2 2022-10-03 21:02:46 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment b4ee8623-91d9-4f97-b8b4-fd5e2884fadd 0xc003183997 0xc003183998}] [] [{kube-controller-manager Update apps/v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4ee8623-91d9-4f97-b8b4-fd5e2884fadd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003183a48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Oct  3 21:02:50.538: INFO: Pod "test-recreate-deployment-9d58999df-w44lq" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-w44lq test-recreate-deployment-9d58999df- deployment-5877  547e3c89-25ae-4acc-b8d3-742a57212d8f 48605 0 2022-10-03 21:02:50 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df d247fc7e-2d7e-4885-8105-ed675b0e54ab 0xc003183fe0 0xc003183fe1}] [] [{kube-controller-manager Update v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d247fc7e-2d7e-4885-8105-ed675b0e54ab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-03 21:02:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f8x7w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f8x7w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.63.128.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 21:02:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 21:02:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 21:02:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-03 21:02:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.63.128.3,PodIP:,StartTime:2022-10-03 21:02:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Oct  3 21:02:50.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-5877" for this suite. 10/03/22 21:02:50.557
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:02:50.582
Oct  3 21:02:50.582: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename statefulset 10/03/22 21:02:50.583
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:02:50.655
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:02:50.665
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7635 10/03/22 21:02:50.677
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 10/03/22 21:02:50.692
Oct  3 21:02:50.722: INFO: Found 0 stateful pods, waiting for 3
Oct  3 21:03:00.739: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  3 21:03:00.739: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  3 21:03:00.739: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 10/03/22 21:03:00.778
Oct  3 21:03:00.820: INFO: Updating stateful set ss2
STEP: Creating a new revision 10/03/22 21:03:00.82
STEP: Not applying an update when the partition is greater than the number of replicas 10/03/22 21:03:10.874
STEP: Performing a canary update 10/03/22 21:03:10.875
Oct  3 21:03:10.919: INFO: Updating stateful set ss2
Oct  3 21:03:10.948: INFO: Waiting for Pod statefulset-7635/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 10/03/22 21:03:20.978
Oct  3 21:03:21.112: INFO: Found 2 stateful pods, waiting for 3
Oct  3 21:03:31.133: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  3 21:03:31.133: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  3 21:03:31.133: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 10/03/22 21:03:31.162
Oct  3 21:03:31.207: INFO: Updating stateful set ss2
Oct  3 21:03:31.239: INFO: Waiting for Pod statefulset-7635/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Oct  3 21:03:41.311: INFO: Updating stateful set ss2
Oct  3 21:03:41.340: INFO: Waiting for StatefulSet statefulset-7635/ss2 to complete update
Oct  3 21:03:41.340: INFO: Waiting for Pod statefulset-7635/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct  3 21:03:51.368: INFO: Deleting all statefulset in ns statefulset-7635
Oct  3 21:03:51.380: INFO: Scaling statefulset ss2 to 0
Oct  3 21:04:01.446: INFO: Waiting for statefulset status.replicas updated to 0
Oct  3 21:04:01.458: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Oct  3 21:04:01.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7635" for this suite. 10/03/22 21:04:01.529
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":356,"skipped":6623,"failed":0}
------------------------------
• [SLOW TEST] [70.978 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:02:50.582
    Oct  3 21:02:50.582: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename statefulset 10/03/22 21:02:50.583
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:02:50.655
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:02:50.665
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-7635 10/03/22 21:02:50.677
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 10/03/22 21:02:50.692
    Oct  3 21:02:50.722: INFO: Found 0 stateful pods, waiting for 3
    Oct  3 21:03:00.739: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Oct  3 21:03:00.739: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Oct  3 21:03:00.739: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 10/03/22 21:03:00.778
    Oct  3 21:03:00.820: INFO: Updating stateful set ss2
    STEP: Creating a new revision 10/03/22 21:03:00.82
    STEP: Not applying an update when the partition is greater than the number of replicas 10/03/22 21:03:10.874
    STEP: Performing a canary update 10/03/22 21:03:10.875
    Oct  3 21:03:10.919: INFO: Updating stateful set ss2
    Oct  3 21:03:10.948: INFO: Waiting for Pod statefulset-7635/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 10/03/22 21:03:20.978
    Oct  3 21:03:21.112: INFO: Found 2 stateful pods, waiting for 3
    Oct  3 21:03:31.133: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Oct  3 21:03:31.133: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Oct  3 21:03:31.133: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 10/03/22 21:03:31.162
    Oct  3 21:03:31.207: INFO: Updating stateful set ss2
    Oct  3 21:03:31.239: INFO: Waiting for Pod statefulset-7635/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Oct  3 21:03:41.311: INFO: Updating stateful set ss2
    Oct  3 21:03:41.340: INFO: Waiting for StatefulSet statefulset-7635/ss2 to complete update
    Oct  3 21:03:41.340: INFO: Waiting for Pod statefulset-7635/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Oct  3 21:03:51.368: INFO: Deleting all statefulset in ns statefulset-7635
    Oct  3 21:03:51.380: INFO: Scaling statefulset ss2 to 0
    Oct  3 21:04:01.446: INFO: Waiting for statefulset status.replicas updated to 0
    Oct  3 21:04:01.458: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Oct  3 21:04:01.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-7635" for this suite. 10/03/22 21:04:01.529
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:04:01.56
Oct  3 21:04:01.560: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename watch 10/03/22 21:04:01.562
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:04:01.603
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:04:01.614
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 10/03/22 21:04:01.623
STEP: modifying the configmap once 10/03/22 21:04:01.633
STEP: modifying the configmap a second time 10/03/22 21:04:01.657
STEP: deleting the configmap 10/03/22 21:04:01.678
STEP: creating a watch on configmaps from the resource version returned by the first update 10/03/22 21:04:01.692
STEP: Expecting to observe notifications for all changes to the configmap after the first update 10/03/22 21:04:01.698
Oct  3 21:04:01.698: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-223  9ad69c65-5171-403b-b361-51a8b7f37d9a 49077 0 2022-10-03 21:04:01 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-10-03 21:04:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct  3 21:04:01.698: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-223  9ad69c65-5171-403b-b361-51a8b7f37d9a 49078 0 2022-10-03 21:04:01 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-10-03 21:04:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Oct  3 21:04:01.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-223" for this suite. 10/03/22 21:04:01.717
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":357,"skipped":6623,"failed":0}
------------------------------
• [0.176 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:04:01.56
    Oct  3 21:04:01.560: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename watch 10/03/22 21:04:01.562
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:04:01.603
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:04:01.614
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 10/03/22 21:04:01.623
    STEP: modifying the configmap once 10/03/22 21:04:01.633
    STEP: modifying the configmap a second time 10/03/22 21:04:01.657
    STEP: deleting the configmap 10/03/22 21:04:01.678
    STEP: creating a watch on configmaps from the resource version returned by the first update 10/03/22 21:04:01.692
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 10/03/22 21:04:01.698
    Oct  3 21:04:01.698: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-223  9ad69c65-5171-403b-b361-51a8b7f37d9a 49077 0 2022-10-03 21:04:01 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-10-03 21:04:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct  3 21:04:01.698: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-223  9ad69c65-5171-403b-b361-51a8b7f37d9a 49078 0 2022-10-03 21:04:01 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-10-03 21:04:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Oct  3 21:04:01.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-223" for this suite. 10/03/22 21:04:01.717
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:04:01.739
Oct  3 21:04:01.739: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename sched-pred 10/03/22 21:04:01.74
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:04:01.78
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:04:01.791
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Oct  3 21:04:01.804: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  3 21:04:01.842: INFO: Waiting for terminating namespaces to be deleted...
Oct  3 21:04:01.872: INFO: 
Logging pods the apiserver thinks is on node 10.63.128.13 before test
Oct  3 21:04:01.926: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-5lm6l from ibm-system started at 2022-10-03 17:16:04 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:01.927: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
Oct  3 21:04:01.927: INFO: calico-node-zpr9s from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:01.927: INFO: 	Container calico-node ready: true, restart count 0
Oct  3 21:04:01.927: INFO: calico-typha-644fdcd5f-w67fp from kube-system started at 2022-10-03 17:11:18 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:01.927: INFO: 	Container calico-typha ready: true, restart count 0
Oct  3 21:04:01.927: INFO: coredns-6754846f95-bl2wt from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:01.927: INFO: 	Container coredns ready: true, restart count 0
Oct  3 21:04:01.927: INFO: ibm-keepalived-watcher-nw2l6 from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:01.927: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  3 21:04:01.927: INFO: ibm-master-proxy-static-10.63.128.13 from kube-system started at 2022-10-03 17:10:55 +0000 UTC (2 container statuses recorded)
Oct  3 21:04:01.927: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct  3 21:04:01.927: INFO: 	Container pause ready: true, restart count 0
Oct  3 21:04:01.927: INFO: ibmcloud-block-storage-driver-f5thb from kube-system started at 2022-10-03 17:11:06 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:01.927: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct  3 21:04:01.927: INFO: ingress-cluster-healthcheck-6dbd7f8d47-vx87x from kube-system started at 2022-10-03 18:44:30 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:01.927: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Oct  3 21:04:01.927: INFO: konnectivity-agent-qv9fn from kube-system started at 2022-10-03 17:19:11 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:01.927: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct  3 21:04:01.927: INFO: metrics-server-668b4d7ddd-7glct from kube-system started at 2022-10-03 17:55:22 +0000 UTC (3 container statuses recorded)
Oct  3 21:04:01.927: INFO: 	Container config-watcher ready: true, restart count 0
Oct  3 21:04:01.927: INFO: 	Container metrics-server ready: true, restart count 0
Oct  3 21:04:01.927: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct  3 21:04:01.927: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-7vk57 from kube-system started at 2022-10-03 19:52:24 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:01.927: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct  3 21:04:01.927: INFO: sonobuoy-e2e-job-2c5abccdc00d487c from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 21:04:01.927: INFO: 	Container e2e ready: true, restart count 0
Oct  3 21:04:01.927: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 21:04:01.927: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-cwlqc from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 21:04:01.927: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 21:04:01.927: INFO: 	Container systemd-logs ready: true, restart count 0
Oct  3 21:04:01.927: INFO: 
Logging pods the apiserver thinks is on node 10.63.128.3 before test
Oct  3 21:04:01.969: INFO: calico-node-zrfj4 from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:01.969: INFO: 	Container calico-node ready: true, restart count 0
Oct  3 21:04:01.969: INFO: calico-typha-644fdcd5f-rskkx from kube-system started at 2022-10-03 20:20:28 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:01.969: INFO: 	Container calico-typha ready: true, restart count 0
Oct  3 21:04:01.969: INFO: ibm-keepalived-watcher-jr7cc from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:01.969: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  3 21:04:01.969: INFO: ibm-master-proxy-static-10.63.128.3 from kube-system started at 2022-10-03 17:10:52 +0000 UTC (2 container statuses recorded)
Oct  3 21:04:01.969: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct  3 21:04:01.969: INFO: 	Container pause ready: true, restart count 0
Oct  3 21:04:01.969: INFO: ibmcloud-block-storage-driver-j765w from kube-system started at 2022-10-03 17:11:13 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:01.969: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct  3 21:04:01.969: INFO: konnectivity-agent-n5jcf from kube-system started at 2022-10-03 17:19:17 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:01.969: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct  3 21:04:01.969: INFO: sonobuoy from sonobuoy started at 2022-10-03 19:13:32 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:01.969: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  3 21:04:01.969: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-lpx2r from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 21:04:01.969: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 21:04:01.969: INFO: 	Container systemd-logs ready: true, restart count 0
Oct  3 21:04:01.969: INFO: 
Logging pods the apiserver thinks is on node 10.63.128.51 before test
Oct  3 21:04:02.021: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-6mpp7 from ibm-system started at 2022-10-03 19:20:52 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
Oct  3 21:04:02.021: INFO: calico-kube-controllers-5ccfdf4b6d-qxssd from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct  3 21:04:02.021: INFO: calico-node-zfv55 from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container calico-node ready: true, restart count 0
Oct  3 21:04:02.021: INFO: calico-typha-644fdcd5f-7qcns from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container calico-typha ready: true, restart count 0
Oct  3 21:04:02.021: INFO: coredns-6754846f95-9q5kh from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container coredns ready: true, restart count 0
Oct  3 21:04:02.021: INFO: coredns-6754846f95-c7x4x from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container coredns ready: true, restart count 0
Oct  3 21:04:02.021: INFO: coredns-autoscaler-669cf746f6-wwqwh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container autoscaler ready: true, restart count 0
Oct  3 21:04:02.021: INFO: dashboard-metrics-scraper-c964d5594-bvc48 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Oct  3 21:04:02.021: INFO: ibm-file-plugin-bdf4f476-5nc82 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct  3 21:04:02.021: INFO: ibm-keepalived-watcher-8t2hv from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  3 21:04:02.021: INFO: ibm-master-proxy-static-10.63.128.51 from kube-system started at 2022-10-03 17:10:31 +0000 UTC (2 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct  3 21:04:02.021: INFO: 	Container pause ready: true, restart count 0
Oct  3 21:04:02.021: INFO: ibm-storage-watcher-64fb9cdcfc-bsg7k from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct  3 21:04:02.021: INFO: ibmcloud-block-storage-driver-fdv2t from kube-system started at 2022-10-03 17:10:51 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct  3 21:04:02.021: INFO: ibmcloud-block-storage-plugin-7c4cfb55cb-72zmh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Oct  3 21:04:02.021: INFO: konnectivity-agent-lc67p from kube-system started at 2022-10-03 17:19:14 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct  3 21:04:02.021: INFO: kubernetes-dashboard-55c4d56798-qwrbg from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct  3 21:04:02.021: INFO: metrics-server-668b4d7ddd-mpnsv from kube-system started at 2022-10-03 19:20:52 +0000 UTC (3 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container config-watcher ready: true, restart count 0
Oct  3 21:04:02.021: INFO: 	Container metrics-server ready: true, restart count 0
Oct  3 21:04:02.021: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct  3 21:04:02.021: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-cc7hf from kube-system started at 2022-10-03 20:20:26 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.021: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct  3 21:04:02.022: INFO: snapshot-controller-c5c6dddff-2mxr6 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.022: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct  3 21:04:02.022: INFO: snapshot-controller-c5c6dddff-m6kpt from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.022: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct  3 21:04:02.022: INFO: snapshot-controller-c5c6dddff-wjxf9 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
Oct  3 21:04:02.022: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct  3 21:04:02.022: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-z8psd from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
Oct  3 21:04:02.022: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  3 21:04:02.022: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node 10.63.128.13 10/03/22 21:04:02.121
STEP: verifying the node has the label node 10.63.128.3 10/03/22 21:04:02.25
STEP: verifying the node has the label node 10.63.128.51 10/03/22 21:04:02.3
Oct  3 21:04:02.359: INFO: Pod ibm-cloud-provider-ip-130-198-66-222-b8894768-5lm6l requesting resource cpu=5m on Node 10.63.128.13
Oct  3 21:04:02.359: INFO: Pod ibm-cloud-provider-ip-130-198-66-222-b8894768-6mpp7 requesting resource cpu=5m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod calico-kube-controllers-5ccfdf4b6d-qxssd requesting resource cpu=10m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod calico-node-zfv55 requesting resource cpu=250m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod calico-node-zpr9s requesting resource cpu=250m on Node 10.63.128.13
Oct  3 21:04:02.359: INFO: Pod calico-node-zrfj4 requesting resource cpu=250m on Node 10.63.128.3
Oct  3 21:04:02.359: INFO: Pod calico-typha-644fdcd5f-7qcns requesting resource cpu=250m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod calico-typha-644fdcd5f-rskkx requesting resource cpu=250m on Node 10.63.128.3
Oct  3 21:04:02.359: INFO: Pod calico-typha-644fdcd5f-w67fp requesting resource cpu=250m on Node 10.63.128.13
Oct  3 21:04:02.359: INFO: Pod coredns-6754846f95-9q5kh requesting resource cpu=100m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod coredns-6754846f95-bl2wt requesting resource cpu=100m on Node 10.63.128.13
Oct  3 21:04:02.359: INFO: Pod coredns-6754846f95-c7x4x requesting resource cpu=100m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod coredns-autoscaler-669cf746f6-wwqwh requesting resource cpu=1m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod dashboard-metrics-scraper-c964d5594-bvc48 requesting resource cpu=1m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod ibm-file-plugin-bdf4f476-5nc82 requesting resource cpu=50m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod ibm-keepalived-watcher-8t2hv requesting resource cpu=5m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod ibm-keepalived-watcher-jr7cc requesting resource cpu=5m on Node 10.63.128.3
Oct  3 21:04:02.359: INFO: Pod ibm-keepalived-watcher-nw2l6 requesting resource cpu=5m on Node 10.63.128.13
Oct  3 21:04:02.359: INFO: Pod ibm-master-proxy-static-10.63.128.13 requesting resource cpu=25m on Node 10.63.128.13
Oct  3 21:04:02.359: INFO: Pod ibm-master-proxy-static-10.63.128.3 requesting resource cpu=25m on Node 10.63.128.3
Oct  3 21:04:02.359: INFO: Pod ibm-master-proxy-static-10.63.128.51 requesting resource cpu=25m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod ibm-storage-watcher-64fb9cdcfc-bsg7k requesting resource cpu=50m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod ibmcloud-block-storage-driver-f5thb requesting resource cpu=50m on Node 10.63.128.13
Oct  3 21:04:02.359: INFO: Pod ibmcloud-block-storage-driver-fdv2t requesting resource cpu=50m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod ibmcloud-block-storage-driver-j765w requesting resource cpu=50m on Node 10.63.128.3
Oct  3 21:04:02.359: INFO: Pod ibmcloud-block-storage-plugin-7c4cfb55cb-72zmh requesting resource cpu=50m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod ingress-cluster-healthcheck-6dbd7f8d47-vx87x requesting resource cpu=10m on Node 10.63.128.13
Oct  3 21:04:02.359: INFO: Pod konnectivity-agent-lc67p requesting resource cpu=10m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod konnectivity-agent-n5jcf requesting resource cpu=10m on Node 10.63.128.3
Oct  3 21:04:02.359: INFO: Pod konnectivity-agent-qv9fn requesting resource cpu=10m on Node 10.63.128.13
Oct  3 21:04:02.359: INFO: Pod kubernetes-dashboard-55c4d56798-qwrbg requesting resource cpu=50m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod metrics-server-668b4d7ddd-7glct requesting resource cpu=126m on Node 10.63.128.13
Oct  3 21:04:02.359: INFO: Pod metrics-server-668b4d7ddd-mpnsv requesting resource cpu=126m on Node 10.63.128.51
Oct  3 21:04:02.359: INFO: Pod public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-7vk57 requesting resource cpu=10m on Node 10.63.128.13
Oct  3 21:04:02.360: INFO: Pod public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-cc7hf requesting resource cpu=10m on Node 10.63.128.51
Oct  3 21:04:02.360: INFO: Pod snapshot-controller-c5c6dddff-2mxr6 requesting resource cpu=10m on Node 10.63.128.51
Oct  3 21:04:02.360: INFO: Pod snapshot-controller-c5c6dddff-m6kpt requesting resource cpu=10m on Node 10.63.128.51
Oct  3 21:04:02.360: INFO: Pod snapshot-controller-c5c6dddff-wjxf9 requesting resource cpu=10m on Node 10.63.128.51
Oct  3 21:04:02.360: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.63.128.3
Oct  3 21:04:02.360: INFO: Pod sonobuoy-e2e-job-2c5abccdc00d487c requesting resource cpu=0m on Node 10.63.128.13
Oct  3 21:04:02.360: INFO: Pod sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-cwlqc requesting resource cpu=0m on Node 10.63.128.13
Oct  3 21:04:02.360: INFO: Pod sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-lpx2r requesting resource cpu=0m on Node 10.63.128.3
Oct  3 21:04:02.360: INFO: Pod sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-z8psd requesting resource cpu=0m on Node 10.63.128.51
STEP: Starting Pods to consume most of the cluster CPU. 10/03/22 21:04:02.36
Oct  3 21:04:02.360: INFO: Creating a pod which consumes cpu=2148m on Node 10.63.128.13
Oct  3 21:04:02.389: INFO: Creating a pod which consumes cpu=2324m on Node 10.63.128.3
Oct  3 21:04:02.405: INFO: Creating a pod which consumes cpu=1915m on Node 10.63.128.51
Oct  3 21:04:02.420: INFO: Waiting up to 5m0s for pod "filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed" in namespace "sched-pred-9649" to be "running"
Oct  3 21:04:02.443: INFO: Pod "filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed": Phase="Pending", Reason="", readiness=false. Elapsed: 22.462972ms
Oct  3 21:04:04.459: INFO: Pod "filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed": Phase="Running", Reason="", readiness=true. Elapsed: 2.038700394s
Oct  3 21:04:04.459: INFO: Pod "filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed" satisfied condition "running"
Oct  3 21:04:04.459: INFO: Waiting up to 5m0s for pod "filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92" in namespace "sched-pred-9649" to be "running"
Oct  3 21:04:04.473: INFO: Pod "filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92": Phase="Pending", Reason="", readiness=false. Elapsed: 13.002152ms
Oct  3 21:04:06.488: INFO: Pod "filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92": Phase="Running", Reason="", readiness=true. Elapsed: 2.027988367s
Oct  3 21:04:06.488: INFO: Pod "filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92" satisfied condition "running"
Oct  3 21:04:06.488: INFO: Waiting up to 5m0s for pod "filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793" in namespace "sched-pred-9649" to be "running"
Oct  3 21:04:06.511: INFO: Pod "filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793": Phase="Running", Reason="", readiness=true. Elapsed: 22.766566ms
Oct  3 21:04:06.511: INFO: Pod "filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 10/03/22 21:04:06.512
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793.171aab032f9321a0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9649/filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793 to 10.63.128.51] 10/03/22 21:04:06.526
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793.171aab037ac097fb], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 10/03/22 21:04:06.526
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793.171aab03802593c4], Reason = [Created], Message = [Created container filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793] 10/03/22 21:04:06.526
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793.171aab038f3977d4], Reason = [Started], Message = [Started container filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793] 10/03/22 21:04:06.526
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92.171aab032e2a7113], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9649/filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92 to 10.63.128.3] 10/03/22 21:04:06.526
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92.171aab0378156980], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 10/03/22 21:04:06.526
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92.171aab037bd0ecff], Reason = [Created], Message = [Created container filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92] 10/03/22 21:04:06.526
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92.171aab038a47df36], Reason = [Started], Message = [Started container filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92] 10/03/22 21:04:06.526
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed.171aab032d83424a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9649/filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed to 10.63.128.13] 10/03/22 21:04:06.527
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed.171aab0375d92e79], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 10/03/22 21:04:06.527
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed.171aab037a55beac], Reason = [Created], Message = [Created container filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed] 10/03/22 21:04:06.527
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed.171aab0388401788], Reason = [Started], Message = [Started container filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed] 10/03/22 21:04:06.527
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.171aab042479997c], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 10/03/22 21:04:06.564
STEP: removing the label node off the node 10.63.128.51 10/03/22 21:04:07.565
STEP: verifying the node doesn't have the label node 10/03/22 21:04:07.614
STEP: removing the label node off the node 10.63.128.13 10/03/22 21:04:07.628
STEP: verifying the node doesn't have the label node 10/03/22 21:04:07.677
STEP: removing the label node off the node 10.63.128.3 10/03/22 21:04:07.692
STEP: verifying the node doesn't have the label node 10/03/22 21:04:07.743
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Oct  3 21:04:07.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9649" for this suite. 10/03/22 21:04:07.776
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":358,"skipped":6633,"failed":0}
------------------------------
• [SLOW TEST] [6.064 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:04:01.739
    Oct  3 21:04:01.739: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename sched-pred 10/03/22 21:04:01.74
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:04:01.78
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:04:01.791
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Oct  3 21:04:01.804: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Oct  3 21:04:01.842: INFO: Waiting for terminating namespaces to be deleted...
    Oct  3 21:04:01.872: INFO: 
    Logging pods the apiserver thinks is on node 10.63.128.13 before test
    Oct  3 21:04:01.926: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-5lm6l from ibm-system started at 2022-10-03 17:16:04 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:01.927: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: calico-node-zpr9s from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:01.927: INFO: 	Container calico-node ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: calico-typha-644fdcd5f-w67fp from kube-system started at 2022-10-03 17:11:18 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:01.927: INFO: 	Container calico-typha ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: coredns-6754846f95-bl2wt from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:01.927: INFO: 	Container coredns ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: ibm-keepalived-watcher-nw2l6 from kube-system started at 2022-10-03 17:10:58 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:01.927: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: ibm-master-proxy-static-10.63.128.13 from kube-system started at 2022-10-03 17:10:55 +0000 UTC (2 container statuses recorded)
    Oct  3 21:04:01.927: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: 	Container pause ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: ibmcloud-block-storage-driver-f5thb from kube-system started at 2022-10-03 17:11:06 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:01.927: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: ingress-cluster-healthcheck-6dbd7f8d47-vx87x from kube-system started at 2022-10-03 18:44:30 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:01.927: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: konnectivity-agent-qv9fn from kube-system started at 2022-10-03 17:19:11 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:01.927: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: metrics-server-668b4d7ddd-7glct from kube-system started at 2022-10-03 17:55:22 +0000 UTC (3 container statuses recorded)
    Oct  3 21:04:01.927: INFO: 	Container config-watcher ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: 	Container metrics-server ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-7vk57 from kube-system started at 2022-10-03 19:52:24 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:01.927: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: sonobuoy-e2e-job-2c5abccdc00d487c from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 21:04:01.927: INFO: 	Container e2e ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-cwlqc from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 21:04:01.927: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct  3 21:04:01.927: INFO: 
    Logging pods the apiserver thinks is on node 10.63.128.3 before test
    Oct  3 21:04:01.969: INFO: calico-node-zrfj4 from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:01.969: INFO: 	Container calico-node ready: true, restart count 0
    Oct  3 21:04:01.969: INFO: calico-typha-644fdcd5f-rskkx from kube-system started at 2022-10-03 20:20:28 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:01.969: INFO: 	Container calico-typha ready: true, restart count 0
    Oct  3 21:04:01.969: INFO: ibm-keepalived-watcher-jr7cc from kube-system started at 2022-10-03 17:11:04 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:01.969: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct  3 21:04:01.969: INFO: ibm-master-proxy-static-10.63.128.3 from kube-system started at 2022-10-03 17:10:52 +0000 UTC (2 container statuses recorded)
    Oct  3 21:04:01.969: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct  3 21:04:01.969: INFO: 	Container pause ready: true, restart count 0
    Oct  3 21:04:01.969: INFO: ibmcloud-block-storage-driver-j765w from kube-system started at 2022-10-03 17:11:13 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:01.969: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct  3 21:04:01.969: INFO: konnectivity-agent-n5jcf from kube-system started at 2022-10-03 17:19:17 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:01.969: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct  3 21:04:01.969: INFO: sonobuoy from sonobuoy started at 2022-10-03 19:13:32 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:01.969: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Oct  3 21:04:01.969: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-lpx2r from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 21:04:01.969: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 21:04:01.969: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct  3 21:04:01.969: INFO: 
    Logging pods the apiserver thinks is on node 10.63.128.51 before test
    Oct  3 21:04:02.021: INFO: ibm-cloud-provider-ip-130-198-66-222-b8894768-6mpp7 from ibm-system started at 2022-10-03 19:20:52 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container ibm-cloud-provider-ip-130-198-66-222 ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: calico-kube-controllers-5ccfdf4b6d-qxssd from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: calico-node-zfv55 from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container calico-node ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: calico-typha-644fdcd5f-7qcns from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container calico-typha ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: coredns-6754846f95-9q5kh from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container coredns ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: coredns-6754846f95-c7x4x from kube-system started at 2022-10-03 17:19:48 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container coredns ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: coredns-autoscaler-669cf746f6-wwqwh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container autoscaler ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: dashboard-metrics-scraper-c964d5594-bvc48 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: ibm-file-plugin-bdf4f476-5nc82 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: ibm-keepalived-watcher-8t2hv from kube-system started at 2022-10-03 17:10:43 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: ibm-master-proxy-static-10.63.128.51 from kube-system started at 2022-10-03 17:10:31 +0000 UTC (2 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: 	Container pause ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: ibm-storage-watcher-64fb9cdcfc-bsg7k from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: ibmcloud-block-storage-driver-fdv2t from kube-system started at 2022-10-03 17:10:51 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: ibmcloud-block-storage-plugin-7c4cfb55cb-72zmh from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: konnectivity-agent-lc67p from kube-system started at 2022-10-03 17:19:14 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: kubernetes-dashboard-55c4d56798-qwrbg from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: metrics-server-668b4d7ddd-mpnsv from kube-system started at 2022-10-03 19:20:52 +0000 UTC (3 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container config-watcher ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: 	Container metrics-server ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct  3 21:04:02.021: INFO: public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-cc7hf from kube-system started at 2022-10-03 20:20:26 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.021: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct  3 21:04:02.022: INFO: snapshot-controller-c5c6dddff-2mxr6 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.022: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct  3 21:04:02.022: INFO: snapshot-controller-c5c6dddff-m6kpt from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.022: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct  3 21:04:02.022: INFO: snapshot-controller-c5c6dddff-wjxf9 from kube-system started at 2022-10-03 17:10:53 +0000 UTC (1 container statuses recorded)
    Oct  3 21:04:02.022: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct  3 21:04:02.022: INFO: sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-z8psd from sonobuoy started at 2022-10-03 19:13:41 +0000 UTC (2 container statuses recorded)
    Oct  3 21:04:02.022: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct  3 21:04:02.022: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node 10.63.128.13 10/03/22 21:04:02.121
    STEP: verifying the node has the label node 10.63.128.3 10/03/22 21:04:02.25
    STEP: verifying the node has the label node 10.63.128.51 10/03/22 21:04:02.3
    Oct  3 21:04:02.359: INFO: Pod ibm-cloud-provider-ip-130-198-66-222-b8894768-5lm6l requesting resource cpu=5m on Node 10.63.128.13
    Oct  3 21:04:02.359: INFO: Pod ibm-cloud-provider-ip-130-198-66-222-b8894768-6mpp7 requesting resource cpu=5m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod calico-kube-controllers-5ccfdf4b6d-qxssd requesting resource cpu=10m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod calico-node-zfv55 requesting resource cpu=250m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod calico-node-zpr9s requesting resource cpu=250m on Node 10.63.128.13
    Oct  3 21:04:02.359: INFO: Pod calico-node-zrfj4 requesting resource cpu=250m on Node 10.63.128.3
    Oct  3 21:04:02.359: INFO: Pod calico-typha-644fdcd5f-7qcns requesting resource cpu=250m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod calico-typha-644fdcd5f-rskkx requesting resource cpu=250m on Node 10.63.128.3
    Oct  3 21:04:02.359: INFO: Pod calico-typha-644fdcd5f-w67fp requesting resource cpu=250m on Node 10.63.128.13
    Oct  3 21:04:02.359: INFO: Pod coredns-6754846f95-9q5kh requesting resource cpu=100m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod coredns-6754846f95-bl2wt requesting resource cpu=100m on Node 10.63.128.13
    Oct  3 21:04:02.359: INFO: Pod coredns-6754846f95-c7x4x requesting resource cpu=100m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod coredns-autoscaler-669cf746f6-wwqwh requesting resource cpu=1m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod dashboard-metrics-scraper-c964d5594-bvc48 requesting resource cpu=1m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod ibm-file-plugin-bdf4f476-5nc82 requesting resource cpu=50m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod ibm-keepalived-watcher-8t2hv requesting resource cpu=5m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod ibm-keepalived-watcher-jr7cc requesting resource cpu=5m on Node 10.63.128.3
    Oct  3 21:04:02.359: INFO: Pod ibm-keepalived-watcher-nw2l6 requesting resource cpu=5m on Node 10.63.128.13
    Oct  3 21:04:02.359: INFO: Pod ibm-master-proxy-static-10.63.128.13 requesting resource cpu=25m on Node 10.63.128.13
    Oct  3 21:04:02.359: INFO: Pod ibm-master-proxy-static-10.63.128.3 requesting resource cpu=25m on Node 10.63.128.3
    Oct  3 21:04:02.359: INFO: Pod ibm-master-proxy-static-10.63.128.51 requesting resource cpu=25m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod ibm-storage-watcher-64fb9cdcfc-bsg7k requesting resource cpu=50m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod ibmcloud-block-storage-driver-f5thb requesting resource cpu=50m on Node 10.63.128.13
    Oct  3 21:04:02.359: INFO: Pod ibmcloud-block-storage-driver-fdv2t requesting resource cpu=50m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod ibmcloud-block-storage-driver-j765w requesting resource cpu=50m on Node 10.63.128.3
    Oct  3 21:04:02.359: INFO: Pod ibmcloud-block-storage-plugin-7c4cfb55cb-72zmh requesting resource cpu=50m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod ingress-cluster-healthcheck-6dbd7f8d47-vx87x requesting resource cpu=10m on Node 10.63.128.13
    Oct  3 21:04:02.359: INFO: Pod konnectivity-agent-lc67p requesting resource cpu=10m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod konnectivity-agent-n5jcf requesting resource cpu=10m on Node 10.63.128.3
    Oct  3 21:04:02.359: INFO: Pod konnectivity-agent-qv9fn requesting resource cpu=10m on Node 10.63.128.13
    Oct  3 21:04:02.359: INFO: Pod kubernetes-dashboard-55c4d56798-qwrbg requesting resource cpu=50m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod metrics-server-668b4d7ddd-7glct requesting resource cpu=126m on Node 10.63.128.13
    Oct  3 21:04:02.359: INFO: Pod metrics-server-668b4d7ddd-mpnsv requesting resource cpu=126m on Node 10.63.128.51
    Oct  3 21:04:02.359: INFO: Pod public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-7vk57 requesting resource cpu=10m on Node 10.63.128.13
    Oct  3 21:04:02.360: INFO: Pod public-crccth7mps0r4bub83p85g-alb1-6c89b64dc5-cc7hf requesting resource cpu=10m on Node 10.63.128.51
    Oct  3 21:04:02.360: INFO: Pod snapshot-controller-c5c6dddff-2mxr6 requesting resource cpu=10m on Node 10.63.128.51
    Oct  3 21:04:02.360: INFO: Pod snapshot-controller-c5c6dddff-m6kpt requesting resource cpu=10m on Node 10.63.128.51
    Oct  3 21:04:02.360: INFO: Pod snapshot-controller-c5c6dddff-wjxf9 requesting resource cpu=10m on Node 10.63.128.51
    Oct  3 21:04:02.360: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.63.128.3
    Oct  3 21:04:02.360: INFO: Pod sonobuoy-e2e-job-2c5abccdc00d487c requesting resource cpu=0m on Node 10.63.128.13
    Oct  3 21:04:02.360: INFO: Pod sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-cwlqc requesting resource cpu=0m on Node 10.63.128.13
    Oct  3 21:04:02.360: INFO: Pod sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-lpx2r requesting resource cpu=0m on Node 10.63.128.3
    Oct  3 21:04:02.360: INFO: Pod sonobuoy-systemd-logs-daemon-set-2054ca8ed5e847ba-z8psd requesting resource cpu=0m on Node 10.63.128.51
    STEP: Starting Pods to consume most of the cluster CPU. 10/03/22 21:04:02.36
    Oct  3 21:04:02.360: INFO: Creating a pod which consumes cpu=2148m on Node 10.63.128.13
    Oct  3 21:04:02.389: INFO: Creating a pod which consumes cpu=2324m on Node 10.63.128.3
    Oct  3 21:04:02.405: INFO: Creating a pod which consumes cpu=1915m on Node 10.63.128.51
    Oct  3 21:04:02.420: INFO: Waiting up to 5m0s for pod "filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed" in namespace "sched-pred-9649" to be "running"
    Oct  3 21:04:02.443: INFO: Pod "filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed": Phase="Pending", Reason="", readiness=false. Elapsed: 22.462972ms
    Oct  3 21:04:04.459: INFO: Pod "filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed": Phase="Running", Reason="", readiness=true. Elapsed: 2.038700394s
    Oct  3 21:04:04.459: INFO: Pod "filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed" satisfied condition "running"
    Oct  3 21:04:04.459: INFO: Waiting up to 5m0s for pod "filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92" in namespace "sched-pred-9649" to be "running"
    Oct  3 21:04:04.473: INFO: Pod "filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92": Phase="Pending", Reason="", readiness=false. Elapsed: 13.002152ms
    Oct  3 21:04:06.488: INFO: Pod "filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92": Phase="Running", Reason="", readiness=true. Elapsed: 2.027988367s
    Oct  3 21:04:06.488: INFO: Pod "filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92" satisfied condition "running"
    Oct  3 21:04:06.488: INFO: Waiting up to 5m0s for pod "filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793" in namespace "sched-pred-9649" to be "running"
    Oct  3 21:04:06.511: INFO: Pod "filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793": Phase="Running", Reason="", readiness=true. Elapsed: 22.766566ms
    Oct  3 21:04:06.511: INFO: Pod "filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 10/03/22 21:04:06.512
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793.171aab032f9321a0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9649/filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793 to 10.63.128.51] 10/03/22 21:04:06.526
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793.171aab037ac097fb], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 10/03/22 21:04:06.526
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793.171aab03802593c4], Reason = [Created], Message = [Created container filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793] 10/03/22 21:04:06.526
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793.171aab038f3977d4], Reason = [Started], Message = [Started container filler-pod-94a7e396-4a46-41bf-9897-ca65df9f6793] 10/03/22 21:04:06.526
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92.171aab032e2a7113], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9649/filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92 to 10.63.128.3] 10/03/22 21:04:06.526
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92.171aab0378156980], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 10/03/22 21:04:06.526
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92.171aab037bd0ecff], Reason = [Created], Message = [Created container filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92] 10/03/22 21:04:06.526
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92.171aab038a47df36], Reason = [Started], Message = [Started container filler-pod-a7f998f7-683b-45f0-bee9-5c941f645f92] 10/03/22 21:04:06.526
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed.171aab032d83424a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9649/filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed to 10.63.128.13] 10/03/22 21:04:06.527
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed.171aab0375d92e79], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 10/03/22 21:04:06.527
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed.171aab037a55beac], Reason = [Created], Message = [Created container filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed] 10/03/22 21:04:06.527
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed.171aab0388401788], Reason = [Started], Message = [Started container filler-pod-ddaf8ae3-2784-48a2-a1d1-6630b658aaed] 10/03/22 21:04:06.527
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.171aab042479997c], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 10/03/22 21:04:06.564
    STEP: removing the label node off the node 10.63.128.51 10/03/22 21:04:07.565
    STEP: verifying the node doesn't have the label node 10/03/22 21:04:07.614
    STEP: removing the label node off the node 10.63.128.13 10/03/22 21:04:07.628
    STEP: verifying the node doesn't have the label node 10/03/22 21:04:07.677
    STEP: removing the label node off the node 10.63.128.3 10/03/22 21:04:07.692
    STEP: verifying the node doesn't have the label node 10/03/22 21:04:07.743
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Oct  3 21:04:07.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-9649" for this suite. 10/03/22 21:04:07.776
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:04:07.803
Oct  3 21:04:07.803: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir 10/03/22 21:04:07.805
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:04:07.847
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:04:07.858
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 10/03/22 21:04:07.87
Oct  3 21:04:07.902: INFO: Waiting up to 5m0s for pod "pod-68346bfd-c897-4148-8e9a-c38c4befa6b1" in namespace "emptydir-1458" to be "Succeeded or Failed"
Oct  3 21:04:07.924: INFO: Pod "pod-68346bfd-c897-4148-8e9a-c38c4befa6b1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.416052ms
Oct  3 21:04:09.942: INFO: Pod "pod-68346bfd-c897-4148-8e9a-c38c4befa6b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040412649s
Oct  3 21:04:11.941: INFO: Pod "pod-68346bfd-c897-4148-8e9a-c38c4befa6b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039379357s
Oct  3 21:04:13.952: INFO: Pod "pod-68346bfd-c897-4148-8e9a-c38c4befa6b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.050414462s
STEP: Saw pod success 10/03/22 21:04:13.952
Oct  3 21:04:13.952: INFO: Pod "pod-68346bfd-c897-4148-8e9a-c38c4befa6b1" satisfied condition "Succeeded or Failed"
Oct  3 21:04:13.967: INFO: Trying to get logs from node 10.63.128.3 pod pod-68346bfd-c897-4148-8e9a-c38c4befa6b1 container test-container: <nil>
STEP: delete the pod 10/03/22 21:04:14.045
Oct  3 21:04:14.093: INFO: Waiting for pod pod-68346bfd-c897-4148-8e9a-c38c4befa6b1 to disappear
Oct  3 21:04:14.106: INFO: Pod pod-68346bfd-c897-4148-8e9a-c38c4befa6b1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Oct  3 21:04:14.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1458" for this suite. 10/03/22 21:04:14.128
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":359,"skipped":6635,"failed":0}
------------------------------
• [SLOW TEST] [6.353 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:04:07.803
    Oct  3 21:04:07.803: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir 10/03/22 21:04:07.805
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:04:07.847
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:04:07.858
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 10/03/22 21:04:07.87
    Oct  3 21:04:07.902: INFO: Waiting up to 5m0s for pod "pod-68346bfd-c897-4148-8e9a-c38c4befa6b1" in namespace "emptydir-1458" to be "Succeeded or Failed"
    Oct  3 21:04:07.924: INFO: Pod "pod-68346bfd-c897-4148-8e9a-c38c4befa6b1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.416052ms
    Oct  3 21:04:09.942: INFO: Pod "pod-68346bfd-c897-4148-8e9a-c38c4befa6b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040412649s
    Oct  3 21:04:11.941: INFO: Pod "pod-68346bfd-c897-4148-8e9a-c38c4befa6b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039379357s
    Oct  3 21:04:13.952: INFO: Pod "pod-68346bfd-c897-4148-8e9a-c38c4befa6b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.050414462s
    STEP: Saw pod success 10/03/22 21:04:13.952
    Oct  3 21:04:13.952: INFO: Pod "pod-68346bfd-c897-4148-8e9a-c38c4befa6b1" satisfied condition "Succeeded or Failed"
    Oct  3 21:04:13.967: INFO: Trying to get logs from node 10.63.128.3 pod pod-68346bfd-c897-4148-8e9a-c38c4befa6b1 container test-container: <nil>
    STEP: delete the pod 10/03/22 21:04:14.045
    Oct  3 21:04:14.093: INFO: Waiting for pod pod-68346bfd-c897-4148-8e9a-c38c4befa6b1 to disappear
    Oct  3 21:04:14.106: INFO: Pod pod-68346bfd-c897-4148-8e9a-c38c4befa6b1 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Oct  3 21:04:14.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1458" for this suite. 10/03/22 21:04:14.128
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:04:14.157
Oct  3 21:04:14.157: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename emptydir 10/03/22 21:04:14.159
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:04:14.206
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:04:14.217
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 10/03/22 21:04:14.229
Oct  3 21:04:14.261: INFO: Waiting up to 5m0s for pod "pod-f781ca2e-7299-44ca-b89c-055b2fc39f52" in namespace "emptydir-8883" to be "Succeeded or Failed"
Oct  3 21:04:14.279: INFO: Pod "pod-f781ca2e-7299-44ca-b89c-055b2fc39f52": Phase="Pending", Reason="", readiness=false. Elapsed: 18.669417ms
Oct  3 21:04:16.294: INFO: Pod "pod-f781ca2e-7299-44ca-b89c-055b2fc39f52": Phase="Running", Reason="", readiness=true. Elapsed: 2.033248758s
Oct  3 21:04:18.294: INFO: Pod "pod-f781ca2e-7299-44ca-b89c-055b2fc39f52": Phase="Running", Reason="", readiness=false. Elapsed: 4.032953673s
Oct  3 21:04:20.296: INFO: Pod "pod-f781ca2e-7299-44ca-b89c-055b2fc39f52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035187161s
STEP: Saw pod success 10/03/22 21:04:20.296
Oct  3 21:04:20.296: INFO: Pod "pod-f781ca2e-7299-44ca-b89c-055b2fc39f52" satisfied condition "Succeeded or Failed"
Oct  3 21:04:20.311: INFO: Trying to get logs from node 10.63.128.3 pod pod-f781ca2e-7299-44ca-b89c-055b2fc39f52 container test-container: <nil>
STEP: delete the pod 10/03/22 21:04:20.346
Oct  3 21:04:20.389: INFO: Waiting for pod pod-f781ca2e-7299-44ca-b89c-055b2fc39f52 to disappear
Oct  3 21:04:20.402: INFO: Pod pod-f781ca2e-7299-44ca-b89c-055b2fc39f52 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Oct  3 21:04:20.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8883" for this suite. 10/03/22 21:04:20.421
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":360,"skipped":6642,"failed":0}
------------------------------
• [SLOW TEST] [6.289 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:04:14.157
    Oct  3 21:04:14.157: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename emptydir 10/03/22 21:04:14.159
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:04:14.206
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:04:14.217
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 10/03/22 21:04:14.229
    Oct  3 21:04:14.261: INFO: Waiting up to 5m0s for pod "pod-f781ca2e-7299-44ca-b89c-055b2fc39f52" in namespace "emptydir-8883" to be "Succeeded or Failed"
    Oct  3 21:04:14.279: INFO: Pod "pod-f781ca2e-7299-44ca-b89c-055b2fc39f52": Phase="Pending", Reason="", readiness=false. Elapsed: 18.669417ms
    Oct  3 21:04:16.294: INFO: Pod "pod-f781ca2e-7299-44ca-b89c-055b2fc39f52": Phase="Running", Reason="", readiness=true. Elapsed: 2.033248758s
    Oct  3 21:04:18.294: INFO: Pod "pod-f781ca2e-7299-44ca-b89c-055b2fc39f52": Phase="Running", Reason="", readiness=false. Elapsed: 4.032953673s
    Oct  3 21:04:20.296: INFO: Pod "pod-f781ca2e-7299-44ca-b89c-055b2fc39f52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035187161s
    STEP: Saw pod success 10/03/22 21:04:20.296
    Oct  3 21:04:20.296: INFO: Pod "pod-f781ca2e-7299-44ca-b89c-055b2fc39f52" satisfied condition "Succeeded or Failed"
    Oct  3 21:04:20.311: INFO: Trying to get logs from node 10.63.128.3 pod pod-f781ca2e-7299-44ca-b89c-055b2fc39f52 container test-container: <nil>
    STEP: delete the pod 10/03/22 21:04:20.346
    Oct  3 21:04:20.389: INFO: Waiting for pod pod-f781ca2e-7299-44ca-b89c-055b2fc39f52 to disappear
    Oct  3 21:04:20.402: INFO: Pod pod-f781ca2e-7299-44ca-b89c-055b2fc39f52 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Oct  3 21:04:20.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8883" for this suite. 10/03/22 21:04:20.421
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:04:20.455
Oct  3 21:04:20.455: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename projected 10/03/22 21:04:20.456
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:04:20.503
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:04:20.514
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-9e9e6f36-ef48-4fa8-9732-760d5284cc7a 10/03/22 21:04:20.545
STEP: Creating secret with name s-test-opt-upd-5364f7ef-1a04-4282-b730-ae4ede46eceb 10/03/22 21:04:20.561
STEP: Creating the pod 10/03/22 21:04:20.577
Oct  3 21:04:20.606: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24" in namespace "projected-1168" to be "running and ready"
Oct  3 21:04:20.620: INFO: Pod "pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24": Phase="Pending", Reason="", readiness=false. Elapsed: 13.533803ms
Oct  3 21:04:20.620: INFO: The phase of Pod pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 21:04:22.635: INFO: Pod "pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028830142s
Oct  3 21:04:22.636: INFO: The phase of Pod pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24 is Pending, waiting for it to be Running (with Ready = true)
Oct  3 21:04:24.634: INFO: Pod "pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24": Phase="Running", Reason="", readiness=true. Elapsed: 4.027694903s
Oct  3 21:04:24.635: INFO: The phase of Pod pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24 is Running (Ready = true)
Oct  3 21:04:24.635: INFO: Pod "pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-9e9e6f36-ef48-4fa8-9732-760d5284cc7a 10/03/22 21:04:24.743
STEP: Updating secret s-test-opt-upd-5364f7ef-1a04-4282-b730-ae4ede46eceb 10/03/22 21:04:24.765
STEP: Creating secret with name s-test-opt-create-2c5a0700-b4e2-407e-8185-e6b872f8c14f 10/03/22 21:04:24.779
STEP: waiting to observe update in volume 10/03/22 21:04:24.795
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Oct  3 21:05:52.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1168" for this suite. 10/03/22 21:05:52.37
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":361,"skipped":6679,"failed":0}
------------------------------
• [SLOW TEST] [91.941 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:04:20.455
    Oct  3 21:04:20.455: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename projected 10/03/22 21:04:20.456
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:04:20.503
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:04:20.514
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-9e9e6f36-ef48-4fa8-9732-760d5284cc7a 10/03/22 21:04:20.545
    STEP: Creating secret with name s-test-opt-upd-5364f7ef-1a04-4282-b730-ae4ede46eceb 10/03/22 21:04:20.561
    STEP: Creating the pod 10/03/22 21:04:20.577
    Oct  3 21:04:20.606: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24" in namespace "projected-1168" to be "running and ready"
    Oct  3 21:04:20.620: INFO: Pod "pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24": Phase="Pending", Reason="", readiness=false. Elapsed: 13.533803ms
    Oct  3 21:04:20.620: INFO: The phase of Pod pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 21:04:22.635: INFO: Pod "pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028830142s
    Oct  3 21:04:22.636: INFO: The phase of Pod pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24 is Pending, waiting for it to be Running (with Ready = true)
    Oct  3 21:04:24.634: INFO: Pod "pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24": Phase="Running", Reason="", readiness=true. Elapsed: 4.027694903s
    Oct  3 21:04:24.635: INFO: The phase of Pod pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24 is Running (Ready = true)
    Oct  3 21:04:24.635: INFO: Pod "pod-projected-secrets-67368cca-b6bc-4af8-83bc-ebba63851e24" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-9e9e6f36-ef48-4fa8-9732-760d5284cc7a 10/03/22 21:04:24.743
    STEP: Updating secret s-test-opt-upd-5364f7ef-1a04-4282-b730-ae4ede46eceb 10/03/22 21:04:24.765
    STEP: Creating secret with name s-test-opt-create-2c5a0700-b4e2-407e-8185-e6b872f8c14f 10/03/22 21:04:24.779
    STEP: waiting to observe update in volume 10/03/22 21:04:24.795
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Oct  3 21:05:52.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1168" for this suite. 10/03/22 21:05:52.37
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 10/03/22 21:05:52.4
Oct  3 21:05:52.400: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
STEP: Building a namespace api object, basename downward-api 10/03/22 21:05:52.401
STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:05:52.442
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:05:52.448
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 10/03/22 21:05:52.454
Oct  3 21:05:52.473: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510" in namespace "downward-api-4270" to be "Succeeded or Failed"
Oct  3 21:05:52.481: INFO: Pod "downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510": Phase="Pending", Reason="", readiness=false. Elapsed: 7.877171ms
Oct  3 21:05:54.491: INFO: Pod "downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017594946s
Oct  3 21:05:56.492: INFO: Pod "downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018531952s
Oct  3 21:05:58.491: INFO: Pod "downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017625969s
STEP: Saw pod success 10/03/22 21:05:58.491
Oct  3 21:05:58.491: INFO: Pod "downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510" satisfied condition "Succeeded or Failed"
Oct  3 21:05:58.499: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510 container client-container: <nil>
STEP: delete the pod 10/03/22 21:05:58.592
Oct  3 21:05:58.622: INFO: Waiting for pod downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510 to disappear
Oct  3 21:05:58.631: INFO: Pod downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Oct  3 21:05:58.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4270" for this suite. 10/03/22 21:05:58.645
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":362,"skipped":6685,"failed":0}
------------------------------
• [SLOW TEST] [6.262 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 10/03/22 21:05:52.4
    Oct  3 21:05:52.400: INFO: >>> kubeConfig: /tmp/kubeconfig-4105927341
    STEP: Building a namespace api object, basename downward-api 10/03/22 21:05:52.401
    STEP: Waiting for a default service account to be provisioned in namespace 10/03/22 21:05:52.442
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/03/22 21:05:52.448
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 10/03/22 21:05:52.454
    Oct  3 21:05:52.473: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510" in namespace "downward-api-4270" to be "Succeeded or Failed"
    Oct  3 21:05:52.481: INFO: Pod "downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510": Phase="Pending", Reason="", readiness=false. Elapsed: 7.877171ms
    Oct  3 21:05:54.491: INFO: Pod "downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017594946s
    Oct  3 21:05:56.492: INFO: Pod "downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018531952s
    Oct  3 21:05:58.491: INFO: Pod "downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017625969s
    STEP: Saw pod success 10/03/22 21:05:58.491
    Oct  3 21:05:58.491: INFO: Pod "downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510" satisfied condition "Succeeded or Failed"
    Oct  3 21:05:58.499: INFO: Trying to get logs from node 10.63.128.3 pod downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510 container client-container: <nil>
    STEP: delete the pod 10/03/22 21:05:58.592
    Oct  3 21:05:58.622: INFO: Waiting for pod downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510 to disappear
    Oct  3 21:05:58.631: INFO: Pod downwardapi-volume-f56eba80-0e7c-498c-94df-3454a2d40510 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Oct  3 21:05:58.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4270" for this suite. 10/03/22 21:05:58.645
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6705,"failed":0}
Oct  3 21:05:58.668: INFO: Running AfterSuite actions on all nodes
Oct  3 21:05:58.668: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Oct  3 21:05:58.668: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Oct  3 21:05:58.668: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Oct  3 21:05:58.668: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Oct  3 21:05:58.669: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Oct  3 21:05:58.669: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Oct  3 21:05:58.669: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Oct  3 21:05:58.669: INFO: Running AfterSuite actions on node 1
Oct  3 21:05:58.669: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.001 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Oct  3 21:05:58.668: INFO: Running AfterSuite actions on all nodes
    Oct  3 21:05:58.668: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Oct  3 21:05:58.668: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Oct  3 21:05:58.668: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Oct  3 21:05:58.668: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Oct  3 21:05:58.669: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Oct  3 21:05:58.669: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Oct  3 21:05:58.669: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Oct  3 21:05:58.669: INFO: Running AfterSuite actions on node 1
    Oct  3 21:05:58.669: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.097 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7067 Specs in 6723.209 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6705 Skipped
PASS

Ginkgo ran 1 suite in 1h52m3.756870526s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m

